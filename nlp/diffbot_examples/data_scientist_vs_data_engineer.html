<!-- some code adapted from www.degeneratestate.org/static/metal_lyrics/metal_line.html -->
<!-- <!DOCTYPE html>
<meta content="utf-8"> -->
<style> /* set the CSS */

body {
  font: 12px Arial;
}

svg {
  font: 12px Helvetica;
}

path {
  stroke: steelblue;
  stroke-width: 2;
  fill: none;
}

.grid line {
  stroke: lightgrey;
  stroke-opacity: 0.4;
  shape-rendering: crispEdges;
}

.grid path {
  stroke-width: 0;
}

.axis path,
.axis lineper {
  fill: none;
  stroke: grey;
  stroke-width: 1;
  shape-rendering: crispEdges;
}

div.tooltip {
  position: absolute;
  text-align: center;
  width: 150px;
  height: 28px;
  padding: 2px;
  font: 12px sans-serif;
  background: lightsteelblue;
  border: 0px;
  border-radius: 8px;
  pointer-events: none;
}

div.tooltipscore {
  position: absolute;
  text-align: center;
  width: 150px;
  height: 50px;
  padding: 2px;
  font: 10px sans-serif;
  background: lightsteelblue;
  border: 0px;
  border-radius: 8px;
  pointer-events: none;
}

.category_header {
  font: 12px sans-serif;
  font-weight: bolder;
  text-decoration: underline;
}

div.label {
  color: rgb(252, 251, 253);
  color: rgb(63, 0, 125);
  color: rgb(158, 155, 201);

  position: absolute;
  text-align: left;
  padding: 1px;
  border-spacing: 1px;
  font: 10px sans-serif;
  font-family: Sans-Serif;
  border: 0;
  pointer-events: none;
}
/*
input {
  border: 1px dotted #ccc;
  background: white;
  font-family: monospace;
  padding: 10px 20px;
  font-size: 14px;
  margin: 20px 10px 30px 0;
  color: darkred;
}*/

.alert {
  font-family: monospace;
  padding: 10px 20px;
  font-size: 14px;
  margin: 20px 10px 30px 0;
  color: darkred;
}

ul.top_terms li {
  padding-right: 20px;
  font-size: 30pt;
  color: red;
}
/*
input:focus {
  background-color: lightyellow;
  outline: none;
}*/

.snippet {
  padding-bottom: 10px;
  padding-left: 5px;
  padding-right: 5px;
  white-space: pre-wrap;
}

.snippet_header {
  font-size: 20px;
  font-family: Helvetica, Arial, Sans-Serif;
  font-weight: bolder;
  #text-decoration: underline;
  text-align: center;
  border-bottom-width: 10px;
  border-bottom-color: #888888;
  padding-bottom: 10px;
}

.topic_preview {
  font-size: 12px;
  font-family: Helvetica, Arial, Sans-Serif;
  text-align: center;
  padding-bottom: 10px;
  font-weight: normal;
  text-decoration: none;
}


#d3-div-1-categoryinfo {
  font-size: 12px;
  font-family: Helvetica, Arial, Sans-Serif;
  text-align: center;
  padding-bottom: 10px;    

}


#d3-div-1-title-div {
  font-size: 20px;
  font-family: Helvetica, Arial, Sans-Serif;
  text-align: center;
}

.text_header {
  font: 18px sans-serif;
  font-size: 18px;
  font-family: Helvetica, Arial, Sans-Serif;

  font-weight: bolder;
  text-decoration: underline;
  text-align: center;
  color: darkblue;
  padding-bottom: 10px;
}

.text_subheader {
  font-size: 14px;
  font-family: Helvetica, Arial, Sans-Serif;

  text-align: center;
}

.snippet_meta {
  border-top: 3px solid #4588ba;
  font-size: 12px;
  font-family: Helvetica, Arial, Sans-Serif;
  color: darkblue;
}

.not_match {
    background-color: #F0F8FF;
}
    
.contexts {
  width: 45%;
  float: left;
}

.neut_display {
  display: none;
  float: left
}

.scattertext {
  font-size: 10px;
  font-family: Helvetica, Arial, Sans-Serif;
}

.label {
  font-size: 10px;
  font-family: Helvetica, Arial, Sans-Serif;
}

.obscured {
  /*font-size: 14px;
  font-weight: normal;
  color: dimgrey;
  font-family: Helvetica;*/
  text-align: center;
}

.small_label {
  font-size: 10px;
}

#d3-div-1-corpus-stats {
  text-align: center;
}

#d3-div-1-cat {
}

#d3-div-1-notcat {
}

#d3-div-1-neut {
}

#d3-div-1-neutcol {
  display: none;
}
/* Adapted from https://www.w3schools.com/howto/tryit.asp?filename=tryhow_js_autocomplete */

.autocomplete {
  position: relative;
  display: inline-block;
}

input {
  border: 1px solid transparent;
  background-color: #f1f1f1;
  padding: 10px;
  font-size: 16px;
}

input[type=text] {
  background-color: #f1f1f1;
  width: 100%;
}

input[type=submit] {
  background-color: DodgerBlue;
  color: #fff;
  cursor: pointer;
}

.autocomplete-items {
  position: absolute;
  border: 2px solid #d4d4d4;
  border-bottom: none;
  border-top: none;
  z-index: 99;
  /*position the autocomplete items to be the same width as the container:*/
  top: 100%;
  left: 0;
  right: 0;
}

.autocomplete-items div {
  padding: 10px;
  cursor: pointer;
  background-color: #fff;
  border-bottom: 2px solid #d4d4d4;
}

/*when hovering an item:*/
.autocomplete-items div:hover {
  background-color: #e9e9e9;
}

/*when navigating through the items using the arrow keys:*/
.autocomplete-active {
  background-color: DodgerBlue !important;
  color: #ffffff;
}
</style>

<script src="https://cdnjs.cloudflare.com/ajax/libs/d3/4.6.0/d3.min.js" charset="utf-8"></script>
<script src="https://d3js.org/d3-scale-chromatic.v1.min.js" charset="utf-8"></script>

<!-- INSERT SEMIOTIC SQUARE -->
<!--<a onclick="maxFreq = Math.log(data.map(d => d.cat + d.ncat).reduce((a,b) => Math.max(a,b))); plotInterface.redrawPoints(0.1, d => (Math.log(d.ncat + d.cat)/maxFreq), d => d.s, false); plotInterface.redrawPoints(0.1, d => (Math.log(d.ncat + d.cat)/maxFreq), d => d.s, true)">View Score Plot</a>-->
<span id="d3-div-1-title-div"></span>
<div class="scattertext" id="d3-div-1" style="float: left"></div>
<div style="floag: left;">
    <div autocomplete="off">
        <div class="autocomplete">
            <input id="searchInput" type="text" placeholder="Search the chart">
        </div>
    </div>
</div>
<br/>
<div id="d3-div-1-corpus-stats"></div>
<div id="d3-div-1-overlapped-terms"></div>
<a name="d3-div-1-snippets"></a>
<a name="d3-div-1-snippetsalt"></a>
<div id="d3-div-1-termstats"></div>
<div id="d3-div-1-overlapped-terms-clicked"></div>
<div id="d3-div-1-categoryinfo" style="display: hidden"></div>
<div id="d3-div-2">
  <div class="d3-div-1-contexts">
    <div class="snippet_header" id="d3-div-1-cathead"></div>
    <div class="snippet" id="d3-div-1-cat"></div>
  </div>
  <div id="d3-div-1-notcol" class="d3-div-1-contexts">
    <div class="snippet_header" id="d3-div-1-notcathead"></div>
    <div class="snippet" id="d3-div-1-notcat"></div>
  </div>
  <div id="d3-div-1-neutcol" class="d3-div-1-contexts">
    <div class="snippet_header" id="d3-div-1-neuthead"></div>
    <div class="snippet" id="d3-div-1-neut"></div>
  </div>
</div>
<script charset="utf-8">
    // Created using Cozy: github.com/uwplse/cozy
function Rectangle(ax1, ay1, ax2, ay2) {
    this.ax1 = ax1;
    this.ay1 = ay1;
    this.ax2 = ax2;
    this.ay2 = ay2;
    this._left7 = undefined;
    this._right8 = undefined;
    this._parent9 = undefined;
    this._min_ax12 = undefined;
    this._min_ay13 = undefined;
    this._max_ay24 = undefined;
    this._height10 = undefined;
}
function RectangleHolder() {
    this.my_size = 0;
    (this)._root1 = null;
}
RectangleHolder.prototype.size = function () {
    return this.my_size;
};
RectangleHolder.prototype.add = function (x) {
    ++this.my_size;
    var _idx69 = (x).ax2;
    (x)._left7 = null;
    (x)._right8 = null;
    (x)._min_ax12 = (x).ax1;
    (x)._min_ay13 = (x).ay1;
    (x)._max_ay24 = (x).ay2;
    (x)._height10 = 0;
    var _previous70 = null;
    var _current71 = (this)._root1;
    var _is_left72 = false;
    while (!((_current71) == null)) {
        _previous70 = _current71;
        if ((_idx69) < ((_current71).ax2)) {
            _current71 = (_current71)._left7;
            _is_left72 = true;
        } else {
            _current71 = (_current71)._right8;
            _is_left72 = false;
        }
    }
    if ((_previous70) == null) {
        (this)._root1 = x;
    } else {
        (x)._parent9 = _previous70;
        if (_is_left72) {
            (_previous70)._left7 = x;
        } else {
            (_previous70)._right8 = x;
        }
    }
    var _cursor73 = (x)._parent9;
    var _changed74 = true;
    while ((_changed74) && (!((_cursor73) == (null)))) {
        var _old__min_ax1275 = (_cursor73)._min_ax12;
        var _old__min_ay1376 = (_cursor73)._min_ay13;
        var _old__max_ay2477 = (_cursor73)._max_ay24;
        var _old_height78 = (_cursor73)._height10;
        /* _min_ax12 is min of ax1 */
        var _augval79 = (_cursor73).ax1;
        var _child80 = (_cursor73)._left7;
        if (!((_child80) == null)) {
            var _val81 = (_child80)._min_ax12;
            _augval79 = ((_augval79) < (_val81)) ? (_augval79) : (_val81);
        }
        var _child82 = (_cursor73)._right8;
        if (!((_child82) == null)) {
            var _val83 = (_child82)._min_ax12;
            _augval79 = ((_augval79) < (_val83)) ? (_augval79) : (_val83);
        }
        (_cursor73)._min_ax12 = _augval79;
        /* _min_ay13 is min of ay1 */
        var _augval84 = (_cursor73).ay1;
        var _child85 = (_cursor73)._left7;
        if (!((_child85) == null)) {
            var _val86 = (_child85)._min_ay13;
            _augval84 = ((_augval84) < (_val86)) ? (_augval84) : (_val86);
        }
        var _child87 = (_cursor73)._right8;
        if (!((_child87) == null)) {
            var _val88 = (_child87)._min_ay13;
            _augval84 = ((_augval84) < (_val88)) ? (_augval84) : (_val88);
        }
        (_cursor73)._min_ay13 = _augval84;
        /* _max_ay24 is max of ay2 */
        var _augval89 = (_cursor73).ay2;
        var _child90 = (_cursor73)._left7;
        if (!((_child90) == null)) {
            var _val91 = (_child90)._max_ay24;
            _augval89 = ((_augval89) < (_val91)) ? (_val91) : (_augval89);
        }
        var _child92 = (_cursor73)._right8;
        if (!((_child92) == null)) {
            var _val93 = (_child92)._max_ay24;
            _augval89 = ((_augval89) < (_val93)) ? (_val93) : (_augval89);
        }
        (_cursor73)._max_ay24 = _augval89;
        (_cursor73)._height10 = 1 + ((((((_cursor73)._left7) == null) ? (-1) : (((_cursor73)._left7)._height10)) > ((((_cursor73)._right8) == null) ? (-1) : (((_cursor73)._right8)._height10))) ? ((((_cursor73)._left7) == null) ? (-1) : (((_cursor73)._left7)._height10)) : ((((_cursor73)._right8) == null) ? (-1) : (((_cursor73)._right8)._height10)));
        _changed74 = false;
        _changed74 = (_changed74) || (!((_old__min_ax1275) == ((_cursor73)._min_ax12)));
        _changed74 = (_changed74) || (!((_old__min_ay1376) == ((_cursor73)._min_ay13)));
        _changed74 = (_changed74) || (!((_old__max_ay2477) == ((_cursor73)._max_ay24)));
        _changed74 = (_changed74) || (!((_old_height78) == ((_cursor73)._height10)));
        _cursor73 = (_cursor73)._parent9;
    }
    /* rebalance AVL tree */
    var _cursor94 = x;
    var _imbalance95;
    while (!(((_cursor94)._parent9) == null)) {
        _cursor94 = (_cursor94)._parent9;
        (_cursor94)._height10 = 1 + ((((((_cursor94)._left7) == null) ? (-1) : (((_cursor94)._left7)._height10)) > ((((_cursor94)._right8) == null) ? (-1) : (((_cursor94)._right8)._height10))) ? ((((_cursor94)._left7) == null) ? (-1) : (((_cursor94)._left7)._height10)) : ((((_cursor94)._right8) == null) ? (-1) : (((_cursor94)._right8)._height10)));
        _imbalance95 = ((((_cursor94)._left7) == null) ? (-1) : (((_cursor94)._left7)._height10)) - ((((_cursor94)._right8) == null) ? (-1) : (((_cursor94)._right8)._height10));
        if ((_imbalance95) > (1)) {
            if ((((((_cursor94)._left7)._left7) == null) ? (-1) : ((((_cursor94)._left7)._left7)._height10)) < (((((_cursor94)._left7)._right8) == null) ? (-1) : ((((_cursor94)._left7)._right8)._height10))) {
                /* rotate ((_cursor94)._left7)._right8 */
                var _a96 = (_cursor94)._left7;
                var _b97 = (_a96)._right8;
                var _c98 = (_b97)._left7;
                /* replace _a96 with _b97 in (_a96)._parent9 */
                if (!(((_a96)._parent9) == null)) {
                    if ((((_a96)._parent9)._left7) == (_a96)) {
                        ((_a96)._parent9)._left7 = _b97;
                    } else {
                        ((_a96)._parent9)._right8 = _b97;
                    }
                }
                if (!((_b97) == null)) {
                    (_b97)._parent9 = (_a96)._parent9;
                }
                /* replace _c98 with _a96 in _b97 */
                (_b97)._left7 = _a96;
                if (!((_a96) == null)) {
                    (_a96)._parent9 = _b97;
                }
                /* replace _b97 with _c98 in _a96 */
                (_a96)._right8 = _c98;
                if (!((_c98) == null)) {
                    (_c98)._parent9 = _a96;
                }
                /* _min_ax12 is min of ax1 */
                var _augval99 = (_a96).ax1;
                var _child100 = (_a96)._left7;
                if (!((_child100) == null)) {
                    var _val101 = (_child100)._min_ax12;
                    _augval99 = ((_augval99) < (_val101)) ? (_augval99) : (_val101);
                }
                var _child102 = (_a96)._right8;
                if (!((_child102) == null)) {
                    var _val103 = (_child102)._min_ax12;
                    _augval99 = ((_augval99) < (_val103)) ? (_augval99) : (_val103);
                }
                (_a96)._min_ax12 = _augval99;
                /* _min_ay13 is min of ay1 */
                var _augval104 = (_a96).ay1;
                var _child105 = (_a96)._left7;
                if (!((_child105) == null)) {
                    var _val106 = (_child105)._min_ay13;
                    _augval104 = ((_augval104) < (_val106)) ? (_augval104) : (_val106);
                }
                var _child107 = (_a96)._right8;
                if (!((_child107) == null)) {
                    var _val108 = (_child107)._min_ay13;
                    _augval104 = ((_augval104) < (_val108)) ? (_augval104) : (_val108);
                }
                (_a96)._min_ay13 = _augval104;
                /* _max_ay24 is max of ay2 */
                var _augval109 = (_a96).ay2;
                var _child110 = (_a96)._left7;
                if (!((_child110) == null)) {
                    var _val111 = (_child110)._max_ay24;
                    _augval109 = ((_augval109) < (_val111)) ? (_val111) : (_augval109);
                }
                var _child112 = (_a96)._right8;
                if (!((_child112) == null)) {
                    var _val113 = (_child112)._max_ay24;
                    _augval109 = ((_augval109) < (_val113)) ? (_val113) : (_augval109);
                }
                (_a96)._max_ay24 = _augval109;
                (_a96)._height10 = 1 + ((((((_a96)._left7) == null) ? (-1) : (((_a96)._left7)._height10)) > ((((_a96)._right8) == null) ? (-1) : (((_a96)._right8)._height10))) ? ((((_a96)._left7) == null) ? (-1) : (((_a96)._left7)._height10)) : ((((_a96)._right8) == null) ? (-1) : (((_a96)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval114 = (_b97).ax1;
                var _child115 = (_b97)._left7;
                if (!((_child115) == null)) {
                    var _val116 = (_child115)._min_ax12;
                    _augval114 = ((_augval114) < (_val116)) ? (_augval114) : (_val116);
                }
                var _child117 = (_b97)._right8;
                if (!((_child117) == null)) {
                    var _val118 = (_child117)._min_ax12;
                    _augval114 = ((_augval114) < (_val118)) ? (_augval114) : (_val118);
                }
                (_b97)._min_ax12 = _augval114;
                /* _min_ay13 is min of ay1 */
                var _augval119 = (_b97).ay1;
                var _child120 = (_b97)._left7;
                if (!((_child120) == null)) {
                    var _val121 = (_child120)._min_ay13;
                    _augval119 = ((_augval119) < (_val121)) ? (_augval119) : (_val121);
                }
                var _child122 = (_b97)._right8;
                if (!((_child122) == null)) {
                    var _val123 = (_child122)._min_ay13;
                    _augval119 = ((_augval119) < (_val123)) ? (_augval119) : (_val123);
                }
                (_b97)._min_ay13 = _augval119;
                /* _max_ay24 is max of ay2 */
                var _augval124 = (_b97).ay2;
                var _child125 = (_b97)._left7;
                if (!((_child125) == null)) {
                    var _val126 = (_child125)._max_ay24;
                    _augval124 = ((_augval124) < (_val126)) ? (_val126) : (_augval124);
                }
                var _child127 = (_b97)._right8;
                if (!((_child127) == null)) {
                    var _val128 = (_child127)._max_ay24;
                    _augval124 = ((_augval124) < (_val128)) ? (_val128) : (_augval124);
                }
                (_b97)._max_ay24 = _augval124;
                (_b97)._height10 = 1 + ((((((_b97)._left7) == null) ? (-1) : (((_b97)._left7)._height10)) > ((((_b97)._right8) == null) ? (-1) : (((_b97)._right8)._height10))) ? ((((_b97)._left7) == null) ? (-1) : (((_b97)._left7)._height10)) : ((((_b97)._right8) == null) ? (-1) : (((_b97)._right8)._height10)));
                if (!(((_b97)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval129 = ((_b97)._parent9).ax1;
                    var _child130 = ((_b97)._parent9)._left7;
                    if (!((_child130) == null)) {
                        var _val131 = (_child130)._min_ax12;
                        _augval129 = ((_augval129) < (_val131)) ? (_augval129) : (_val131);
                    }
                    var _child132 = ((_b97)._parent9)._right8;
                    if (!((_child132) == null)) {
                        var _val133 = (_child132)._min_ax12;
                        _augval129 = ((_augval129) < (_val133)) ? (_augval129) : (_val133);
                    }
                    ((_b97)._parent9)._min_ax12 = _augval129;
                    /* _min_ay13 is min of ay1 */
                    var _augval134 = ((_b97)._parent9).ay1;
                    var _child135 = ((_b97)._parent9)._left7;
                    if (!((_child135) == null)) {
                        var _val136 = (_child135)._min_ay13;
                        _augval134 = ((_augval134) < (_val136)) ? (_augval134) : (_val136);
                    }
                    var _child137 = ((_b97)._parent9)._right8;
                    if (!((_child137) == null)) {
                        var _val138 = (_child137)._min_ay13;
                        _augval134 = ((_augval134) < (_val138)) ? (_augval134) : (_val138);
                    }
                    ((_b97)._parent9)._min_ay13 = _augval134;
                    /* _max_ay24 is max of ay2 */
                    var _augval139 = ((_b97)._parent9).ay2;
                    var _child140 = ((_b97)._parent9)._left7;
                    if (!((_child140) == null)) {
                        var _val141 = (_child140)._max_ay24;
                        _augval139 = ((_augval139) < (_val141)) ? (_val141) : (_augval139);
                    }
                    var _child142 = ((_b97)._parent9)._right8;
                    if (!((_child142) == null)) {
                        var _val143 = (_child142)._max_ay24;
                        _augval139 = ((_augval139) < (_val143)) ? (_val143) : (_augval139);
                    }
                    ((_b97)._parent9)._max_ay24 = _augval139;
                    ((_b97)._parent9)._height10 = 1 + (((((((_b97)._parent9)._left7) == null) ? (-1) : ((((_b97)._parent9)._left7)._height10)) > (((((_b97)._parent9)._right8) == null) ? (-1) : ((((_b97)._parent9)._right8)._height10))) ? (((((_b97)._parent9)._left7) == null) ? (-1) : ((((_b97)._parent9)._left7)._height10)) : (((((_b97)._parent9)._right8) == null) ? (-1) : ((((_b97)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b97;
                }
            }
            /* rotate (_cursor94)._left7 */
            var _a144 = _cursor94;
            var _b145 = (_a144)._left7;
            var _c146 = (_b145)._right8;
            /* replace _a144 with _b145 in (_a144)._parent9 */
            if (!(((_a144)._parent9) == null)) {
                if ((((_a144)._parent9)._left7) == (_a144)) {
                    ((_a144)._parent9)._left7 = _b145;
                } else {
                    ((_a144)._parent9)._right8 = _b145;
                }
            }
            if (!((_b145) == null)) {
                (_b145)._parent9 = (_a144)._parent9;
            }
            /* replace _c146 with _a144 in _b145 */
            (_b145)._right8 = _a144;
            if (!((_a144) == null)) {
                (_a144)._parent9 = _b145;
            }
            /* replace _b145 with _c146 in _a144 */
            (_a144)._left7 = _c146;
            if (!((_c146) == null)) {
                (_c146)._parent9 = _a144;
            }
            /* _min_ax12 is min of ax1 */
            var _augval147 = (_a144).ax1;
            var _child148 = (_a144)._left7;
            if (!((_child148) == null)) {
                var _val149 = (_child148)._min_ax12;
                _augval147 = ((_augval147) < (_val149)) ? (_augval147) : (_val149);
            }
            var _child150 = (_a144)._right8;
            if (!((_child150) == null)) {
                var _val151 = (_child150)._min_ax12;
                _augval147 = ((_augval147) < (_val151)) ? (_augval147) : (_val151);
            }
            (_a144)._min_ax12 = _augval147;
            /* _min_ay13 is min of ay1 */
            var _augval152 = (_a144).ay1;
            var _child153 = (_a144)._left7;
            if (!((_child153) == null)) {
                var _val154 = (_child153)._min_ay13;
                _augval152 = ((_augval152) < (_val154)) ? (_augval152) : (_val154);
            }
            var _child155 = (_a144)._right8;
            if (!((_child155) == null)) {
                var _val156 = (_child155)._min_ay13;
                _augval152 = ((_augval152) < (_val156)) ? (_augval152) : (_val156);
            }
            (_a144)._min_ay13 = _augval152;
            /* _max_ay24 is max of ay2 */
            var _augval157 = (_a144).ay2;
            var _child158 = (_a144)._left7;
            if (!((_child158) == null)) {
                var _val159 = (_child158)._max_ay24;
                _augval157 = ((_augval157) < (_val159)) ? (_val159) : (_augval157);
            }
            var _child160 = (_a144)._right8;
            if (!((_child160) == null)) {
                var _val161 = (_child160)._max_ay24;
                _augval157 = ((_augval157) < (_val161)) ? (_val161) : (_augval157);
            }
            (_a144)._max_ay24 = _augval157;
            (_a144)._height10 = 1 + ((((((_a144)._left7) == null) ? (-1) : (((_a144)._left7)._height10)) > ((((_a144)._right8) == null) ? (-1) : (((_a144)._right8)._height10))) ? ((((_a144)._left7) == null) ? (-1) : (((_a144)._left7)._height10)) : ((((_a144)._right8) == null) ? (-1) : (((_a144)._right8)._height10)));
            /* _min_ax12 is min of ax1 */
            var _augval162 = (_b145).ax1;
            var _child163 = (_b145)._left7;
            if (!((_child163) == null)) {
                var _val164 = (_child163)._min_ax12;
                _augval162 = ((_augval162) < (_val164)) ? (_augval162) : (_val164);
            }
            var _child165 = (_b145)._right8;
            if (!((_child165) == null)) {
                var _val166 = (_child165)._min_ax12;
                _augval162 = ((_augval162) < (_val166)) ? (_augval162) : (_val166);
            }
            (_b145)._min_ax12 = _augval162;
            /* _min_ay13 is min of ay1 */
            var _augval167 = (_b145).ay1;
            var _child168 = (_b145)._left7;
            if (!((_child168) == null)) {
                var _val169 = (_child168)._min_ay13;
                _augval167 = ((_augval167) < (_val169)) ? (_augval167) : (_val169);
            }
            var _child170 = (_b145)._right8;
            if (!((_child170) == null)) {
                var _val171 = (_child170)._min_ay13;
                _augval167 = ((_augval167) < (_val171)) ? (_augval167) : (_val171);
            }
            (_b145)._min_ay13 = _augval167;
            /* _max_ay24 is max of ay2 */
            var _augval172 = (_b145).ay2;
            var _child173 = (_b145)._left7;
            if (!((_child173) == null)) {
                var _val174 = (_child173)._max_ay24;
                _augval172 = ((_augval172) < (_val174)) ? (_val174) : (_augval172);
            }
            var _child175 = (_b145)._right8;
            if (!((_child175) == null)) {
                var _val176 = (_child175)._max_ay24;
                _augval172 = ((_augval172) < (_val176)) ? (_val176) : (_augval172);
            }
            (_b145)._max_ay24 = _augval172;
            (_b145)._height10 = 1 + ((((((_b145)._left7) == null) ? (-1) : (((_b145)._left7)._height10)) > ((((_b145)._right8) == null) ? (-1) : (((_b145)._right8)._height10))) ? ((((_b145)._left7) == null) ? (-1) : (((_b145)._left7)._height10)) : ((((_b145)._right8) == null) ? (-1) : (((_b145)._right8)._height10)));
            if (!(((_b145)._parent9) == null)) {
                /* _min_ax12 is min of ax1 */
                var _augval177 = ((_b145)._parent9).ax1;
                var _child178 = ((_b145)._parent9)._left7;
                if (!((_child178) == null)) {
                    var _val179 = (_child178)._min_ax12;
                    _augval177 = ((_augval177) < (_val179)) ? (_augval177) : (_val179);
                }
                var _child180 = ((_b145)._parent9)._right8;
                if (!((_child180) == null)) {
                    var _val181 = (_child180)._min_ax12;
                    _augval177 = ((_augval177) < (_val181)) ? (_augval177) : (_val181);
                }
                ((_b145)._parent9)._min_ax12 = _augval177;
                /* _min_ay13 is min of ay1 */
                var _augval182 = ((_b145)._parent9).ay1;
                var _child183 = ((_b145)._parent9)._left7;
                if (!((_child183) == null)) {
                    var _val184 = (_child183)._min_ay13;
                    _augval182 = ((_augval182) < (_val184)) ? (_augval182) : (_val184);
                }
                var _child185 = ((_b145)._parent9)._right8;
                if (!((_child185) == null)) {
                    var _val186 = (_child185)._min_ay13;
                    _augval182 = ((_augval182) < (_val186)) ? (_augval182) : (_val186);
                }
                ((_b145)._parent9)._min_ay13 = _augval182;
                /* _max_ay24 is max of ay2 */
                var _augval187 = ((_b145)._parent9).ay2;
                var _child188 = ((_b145)._parent9)._left7;
                if (!((_child188) == null)) {
                    var _val189 = (_child188)._max_ay24;
                    _augval187 = ((_augval187) < (_val189)) ? (_val189) : (_augval187);
                }
                var _child190 = ((_b145)._parent9)._right8;
                if (!((_child190) == null)) {
                    var _val191 = (_child190)._max_ay24;
                    _augval187 = ((_augval187) < (_val191)) ? (_val191) : (_augval187);
                }
                ((_b145)._parent9)._max_ay24 = _augval187;
                ((_b145)._parent9)._height10 = 1 + (((((((_b145)._parent9)._left7) == null) ? (-1) : ((((_b145)._parent9)._left7)._height10)) > (((((_b145)._parent9)._right8) == null) ? (-1) : ((((_b145)._parent9)._right8)._height10))) ? (((((_b145)._parent9)._left7) == null) ? (-1) : ((((_b145)._parent9)._left7)._height10)) : (((((_b145)._parent9)._right8) == null) ? (-1) : ((((_b145)._parent9)._right8)._height10)));
            } else {
                (this)._root1 = _b145;
            }
            _cursor94 = (_cursor94)._parent9;
        } else if ((_imbalance95) < (-1)) {
            if ((((((_cursor94)._right8)._left7) == null) ? (-1) : ((((_cursor94)._right8)._left7)._height10)) > (((((_cursor94)._right8)._right8) == null) ? (-1) : ((((_cursor94)._right8)._right8)._height10))) {
                /* rotate ((_cursor94)._right8)._left7 */
                var _a192 = (_cursor94)._right8;
                var _b193 = (_a192)._left7;
                var _c194 = (_b193)._right8;
                /* replace _a192 with _b193 in (_a192)._parent9 */
                if (!(((_a192)._parent9) == null)) {
                    if ((((_a192)._parent9)._left7) == (_a192)) {
                        ((_a192)._parent9)._left7 = _b193;
                    } else {
                        ((_a192)._parent9)._right8 = _b193;
                    }
                }
                if (!((_b193) == null)) {
                    (_b193)._parent9 = (_a192)._parent9;
                }
                /* replace _c194 with _a192 in _b193 */
                (_b193)._right8 = _a192;
                if (!((_a192) == null)) {
                    (_a192)._parent9 = _b193;
                }
                /* replace _b193 with _c194 in _a192 */
                (_a192)._left7 = _c194;
                if (!((_c194) == null)) {
                    (_c194)._parent9 = _a192;
                }
                /* _min_ax12 is min of ax1 */
                var _augval195 = (_a192).ax1;
                var _child196 = (_a192)._left7;
                if (!((_child196) == null)) {
                    var _val197 = (_child196)._min_ax12;
                    _augval195 = ((_augval195) < (_val197)) ? (_augval195) : (_val197);
                }
                var _child198 = (_a192)._right8;
                if (!((_child198) == null)) {
                    var _val199 = (_child198)._min_ax12;
                    _augval195 = ((_augval195) < (_val199)) ? (_augval195) : (_val199);
                }
                (_a192)._min_ax12 = _augval195;
                /* _min_ay13 is min of ay1 */
                var _augval200 = (_a192).ay1;
                var _child201 = (_a192)._left7;
                if (!((_child201) == null)) {
                    var _val202 = (_child201)._min_ay13;
                    _augval200 = ((_augval200) < (_val202)) ? (_augval200) : (_val202);
                }
                var _child203 = (_a192)._right8;
                if (!((_child203) == null)) {
                    var _val204 = (_child203)._min_ay13;
                    _augval200 = ((_augval200) < (_val204)) ? (_augval200) : (_val204);
                }
                (_a192)._min_ay13 = _augval200;
                /* _max_ay24 is max of ay2 */
                var _augval205 = (_a192).ay2;
                var _child206 = (_a192)._left7;
                if (!((_child206) == null)) {
                    var _val207 = (_child206)._max_ay24;
                    _augval205 = ((_augval205) < (_val207)) ? (_val207) : (_augval205);
                }
                var _child208 = (_a192)._right8;
                if (!((_child208) == null)) {
                    var _val209 = (_child208)._max_ay24;
                    _augval205 = ((_augval205) < (_val209)) ? (_val209) : (_augval205);
                }
                (_a192)._max_ay24 = _augval205;
                (_a192)._height10 = 1 + ((((((_a192)._left7) == null) ? (-1) : (((_a192)._left7)._height10)) > ((((_a192)._right8) == null) ? (-1) : (((_a192)._right8)._height10))) ? ((((_a192)._left7) == null) ? (-1) : (((_a192)._left7)._height10)) : ((((_a192)._right8) == null) ? (-1) : (((_a192)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval210 = (_b193).ax1;
                var _child211 = (_b193)._left7;
                if (!((_child211) == null)) {
                    var _val212 = (_child211)._min_ax12;
                    _augval210 = ((_augval210) < (_val212)) ? (_augval210) : (_val212);
                }
                var _child213 = (_b193)._right8;
                if (!((_child213) == null)) {
                    var _val214 = (_child213)._min_ax12;
                    _augval210 = ((_augval210) < (_val214)) ? (_augval210) : (_val214);
                }
                (_b193)._min_ax12 = _augval210;
                /* _min_ay13 is min of ay1 */
                var _augval215 = (_b193).ay1;
                var _child216 = (_b193)._left7;
                if (!((_child216) == null)) {
                    var _val217 = (_child216)._min_ay13;
                    _augval215 = ((_augval215) < (_val217)) ? (_augval215) : (_val217);
                }
                var _child218 = (_b193)._right8;
                if (!((_child218) == null)) {
                    var _val219 = (_child218)._min_ay13;
                    _augval215 = ((_augval215) < (_val219)) ? (_augval215) : (_val219);
                }
                (_b193)._min_ay13 = _augval215;
                /* _max_ay24 is max of ay2 */
                var _augval220 = (_b193).ay2;
                var _child221 = (_b193)._left7;
                if (!((_child221) == null)) {
                    var _val222 = (_child221)._max_ay24;
                    _augval220 = ((_augval220) < (_val222)) ? (_val222) : (_augval220);
                }
                var _child223 = (_b193)._right8;
                if (!((_child223) == null)) {
                    var _val224 = (_child223)._max_ay24;
                    _augval220 = ((_augval220) < (_val224)) ? (_val224) : (_augval220);
                }
                (_b193)._max_ay24 = _augval220;
                (_b193)._height10 = 1 + ((((((_b193)._left7) == null) ? (-1) : (((_b193)._left7)._height10)) > ((((_b193)._right8) == null) ? (-1) : (((_b193)._right8)._height10))) ? ((((_b193)._left7) == null) ? (-1) : (((_b193)._left7)._height10)) : ((((_b193)._right8) == null) ? (-1) : (((_b193)._right8)._height10)));
                if (!(((_b193)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval225 = ((_b193)._parent9).ax1;
                    var _child226 = ((_b193)._parent9)._left7;
                    if (!((_child226) == null)) {
                        var _val227 = (_child226)._min_ax12;
                        _augval225 = ((_augval225) < (_val227)) ? (_augval225) : (_val227);
                    }
                    var _child228 = ((_b193)._parent9)._right8;
                    if (!((_child228) == null)) {
                        var _val229 = (_child228)._min_ax12;
                        _augval225 = ((_augval225) < (_val229)) ? (_augval225) : (_val229);
                    }
                    ((_b193)._parent9)._min_ax12 = _augval225;
                    /* _min_ay13 is min of ay1 */
                    var _augval230 = ((_b193)._parent9).ay1;
                    var _child231 = ((_b193)._parent9)._left7;
                    if (!((_child231) == null)) {
                        var _val232 = (_child231)._min_ay13;
                        _augval230 = ((_augval230) < (_val232)) ? (_augval230) : (_val232);
                    }
                    var _child233 = ((_b193)._parent9)._right8;
                    if (!((_child233) == null)) {
                        var _val234 = (_child233)._min_ay13;
                        _augval230 = ((_augval230) < (_val234)) ? (_augval230) : (_val234);
                    }
                    ((_b193)._parent9)._min_ay13 = _augval230;
                    /* _max_ay24 is max of ay2 */
                    var _augval235 = ((_b193)._parent9).ay2;
                    var _child236 = ((_b193)._parent9)._left7;
                    if (!((_child236) == null)) {
                        var _val237 = (_child236)._max_ay24;
                        _augval235 = ((_augval235) < (_val237)) ? (_val237) : (_augval235);
                    }
                    var _child238 = ((_b193)._parent9)._right8;
                    if (!((_child238) == null)) {
                        var _val239 = (_child238)._max_ay24;
                        _augval235 = ((_augval235) < (_val239)) ? (_val239) : (_augval235);
                    }
                    ((_b193)._parent9)._max_ay24 = _augval235;
                    ((_b193)._parent9)._height10 = 1 + (((((((_b193)._parent9)._left7) == null) ? (-1) : ((((_b193)._parent9)._left7)._height10)) > (((((_b193)._parent9)._right8) == null) ? (-1) : ((((_b193)._parent9)._right8)._height10))) ? (((((_b193)._parent9)._left7) == null) ? (-1) : ((((_b193)._parent9)._left7)._height10)) : (((((_b193)._parent9)._right8) == null) ? (-1) : ((((_b193)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b193;
                }
            }
            /* rotate (_cursor94)._right8 */
            var _a240 = _cursor94;
            var _b241 = (_a240)._right8;
            var _c242 = (_b241)._left7;
            /* replace _a240 with _b241 in (_a240)._parent9 */
            if (!(((_a240)._parent9) == null)) {
                if ((((_a240)._parent9)._left7) == (_a240)) {
                    ((_a240)._parent9)._left7 = _b241;
                } else {
                    ((_a240)._parent9)._right8 = _b241;
                }
            }
            if (!((_b241) == null)) {
                (_b241)._parent9 = (_a240)._parent9;
            }
            /* replace _c242 with _a240 in _b241 */
            (_b241)._left7 = _a240;
            if (!((_a240) == null)) {
                (_a240)._parent9 = _b241;
            }
            /* replace _b241 with _c242 in _a240 */
            (_a240)._right8 = _c242;
            if (!((_c242) == null)) {
                (_c242)._parent9 = _a240;
            }
            /* _min_ax12 is min of ax1 */
            var _augval243 = (_a240).ax1;
            var _child244 = (_a240)._left7;
            if (!((_child244) == null)) {
                var _val245 = (_child244)._min_ax12;
                _augval243 = ((_augval243) < (_val245)) ? (_augval243) : (_val245);
            }
            var _child246 = (_a240)._right8;
            if (!((_child246) == null)) {
                var _val247 = (_child246)._min_ax12;
                _augval243 = ((_augval243) < (_val247)) ? (_augval243) : (_val247);
            }
            (_a240)._min_ax12 = _augval243;
            /* _min_ay13 is min of ay1 */
            var _augval248 = (_a240).ay1;
            var _child249 = (_a240)._left7;
            if (!((_child249) == null)) {
                var _val250 = (_child249)._min_ay13;
                _augval248 = ((_augval248) < (_val250)) ? (_augval248) : (_val250);
            }
            var _child251 = (_a240)._right8;
            if (!((_child251) == null)) {
                var _val252 = (_child251)._min_ay13;
                _augval248 = ((_augval248) < (_val252)) ? (_augval248) : (_val252);
            }
            (_a240)._min_ay13 = _augval248;
            /* _max_ay24 is max of ay2 */
            var _augval253 = (_a240).ay2;
            var _child254 = (_a240)._left7;
            if (!((_child254) == null)) {
                var _val255 = (_child254)._max_ay24;
                _augval253 = ((_augval253) < (_val255)) ? (_val255) : (_augval253);
            }
            var _child256 = (_a240)._right8;
            if (!((_child256) == null)) {
                var _val257 = (_child256)._max_ay24;
                _augval253 = ((_augval253) < (_val257)) ? (_val257) : (_augval253);
            }
            (_a240)._max_ay24 = _augval253;
            (_a240)._height10 = 1 + ((((((_a240)._left7) == null) ? (-1) : (((_a240)._left7)._height10)) > ((((_a240)._right8) == null) ? (-1) : (((_a240)._right8)._height10))) ? ((((_a240)._left7) == null) ? (-1) : (((_a240)._left7)._height10)) : ((((_a240)._right8) == null) ? (-1) : (((_a240)._right8)._height10)));
            /* _min_ax12 is min of ax1 */
            var _augval258 = (_b241).ax1;
            var _child259 = (_b241)._left7;
            if (!((_child259) == null)) {
                var _val260 = (_child259)._min_ax12;
                _augval258 = ((_augval258) < (_val260)) ? (_augval258) : (_val260);
            }
            var _child261 = (_b241)._right8;
            if (!((_child261) == null)) {
                var _val262 = (_child261)._min_ax12;
                _augval258 = ((_augval258) < (_val262)) ? (_augval258) : (_val262);
            }
            (_b241)._min_ax12 = _augval258;
            /* _min_ay13 is min of ay1 */
            var _augval263 = (_b241).ay1;
            var _child264 = (_b241)._left7;
            if (!((_child264) == null)) {
                var _val265 = (_child264)._min_ay13;
                _augval263 = ((_augval263) < (_val265)) ? (_augval263) : (_val265);
            }
            var _child266 = (_b241)._right8;
            if (!((_child266) == null)) {
                var _val267 = (_child266)._min_ay13;
                _augval263 = ((_augval263) < (_val267)) ? (_augval263) : (_val267);
            }
            (_b241)._min_ay13 = _augval263;
            /* _max_ay24 is max of ay2 */
            var _augval268 = (_b241).ay2;
            var _child269 = (_b241)._left7;
            if (!((_child269) == null)) {
                var _val270 = (_child269)._max_ay24;
                _augval268 = ((_augval268) < (_val270)) ? (_val270) : (_augval268);
            }
            var _child271 = (_b241)._right8;
            if (!((_child271) == null)) {
                var _val272 = (_child271)._max_ay24;
                _augval268 = ((_augval268) < (_val272)) ? (_val272) : (_augval268);
            }
            (_b241)._max_ay24 = _augval268;
            (_b241)._height10 = 1 + ((((((_b241)._left7) == null) ? (-1) : (((_b241)._left7)._height10)) > ((((_b241)._right8) == null) ? (-1) : (((_b241)._right8)._height10))) ? ((((_b241)._left7) == null) ? (-1) : (((_b241)._left7)._height10)) : ((((_b241)._right8) == null) ? (-1) : (((_b241)._right8)._height10)));
            if (!(((_b241)._parent9) == null)) {
                /* _min_ax12 is min of ax1 */
                var _augval273 = ((_b241)._parent9).ax1;
                var _child274 = ((_b241)._parent9)._left7;
                if (!((_child274) == null)) {
                    var _val275 = (_child274)._min_ax12;
                    _augval273 = ((_augval273) < (_val275)) ? (_augval273) : (_val275);
                }
                var _child276 = ((_b241)._parent9)._right8;
                if (!((_child276) == null)) {
                    var _val277 = (_child276)._min_ax12;
                    _augval273 = ((_augval273) < (_val277)) ? (_augval273) : (_val277);
                }
                ((_b241)._parent9)._min_ax12 = _augval273;
                /* _min_ay13 is min of ay1 */
                var _augval278 = ((_b241)._parent9).ay1;
                var _child279 = ((_b241)._parent9)._left7;
                if (!((_child279) == null)) {
                    var _val280 = (_child279)._min_ay13;
                    _augval278 = ((_augval278) < (_val280)) ? (_augval278) : (_val280);
                }
                var _child281 = ((_b241)._parent9)._right8;
                if (!((_child281) == null)) {
                    var _val282 = (_child281)._min_ay13;
                    _augval278 = ((_augval278) < (_val282)) ? (_augval278) : (_val282);
                }
                ((_b241)._parent9)._min_ay13 = _augval278;
                /* _max_ay24 is max of ay2 */
                var _augval283 = ((_b241)._parent9).ay2;
                var _child284 = ((_b241)._parent9)._left7;
                if (!((_child284) == null)) {
                    var _val285 = (_child284)._max_ay24;
                    _augval283 = ((_augval283) < (_val285)) ? (_val285) : (_augval283);
                }
                var _child286 = ((_b241)._parent9)._right8;
                if (!((_child286) == null)) {
                    var _val287 = (_child286)._max_ay24;
                    _augval283 = ((_augval283) < (_val287)) ? (_val287) : (_augval283);
                }
                ((_b241)._parent9)._max_ay24 = _augval283;
                ((_b241)._parent9)._height10 = 1 + (((((((_b241)._parent9)._left7) == null) ? (-1) : ((((_b241)._parent9)._left7)._height10)) > (((((_b241)._parent9)._right8) == null) ? (-1) : ((((_b241)._parent9)._right8)._height10))) ? (((((_b241)._parent9)._left7) == null) ? (-1) : ((((_b241)._parent9)._left7)._height10)) : (((((_b241)._parent9)._right8) == null) ? (-1) : ((((_b241)._parent9)._right8)._height10)));
            } else {
                (this)._root1 = _b241;
            }
            _cursor94 = (_cursor94)._parent9;
        }
    }
};
RectangleHolder.prototype.remove = function (x) {
    --this.my_size;
    var _parent288 = (x)._parent9;
    var _left289 = (x)._left7;
    var _right290 = (x)._right8;
    var _new_x291;
    if (((_left289) == null) && ((_right290) == null)) {
        _new_x291 = null;
        /* replace x with _new_x291 in _parent288 */
        if (!((_parent288) == null)) {
            if (((_parent288)._left7) == (x)) {
                (_parent288)._left7 = _new_x291;
            } else {
                (_parent288)._right8 = _new_x291;
            }
        }
        if (!((_new_x291) == null)) {
            (_new_x291)._parent9 = _parent288;
        }
    } else if ((!((_left289) == null)) && ((_right290) == null)) {
        _new_x291 = _left289;
        /* replace x with _new_x291 in _parent288 */
        if (!((_parent288) == null)) {
            if (((_parent288)._left7) == (x)) {
                (_parent288)._left7 = _new_x291;
            } else {
                (_parent288)._right8 = _new_x291;
            }
        }
        if (!((_new_x291) == null)) {
            (_new_x291)._parent9 = _parent288;
        }
    } else if (((_left289) == null) && (!((_right290) == null))) {
        _new_x291 = _right290;
        /* replace x with _new_x291 in _parent288 */
        if (!((_parent288) == null)) {
            if (((_parent288)._left7) == (x)) {
                (_parent288)._left7 = _new_x291;
            } else {
                (_parent288)._right8 = _new_x291;
            }
        }
        if (!((_new_x291) == null)) {
            (_new_x291)._parent9 = _parent288;
        }
    } else {
        var _root292 = (x)._right8;
        var _x293 = _root292;
        var _descend294 = true;
        var _from_left295 = true;
        while (true) {
            if ((_x293) == null) {
                _x293 = null;
                break;
            }
            if (_descend294) {
                /* too small? */
                if (false) {
                    if ((!(((_x293)._right8) == null)) && (true)) {
                        if ((_x293) == (_root292)) {
                            _root292 = (_x293)._right8;
                        }
                        _x293 = (_x293)._right8;
                    } else if ((_x293) == (_root292)) {
                        _x293 = null;
                        break;
                    } else {
                        _descend294 = false;
                        _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                        _x293 = (_x293)._parent9;
                    }
                } else if ((!(((_x293)._left7) == null)) && (true)) {
                    _x293 = (_x293)._left7;
                    /* too large? */
                } else if (false) {
                    if ((_x293) == (_root292)) {
                        _x293 = null;
                        break;
                    } else {
                        _descend294 = false;
                        _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                        _x293 = (_x293)._parent9;
                    }
                    /* node ok? */
                } else if (true) {
                    break;
                } else if ((_x293) == (_root292)) {
                    _root292 = (_x293)._right8;
                    _x293 = (_x293)._right8;
                } else {
                    if ((!(((_x293)._right8) == null)) && (true)) {
                        if ((_x293) == (_root292)) {
                            _root292 = (_x293)._right8;
                        }
                        _x293 = (_x293)._right8;
                    } else {
                        _descend294 = false;
                        _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                        _x293 = (_x293)._parent9;
                    }
                }
            } else if (_from_left295) {
                if (false) {
                    _x293 = null;
                    break;
                } else if (true) {
                    break;
                } else if ((!(((_x293)._right8) == null)) && (true)) {
                    _descend294 = true;
                    if ((_x293) == (_root292)) {
                        _root292 = (_x293)._right8;
                    }
                    _x293 = (_x293)._right8;
                } else if ((_x293) == (_root292)) {
                    _x293 = null;
                    break;
                } else {
                    _descend294 = false;
                    _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                    _x293 = (_x293)._parent9;
                }
            } else {
                if ((_x293) == (_root292)) {
                    _x293 = null;
                    break;
                } else {
                    _descend294 = false;
                    _from_left295 = (!(((_x293)._parent9) == null)) && ((_x293) == (((_x293)._parent9)._left7));
                    _x293 = (_x293)._parent9;
                }
            }
        }
        _new_x291 = _x293;
        var _mp296 = (_x293)._parent9;
        var _mr297 = (_x293)._right8;
        /* replace _x293 with _mr297 in _mp296 */
        if (!((_mp296) == null)) {
            if (((_mp296)._left7) == (_x293)) {
                (_mp296)._left7 = _mr297;
            } else {
                (_mp296)._right8 = _mr297;
            }
        }
        if (!((_mr297) == null)) {
            (_mr297)._parent9 = _mp296;
        }
        /* replace x with _x293 in _parent288 */
        if (!((_parent288) == null)) {
            if (((_parent288)._left7) == (x)) {
                (_parent288)._left7 = _x293;
            } else {
                (_parent288)._right8 = _x293;
            }
        }
        if (!((_x293) == null)) {
            (_x293)._parent9 = _parent288;
        }
        /* replace null with _left289 in _x293 */
        (_x293)._left7 = _left289;
        if (!((_left289) == null)) {
            (_left289)._parent9 = _x293;
        }
        /* replace _mr297 with (x)._right8 in _x293 */
        (_x293)._right8 = (x)._right8;
        if (!(((x)._right8) == null)) {
            ((x)._right8)._parent9 = _x293;
        }
        /* _min_ax12 is min of ax1 */
        var _augval298 = (_x293).ax1;
        var _child299 = (_x293)._left7;
        if (!((_child299) == null)) {
            var _val300 = (_child299)._min_ax12;
            _augval298 = ((_augval298) < (_val300)) ? (_augval298) : (_val300);
        }
        var _child301 = (_x293)._right8;
        if (!((_child301) == null)) {
            var _val302 = (_child301)._min_ax12;
            _augval298 = ((_augval298) < (_val302)) ? (_augval298) : (_val302);
        }
        (_x293)._min_ax12 = _augval298;
        /* _min_ay13 is min of ay1 */
        var _augval303 = (_x293).ay1;
        var _child304 = (_x293)._left7;
        if (!((_child304) == null)) {
            var _val305 = (_child304)._min_ay13;
            _augval303 = ((_augval303) < (_val305)) ? (_augval303) : (_val305);
        }
        var _child306 = (_x293)._right8;
        if (!((_child306) == null)) {
            var _val307 = (_child306)._min_ay13;
            _augval303 = ((_augval303) < (_val307)) ? (_augval303) : (_val307);
        }
        (_x293)._min_ay13 = _augval303;
        /* _max_ay24 is max of ay2 */
        var _augval308 = (_x293).ay2;
        var _child309 = (_x293)._left7;
        if (!((_child309) == null)) {
            var _val310 = (_child309)._max_ay24;
            _augval308 = ((_augval308) < (_val310)) ? (_val310) : (_augval308);
        }
        var _child311 = (_x293)._right8;
        if (!((_child311) == null)) {
            var _val312 = (_child311)._max_ay24;
            _augval308 = ((_augval308) < (_val312)) ? (_val312) : (_augval308);
        }
        (_x293)._max_ay24 = _augval308;
        (_x293)._height10 = 1 + ((((((_x293)._left7) == null) ? (-1) : (((_x293)._left7)._height10)) > ((((_x293)._right8) == null) ? (-1) : (((_x293)._right8)._height10))) ? ((((_x293)._left7) == null) ? (-1) : (((_x293)._left7)._height10)) : ((((_x293)._right8) == null) ? (-1) : (((_x293)._right8)._height10)));
        var _cursor313 = _mp296;
        var _changed314 = true;
        while ((_changed314) && (!((_cursor313) == (_parent288)))) {
            var _old__min_ax12315 = (_cursor313)._min_ax12;
            var _old__min_ay13316 = (_cursor313)._min_ay13;
            var _old__max_ay24317 = (_cursor313)._max_ay24;
            var _old_height318 = (_cursor313)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval319 = (_cursor313).ax1;
            var _child320 = (_cursor313)._left7;
            if (!((_child320) == null)) {
                var _val321 = (_child320)._min_ax12;
                _augval319 = ((_augval319) < (_val321)) ? (_augval319) : (_val321);
            }
            var _child322 = (_cursor313)._right8;
            if (!((_child322) == null)) {
                var _val323 = (_child322)._min_ax12;
                _augval319 = ((_augval319) < (_val323)) ? (_augval319) : (_val323);
            }
            (_cursor313)._min_ax12 = _augval319;
            /* _min_ay13 is min of ay1 */
            var _augval324 = (_cursor313).ay1;
            var _child325 = (_cursor313)._left7;
            if (!((_child325) == null)) {
                var _val326 = (_child325)._min_ay13;
                _augval324 = ((_augval324) < (_val326)) ? (_augval324) : (_val326);
            }
            var _child327 = (_cursor313)._right8;
            if (!((_child327) == null)) {
                var _val328 = (_child327)._min_ay13;
                _augval324 = ((_augval324) < (_val328)) ? (_augval324) : (_val328);
            }
            (_cursor313)._min_ay13 = _augval324;
            /* _max_ay24 is max of ay2 */
            var _augval329 = (_cursor313).ay2;
            var _child330 = (_cursor313)._left7;
            if (!((_child330) == null)) {
                var _val331 = (_child330)._max_ay24;
                _augval329 = ((_augval329) < (_val331)) ? (_val331) : (_augval329);
            }
            var _child332 = (_cursor313)._right8;
            if (!((_child332) == null)) {
                var _val333 = (_child332)._max_ay24;
                _augval329 = ((_augval329) < (_val333)) ? (_val333) : (_augval329);
            }
            (_cursor313)._max_ay24 = _augval329;
            (_cursor313)._height10 = 1 + ((((((_cursor313)._left7) == null) ? (-1) : (((_cursor313)._left7)._height10)) > ((((_cursor313)._right8) == null) ? (-1) : (((_cursor313)._right8)._height10))) ? ((((_cursor313)._left7) == null) ? (-1) : (((_cursor313)._left7)._height10)) : ((((_cursor313)._right8) == null) ? (-1) : (((_cursor313)._right8)._height10)));
            _changed314 = false;
            _changed314 = (_changed314) || (!((_old__min_ax12315) == ((_cursor313)._min_ax12)));
            _changed314 = (_changed314) || (!((_old__min_ay13316) == ((_cursor313)._min_ay13)));
            _changed314 = (_changed314) || (!((_old__max_ay24317) == ((_cursor313)._max_ay24)));
            _changed314 = (_changed314) || (!((_old_height318) == ((_cursor313)._height10)));
            _cursor313 = (_cursor313)._parent9;
        }
    }
    var _cursor334 = _parent288;
    var _changed335 = true;
    while ((_changed335) && (!((_cursor334) == (null)))) {
        var _old__min_ax12336 = (_cursor334)._min_ax12;
        var _old__min_ay13337 = (_cursor334)._min_ay13;
        var _old__max_ay24338 = (_cursor334)._max_ay24;
        var _old_height339 = (_cursor334)._height10;
        /* _min_ax12 is min of ax1 */
        var _augval340 = (_cursor334).ax1;
        var _child341 = (_cursor334)._left7;
        if (!((_child341) == null)) {
            var _val342 = (_child341)._min_ax12;
            _augval340 = ((_augval340) < (_val342)) ? (_augval340) : (_val342);
        }
        var _child343 = (_cursor334)._right8;
        if (!((_child343) == null)) {
            var _val344 = (_child343)._min_ax12;
            _augval340 = ((_augval340) < (_val344)) ? (_augval340) : (_val344);
        }
        (_cursor334)._min_ax12 = _augval340;
        /* _min_ay13 is min of ay1 */
        var _augval345 = (_cursor334).ay1;
        var _child346 = (_cursor334)._left7;
        if (!((_child346) == null)) {
            var _val347 = (_child346)._min_ay13;
            _augval345 = ((_augval345) < (_val347)) ? (_augval345) : (_val347);
        }
        var _child348 = (_cursor334)._right8;
        if (!((_child348) == null)) {
            var _val349 = (_child348)._min_ay13;
            _augval345 = ((_augval345) < (_val349)) ? (_augval345) : (_val349);
        }
        (_cursor334)._min_ay13 = _augval345;
        /* _max_ay24 is max of ay2 */
        var _augval350 = (_cursor334).ay2;
        var _child351 = (_cursor334)._left7;
        if (!((_child351) == null)) {
            var _val352 = (_child351)._max_ay24;
            _augval350 = ((_augval350) < (_val352)) ? (_val352) : (_augval350);
        }
        var _child353 = (_cursor334)._right8;
        if (!((_child353) == null)) {
            var _val354 = (_child353)._max_ay24;
            _augval350 = ((_augval350) < (_val354)) ? (_val354) : (_augval350);
        }
        (_cursor334)._max_ay24 = _augval350;
        (_cursor334)._height10 = 1 + ((((((_cursor334)._left7) == null) ? (-1) : (((_cursor334)._left7)._height10)) > ((((_cursor334)._right8) == null) ? (-1) : (((_cursor334)._right8)._height10))) ? ((((_cursor334)._left7) == null) ? (-1) : (((_cursor334)._left7)._height10)) : ((((_cursor334)._right8) == null) ? (-1) : (((_cursor334)._right8)._height10)));
        _changed335 = false;
        _changed335 = (_changed335) || (!((_old__min_ax12336) == ((_cursor334)._min_ax12)));
        _changed335 = (_changed335) || (!((_old__min_ay13337) == ((_cursor334)._min_ay13)));
        _changed335 = (_changed335) || (!((_old__max_ay24338) == ((_cursor334)._max_ay24)));
        _changed335 = (_changed335) || (!((_old_height339) == ((_cursor334)._height10)));
        _cursor334 = (_cursor334)._parent9;
    }
    if (((this)._root1) == (x)) {
        (this)._root1 = _new_x291;
    }
};
RectangleHolder.prototype.updateAx1 = function (__x, new_val) {
    if ((__x).ax1 != new_val) {
        /* _min_ax12 is min of ax1 */
        var _augval355 = new_val;
        var _child356 = (__x)._left7;
        if (!((_child356) == null)) {
            var _val357 = (_child356)._min_ax12;
            _augval355 = ((_augval355) < (_val357)) ? (_augval355) : (_val357);
        }
        var _child358 = (__x)._right8;
        if (!((_child358) == null)) {
            var _val359 = (_child358)._min_ax12;
            _augval355 = ((_augval355) < (_val359)) ? (_augval355) : (_val359);
        }
        (__x)._min_ax12 = _augval355;
        var _cursor360 = (__x)._parent9;
        var _changed361 = true;
        while ((_changed361) && (!((_cursor360) == (null)))) {
            var _old__min_ax12362 = (_cursor360)._min_ax12;
            var _old_height363 = (_cursor360)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval364 = (_cursor360).ax1;
            var _child365 = (_cursor360)._left7;
            if (!((_child365) == null)) {
                var _val366 = (_child365)._min_ax12;
                _augval364 = ((_augval364) < (_val366)) ? (_augval364) : (_val366);
            }
            var _child367 = (_cursor360)._right8;
            if (!((_child367) == null)) {
                var _val368 = (_child367)._min_ax12;
                _augval364 = ((_augval364) < (_val368)) ? (_augval364) : (_val368);
            }
            (_cursor360)._min_ax12 = _augval364;
            (_cursor360)._height10 = 1 + ((((((_cursor360)._left7) == null) ? (-1) : (((_cursor360)._left7)._height10)) > ((((_cursor360)._right8) == null) ? (-1) : (((_cursor360)._right8)._height10))) ? ((((_cursor360)._left7) == null) ? (-1) : (((_cursor360)._left7)._height10)) : ((((_cursor360)._right8) == null) ? (-1) : (((_cursor360)._right8)._height10)));
            _changed361 = false;
            _changed361 = (_changed361) || (!((_old__min_ax12362) == ((_cursor360)._min_ax12)));
            _changed361 = (_changed361) || (!((_old_height363) == ((_cursor360)._height10)));
            _cursor360 = (_cursor360)._parent9;
        }
        (__x).ax1 = new_val;
    }
}
RectangleHolder.prototype.updateAy1 = function (__x, new_val) {
    if ((__x).ay1 != new_val) {
        /* _min_ay13 is min of ay1 */
        var _augval369 = new_val;
        var _child370 = (__x)._left7;
        if (!((_child370) == null)) {
            var _val371 = (_child370)._min_ay13;
            _augval369 = ((_augval369) < (_val371)) ? (_augval369) : (_val371);
        }
        var _child372 = (__x)._right8;
        if (!((_child372) == null)) {
            var _val373 = (_child372)._min_ay13;
            _augval369 = ((_augval369) < (_val373)) ? (_augval369) : (_val373);
        }
        (__x)._min_ay13 = _augval369;
        var _cursor374 = (__x)._parent9;
        var _changed375 = true;
        while ((_changed375) && (!((_cursor374) == (null)))) {
            var _old__min_ay13376 = (_cursor374)._min_ay13;
            var _old_height377 = (_cursor374)._height10;
            /* _min_ay13 is min of ay1 */
            var _augval378 = (_cursor374).ay1;
            var _child379 = (_cursor374)._left7;
            if (!((_child379) == null)) {
                var _val380 = (_child379)._min_ay13;
                _augval378 = ((_augval378) < (_val380)) ? (_augval378) : (_val380);
            }
            var _child381 = (_cursor374)._right8;
            if (!((_child381) == null)) {
                var _val382 = (_child381)._min_ay13;
                _augval378 = ((_augval378) < (_val382)) ? (_augval378) : (_val382);
            }
            (_cursor374)._min_ay13 = _augval378;
            (_cursor374)._height10 = 1 + ((((((_cursor374)._left7) == null) ? (-1) : (((_cursor374)._left7)._height10)) > ((((_cursor374)._right8) == null) ? (-1) : (((_cursor374)._right8)._height10))) ? ((((_cursor374)._left7) == null) ? (-1) : (((_cursor374)._left7)._height10)) : ((((_cursor374)._right8) == null) ? (-1) : (((_cursor374)._right8)._height10)));
            _changed375 = false;
            _changed375 = (_changed375) || (!((_old__min_ay13376) == ((_cursor374)._min_ay13)));
            _changed375 = (_changed375) || (!((_old_height377) == ((_cursor374)._height10)));
            _cursor374 = (_cursor374)._parent9;
        }
        (__x).ay1 = new_val;
    }
}
RectangleHolder.prototype.updateAx2 = function (__x, new_val) {
    if ((__x).ax2 != new_val) {
        var _parent383 = (__x)._parent9;
        var _left384 = (__x)._left7;
        var _right385 = (__x)._right8;
        var _new_x386;
        if (((_left384) == null) && ((_right385) == null)) {
            _new_x386 = null;
            /* replace __x with _new_x386 in _parent383 */
            if (!((_parent383) == null)) {
                if (((_parent383)._left7) == (__x)) {
                    (_parent383)._left7 = _new_x386;
                } else {
                    (_parent383)._right8 = _new_x386;
                }
            }
            if (!((_new_x386) == null)) {
                (_new_x386)._parent9 = _parent383;
            }
        } else if ((!((_left384) == null)) && ((_right385) == null)) {
            _new_x386 = _left384;
            /* replace __x with _new_x386 in _parent383 */
            if (!((_parent383) == null)) {
                if (((_parent383)._left7) == (__x)) {
                    (_parent383)._left7 = _new_x386;
                } else {
                    (_parent383)._right8 = _new_x386;
                }
            }
            if (!((_new_x386) == null)) {
                (_new_x386)._parent9 = _parent383;
            }
        } else if (((_left384) == null) && (!((_right385) == null))) {
            _new_x386 = _right385;
            /* replace __x with _new_x386 in _parent383 */
            if (!((_parent383) == null)) {
                if (((_parent383)._left7) == (__x)) {
                    (_parent383)._left7 = _new_x386;
                } else {
                    (_parent383)._right8 = _new_x386;
                }
            }
            if (!((_new_x386) == null)) {
                (_new_x386)._parent9 = _parent383;
            }
        } else {
            var _root387 = (__x)._right8;
            var _x388 = _root387;
            var _descend389 = true;
            var _from_left390 = true;
            while (true) {
                if ((_x388) == null) {
                    _x388 = null;
                    break;
                }
                if (_descend389) {
                    /* too small? */
                    if (false) {
                        if ((!(((_x388)._right8) == null)) && (true)) {
                            if ((_x388) == (_root387)) {
                                _root387 = (_x388)._right8;
                            }
                            _x388 = (_x388)._right8;
                        } else if ((_x388) == (_root387)) {
                            _x388 = null;
                            break;
                        } else {
                            _descend389 = false;
                            _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                            _x388 = (_x388)._parent9;
                        }
                    } else if ((!(((_x388)._left7) == null)) && (true)) {
                        _x388 = (_x388)._left7;
                        /* too large? */
                    } else if (false) {
                        if ((_x388) == (_root387)) {
                            _x388 = null;
                            break;
                        } else {
                            _descend389 = false;
                            _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                            _x388 = (_x388)._parent9;
                        }
                        /* node ok? */
                    } else if (true) {
                        break;
                    } else if ((_x388) == (_root387)) {
                        _root387 = (_x388)._right8;
                        _x388 = (_x388)._right8;
                    } else {
                        if ((!(((_x388)._right8) == null)) && (true)) {
                            if ((_x388) == (_root387)) {
                                _root387 = (_x388)._right8;
                            }
                            _x388 = (_x388)._right8;
                        } else {
                            _descend389 = false;
                            _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                            _x388 = (_x388)._parent9;
                        }
                    }
                } else if (_from_left390) {
                    if (false) {
                        _x388 = null;
                        break;
                    } else if (true) {
                        break;
                    } else if ((!(((_x388)._right8) == null)) && (true)) {
                        _descend389 = true;
                        if ((_x388) == (_root387)) {
                            _root387 = (_x388)._right8;
                        }
                        _x388 = (_x388)._right8;
                    } else if ((_x388) == (_root387)) {
                        _x388 = null;
                        break;
                    } else {
                        _descend389 = false;
                        _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                        _x388 = (_x388)._parent9;
                    }
                } else {
                    if ((_x388) == (_root387)) {
                        _x388 = null;
                        break;
                    } else {
                        _descend389 = false;
                        _from_left390 = (!(((_x388)._parent9) == null)) && ((_x388) == (((_x388)._parent9)._left7));
                        _x388 = (_x388)._parent9;
                    }
                }
            }
            _new_x386 = _x388;
            var _mp391 = (_x388)._parent9;
            var _mr392 = (_x388)._right8;
            /* replace _x388 with _mr392 in _mp391 */
            if (!((_mp391) == null)) {
                if (((_mp391)._left7) == (_x388)) {
                    (_mp391)._left7 = _mr392;
                } else {
                    (_mp391)._right8 = _mr392;
                }
            }
            if (!((_mr392) == null)) {
                (_mr392)._parent9 = _mp391;
            }
            /* replace __x with _x388 in _parent383 */
            if (!((_parent383) == null)) {
                if (((_parent383)._left7) == (__x)) {
                    (_parent383)._left7 = _x388;
                } else {
                    (_parent383)._right8 = _x388;
                }
            }
            if (!((_x388) == null)) {
                (_x388)._parent9 = _parent383;
            }
            /* replace null with _left384 in _x388 */
            (_x388)._left7 = _left384;
            if (!((_left384) == null)) {
                (_left384)._parent9 = _x388;
            }
            /* replace _mr392 with (__x)._right8 in _x388 */
            (_x388)._right8 = (__x)._right8;
            if (!(((__x)._right8) == null)) {
                ((__x)._right8)._parent9 = _x388;
            }
            /* _min_ax12 is min of ax1 */
            var _augval393 = (_x388).ax1;
            var _child394 = (_x388)._left7;
            if (!((_child394) == null)) {
                var _val395 = (_child394)._min_ax12;
                _augval393 = ((_augval393) < (_val395)) ? (_augval393) : (_val395);
            }
            var _child396 = (_x388)._right8;
            if (!((_child396) == null)) {
                var _val397 = (_child396)._min_ax12;
                _augval393 = ((_augval393) < (_val397)) ? (_augval393) : (_val397);
            }
            (_x388)._min_ax12 = _augval393;
            /* _min_ay13 is min of ay1 */
            var _augval398 = (_x388).ay1;
            var _child399 = (_x388)._left7;
            if (!((_child399) == null)) {
                var _val400 = (_child399)._min_ay13;
                _augval398 = ((_augval398) < (_val400)) ? (_augval398) : (_val400);
            }
            var _child401 = (_x388)._right8;
            if (!((_child401) == null)) {
                var _val402 = (_child401)._min_ay13;
                _augval398 = ((_augval398) < (_val402)) ? (_augval398) : (_val402);
            }
            (_x388)._min_ay13 = _augval398;
            /* _max_ay24 is max of ay2 */
            var _augval403 = (_x388).ay2;
            var _child404 = (_x388)._left7;
            if (!((_child404) == null)) {
                var _val405 = (_child404)._max_ay24;
                _augval403 = ((_augval403) < (_val405)) ? (_val405) : (_augval403);
            }
            var _child406 = (_x388)._right8;
            if (!((_child406) == null)) {
                var _val407 = (_child406)._max_ay24;
                _augval403 = ((_augval403) < (_val407)) ? (_val407) : (_augval403);
            }
            (_x388)._max_ay24 = _augval403;
            (_x388)._height10 = 1 + ((((((_x388)._left7) == null) ? (-1) : (((_x388)._left7)._height10)) > ((((_x388)._right8) == null) ? (-1) : (((_x388)._right8)._height10))) ? ((((_x388)._left7) == null) ? (-1) : (((_x388)._left7)._height10)) : ((((_x388)._right8) == null) ? (-1) : (((_x388)._right8)._height10)));
            var _cursor408 = _mp391;
            var _changed409 = true;
            while ((_changed409) && (!((_cursor408) == (_parent383)))) {
                var _old__min_ax12410 = (_cursor408)._min_ax12;
                var _old__min_ay13411 = (_cursor408)._min_ay13;
                var _old__max_ay24412 = (_cursor408)._max_ay24;
                var _old_height413 = (_cursor408)._height10;
                /* _min_ax12 is min of ax1 */
                var _augval414 = (_cursor408).ax1;
                var _child415 = (_cursor408)._left7;
                if (!((_child415) == null)) {
                    var _val416 = (_child415)._min_ax12;
                    _augval414 = ((_augval414) < (_val416)) ? (_augval414) : (_val416);
                }
                var _child417 = (_cursor408)._right8;
                if (!((_child417) == null)) {
                    var _val418 = (_child417)._min_ax12;
                    _augval414 = ((_augval414) < (_val418)) ? (_augval414) : (_val418);
                }
                (_cursor408)._min_ax12 = _augval414;
                /* _min_ay13 is min of ay1 */
                var _augval419 = (_cursor408).ay1;
                var _child420 = (_cursor408)._left7;
                if (!((_child420) == null)) {
                    var _val421 = (_child420)._min_ay13;
                    _augval419 = ((_augval419) < (_val421)) ? (_augval419) : (_val421);
                }
                var _child422 = (_cursor408)._right8;
                if (!((_child422) == null)) {
                    var _val423 = (_child422)._min_ay13;
                    _augval419 = ((_augval419) < (_val423)) ? (_augval419) : (_val423);
                }
                (_cursor408)._min_ay13 = _augval419;
                /* _max_ay24 is max of ay2 */
                var _augval424 = (_cursor408).ay2;
                var _child425 = (_cursor408)._left7;
                if (!((_child425) == null)) {
                    var _val426 = (_child425)._max_ay24;
                    _augval424 = ((_augval424) < (_val426)) ? (_val426) : (_augval424);
                }
                var _child427 = (_cursor408)._right8;
                if (!((_child427) == null)) {
                    var _val428 = (_child427)._max_ay24;
                    _augval424 = ((_augval424) < (_val428)) ? (_val428) : (_augval424);
                }
                (_cursor408)._max_ay24 = _augval424;
                (_cursor408)._height10 = 1 + ((((((_cursor408)._left7) == null) ? (-1) : (((_cursor408)._left7)._height10)) > ((((_cursor408)._right8) == null) ? (-1) : (((_cursor408)._right8)._height10))) ? ((((_cursor408)._left7) == null) ? (-1) : (((_cursor408)._left7)._height10)) : ((((_cursor408)._right8) == null) ? (-1) : (((_cursor408)._right8)._height10)));
                _changed409 = false;
                _changed409 = (_changed409) || (!((_old__min_ax12410) == ((_cursor408)._min_ax12)));
                _changed409 = (_changed409) || (!((_old__min_ay13411) == ((_cursor408)._min_ay13)));
                _changed409 = (_changed409) || (!((_old__max_ay24412) == ((_cursor408)._max_ay24)));
                _changed409 = (_changed409) || (!((_old_height413) == ((_cursor408)._height10)));
                _cursor408 = (_cursor408)._parent9;
            }
        }
        var _cursor429 = _parent383;
        var _changed430 = true;
        while ((_changed430) && (!((_cursor429) == (null)))) {
            var _old__min_ax12431 = (_cursor429)._min_ax12;
            var _old__min_ay13432 = (_cursor429)._min_ay13;
            var _old__max_ay24433 = (_cursor429)._max_ay24;
            var _old_height434 = (_cursor429)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval435 = (_cursor429).ax1;
            var _child436 = (_cursor429)._left7;
            if (!((_child436) == null)) {
                var _val437 = (_child436)._min_ax12;
                _augval435 = ((_augval435) < (_val437)) ? (_augval435) : (_val437);
            }
            var _child438 = (_cursor429)._right8;
            if (!((_child438) == null)) {
                var _val439 = (_child438)._min_ax12;
                _augval435 = ((_augval435) < (_val439)) ? (_augval435) : (_val439);
            }
            (_cursor429)._min_ax12 = _augval435;
            /* _min_ay13 is min of ay1 */
            var _augval440 = (_cursor429).ay1;
            var _child441 = (_cursor429)._left7;
            if (!((_child441) == null)) {
                var _val442 = (_child441)._min_ay13;
                _augval440 = ((_augval440) < (_val442)) ? (_augval440) : (_val442);
            }
            var _child443 = (_cursor429)._right8;
            if (!((_child443) == null)) {
                var _val444 = (_child443)._min_ay13;
                _augval440 = ((_augval440) < (_val444)) ? (_augval440) : (_val444);
            }
            (_cursor429)._min_ay13 = _augval440;
            /* _max_ay24 is max of ay2 */
            var _augval445 = (_cursor429).ay2;
            var _child446 = (_cursor429)._left7;
            if (!((_child446) == null)) {
                var _val447 = (_child446)._max_ay24;
                _augval445 = ((_augval445) < (_val447)) ? (_val447) : (_augval445);
            }
            var _child448 = (_cursor429)._right8;
            if (!((_child448) == null)) {
                var _val449 = (_child448)._max_ay24;
                _augval445 = ((_augval445) < (_val449)) ? (_val449) : (_augval445);
            }
            (_cursor429)._max_ay24 = _augval445;
            (_cursor429)._height10 = 1 + ((((((_cursor429)._left7) == null) ? (-1) : (((_cursor429)._left7)._height10)) > ((((_cursor429)._right8) == null) ? (-1) : (((_cursor429)._right8)._height10))) ? ((((_cursor429)._left7) == null) ? (-1) : (((_cursor429)._left7)._height10)) : ((((_cursor429)._right8) == null) ? (-1) : (((_cursor429)._right8)._height10)));
            _changed430 = false;
            _changed430 = (_changed430) || (!((_old__min_ax12431) == ((_cursor429)._min_ax12)));
            _changed430 = (_changed430) || (!((_old__min_ay13432) == ((_cursor429)._min_ay13)));
            _changed430 = (_changed430) || (!((_old__max_ay24433) == ((_cursor429)._max_ay24)));
            _changed430 = (_changed430) || (!((_old_height434) == ((_cursor429)._height10)));
            _cursor429 = (_cursor429)._parent9;
        }
        if (((this)._root1) == (__x)) {
            (this)._root1 = _new_x386;
        }
        (__x)._left7 = null;
        (__x)._right8 = null;
        (__x)._min_ax12 = (__x).ax1;
        (__x)._min_ay13 = (__x).ay1;
        (__x)._max_ay24 = (__x).ay2;
        (__x)._height10 = 0;
        var _previous450 = null;
        var _current451 = (this)._root1;
        var _is_left452 = false;
        while (!((_current451) == null)) {
            _previous450 = _current451;
            if ((new_val) < ((_current451).ax2)) {
                _current451 = (_current451)._left7;
                _is_left452 = true;
            } else {
                _current451 = (_current451)._right8;
                _is_left452 = false;
            }
        }
        if ((_previous450) == null) {
            (this)._root1 = __x;
        } else {
            (__x)._parent9 = _previous450;
            if (_is_left452) {
                (_previous450)._left7 = __x;
            } else {
                (_previous450)._right8 = __x;
            }
        }
        var _cursor453 = (__x)._parent9;
        var _changed454 = true;
        while ((_changed454) && (!((_cursor453) == (null)))) {
            var _old__min_ax12455 = (_cursor453)._min_ax12;
            var _old__min_ay13456 = (_cursor453)._min_ay13;
            var _old__max_ay24457 = (_cursor453)._max_ay24;
            var _old_height458 = (_cursor453)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval459 = (_cursor453).ax1;
            var _child460 = (_cursor453)._left7;
            if (!((_child460) == null)) {
                var _val461 = (_child460)._min_ax12;
                _augval459 = ((_augval459) < (_val461)) ? (_augval459) : (_val461);
            }
            var _child462 = (_cursor453)._right8;
            if (!((_child462) == null)) {
                var _val463 = (_child462)._min_ax12;
                _augval459 = ((_augval459) < (_val463)) ? (_augval459) : (_val463);
            }
            (_cursor453)._min_ax12 = _augval459;
            /* _min_ay13 is min of ay1 */
            var _augval464 = (_cursor453).ay1;
            var _child465 = (_cursor453)._left7;
            if (!((_child465) == null)) {
                var _val466 = (_child465)._min_ay13;
                _augval464 = ((_augval464) < (_val466)) ? (_augval464) : (_val466);
            }
            var _child467 = (_cursor453)._right8;
            if (!((_child467) == null)) {
                var _val468 = (_child467)._min_ay13;
                _augval464 = ((_augval464) < (_val468)) ? (_augval464) : (_val468);
            }
            (_cursor453)._min_ay13 = _augval464;
            /* _max_ay24 is max of ay2 */
            var _augval469 = (_cursor453).ay2;
            var _child470 = (_cursor453)._left7;
            if (!((_child470) == null)) {
                var _val471 = (_child470)._max_ay24;
                _augval469 = ((_augval469) < (_val471)) ? (_val471) : (_augval469);
            }
            var _child472 = (_cursor453)._right8;
            if (!((_child472) == null)) {
                var _val473 = (_child472)._max_ay24;
                _augval469 = ((_augval469) < (_val473)) ? (_val473) : (_augval469);
            }
            (_cursor453)._max_ay24 = _augval469;
            (_cursor453)._height10 = 1 + ((((((_cursor453)._left7) == null) ? (-1) : (((_cursor453)._left7)._height10)) > ((((_cursor453)._right8) == null) ? (-1) : (((_cursor453)._right8)._height10))) ? ((((_cursor453)._left7) == null) ? (-1) : (((_cursor453)._left7)._height10)) : ((((_cursor453)._right8) == null) ? (-1) : (((_cursor453)._right8)._height10)));
            _changed454 = false;
            _changed454 = (_changed454) || (!((_old__min_ax12455) == ((_cursor453)._min_ax12)));
            _changed454 = (_changed454) || (!((_old__min_ay13456) == ((_cursor453)._min_ay13)));
            _changed454 = (_changed454) || (!((_old__max_ay24457) == ((_cursor453)._max_ay24)));
            _changed454 = (_changed454) || (!((_old_height458) == ((_cursor453)._height10)));
            _cursor453 = (_cursor453)._parent9;
        }
        /* rebalance AVL tree */
        var _cursor474 = __x;
        var _imbalance475;
        while (!(((_cursor474)._parent9) == null)) {
            _cursor474 = (_cursor474)._parent9;
            (_cursor474)._height10 = 1 + ((((((_cursor474)._left7) == null) ? (-1) : (((_cursor474)._left7)._height10)) > ((((_cursor474)._right8) == null) ? (-1) : (((_cursor474)._right8)._height10))) ? ((((_cursor474)._left7) == null) ? (-1) : (((_cursor474)._left7)._height10)) : ((((_cursor474)._right8) == null) ? (-1) : (((_cursor474)._right8)._height10)));
            _imbalance475 = ((((_cursor474)._left7) == null) ? (-1) : (((_cursor474)._left7)._height10)) - ((((_cursor474)._right8) == null) ? (-1) : (((_cursor474)._right8)._height10));
            if ((_imbalance475) > (1)) {
                if ((((((_cursor474)._left7)._left7) == null) ? (-1) : ((((_cursor474)._left7)._left7)._height10)) < (((((_cursor474)._left7)._right8) == null) ? (-1) : ((((_cursor474)._left7)._right8)._height10))) {
                    /* rotate ((_cursor474)._left7)._right8 */
                    var _a476 = (_cursor474)._left7;
                    var _b477 = (_a476)._right8;
                    var _c478 = (_b477)._left7;
                    /* replace _a476 with _b477 in (_a476)._parent9 */
                    if (!(((_a476)._parent9) == null)) {
                        if ((((_a476)._parent9)._left7) == (_a476)) {
                            ((_a476)._parent9)._left7 = _b477;
                        } else {
                            ((_a476)._parent9)._right8 = _b477;
                        }
                    }
                    if (!((_b477) == null)) {
                        (_b477)._parent9 = (_a476)._parent9;
                    }
                    /* replace _c478 with _a476 in _b477 */
                    (_b477)._left7 = _a476;
                    if (!((_a476) == null)) {
                        (_a476)._parent9 = _b477;
                    }
                    /* replace _b477 with _c478 in _a476 */
                    (_a476)._right8 = _c478;
                    if (!((_c478) == null)) {
                        (_c478)._parent9 = _a476;
                    }
                    /* _min_ax12 is min of ax1 */
                    var _augval479 = (_a476).ax1;
                    var _child480 = (_a476)._left7;
                    if (!((_child480) == null)) {
                        var _val481 = (_child480)._min_ax12;
                        _augval479 = ((_augval479) < (_val481)) ? (_augval479) : (_val481);
                    }
                    var _child482 = (_a476)._right8;
                    if (!((_child482) == null)) {
                        var _val483 = (_child482)._min_ax12;
                        _augval479 = ((_augval479) < (_val483)) ? (_augval479) : (_val483);
                    }
                    (_a476)._min_ax12 = _augval479;
                    /* _min_ay13 is min of ay1 */
                    var _augval484 = (_a476).ay1;
                    var _child485 = (_a476)._left7;
                    if (!((_child485) == null)) {
                        var _val486 = (_child485)._min_ay13;
                        _augval484 = ((_augval484) < (_val486)) ? (_augval484) : (_val486);
                    }
                    var _child487 = (_a476)._right8;
                    if (!((_child487) == null)) {
                        var _val488 = (_child487)._min_ay13;
                        _augval484 = ((_augval484) < (_val488)) ? (_augval484) : (_val488);
                    }
                    (_a476)._min_ay13 = _augval484;
                    /* _max_ay24 is max of ay2 */
                    var _augval489 = (_a476).ay2;
                    var _child490 = (_a476)._left7;
                    if (!((_child490) == null)) {
                        var _val491 = (_child490)._max_ay24;
                        _augval489 = ((_augval489) < (_val491)) ? (_val491) : (_augval489);
                    }
                    var _child492 = (_a476)._right8;
                    if (!((_child492) == null)) {
                        var _val493 = (_child492)._max_ay24;
                        _augval489 = ((_augval489) < (_val493)) ? (_val493) : (_augval489);
                    }
                    (_a476)._max_ay24 = _augval489;
                    (_a476)._height10 = 1 + ((((((_a476)._left7) == null) ? (-1) : (((_a476)._left7)._height10)) > ((((_a476)._right8) == null) ? (-1) : (((_a476)._right8)._height10))) ? ((((_a476)._left7) == null) ? (-1) : (((_a476)._left7)._height10)) : ((((_a476)._right8) == null) ? (-1) : (((_a476)._right8)._height10)));
                    /* _min_ax12 is min of ax1 */
                    var _augval494 = (_b477).ax1;
                    var _child495 = (_b477)._left7;
                    if (!((_child495) == null)) {
                        var _val496 = (_child495)._min_ax12;
                        _augval494 = ((_augval494) < (_val496)) ? (_augval494) : (_val496);
                    }
                    var _child497 = (_b477)._right8;
                    if (!((_child497) == null)) {
                        var _val498 = (_child497)._min_ax12;
                        _augval494 = ((_augval494) < (_val498)) ? (_augval494) : (_val498);
                    }
                    (_b477)._min_ax12 = _augval494;
                    /* _min_ay13 is min of ay1 */
                    var _augval499 = (_b477).ay1;
                    var _child500 = (_b477)._left7;
                    if (!((_child500) == null)) {
                        var _val501 = (_child500)._min_ay13;
                        _augval499 = ((_augval499) < (_val501)) ? (_augval499) : (_val501);
                    }
                    var _child502 = (_b477)._right8;
                    if (!((_child502) == null)) {
                        var _val503 = (_child502)._min_ay13;
                        _augval499 = ((_augval499) < (_val503)) ? (_augval499) : (_val503);
                    }
                    (_b477)._min_ay13 = _augval499;
                    /* _max_ay24 is max of ay2 */
                    var _augval504 = (_b477).ay2;
                    var _child505 = (_b477)._left7;
                    if (!((_child505) == null)) {
                        var _val506 = (_child505)._max_ay24;
                        _augval504 = ((_augval504) < (_val506)) ? (_val506) : (_augval504);
                    }
                    var _child507 = (_b477)._right8;
                    if (!((_child507) == null)) {
                        var _val508 = (_child507)._max_ay24;
                        _augval504 = ((_augval504) < (_val508)) ? (_val508) : (_augval504);
                    }
                    (_b477)._max_ay24 = _augval504;
                    (_b477)._height10 = 1 + ((((((_b477)._left7) == null) ? (-1) : (((_b477)._left7)._height10)) > ((((_b477)._right8) == null) ? (-1) : (((_b477)._right8)._height10))) ? ((((_b477)._left7) == null) ? (-1) : (((_b477)._left7)._height10)) : ((((_b477)._right8) == null) ? (-1) : (((_b477)._right8)._height10)));
                    if (!(((_b477)._parent9) == null)) {
                        /* _min_ax12 is min of ax1 */
                        var _augval509 = ((_b477)._parent9).ax1;
                        var _child510 = ((_b477)._parent9)._left7;
                        if (!((_child510) == null)) {
                            var _val511 = (_child510)._min_ax12;
                            _augval509 = ((_augval509) < (_val511)) ? (_augval509) : (_val511);
                        }
                        var _child512 = ((_b477)._parent9)._right8;
                        if (!((_child512) == null)) {
                            var _val513 = (_child512)._min_ax12;
                            _augval509 = ((_augval509) < (_val513)) ? (_augval509) : (_val513);
                        }
                        ((_b477)._parent9)._min_ax12 = _augval509;
                        /* _min_ay13 is min of ay1 */
                        var _augval514 = ((_b477)._parent9).ay1;
                        var _child515 = ((_b477)._parent9)._left7;
                        if (!((_child515) == null)) {
                            var _val516 = (_child515)._min_ay13;
                            _augval514 = ((_augval514) < (_val516)) ? (_augval514) : (_val516);
                        }
                        var _child517 = ((_b477)._parent9)._right8;
                        if (!((_child517) == null)) {
                            var _val518 = (_child517)._min_ay13;
                            _augval514 = ((_augval514) < (_val518)) ? (_augval514) : (_val518);
                        }
                        ((_b477)._parent9)._min_ay13 = _augval514;
                        /* _max_ay24 is max of ay2 */
                        var _augval519 = ((_b477)._parent9).ay2;
                        var _child520 = ((_b477)._parent9)._left7;
                        if (!((_child520) == null)) {
                            var _val521 = (_child520)._max_ay24;
                            _augval519 = ((_augval519) < (_val521)) ? (_val521) : (_augval519);
                        }
                        var _child522 = ((_b477)._parent9)._right8;
                        if (!((_child522) == null)) {
                            var _val523 = (_child522)._max_ay24;
                            _augval519 = ((_augval519) < (_val523)) ? (_val523) : (_augval519);
                        }
                        ((_b477)._parent9)._max_ay24 = _augval519;
                        ((_b477)._parent9)._height10 = 1 + (((((((_b477)._parent9)._left7) == null) ? (-1) : ((((_b477)._parent9)._left7)._height10)) > (((((_b477)._parent9)._right8) == null) ? (-1) : ((((_b477)._parent9)._right8)._height10))) ? (((((_b477)._parent9)._left7) == null) ? (-1) : ((((_b477)._parent9)._left7)._height10)) : (((((_b477)._parent9)._right8) == null) ? (-1) : ((((_b477)._parent9)._right8)._height10)));
                    } else {
                        (this)._root1 = _b477;
                    }
                }
                /* rotate (_cursor474)._left7 */
                var _a524 = _cursor474;
                var _b525 = (_a524)._left7;
                var _c526 = (_b525)._right8;
                /* replace _a524 with _b525 in (_a524)._parent9 */
                if (!(((_a524)._parent9) == null)) {
                    if ((((_a524)._parent9)._left7) == (_a524)) {
                        ((_a524)._parent9)._left7 = _b525;
                    } else {
                        ((_a524)._parent9)._right8 = _b525;
                    }
                }
                if (!((_b525) == null)) {
                    (_b525)._parent9 = (_a524)._parent9;
                }
                /* replace _c526 with _a524 in _b525 */
                (_b525)._right8 = _a524;
                if (!((_a524) == null)) {
                    (_a524)._parent9 = _b525;
                }
                /* replace _b525 with _c526 in _a524 */
                (_a524)._left7 = _c526;
                if (!((_c526) == null)) {
                    (_c526)._parent9 = _a524;
                }
                /* _min_ax12 is min of ax1 */
                var _augval527 = (_a524).ax1;
                var _child528 = (_a524)._left7;
                if (!((_child528) == null)) {
                    var _val529 = (_child528)._min_ax12;
                    _augval527 = ((_augval527) < (_val529)) ? (_augval527) : (_val529);
                }
                var _child530 = (_a524)._right8;
                if (!((_child530) == null)) {
                    var _val531 = (_child530)._min_ax12;
                    _augval527 = ((_augval527) < (_val531)) ? (_augval527) : (_val531);
                }
                (_a524)._min_ax12 = _augval527;
                /* _min_ay13 is min of ay1 */
                var _augval532 = (_a524).ay1;
                var _child533 = (_a524)._left7;
                if (!((_child533) == null)) {
                    var _val534 = (_child533)._min_ay13;
                    _augval532 = ((_augval532) < (_val534)) ? (_augval532) : (_val534);
                }
                var _child535 = (_a524)._right8;
                if (!((_child535) == null)) {
                    var _val536 = (_child535)._min_ay13;
                    _augval532 = ((_augval532) < (_val536)) ? (_augval532) : (_val536);
                }
                (_a524)._min_ay13 = _augval532;
                /* _max_ay24 is max of ay2 */
                var _augval537 = (_a524).ay2;
                var _child538 = (_a524)._left7;
                if (!((_child538) == null)) {
                    var _val539 = (_child538)._max_ay24;
                    _augval537 = ((_augval537) < (_val539)) ? (_val539) : (_augval537);
                }
                var _child540 = (_a524)._right8;
                if (!((_child540) == null)) {
                    var _val541 = (_child540)._max_ay24;
                    _augval537 = ((_augval537) < (_val541)) ? (_val541) : (_augval537);
                }
                (_a524)._max_ay24 = _augval537;
                (_a524)._height10 = 1 + ((((((_a524)._left7) == null) ? (-1) : (((_a524)._left7)._height10)) > ((((_a524)._right8) == null) ? (-1) : (((_a524)._right8)._height10))) ? ((((_a524)._left7) == null) ? (-1) : (((_a524)._left7)._height10)) : ((((_a524)._right8) == null) ? (-1) : (((_a524)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval542 = (_b525).ax1;
                var _child543 = (_b525)._left7;
                if (!((_child543) == null)) {
                    var _val544 = (_child543)._min_ax12;
                    _augval542 = ((_augval542) < (_val544)) ? (_augval542) : (_val544);
                }
                var _child545 = (_b525)._right8;
                if (!((_child545) == null)) {
                    var _val546 = (_child545)._min_ax12;
                    _augval542 = ((_augval542) < (_val546)) ? (_augval542) : (_val546);
                }
                (_b525)._min_ax12 = _augval542;
                /* _min_ay13 is min of ay1 */
                var _augval547 = (_b525).ay1;
                var _child548 = (_b525)._left7;
                if (!((_child548) == null)) {
                    var _val549 = (_child548)._min_ay13;
                    _augval547 = ((_augval547) < (_val549)) ? (_augval547) : (_val549);
                }
                var _child550 = (_b525)._right8;
                if (!((_child550) == null)) {
                    var _val551 = (_child550)._min_ay13;
                    _augval547 = ((_augval547) < (_val551)) ? (_augval547) : (_val551);
                }
                (_b525)._min_ay13 = _augval547;
                /* _max_ay24 is max of ay2 */
                var _augval552 = (_b525).ay2;
                var _child553 = (_b525)._left7;
                if (!((_child553) == null)) {
                    var _val554 = (_child553)._max_ay24;
                    _augval552 = ((_augval552) < (_val554)) ? (_val554) : (_augval552);
                }
                var _child555 = (_b525)._right8;
                if (!((_child555) == null)) {
                    var _val556 = (_child555)._max_ay24;
                    _augval552 = ((_augval552) < (_val556)) ? (_val556) : (_augval552);
                }
                (_b525)._max_ay24 = _augval552;
                (_b525)._height10 = 1 + ((((((_b525)._left7) == null) ? (-1) : (((_b525)._left7)._height10)) > ((((_b525)._right8) == null) ? (-1) : (((_b525)._right8)._height10))) ? ((((_b525)._left7) == null) ? (-1) : (((_b525)._left7)._height10)) : ((((_b525)._right8) == null) ? (-1) : (((_b525)._right8)._height10)));
                if (!(((_b525)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval557 = ((_b525)._parent9).ax1;
                    var _child558 = ((_b525)._parent9)._left7;
                    if (!((_child558) == null)) {
                        var _val559 = (_child558)._min_ax12;
                        _augval557 = ((_augval557) < (_val559)) ? (_augval557) : (_val559);
                    }
                    var _child560 = ((_b525)._parent9)._right8;
                    if (!((_child560) == null)) {
                        var _val561 = (_child560)._min_ax12;
                        _augval557 = ((_augval557) < (_val561)) ? (_augval557) : (_val561);
                    }
                    ((_b525)._parent9)._min_ax12 = _augval557;
                    /* _min_ay13 is min of ay1 */
                    var _augval562 = ((_b525)._parent9).ay1;
                    var _child563 = ((_b525)._parent9)._left7;
                    if (!((_child563) == null)) {
                        var _val564 = (_child563)._min_ay13;
                        _augval562 = ((_augval562) < (_val564)) ? (_augval562) : (_val564);
                    }
                    var _child565 = ((_b525)._parent9)._right8;
                    if (!((_child565) == null)) {
                        var _val566 = (_child565)._min_ay13;
                        _augval562 = ((_augval562) < (_val566)) ? (_augval562) : (_val566);
                    }
                    ((_b525)._parent9)._min_ay13 = _augval562;
                    /* _max_ay24 is max of ay2 */
                    var _augval567 = ((_b525)._parent9).ay2;
                    var _child568 = ((_b525)._parent9)._left7;
                    if (!((_child568) == null)) {
                        var _val569 = (_child568)._max_ay24;
                        _augval567 = ((_augval567) < (_val569)) ? (_val569) : (_augval567);
                    }
                    var _child570 = ((_b525)._parent9)._right8;
                    if (!((_child570) == null)) {
                        var _val571 = (_child570)._max_ay24;
                        _augval567 = ((_augval567) < (_val571)) ? (_val571) : (_augval567);
                    }
                    ((_b525)._parent9)._max_ay24 = _augval567;
                    ((_b525)._parent9)._height10 = 1 + (((((((_b525)._parent9)._left7) == null) ? (-1) : ((((_b525)._parent9)._left7)._height10)) > (((((_b525)._parent9)._right8) == null) ? (-1) : ((((_b525)._parent9)._right8)._height10))) ? (((((_b525)._parent9)._left7) == null) ? (-1) : ((((_b525)._parent9)._left7)._height10)) : (((((_b525)._parent9)._right8) == null) ? (-1) : ((((_b525)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b525;
                }
                _cursor474 = (_cursor474)._parent9;
            } else if ((_imbalance475) < (-1)) {
                if ((((((_cursor474)._right8)._left7) == null) ? (-1) : ((((_cursor474)._right8)._left7)._height10)) > (((((_cursor474)._right8)._right8) == null) ? (-1) : ((((_cursor474)._right8)._right8)._height10))) {
                    /* rotate ((_cursor474)._right8)._left7 */
                    var _a572 = (_cursor474)._right8;
                    var _b573 = (_a572)._left7;
                    var _c574 = (_b573)._right8;
                    /* replace _a572 with _b573 in (_a572)._parent9 */
                    if (!(((_a572)._parent9) == null)) {
                        if ((((_a572)._parent9)._left7) == (_a572)) {
                            ((_a572)._parent9)._left7 = _b573;
                        } else {
                            ((_a572)._parent9)._right8 = _b573;
                        }
                    }
                    if (!((_b573) == null)) {
                        (_b573)._parent9 = (_a572)._parent9;
                    }
                    /* replace _c574 with _a572 in _b573 */
                    (_b573)._right8 = _a572;
                    if (!((_a572) == null)) {
                        (_a572)._parent9 = _b573;
                    }
                    /* replace _b573 with _c574 in _a572 */
                    (_a572)._left7 = _c574;
                    if (!((_c574) == null)) {
                        (_c574)._parent9 = _a572;
                    }
                    /* _min_ax12 is min of ax1 */
                    var _augval575 = (_a572).ax1;
                    var _child576 = (_a572)._left7;
                    if (!((_child576) == null)) {
                        var _val577 = (_child576)._min_ax12;
                        _augval575 = ((_augval575) < (_val577)) ? (_augval575) : (_val577);
                    }
                    var _child578 = (_a572)._right8;
                    if (!((_child578) == null)) {
                        var _val579 = (_child578)._min_ax12;
                        _augval575 = ((_augval575) < (_val579)) ? (_augval575) : (_val579);
                    }
                    (_a572)._min_ax12 = _augval575;
                    /* _min_ay13 is min of ay1 */
                    var _augval580 = (_a572).ay1;
                    var _child581 = (_a572)._left7;
                    if (!((_child581) == null)) {
                        var _val582 = (_child581)._min_ay13;
                        _augval580 = ((_augval580) < (_val582)) ? (_augval580) : (_val582);
                    }
                    var _child583 = (_a572)._right8;
                    if (!((_child583) == null)) {
                        var _val584 = (_child583)._min_ay13;
                        _augval580 = ((_augval580) < (_val584)) ? (_augval580) : (_val584);
                    }
                    (_a572)._min_ay13 = _augval580;
                    /* _max_ay24 is max of ay2 */
                    var _augval585 = (_a572).ay2;
                    var _child586 = (_a572)._left7;
                    if (!((_child586) == null)) {
                        var _val587 = (_child586)._max_ay24;
                        _augval585 = ((_augval585) < (_val587)) ? (_val587) : (_augval585);
                    }
                    var _child588 = (_a572)._right8;
                    if (!((_child588) == null)) {
                        var _val589 = (_child588)._max_ay24;
                        _augval585 = ((_augval585) < (_val589)) ? (_val589) : (_augval585);
                    }
                    (_a572)._max_ay24 = _augval585;
                    (_a572)._height10 = 1 + ((((((_a572)._left7) == null) ? (-1) : (((_a572)._left7)._height10)) > ((((_a572)._right8) == null) ? (-1) : (((_a572)._right8)._height10))) ? ((((_a572)._left7) == null) ? (-1) : (((_a572)._left7)._height10)) : ((((_a572)._right8) == null) ? (-1) : (((_a572)._right8)._height10)));
                    /* _min_ax12 is min of ax1 */
                    var _augval590 = (_b573).ax1;
                    var _child591 = (_b573)._left7;
                    if (!((_child591) == null)) {
                        var _val592 = (_child591)._min_ax12;
                        _augval590 = ((_augval590) < (_val592)) ? (_augval590) : (_val592);
                    }
                    var _child593 = (_b573)._right8;
                    if (!((_child593) == null)) {
                        var _val594 = (_child593)._min_ax12;
                        _augval590 = ((_augval590) < (_val594)) ? (_augval590) : (_val594);
                    }
                    (_b573)._min_ax12 = _augval590;
                    /* _min_ay13 is min of ay1 */
                    var _augval595 = (_b573).ay1;
                    var _child596 = (_b573)._left7;
                    if (!((_child596) == null)) {
                        var _val597 = (_child596)._min_ay13;
                        _augval595 = ((_augval595) < (_val597)) ? (_augval595) : (_val597);
                    }
                    var _child598 = (_b573)._right8;
                    if (!((_child598) == null)) {
                        var _val599 = (_child598)._min_ay13;
                        _augval595 = ((_augval595) < (_val599)) ? (_augval595) : (_val599);
                    }
                    (_b573)._min_ay13 = _augval595;
                    /* _max_ay24 is max of ay2 */
                    var _augval600 = (_b573).ay2;
                    var _child601 = (_b573)._left7;
                    if (!((_child601) == null)) {
                        var _val602 = (_child601)._max_ay24;
                        _augval600 = ((_augval600) < (_val602)) ? (_val602) : (_augval600);
                    }
                    var _child603 = (_b573)._right8;
                    if (!((_child603) == null)) {
                        var _val604 = (_child603)._max_ay24;
                        _augval600 = ((_augval600) < (_val604)) ? (_val604) : (_augval600);
                    }
                    (_b573)._max_ay24 = _augval600;
                    (_b573)._height10 = 1 + ((((((_b573)._left7) == null) ? (-1) : (((_b573)._left7)._height10)) > ((((_b573)._right8) == null) ? (-1) : (((_b573)._right8)._height10))) ? ((((_b573)._left7) == null) ? (-1) : (((_b573)._left7)._height10)) : ((((_b573)._right8) == null) ? (-1) : (((_b573)._right8)._height10)));
                    if (!(((_b573)._parent9) == null)) {
                        /* _min_ax12 is min of ax1 */
                        var _augval605 = ((_b573)._parent9).ax1;
                        var _child606 = ((_b573)._parent9)._left7;
                        if (!((_child606) == null)) {
                            var _val607 = (_child606)._min_ax12;
                            _augval605 = ((_augval605) < (_val607)) ? (_augval605) : (_val607);
                        }
                        var _child608 = ((_b573)._parent9)._right8;
                        if (!((_child608) == null)) {
                            var _val609 = (_child608)._min_ax12;
                            _augval605 = ((_augval605) < (_val609)) ? (_augval605) : (_val609);
                        }
                        ((_b573)._parent9)._min_ax12 = _augval605;
                        /* _min_ay13 is min of ay1 */
                        var _augval610 = ((_b573)._parent9).ay1;
                        var _child611 = ((_b573)._parent9)._left7;
                        if (!((_child611) == null)) {
                            var _val612 = (_child611)._min_ay13;
                            _augval610 = ((_augval610) < (_val612)) ? (_augval610) : (_val612);
                        }
                        var _child613 = ((_b573)._parent9)._right8;
                        if (!((_child613) == null)) {
                            var _val614 = (_child613)._min_ay13;
                            _augval610 = ((_augval610) < (_val614)) ? (_augval610) : (_val614);
                        }
                        ((_b573)._parent9)._min_ay13 = _augval610;
                        /* _max_ay24 is max of ay2 */
                        var _augval615 = ((_b573)._parent9).ay2;
                        var _child616 = ((_b573)._parent9)._left7;
                        if (!((_child616) == null)) {
                            var _val617 = (_child616)._max_ay24;
                            _augval615 = ((_augval615) < (_val617)) ? (_val617) : (_augval615);
                        }
                        var _child618 = ((_b573)._parent9)._right8;
                        if (!((_child618) == null)) {
                            var _val619 = (_child618)._max_ay24;
                            _augval615 = ((_augval615) < (_val619)) ? (_val619) : (_augval615);
                        }
                        ((_b573)._parent9)._max_ay24 = _augval615;
                        ((_b573)._parent9)._height10 = 1 + (((((((_b573)._parent9)._left7) == null) ? (-1) : ((((_b573)._parent9)._left7)._height10)) > (((((_b573)._parent9)._right8) == null) ? (-1) : ((((_b573)._parent9)._right8)._height10))) ? (((((_b573)._parent9)._left7) == null) ? (-1) : ((((_b573)._parent9)._left7)._height10)) : (((((_b573)._parent9)._right8) == null) ? (-1) : ((((_b573)._parent9)._right8)._height10)));
                    } else {
                        (this)._root1 = _b573;
                    }
                }
                /* rotate (_cursor474)._right8 */
                var _a620 = _cursor474;
                var _b621 = (_a620)._right8;
                var _c622 = (_b621)._left7;
                /* replace _a620 with _b621 in (_a620)._parent9 */
                if (!(((_a620)._parent9) == null)) {
                    if ((((_a620)._parent9)._left7) == (_a620)) {
                        ((_a620)._parent9)._left7 = _b621;
                    } else {
                        ((_a620)._parent9)._right8 = _b621;
                    }
                }
                if (!((_b621) == null)) {
                    (_b621)._parent9 = (_a620)._parent9;
                }
                /* replace _c622 with _a620 in _b621 */
                (_b621)._left7 = _a620;
                if (!((_a620) == null)) {
                    (_a620)._parent9 = _b621;
                }
                /* replace _b621 with _c622 in _a620 */
                (_a620)._right8 = _c622;
                if (!((_c622) == null)) {
                    (_c622)._parent9 = _a620;
                }
                /* _min_ax12 is min of ax1 */
                var _augval623 = (_a620).ax1;
                var _child624 = (_a620)._left7;
                if (!((_child624) == null)) {
                    var _val625 = (_child624)._min_ax12;
                    _augval623 = ((_augval623) < (_val625)) ? (_augval623) : (_val625);
                }
                var _child626 = (_a620)._right8;
                if (!((_child626) == null)) {
                    var _val627 = (_child626)._min_ax12;
                    _augval623 = ((_augval623) < (_val627)) ? (_augval623) : (_val627);
                }
                (_a620)._min_ax12 = _augval623;
                /* _min_ay13 is min of ay1 */
                var _augval628 = (_a620).ay1;
                var _child629 = (_a620)._left7;
                if (!((_child629) == null)) {
                    var _val630 = (_child629)._min_ay13;
                    _augval628 = ((_augval628) < (_val630)) ? (_augval628) : (_val630);
                }
                var _child631 = (_a620)._right8;
                if (!((_child631) == null)) {
                    var _val632 = (_child631)._min_ay13;
                    _augval628 = ((_augval628) < (_val632)) ? (_augval628) : (_val632);
                }
                (_a620)._min_ay13 = _augval628;
                /* _max_ay24 is max of ay2 */
                var _augval633 = (_a620).ay2;
                var _child634 = (_a620)._left7;
                if (!((_child634) == null)) {
                    var _val635 = (_child634)._max_ay24;
                    _augval633 = ((_augval633) < (_val635)) ? (_val635) : (_augval633);
                }
                var _child636 = (_a620)._right8;
                if (!((_child636) == null)) {
                    var _val637 = (_child636)._max_ay24;
                    _augval633 = ((_augval633) < (_val637)) ? (_val637) : (_augval633);
                }
                (_a620)._max_ay24 = _augval633;
                (_a620)._height10 = 1 + ((((((_a620)._left7) == null) ? (-1) : (((_a620)._left7)._height10)) > ((((_a620)._right8) == null) ? (-1) : (((_a620)._right8)._height10))) ? ((((_a620)._left7) == null) ? (-1) : (((_a620)._left7)._height10)) : ((((_a620)._right8) == null) ? (-1) : (((_a620)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval638 = (_b621).ax1;
                var _child639 = (_b621)._left7;
                if (!((_child639) == null)) {
                    var _val640 = (_child639)._min_ax12;
                    _augval638 = ((_augval638) < (_val640)) ? (_augval638) : (_val640);
                }
                var _child641 = (_b621)._right8;
                if (!((_child641) == null)) {
                    var _val642 = (_child641)._min_ax12;
                    _augval638 = ((_augval638) < (_val642)) ? (_augval638) : (_val642);
                }
                (_b621)._min_ax12 = _augval638;
                /* _min_ay13 is min of ay1 */
                var _augval643 = (_b621).ay1;
                var _child644 = (_b621)._left7;
                if (!((_child644) == null)) {
                    var _val645 = (_child644)._min_ay13;
                    _augval643 = ((_augval643) < (_val645)) ? (_augval643) : (_val645);
                }
                var _child646 = (_b621)._right8;
                if (!((_child646) == null)) {
                    var _val647 = (_child646)._min_ay13;
                    _augval643 = ((_augval643) < (_val647)) ? (_augval643) : (_val647);
                }
                (_b621)._min_ay13 = _augval643;
                /* _max_ay24 is max of ay2 */
                var _augval648 = (_b621).ay2;
                var _child649 = (_b621)._left7;
                if (!((_child649) == null)) {
                    var _val650 = (_child649)._max_ay24;
                    _augval648 = ((_augval648) < (_val650)) ? (_val650) : (_augval648);
                }
                var _child651 = (_b621)._right8;
                if (!((_child651) == null)) {
                    var _val652 = (_child651)._max_ay24;
                    _augval648 = ((_augval648) < (_val652)) ? (_val652) : (_augval648);
                }
                (_b621)._max_ay24 = _augval648;
                (_b621)._height10 = 1 + ((((((_b621)._left7) == null) ? (-1) : (((_b621)._left7)._height10)) > ((((_b621)._right8) == null) ? (-1) : (((_b621)._right8)._height10))) ? ((((_b621)._left7) == null) ? (-1) : (((_b621)._left7)._height10)) : ((((_b621)._right8) == null) ? (-1) : (((_b621)._right8)._height10)));
                if (!(((_b621)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval653 = ((_b621)._parent9).ax1;
                    var _child654 = ((_b621)._parent9)._left7;
                    if (!((_child654) == null)) {
                        var _val655 = (_child654)._min_ax12;
                        _augval653 = ((_augval653) < (_val655)) ? (_augval653) : (_val655);
                    }
                    var _child656 = ((_b621)._parent9)._right8;
                    if (!((_child656) == null)) {
                        var _val657 = (_child656)._min_ax12;
                        _augval653 = ((_augval653) < (_val657)) ? (_augval653) : (_val657);
                    }
                    ((_b621)._parent9)._min_ax12 = _augval653;
                    /* _min_ay13 is min of ay1 */
                    var _augval658 = ((_b621)._parent9).ay1;
                    var _child659 = ((_b621)._parent9)._left7;
                    if (!((_child659) == null)) {
                        var _val660 = (_child659)._min_ay13;
                        _augval658 = ((_augval658) < (_val660)) ? (_augval658) : (_val660);
                    }
                    var _child661 = ((_b621)._parent9)._right8;
                    if (!((_child661) == null)) {
                        var _val662 = (_child661)._min_ay13;
                        _augval658 = ((_augval658) < (_val662)) ? (_augval658) : (_val662);
                    }
                    ((_b621)._parent9)._min_ay13 = _augval658;
                    /* _max_ay24 is max of ay2 */
                    var _augval663 = ((_b621)._parent9).ay2;
                    var _child664 = ((_b621)._parent9)._left7;
                    if (!((_child664) == null)) {
                        var _val665 = (_child664)._max_ay24;
                        _augval663 = ((_augval663) < (_val665)) ? (_val665) : (_augval663);
                    }
                    var _child666 = ((_b621)._parent9)._right8;
                    if (!((_child666) == null)) {
                        var _val667 = (_child666)._max_ay24;
                        _augval663 = ((_augval663) < (_val667)) ? (_val667) : (_augval663);
                    }
                    ((_b621)._parent9)._max_ay24 = _augval663;
                    ((_b621)._parent9)._height10 = 1 + (((((((_b621)._parent9)._left7) == null) ? (-1) : ((((_b621)._parent9)._left7)._height10)) > (((((_b621)._parent9)._right8) == null) ? (-1) : ((((_b621)._parent9)._right8)._height10))) ? (((((_b621)._parent9)._left7) == null) ? (-1) : ((((_b621)._parent9)._left7)._height10)) : (((((_b621)._parent9)._right8) == null) ? (-1) : ((((_b621)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b621;
                }
                _cursor474 = (_cursor474)._parent9;
            }
        }
        (__x).ax2 = new_val;
    }
}
RectangleHolder.prototype.updateAy2 = function (__x, new_val) {
    if ((__x).ay2 != new_val) {
        /* _max_ay24 is max of ay2 */
        var _augval668 = new_val;
        var _child669 = (__x)._left7;
        if (!((_child669) == null)) {
            var _val670 = (_child669)._max_ay24;
            _augval668 = ((_augval668) < (_val670)) ? (_val670) : (_augval668);
        }
        var _child671 = (__x)._right8;
        if (!((_child671) == null)) {
            var _val672 = (_child671)._max_ay24;
            _augval668 = ((_augval668) < (_val672)) ? (_val672) : (_augval668);
        }
        (__x)._max_ay24 = _augval668;
        var _cursor673 = (__x)._parent9;
        var _changed674 = true;
        while ((_changed674) && (!((_cursor673) == (null)))) {
            var _old__max_ay24675 = (_cursor673)._max_ay24;
            var _old_height676 = (_cursor673)._height10;
            /* _max_ay24 is max of ay2 */
            var _augval677 = (_cursor673).ay2;
            var _child678 = (_cursor673)._left7;
            if (!((_child678) == null)) {
                var _val679 = (_child678)._max_ay24;
                _augval677 = ((_augval677) < (_val679)) ? (_val679) : (_augval677);
            }
            var _child680 = (_cursor673)._right8;
            if (!((_child680) == null)) {
                var _val681 = (_child680)._max_ay24;
                _augval677 = ((_augval677) < (_val681)) ? (_val681) : (_augval677);
            }
            (_cursor673)._max_ay24 = _augval677;
            (_cursor673)._height10 = 1 + ((((((_cursor673)._left7) == null) ? (-1) : (((_cursor673)._left7)._height10)) > ((((_cursor673)._right8) == null) ? (-1) : (((_cursor673)._right8)._height10))) ? ((((_cursor673)._left7) == null) ? (-1) : (((_cursor673)._left7)._height10)) : ((((_cursor673)._right8) == null) ? (-1) : (((_cursor673)._right8)._height10)));
            _changed674 = false;
            _changed674 = (_changed674) || (!((_old__max_ay24675) == ((_cursor673)._max_ay24)));
            _changed674 = (_changed674) || (!((_old_height676) == ((_cursor673)._height10)));
            _cursor673 = (_cursor673)._parent9;
        }
        (__x).ay2 = new_val;
    }
}
RectangleHolder.prototype.update = function (__x, ax1, ay1, ax2, ay2) {
    var _parent682 = (__x)._parent9;
    var _left683 = (__x)._left7;
    var _right684 = (__x)._right8;
    var _new_x685;
    if (((_left683) == null) && ((_right684) == null)) {
        _new_x685 = null;
        /* replace __x with _new_x685 in _parent682 */
        if (!((_parent682) == null)) {
            if (((_parent682)._left7) == (__x)) {
                (_parent682)._left7 = _new_x685;
            } else {
                (_parent682)._right8 = _new_x685;
            }
        }
        if (!((_new_x685) == null)) {
            (_new_x685)._parent9 = _parent682;
        }
    } else if ((!((_left683) == null)) && ((_right684) == null)) {
        _new_x685 = _left683;
        /* replace __x with _new_x685 in _parent682 */
        if (!((_parent682) == null)) {
            if (((_parent682)._left7) == (__x)) {
                (_parent682)._left7 = _new_x685;
            } else {
                (_parent682)._right8 = _new_x685;
            }
        }
        if (!((_new_x685) == null)) {
            (_new_x685)._parent9 = _parent682;
        }
    } else if (((_left683) == null) && (!((_right684) == null))) {
        _new_x685 = _right684;
        /* replace __x with _new_x685 in _parent682 */
        if (!((_parent682) == null)) {
            if (((_parent682)._left7) == (__x)) {
                (_parent682)._left7 = _new_x685;
            } else {
                (_parent682)._right8 = _new_x685;
            }
        }
        if (!((_new_x685) == null)) {
            (_new_x685)._parent9 = _parent682;
        }
    } else {
        var _root686 = (__x)._right8;
        var _x687 = _root686;
        var _descend688 = true;
        var _from_left689 = true;
        while (true) {
            if ((_x687) == null) {
                _x687 = null;
                break;
            }
            if (_descend688) {
                /* too small? */
                if (false) {
                    if ((!(((_x687)._right8) == null)) && (true)) {
                        if ((_x687) == (_root686)) {
                            _root686 = (_x687)._right8;
                        }
                        _x687 = (_x687)._right8;
                    } else if ((_x687) == (_root686)) {
                        _x687 = null;
                        break;
                    } else {
                        _descend688 = false;
                        _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                        _x687 = (_x687)._parent9;
                    }
                } else if ((!(((_x687)._left7) == null)) && (true)) {
                    _x687 = (_x687)._left7;
                    /* too large? */
                } else if (false) {
                    if ((_x687) == (_root686)) {
                        _x687 = null;
                        break;
                    } else {
                        _descend688 = false;
                        _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                        _x687 = (_x687)._parent9;
                    }
                    /* node ok? */
                } else if (true) {
                    break;
                } else if ((_x687) == (_root686)) {
                    _root686 = (_x687)._right8;
                    _x687 = (_x687)._right8;
                } else {
                    if ((!(((_x687)._right8) == null)) && (true)) {
                        if ((_x687) == (_root686)) {
                            _root686 = (_x687)._right8;
                        }
                        _x687 = (_x687)._right8;
                    } else {
                        _descend688 = false;
                        _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                        _x687 = (_x687)._parent9;
                    }
                }
            } else if (_from_left689) {
                if (false) {
                    _x687 = null;
                    break;
                } else if (true) {
                    break;
                } else if ((!(((_x687)._right8) == null)) && (true)) {
                    _descend688 = true;
                    if ((_x687) == (_root686)) {
                        _root686 = (_x687)._right8;
                    }
                    _x687 = (_x687)._right8;
                } else if ((_x687) == (_root686)) {
                    _x687 = null;
                    break;
                } else {
                    _descend688 = false;
                    _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                    _x687 = (_x687)._parent9;
                }
            } else {
                if ((_x687) == (_root686)) {
                    _x687 = null;
                    break;
                } else {
                    _descend688 = false;
                    _from_left689 = (!(((_x687)._parent9) == null)) && ((_x687) == (((_x687)._parent9)._left7));
                    _x687 = (_x687)._parent9;
                }
            }
        }
        _new_x685 = _x687;
        var _mp690 = (_x687)._parent9;
        var _mr691 = (_x687)._right8;
        /* replace _x687 with _mr691 in _mp690 */
        if (!((_mp690) == null)) {
            if (((_mp690)._left7) == (_x687)) {
                (_mp690)._left7 = _mr691;
            } else {
                (_mp690)._right8 = _mr691;
            }
        }
        if (!((_mr691) == null)) {
            (_mr691)._parent9 = _mp690;
        }
        /* replace __x with _x687 in _parent682 */
        if (!((_parent682) == null)) {
            if (((_parent682)._left7) == (__x)) {
                (_parent682)._left7 = _x687;
            } else {
                (_parent682)._right8 = _x687;
            }
        }
        if (!((_x687) == null)) {
            (_x687)._parent9 = _parent682;
        }
        /* replace null with _left683 in _x687 */
        (_x687)._left7 = _left683;
        if (!((_left683) == null)) {
            (_left683)._parent9 = _x687;
        }
        /* replace _mr691 with (__x)._right8 in _x687 */
        (_x687)._right8 = (__x)._right8;
        if (!(((__x)._right8) == null)) {
            ((__x)._right8)._parent9 = _x687;
        }
        /* _min_ax12 is min of ax1 */
        var _augval692 = (_x687).ax1;
        var _child693 = (_x687)._left7;
        if (!((_child693) == null)) {
            var _val694 = (_child693)._min_ax12;
            _augval692 = ((_augval692) < (_val694)) ? (_augval692) : (_val694);
        }
        var _child695 = (_x687)._right8;
        if (!((_child695) == null)) {
            var _val696 = (_child695)._min_ax12;
            _augval692 = ((_augval692) < (_val696)) ? (_augval692) : (_val696);
        }
        (_x687)._min_ax12 = _augval692;
        /* _min_ay13 is min of ay1 */
        var _augval697 = (_x687).ay1;
        var _child698 = (_x687)._left7;
        if (!((_child698) == null)) {
            var _val699 = (_child698)._min_ay13;
            _augval697 = ((_augval697) < (_val699)) ? (_augval697) : (_val699);
        }
        var _child700 = (_x687)._right8;
        if (!((_child700) == null)) {
            var _val701 = (_child700)._min_ay13;
            _augval697 = ((_augval697) < (_val701)) ? (_augval697) : (_val701);
        }
        (_x687)._min_ay13 = _augval697;
        /* _max_ay24 is max of ay2 */
        var _augval702 = (_x687).ay2;
        var _child703 = (_x687)._left7;
        if (!((_child703) == null)) {
            var _val704 = (_child703)._max_ay24;
            _augval702 = ((_augval702) < (_val704)) ? (_val704) : (_augval702);
        }
        var _child705 = (_x687)._right8;
        if (!((_child705) == null)) {
            var _val706 = (_child705)._max_ay24;
            _augval702 = ((_augval702) < (_val706)) ? (_val706) : (_augval702);
        }
        (_x687)._max_ay24 = _augval702;
        (_x687)._height10 = 1 + ((((((_x687)._left7) == null) ? (-1) : (((_x687)._left7)._height10)) > ((((_x687)._right8) == null) ? (-1) : (((_x687)._right8)._height10))) ? ((((_x687)._left7) == null) ? (-1) : (((_x687)._left7)._height10)) : ((((_x687)._right8) == null) ? (-1) : (((_x687)._right8)._height10)));
        var _cursor707 = _mp690;
        var _changed708 = true;
        while ((_changed708) && (!((_cursor707) == (_parent682)))) {
            var _old__min_ax12709 = (_cursor707)._min_ax12;
            var _old__min_ay13710 = (_cursor707)._min_ay13;
            var _old__max_ay24711 = (_cursor707)._max_ay24;
            var _old_height712 = (_cursor707)._height10;
            /* _min_ax12 is min of ax1 */
            var _augval713 = (_cursor707).ax1;
            var _child714 = (_cursor707)._left7;
            if (!((_child714) == null)) {
                var _val715 = (_child714)._min_ax12;
                _augval713 = ((_augval713) < (_val715)) ? (_augval713) : (_val715);
            }
            var _child716 = (_cursor707)._right8;
            if (!((_child716) == null)) {
                var _val717 = (_child716)._min_ax12;
                _augval713 = ((_augval713) < (_val717)) ? (_augval713) : (_val717);
            }
            (_cursor707)._min_ax12 = _augval713;
            /* _min_ay13 is min of ay1 */
            var _augval718 = (_cursor707).ay1;
            var _child719 = (_cursor707)._left7;
            if (!((_child719) == null)) {
                var _val720 = (_child719)._min_ay13;
                _augval718 = ((_augval718) < (_val720)) ? (_augval718) : (_val720);
            }
            var _child721 = (_cursor707)._right8;
            if (!((_child721) == null)) {
                var _val722 = (_child721)._min_ay13;
                _augval718 = ((_augval718) < (_val722)) ? (_augval718) : (_val722);
            }
            (_cursor707)._min_ay13 = _augval718;
            /* _max_ay24 is max of ay2 */
            var _augval723 = (_cursor707).ay2;
            var _child724 = (_cursor707)._left7;
            if (!((_child724) == null)) {
                var _val725 = (_child724)._max_ay24;
                _augval723 = ((_augval723) < (_val725)) ? (_val725) : (_augval723);
            }
            var _child726 = (_cursor707)._right8;
            if (!((_child726) == null)) {
                var _val727 = (_child726)._max_ay24;
                _augval723 = ((_augval723) < (_val727)) ? (_val727) : (_augval723);
            }
            (_cursor707)._max_ay24 = _augval723;
            (_cursor707)._height10 = 1 + ((((((_cursor707)._left7) == null) ? (-1) : (((_cursor707)._left7)._height10)) > ((((_cursor707)._right8) == null) ? (-1) : (((_cursor707)._right8)._height10))) ? ((((_cursor707)._left7) == null) ? (-1) : (((_cursor707)._left7)._height10)) : ((((_cursor707)._right8) == null) ? (-1) : (((_cursor707)._right8)._height10)));
            _changed708 = false;
            _changed708 = (_changed708) || (!((_old__min_ax12709) == ((_cursor707)._min_ax12)));
            _changed708 = (_changed708) || (!((_old__min_ay13710) == ((_cursor707)._min_ay13)));
            _changed708 = (_changed708) || (!((_old__max_ay24711) == ((_cursor707)._max_ay24)));
            _changed708 = (_changed708) || (!((_old_height712) == ((_cursor707)._height10)));
            _cursor707 = (_cursor707)._parent9;
        }
    }
    var _cursor728 = _parent682;
    var _changed729 = true;
    while ((_changed729) && (!((_cursor728) == (null)))) {
        var _old__min_ax12730 = (_cursor728)._min_ax12;
        var _old__min_ay13731 = (_cursor728)._min_ay13;
        var _old__max_ay24732 = (_cursor728)._max_ay24;
        var _old_height733 = (_cursor728)._height10;
        /* _min_ax12 is min of ax1 */
        var _augval734 = (_cursor728).ax1;
        var _child735 = (_cursor728)._left7;
        if (!((_child735) == null)) {
            var _val736 = (_child735)._min_ax12;
            _augval734 = ((_augval734) < (_val736)) ? (_augval734) : (_val736);
        }
        var _child737 = (_cursor728)._right8;
        if (!((_child737) == null)) {
            var _val738 = (_child737)._min_ax12;
            _augval734 = ((_augval734) < (_val738)) ? (_augval734) : (_val738);
        }
        (_cursor728)._min_ax12 = _augval734;
        /* _min_ay13 is min of ay1 */
        var _augval739 = (_cursor728).ay1;
        var _child740 = (_cursor728)._left7;
        if (!((_child740) == null)) {
            var _val741 = (_child740)._min_ay13;
            _augval739 = ((_augval739) < (_val741)) ? (_augval739) : (_val741);
        }
        var _child742 = (_cursor728)._right8;
        if (!((_child742) == null)) {
            var _val743 = (_child742)._min_ay13;
            _augval739 = ((_augval739) < (_val743)) ? (_augval739) : (_val743);
        }
        (_cursor728)._min_ay13 = _augval739;
        /* _max_ay24 is max of ay2 */
        var _augval744 = (_cursor728).ay2;
        var _child745 = (_cursor728)._left7;
        if (!((_child745) == null)) {
            var _val746 = (_child745)._max_ay24;
            _augval744 = ((_augval744) < (_val746)) ? (_val746) : (_augval744);
        }
        var _child747 = (_cursor728)._right8;
        if (!((_child747) == null)) {
            var _val748 = (_child747)._max_ay24;
            _augval744 = ((_augval744) < (_val748)) ? (_val748) : (_augval744);
        }
        (_cursor728)._max_ay24 = _augval744;
        (_cursor728)._height10 = 1 + ((((((_cursor728)._left7) == null) ? (-1) : (((_cursor728)._left7)._height10)) > ((((_cursor728)._right8) == null) ? (-1) : (((_cursor728)._right8)._height10))) ? ((((_cursor728)._left7) == null) ? (-1) : (((_cursor728)._left7)._height10)) : ((((_cursor728)._right8) == null) ? (-1) : (((_cursor728)._right8)._height10)));
        _changed729 = false;
        _changed729 = (_changed729) || (!((_old__min_ax12730) == ((_cursor728)._min_ax12)));
        _changed729 = (_changed729) || (!((_old__min_ay13731) == ((_cursor728)._min_ay13)));
        _changed729 = (_changed729) || (!((_old__max_ay24732) == ((_cursor728)._max_ay24)));
        _changed729 = (_changed729) || (!((_old_height733) == ((_cursor728)._height10)));
        _cursor728 = (_cursor728)._parent9;
    }
    if (((this)._root1) == (__x)) {
        (this)._root1 = _new_x685;
    }
    (__x)._left7 = null;
    (__x)._right8 = null;
    (__x)._min_ax12 = (__x).ax1;
    (__x)._min_ay13 = (__x).ay1;
    (__x)._max_ay24 = (__x).ay2;
    (__x)._height10 = 0;
    var _previous749 = null;
    var _current750 = (this)._root1;
    var _is_left751 = false;
    while (!((_current750) == null)) {
        _previous749 = _current750;
        if ((ax2) < ((_current750).ax2)) {
            _current750 = (_current750)._left7;
            _is_left751 = true;
        } else {
            _current750 = (_current750)._right8;
            _is_left751 = false;
        }
    }
    if ((_previous749) == null) {
        (this)._root1 = __x;
    } else {
        (__x)._parent9 = _previous749;
        if (_is_left751) {
            (_previous749)._left7 = __x;
        } else {
            (_previous749)._right8 = __x;
        }
    }
    var _cursor752 = (__x)._parent9;
    var _changed753 = true;
    while ((_changed753) && (!((_cursor752) == (null)))) {
        var _old__min_ax12754 = (_cursor752)._min_ax12;
        var _old__min_ay13755 = (_cursor752)._min_ay13;
        var _old__max_ay24756 = (_cursor752)._max_ay24;
        var _old_height757 = (_cursor752)._height10;
        /* _min_ax12 is min of ax1 */
        var _augval758 = (_cursor752).ax1;
        var _child759 = (_cursor752)._left7;
        if (!((_child759) == null)) {
            var _val760 = (_child759)._min_ax12;
            _augval758 = ((_augval758) < (_val760)) ? (_augval758) : (_val760);
        }
        var _child761 = (_cursor752)._right8;
        if (!((_child761) == null)) {
            var _val762 = (_child761)._min_ax12;
            _augval758 = ((_augval758) < (_val762)) ? (_augval758) : (_val762);
        }
        (_cursor752)._min_ax12 = _augval758;
        /* _min_ay13 is min of ay1 */
        var _augval763 = (_cursor752).ay1;
        var _child764 = (_cursor752)._left7;
        if (!((_child764) == null)) {
            var _val765 = (_child764)._min_ay13;
            _augval763 = ((_augval763) < (_val765)) ? (_augval763) : (_val765);
        }
        var _child766 = (_cursor752)._right8;
        if (!((_child766) == null)) {
            var _val767 = (_child766)._min_ay13;
            _augval763 = ((_augval763) < (_val767)) ? (_augval763) : (_val767);
        }
        (_cursor752)._min_ay13 = _augval763;
        /* _max_ay24 is max of ay2 */
        var _augval768 = (_cursor752).ay2;
        var _child769 = (_cursor752)._left7;
        if (!((_child769) == null)) {
            var _val770 = (_child769)._max_ay24;
            _augval768 = ((_augval768) < (_val770)) ? (_val770) : (_augval768);
        }
        var _child771 = (_cursor752)._right8;
        if (!((_child771) == null)) {
            var _val772 = (_child771)._max_ay24;
            _augval768 = ((_augval768) < (_val772)) ? (_val772) : (_augval768);
        }
        (_cursor752)._max_ay24 = _augval768;
        (_cursor752)._height10 = 1 + ((((((_cursor752)._left7) == null) ? (-1) : (((_cursor752)._left7)._height10)) > ((((_cursor752)._right8) == null) ? (-1) : (((_cursor752)._right8)._height10))) ? ((((_cursor752)._left7) == null) ? (-1) : (((_cursor752)._left7)._height10)) : ((((_cursor752)._right8) == null) ? (-1) : (((_cursor752)._right8)._height10)));
        _changed753 = false;
        _changed753 = (_changed753) || (!((_old__min_ax12754) == ((_cursor752)._min_ax12)));
        _changed753 = (_changed753) || (!((_old__min_ay13755) == ((_cursor752)._min_ay13)));
        _changed753 = (_changed753) || (!((_old__max_ay24756) == ((_cursor752)._max_ay24)));
        _changed753 = (_changed753) || (!((_old_height757) == ((_cursor752)._height10)));
        _cursor752 = (_cursor752)._parent9;
    }
    /* rebalance AVL tree */
    var _cursor773 = __x;
    var _imbalance774;
    while (!(((_cursor773)._parent9) == null)) {
        _cursor773 = (_cursor773)._parent9;
        (_cursor773)._height10 = 1 + ((((((_cursor773)._left7) == null) ? (-1) : (((_cursor773)._left7)._height10)) > ((((_cursor773)._right8) == null) ? (-1) : (((_cursor773)._right8)._height10))) ? ((((_cursor773)._left7) == null) ? (-1) : (((_cursor773)._left7)._height10)) : ((((_cursor773)._right8) == null) ? (-1) : (((_cursor773)._right8)._height10)));
        _imbalance774 = ((((_cursor773)._left7) == null) ? (-1) : (((_cursor773)._left7)._height10)) - ((((_cursor773)._right8) == null) ? (-1) : (((_cursor773)._right8)._height10));
        if ((_imbalance774) > (1)) {
            if ((((((_cursor773)._left7)._left7) == null) ? (-1) : ((((_cursor773)._left7)._left7)._height10)) < (((((_cursor773)._left7)._right8) == null) ? (-1) : ((((_cursor773)._left7)._right8)._height10))) {
                /* rotate ((_cursor773)._left7)._right8 */
                var _a775 = (_cursor773)._left7;
                var _b776 = (_a775)._right8;
                var _c777 = (_b776)._left7;
                /* replace _a775 with _b776 in (_a775)._parent9 */
                if (!(((_a775)._parent9) == null)) {
                    if ((((_a775)._parent9)._left7) == (_a775)) {
                        ((_a775)._parent9)._left7 = _b776;
                    } else {
                        ((_a775)._parent9)._right8 = _b776;
                    }
                }
                if (!((_b776) == null)) {
                    (_b776)._parent9 = (_a775)._parent9;
                }
                /* replace _c777 with _a775 in _b776 */
                (_b776)._left7 = _a775;
                if (!((_a775) == null)) {
                    (_a775)._parent9 = _b776;
                }
                /* replace _b776 with _c777 in _a775 */
                (_a775)._right8 = _c777;
                if (!((_c777) == null)) {
                    (_c777)._parent9 = _a775;
                }
                /* _min_ax12 is min of ax1 */
                var _augval778 = (_a775).ax1;
                var _child779 = (_a775)._left7;
                if (!((_child779) == null)) {
                    var _val780 = (_child779)._min_ax12;
                    _augval778 = ((_augval778) < (_val780)) ? (_augval778) : (_val780);
                }
                var _child781 = (_a775)._right8;
                if (!((_child781) == null)) {
                    var _val782 = (_child781)._min_ax12;
                    _augval778 = ((_augval778) < (_val782)) ? (_augval778) : (_val782);
                }
                (_a775)._min_ax12 = _augval778;
                /* _min_ay13 is min of ay1 */
                var _augval783 = (_a775).ay1;
                var _child784 = (_a775)._left7;
                if (!((_child784) == null)) {
                    var _val785 = (_child784)._min_ay13;
                    _augval783 = ((_augval783) < (_val785)) ? (_augval783) : (_val785);
                }
                var _child786 = (_a775)._right8;
                if (!((_child786) == null)) {
                    var _val787 = (_child786)._min_ay13;
                    _augval783 = ((_augval783) < (_val787)) ? (_augval783) : (_val787);
                }
                (_a775)._min_ay13 = _augval783;
                /* _max_ay24 is max of ay2 */
                var _augval788 = (_a775).ay2;
                var _child789 = (_a775)._left7;
                if (!((_child789) == null)) {
                    var _val790 = (_child789)._max_ay24;
                    _augval788 = ((_augval788) < (_val790)) ? (_val790) : (_augval788);
                }
                var _child791 = (_a775)._right8;
                if (!((_child791) == null)) {
                    var _val792 = (_child791)._max_ay24;
                    _augval788 = ((_augval788) < (_val792)) ? (_val792) : (_augval788);
                }
                (_a775)._max_ay24 = _augval788;
                (_a775)._height10 = 1 + ((((((_a775)._left7) == null) ? (-1) : (((_a775)._left7)._height10)) > ((((_a775)._right8) == null) ? (-1) : (((_a775)._right8)._height10))) ? ((((_a775)._left7) == null) ? (-1) : (((_a775)._left7)._height10)) : ((((_a775)._right8) == null) ? (-1) : (((_a775)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval793 = (_b776).ax1;
                var _child794 = (_b776)._left7;
                if (!((_child794) == null)) {
                    var _val795 = (_child794)._min_ax12;
                    _augval793 = ((_augval793) < (_val795)) ? (_augval793) : (_val795);
                }
                var _child796 = (_b776)._right8;
                if (!((_child796) == null)) {
                    var _val797 = (_child796)._min_ax12;
                    _augval793 = ((_augval793) < (_val797)) ? (_augval793) : (_val797);
                }
                (_b776)._min_ax12 = _augval793;
                /* _min_ay13 is min of ay1 */
                var _augval798 = (_b776).ay1;
                var _child799 = (_b776)._left7;
                if (!((_child799) == null)) {
                    var _val800 = (_child799)._min_ay13;
                    _augval798 = ((_augval798) < (_val800)) ? (_augval798) : (_val800);
                }
                var _child801 = (_b776)._right8;
                if (!((_child801) == null)) {
                    var _val802 = (_child801)._min_ay13;
                    _augval798 = ((_augval798) < (_val802)) ? (_augval798) : (_val802);
                }
                (_b776)._min_ay13 = _augval798;
                /* _max_ay24 is max of ay2 */
                var _augval803 = (_b776).ay2;
                var _child804 = (_b776)._left7;
                if (!((_child804) == null)) {
                    var _val805 = (_child804)._max_ay24;
                    _augval803 = ((_augval803) < (_val805)) ? (_val805) : (_augval803);
                }
                var _child806 = (_b776)._right8;
                if (!((_child806) == null)) {
                    var _val807 = (_child806)._max_ay24;
                    _augval803 = ((_augval803) < (_val807)) ? (_val807) : (_augval803);
                }
                (_b776)._max_ay24 = _augval803;
                (_b776)._height10 = 1 + ((((((_b776)._left7) == null) ? (-1) : (((_b776)._left7)._height10)) > ((((_b776)._right8) == null) ? (-1) : (((_b776)._right8)._height10))) ? ((((_b776)._left7) == null) ? (-1) : (((_b776)._left7)._height10)) : ((((_b776)._right8) == null) ? (-1) : (((_b776)._right8)._height10)));
                if (!(((_b776)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval808 = ((_b776)._parent9).ax1;
                    var _child809 = ((_b776)._parent9)._left7;
                    if (!((_child809) == null)) {
                        var _val810 = (_child809)._min_ax12;
                        _augval808 = ((_augval808) < (_val810)) ? (_augval808) : (_val810);
                    }
                    var _child811 = ((_b776)._parent9)._right8;
                    if (!((_child811) == null)) {
                        var _val812 = (_child811)._min_ax12;
                        _augval808 = ((_augval808) < (_val812)) ? (_augval808) : (_val812);
                    }
                    ((_b776)._parent9)._min_ax12 = _augval808;
                    /* _min_ay13 is min of ay1 */
                    var _augval813 = ((_b776)._parent9).ay1;
                    var _child814 = ((_b776)._parent9)._left7;
                    if (!((_child814) == null)) {
                        var _val815 = (_child814)._min_ay13;
                        _augval813 = ((_augval813) < (_val815)) ? (_augval813) : (_val815);
                    }
                    var _child816 = ((_b776)._parent9)._right8;
                    if (!((_child816) == null)) {
                        var _val817 = (_child816)._min_ay13;
                        _augval813 = ((_augval813) < (_val817)) ? (_augval813) : (_val817);
                    }
                    ((_b776)._parent9)._min_ay13 = _augval813;
                    /* _max_ay24 is max of ay2 */
                    var _augval818 = ((_b776)._parent9).ay2;
                    var _child819 = ((_b776)._parent9)._left7;
                    if (!((_child819) == null)) {
                        var _val820 = (_child819)._max_ay24;
                        _augval818 = ((_augval818) < (_val820)) ? (_val820) : (_augval818);
                    }
                    var _child821 = ((_b776)._parent9)._right8;
                    if (!((_child821) == null)) {
                        var _val822 = (_child821)._max_ay24;
                        _augval818 = ((_augval818) < (_val822)) ? (_val822) : (_augval818);
                    }
                    ((_b776)._parent9)._max_ay24 = _augval818;
                    ((_b776)._parent9)._height10 = 1 + (((((((_b776)._parent9)._left7) == null) ? (-1) : ((((_b776)._parent9)._left7)._height10)) > (((((_b776)._parent9)._right8) == null) ? (-1) : ((((_b776)._parent9)._right8)._height10))) ? (((((_b776)._parent9)._left7) == null) ? (-1) : ((((_b776)._parent9)._left7)._height10)) : (((((_b776)._parent9)._right8) == null) ? (-1) : ((((_b776)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b776;
                }
            }
            /* rotate (_cursor773)._left7 */
            var _a823 = _cursor773;
            var _b824 = (_a823)._left7;
            var _c825 = (_b824)._right8;
            /* replace _a823 with _b824 in (_a823)._parent9 */
            if (!(((_a823)._parent9) == null)) {
                if ((((_a823)._parent9)._left7) == (_a823)) {
                    ((_a823)._parent9)._left7 = _b824;
                } else {
                    ((_a823)._parent9)._right8 = _b824;
                }
            }
            if (!((_b824) == null)) {
                (_b824)._parent9 = (_a823)._parent9;
            }
            /* replace _c825 with _a823 in _b824 */
            (_b824)._right8 = _a823;
            if (!((_a823) == null)) {
                (_a823)._parent9 = _b824;
            }
            /* replace _b824 with _c825 in _a823 */
            (_a823)._left7 = _c825;
            if (!((_c825) == null)) {
                (_c825)._parent9 = _a823;
            }
            /* _min_ax12 is min of ax1 */
            var _augval826 = (_a823).ax1;
            var _child827 = (_a823)._left7;
            if (!((_child827) == null)) {
                var _val828 = (_child827)._min_ax12;
                _augval826 = ((_augval826) < (_val828)) ? (_augval826) : (_val828);
            }
            var _child829 = (_a823)._right8;
            if (!((_child829) == null)) {
                var _val830 = (_child829)._min_ax12;
                _augval826 = ((_augval826) < (_val830)) ? (_augval826) : (_val830);
            }
            (_a823)._min_ax12 = _augval826;
            /* _min_ay13 is min of ay1 */
            var _augval831 = (_a823).ay1;
            var _child832 = (_a823)._left7;
            if (!((_child832) == null)) {
                var _val833 = (_child832)._min_ay13;
                _augval831 = ((_augval831) < (_val833)) ? (_augval831) : (_val833);
            }
            var _child834 = (_a823)._right8;
            if (!((_child834) == null)) {
                var _val835 = (_child834)._min_ay13;
                _augval831 = ((_augval831) < (_val835)) ? (_augval831) : (_val835);
            }
            (_a823)._min_ay13 = _augval831;
            /* _max_ay24 is max of ay2 */
            var _augval836 = (_a823).ay2;
            var _child837 = (_a823)._left7;
            if (!((_child837) == null)) {
                var _val838 = (_child837)._max_ay24;
                _augval836 = ((_augval836) < (_val838)) ? (_val838) : (_augval836);
            }
            var _child839 = (_a823)._right8;
            if (!((_child839) == null)) {
                var _val840 = (_child839)._max_ay24;
                _augval836 = ((_augval836) < (_val840)) ? (_val840) : (_augval836);
            }
            (_a823)._max_ay24 = _augval836;
            (_a823)._height10 = 1 + ((((((_a823)._left7) == null) ? (-1) : (((_a823)._left7)._height10)) > ((((_a823)._right8) == null) ? (-1) : (((_a823)._right8)._height10))) ? ((((_a823)._left7) == null) ? (-1) : (((_a823)._left7)._height10)) : ((((_a823)._right8) == null) ? (-1) : (((_a823)._right8)._height10)));
            /* _min_ax12 is min of ax1 */
            var _augval841 = (_b824).ax1;
            var _child842 = (_b824)._left7;
            if (!((_child842) == null)) {
                var _val843 = (_child842)._min_ax12;
                _augval841 = ((_augval841) < (_val843)) ? (_augval841) : (_val843);
            }
            var _child844 = (_b824)._right8;
            if (!((_child844) == null)) {
                var _val845 = (_child844)._min_ax12;
                _augval841 = ((_augval841) < (_val845)) ? (_augval841) : (_val845);
            }
            (_b824)._min_ax12 = _augval841;
            /* _min_ay13 is min of ay1 */
            var _augval846 = (_b824).ay1;
            var _child847 = (_b824)._left7;
            if (!((_child847) == null)) {
                var _val848 = (_child847)._min_ay13;
                _augval846 = ((_augval846) < (_val848)) ? (_augval846) : (_val848);
            }
            var _child849 = (_b824)._right8;
            if (!((_child849) == null)) {
                var _val850 = (_child849)._min_ay13;
                _augval846 = ((_augval846) < (_val850)) ? (_augval846) : (_val850);
            }
            (_b824)._min_ay13 = _augval846;
            /* _max_ay24 is max of ay2 */
            var _augval851 = (_b824).ay2;
            var _child852 = (_b824)._left7;
            if (!((_child852) == null)) {
                var _val853 = (_child852)._max_ay24;
                _augval851 = ((_augval851) < (_val853)) ? (_val853) : (_augval851);
            }
            var _child854 = (_b824)._right8;
            if (!((_child854) == null)) {
                var _val855 = (_child854)._max_ay24;
                _augval851 = ((_augval851) < (_val855)) ? (_val855) : (_augval851);
            }
            (_b824)._max_ay24 = _augval851;
            (_b824)._height10 = 1 + ((((((_b824)._left7) == null) ? (-1) : (((_b824)._left7)._height10)) > ((((_b824)._right8) == null) ? (-1) : (((_b824)._right8)._height10))) ? ((((_b824)._left7) == null) ? (-1) : (((_b824)._left7)._height10)) : ((((_b824)._right8) == null) ? (-1) : (((_b824)._right8)._height10)));
            if (!(((_b824)._parent9) == null)) {
                /* _min_ax12 is min of ax1 */
                var _augval856 = ((_b824)._parent9).ax1;
                var _child857 = ((_b824)._parent9)._left7;
                if (!((_child857) == null)) {
                    var _val858 = (_child857)._min_ax12;
                    _augval856 = ((_augval856) < (_val858)) ? (_augval856) : (_val858);
                }
                var _child859 = ((_b824)._parent9)._right8;
                if (!((_child859) == null)) {
                    var _val860 = (_child859)._min_ax12;
                    _augval856 = ((_augval856) < (_val860)) ? (_augval856) : (_val860);
                }
                ((_b824)._parent9)._min_ax12 = _augval856;
                /* _min_ay13 is min of ay1 */
                var _augval861 = ((_b824)._parent9).ay1;
                var _child862 = ((_b824)._parent9)._left7;
                if (!((_child862) == null)) {
                    var _val863 = (_child862)._min_ay13;
                    _augval861 = ((_augval861) < (_val863)) ? (_augval861) : (_val863);
                }
                var _child864 = ((_b824)._parent9)._right8;
                if (!((_child864) == null)) {
                    var _val865 = (_child864)._min_ay13;
                    _augval861 = ((_augval861) < (_val865)) ? (_augval861) : (_val865);
                }
                ((_b824)._parent9)._min_ay13 = _augval861;
                /* _max_ay24 is max of ay2 */
                var _augval866 = ((_b824)._parent9).ay2;
                var _child867 = ((_b824)._parent9)._left7;
                if (!((_child867) == null)) {
                    var _val868 = (_child867)._max_ay24;
                    _augval866 = ((_augval866) < (_val868)) ? (_val868) : (_augval866);
                }
                var _child869 = ((_b824)._parent9)._right8;
                if (!((_child869) == null)) {
                    var _val870 = (_child869)._max_ay24;
                    _augval866 = ((_augval866) < (_val870)) ? (_val870) : (_augval866);
                }
                ((_b824)._parent9)._max_ay24 = _augval866;
                ((_b824)._parent9)._height10 = 1 + (((((((_b824)._parent9)._left7) == null) ? (-1) : ((((_b824)._parent9)._left7)._height10)) > (((((_b824)._parent9)._right8) == null) ? (-1) : ((((_b824)._parent9)._right8)._height10))) ? (((((_b824)._parent9)._left7) == null) ? (-1) : ((((_b824)._parent9)._left7)._height10)) : (((((_b824)._parent9)._right8) == null) ? (-1) : ((((_b824)._parent9)._right8)._height10)));
            } else {
                (this)._root1 = _b824;
            }
            _cursor773 = (_cursor773)._parent9;
        } else if ((_imbalance774) < (-1)) {
            if ((((((_cursor773)._right8)._left7) == null) ? (-1) : ((((_cursor773)._right8)._left7)._height10)) > (((((_cursor773)._right8)._right8) == null) ? (-1) : ((((_cursor773)._right8)._right8)._height10))) {
                /* rotate ((_cursor773)._right8)._left7 */
                var _a871 = (_cursor773)._right8;
                var _b872 = (_a871)._left7;
                var _c873 = (_b872)._right8;
                /* replace _a871 with _b872 in (_a871)._parent9 */
                if (!(((_a871)._parent9) == null)) {
                    if ((((_a871)._parent9)._left7) == (_a871)) {
                        ((_a871)._parent9)._left7 = _b872;
                    } else {
                        ((_a871)._parent9)._right8 = _b872;
                    }
                }
                if (!((_b872) == null)) {
                    (_b872)._parent9 = (_a871)._parent9;
                }
                /* replace _c873 with _a871 in _b872 */
                (_b872)._right8 = _a871;
                if (!((_a871) == null)) {
                    (_a871)._parent9 = _b872;
                }
                /* replace _b872 with _c873 in _a871 */
                (_a871)._left7 = _c873;
                if (!((_c873) == null)) {
                    (_c873)._parent9 = _a871;
                }
                /* _min_ax12 is min of ax1 */
                var _augval874 = (_a871).ax1;
                var _child875 = (_a871)._left7;
                if (!((_child875) == null)) {
                    var _val876 = (_child875)._min_ax12;
                    _augval874 = ((_augval874) < (_val876)) ? (_augval874) : (_val876);
                }
                var _child877 = (_a871)._right8;
                if (!((_child877) == null)) {
                    var _val878 = (_child877)._min_ax12;
                    _augval874 = ((_augval874) < (_val878)) ? (_augval874) : (_val878);
                }
                (_a871)._min_ax12 = _augval874;
                /* _min_ay13 is min of ay1 */
                var _augval879 = (_a871).ay1;
                var _child880 = (_a871)._left7;
                if (!((_child880) == null)) {
                    var _val881 = (_child880)._min_ay13;
                    _augval879 = ((_augval879) < (_val881)) ? (_augval879) : (_val881);
                }
                var _child882 = (_a871)._right8;
                if (!((_child882) == null)) {
                    var _val883 = (_child882)._min_ay13;
                    _augval879 = ((_augval879) < (_val883)) ? (_augval879) : (_val883);
                }
                (_a871)._min_ay13 = _augval879;
                /* _max_ay24 is max of ay2 */
                var _augval884 = (_a871).ay2;
                var _child885 = (_a871)._left7;
                if (!((_child885) == null)) {
                    var _val886 = (_child885)._max_ay24;
                    _augval884 = ((_augval884) < (_val886)) ? (_val886) : (_augval884);
                }
                var _child887 = (_a871)._right8;
                if (!((_child887) == null)) {
                    var _val888 = (_child887)._max_ay24;
                    _augval884 = ((_augval884) < (_val888)) ? (_val888) : (_augval884);
                }
                (_a871)._max_ay24 = _augval884;
                (_a871)._height10 = 1 + ((((((_a871)._left7) == null) ? (-1) : (((_a871)._left7)._height10)) > ((((_a871)._right8) == null) ? (-1) : (((_a871)._right8)._height10))) ? ((((_a871)._left7) == null) ? (-1) : (((_a871)._left7)._height10)) : ((((_a871)._right8) == null) ? (-1) : (((_a871)._right8)._height10)));
                /* _min_ax12 is min of ax1 */
                var _augval889 = (_b872).ax1;
                var _child890 = (_b872)._left7;
                if (!((_child890) == null)) {
                    var _val891 = (_child890)._min_ax12;
                    _augval889 = ((_augval889) < (_val891)) ? (_augval889) : (_val891);
                }
                var _child892 = (_b872)._right8;
                if (!((_child892) == null)) {
                    var _val893 = (_child892)._min_ax12;
                    _augval889 = ((_augval889) < (_val893)) ? (_augval889) : (_val893);
                }
                (_b872)._min_ax12 = _augval889;
                /* _min_ay13 is min of ay1 */
                var _augval894 = (_b872).ay1;
                var _child895 = (_b872)._left7;
                if (!((_child895) == null)) {
                    var _val896 = (_child895)._min_ay13;
                    _augval894 = ((_augval894) < (_val896)) ? (_augval894) : (_val896);
                }
                var _child897 = (_b872)._right8;
                if (!((_child897) == null)) {
                    var _val898 = (_child897)._min_ay13;
                    _augval894 = ((_augval894) < (_val898)) ? (_augval894) : (_val898);
                }
                (_b872)._min_ay13 = _augval894;
                /* _max_ay24 is max of ay2 */
                var _augval899 = (_b872).ay2;
                var _child900 = (_b872)._left7;
                if (!((_child900) == null)) {
                    var _val901 = (_child900)._max_ay24;
                    _augval899 = ((_augval899) < (_val901)) ? (_val901) : (_augval899);
                }
                var _child902 = (_b872)._right8;
                if (!((_child902) == null)) {
                    var _val903 = (_child902)._max_ay24;
                    _augval899 = ((_augval899) < (_val903)) ? (_val903) : (_augval899);
                }
                (_b872)._max_ay24 = _augval899;
                (_b872)._height10 = 1 + ((((((_b872)._left7) == null) ? (-1) : (((_b872)._left7)._height10)) > ((((_b872)._right8) == null) ? (-1) : (((_b872)._right8)._height10))) ? ((((_b872)._left7) == null) ? (-1) : (((_b872)._left7)._height10)) : ((((_b872)._right8) == null) ? (-1) : (((_b872)._right8)._height10)));
                if (!(((_b872)._parent9) == null)) {
                    /* _min_ax12 is min of ax1 */
                    var _augval904 = ((_b872)._parent9).ax1;
                    var _child905 = ((_b872)._parent9)._left7;
                    if (!((_child905) == null)) {
                        var _val906 = (_child905)._min_ax12;
                        _augval904 = ((_augval904) < (_val906)) ? (_augval904) : (_val906);
                    }
                    var _child907 = ((_b872)._parent9)._right8;
                    if (!((_child907) == null)) {
                        var _val908 = (_child907)._min_ax12;
                        _augval904 = ((_augval904) < (_val908)) ? (_augval904) : (_val908);
                    }
                    ((_b872)._parent9)._min_ax12 = _augval904;
                    /* _min_ay13 is min of ay1 */
                    var _augval909 = ((_b872)._parent9).ay1;
                    var _child910 = ((_b872)._parent9)._left7;
                    if (!((_child910) == null)) {
                        var _val911 = (_child910)._min_ay13;
                        _augval909 = ((_augval909) < (_val911)) ? (_augval909) : (_val911);
                    }
                    var _child912 = ((_b872)._parent9)._right8;
                    if (!((_child912) == null)) {
                        var _val913 = (_child912)._min_ay13;
                        _augval909 = ((_augval909) < (_val913)) ? (_augval909) : (_val913);
                    }
                    ((_b872)._parent9)._min_ay13 = _augval909;
                    /* _max_ay24 is max of ay2 */
                    var _augval914 = ((_b872)._parent9).ay2;
                    var _child915 = ((_b872)._parent9)._left7;
                    if (!((_child915) == null)) {
                        var _val916 = (_child915)._max_ay24;
                        _augval914 = ((_augval914) < (_val916)) ? (_val916) : (_augval914);
                    }
                    var _child917 = ((_b872)._parent9)._right8;
                    if (!((_child917) == null)) {
                        var _val918 = (_child917)._max_ay24;
                        _augval914 = ((_augval914) < (_val918)) ? (_val918) : (_augval914);
                    }
                    ((_b872)._parent9)._max_ay24 = _augval914;
                    ((_b872)._parent9)._height10 = 1 + (((((((_b872)._parent9)._left7) == null) ? (-1) : ((((_b872)._parent9)._left7)._height10)) > (((((_b872)._parent9)._right8) == null) ? (-1) : ((((_b872)._parent9)._right8)._height10))) ? (((((_b872)._parent9)._left7) == null) ? (-1) : ((((_b872)._parent9)._left7)._height10)) : (((((_b872)._parent9)._right8) == null) ? (-1) : ((((_b872)._parent9)._right8)._height10)));
                } else {
                    (this)._root1 = _b872;
                }
            }
            /* rotate (_cursor773)._right8 */
            var _a919 = _cursor773;
            var _b920 = (_a919)._right8;
            var _c921 = (_b920)._left7;
            /* replace _a919 with _b920 in (_a919)._parent9 */
            if (!(((_a919)._parent9) == null)) {
                if ((((_a919)._parent9)._left7) == (_a919)) {
                    ((_a919)._parent9)._left7 = _b920;
                } else {
                    ((_a919)._parent9)._right8 = _b920;
                }
            }
            if (!((_b920) == null)) {
                (_b920)._parent9 = (_a919)._parent9;
            }
            /* replace _c921 with _a919 in _b920 */
            (_b920)._left7 = _a919;
            if (!((_a919) == null)) {
                (_a919)._parent9 = _b920;
            }
            /* replace _b920 with _c921 in _a919 */
            (_a919)._right8 = _c921;
            if (!((_c921) == null)) {
                (_c921)._parent9 = _a919;
            }
            /* _min_ax12 is min of ax1 */
            var _augval922 = (_a919).ax1;
            var _child923 = (_a919)._left7;
            if (!((_child923) == null)) {
                var _val924 = (_child923)._min_ax12;
                _augval922 = ((_augval922) < (_val924)) ? (_augval922) : (_val924);
            }
            var _child925 = (_a919)._right8;
            if (!((_child925) == null)) {
                var _val926 = (_child925)._min_ax12;
                _augval922 = ((_augval922) < (_val926)) ? (_augval922) : (_val926);
            }
            (_a919)._min_ax12 = _augval922;
            /* _min_ay13 is min of ay1 */
            var _augval927 = (_a919).ay1;
            var _child928 = (_a919)._left7;
            if (!((_child928) == null)) {
                var _val929 = (_child928)._min_ay13;
                _augval927 = ((_augval927) < (_val929)) ? (_augval927) : (_val929);
            }
            var _child930 = (_a919)._right8;
            if (!((_child930) == null)) {
                var _val931 = (_child930)._min_ay13;
                _augval927 = ((_augval927) < (_val931)) ? (_augval927) : (_val931);
            }
            (_a919)._min_ay13 = _augval927;
            /* _max_ay24 is max of ay2 */
            var _augval932 = (_a919).ay2;
            var _child933 = (_a919)._left7;
            if (!((_child933) == null)) {
                var _val934 = (_child933)._max_ay24;
                _augval932 = ((_augval932) < (_val934)) ? (_val934) : (_augval932);
            }
            var _child935 = (_a919)._right8;
            if (!((_child935) == null)) {
                var _val936 = (_child935)._max_ay24;
                _augval932 = ((_augval932) < (_val936)) ? (_val936) : (_augval932);
            }
            (_a919)._max_ay24 = _augval932;
            (_a919)._height10 = 1 + ((((((_a919)._left7) == null) ? (-1) : (((_a919)._left7)._height10)) > ((((_a919)._right8) == null) ? (-1) : (((_a919)._right8)._height10))) ? ((((_a919)._left7) == null) ? (-1) : (((_a919)._left7)._height10)) : ((((_a919)._right8) == null) ? (-1) : (((_a919)._right8)._height10)));
            /* _min_ax12 is min of ax1 */
            var _augval937 = (_b920).ax1;
            var _child938 = (_b920)._left7;
            if (!((_child938) == null)) {
                var _val939 = (_child938)._min_ax12;
                _augval937 = ((_augval937) < (_val939)) ? (_augval937) : (_val939);
            }
            var _child940 = (_b920)._right8;
            if (!((_child940) == null)) {
                var _val941 = (_child940)._min_ax12;
                _augval937 = ((_augval937) < (_val941)) ? (_augval937) : (_val941);
            }
            (_b920)._min_ax12 = _augval937;
            /* _min_ay13 is min of ay1 */
            var _augval942 = (_b920).ay1;
            var _child943 = (_b920)._left7;
            if (!((_child943) == null)) {
                var _val944 = (_child943)._min_ay13;
                _augval942 = ((_augval942) < (_val944)) ? (_augval942) : (_val944);
            }
            var _child945 = (_b920)._right8;
            if (!((_child945) == null)) {
                var _val946 = (_child945)._min_ay13;
                _augval942 = ((_augval942) < (_val946)) ? (_augval942) : (_val946);
            }
            (_b920)._min_ay13 = _augval942;
            /* _max_ay24 is max of ay2 */
            var _augval947 = (_b920).ay2;
            var _child948 = (_b920)._left7;
            if (!((_child948) == null)) {
                var _val949 = (_child948)._max_ay24;
                _augval947 = ((_augval947) < (_val949)) ? (_val949) : (_augval947);
            }
            var _child950 = (_b920)._right8;
            if (!((_child950) == null)) {
                var _val951 = (_child950)._max_ay24;
                _augval947 = ((_augval947) < (_val951)) ? (_val951) : (_augval947);
            }
            (_b920)._max_ay24 = _augval947;
            (_b920)._height10 = 1 + ((((((_b920)._left7) == null) ? (-1) : (((_b920)._left7)._height10)) > ((((_b920)._right8) == null) ? (-1) : (((_b920)._right8)._height10))) ? ((((_b920)._left7) == null) ? (-1) : (((_b920)._left7)._height10)) : ((((_b920)._right8) == null) ? (-1) : (((_b920)._right8)._height10)));
            if (!(((_b920)._parent9) == null)) {
                /* _min_ax12 is min of ax1 */
                var _augval952 = ((_b920)._parent9).ax1;
                var _child953 = ((_b920)._parent9)._left7;
                if (!((_child953) == null)) {
                    var _val954 = (_child953)._min_ax12;
                    _augval952 = ((_augval952) < (_val954)) ? (_augval952) : (_val954);
                }
                var _child955 = ((_b920)._parent9)._right8;
                if (!((_child955) == null)) {
                    var _val956 = (_child955)._min_ax12;
                    _augval952 = ((_augval952) < (_val956)) ? (_augval952) : (_val956);
                }
                ((_b920)._parent9)._min_ax12 = _augval952;
                /* _min_ay13 is min of ay1 */
                var _augval957 = ((_b920)._parent9).ay1;
                var _child958 = ((_b920)._parent9)._left7;
                if (!((_child958) == null)) {
                    var _val959 = (_child958)._min_ay13;
                    _augval957 = ((_augval957) < (_val959)) ? (_augval957) : (_val959);
                }
                var _child960 = ((_b920)._parent9)._right8;
                if (!((_child960) == null)) {
                    var _val961 = (_child960)._min_ay13;
                    _augval957 = ((_augval957) < (_val961)) ? (_augval957) : (_val961);
                }
                ((_b920)._parent9)._min_ay13 = _augval957;
                /* _max_ay24 is max of ay2 */
                var _augval962 = ((_b920)._parent9).ay2;
                var _child963 = ((_b920)._parent9)._left7;
                if (!((_child963) == null)) {
                    var _val964 = (_child963)._max_ay24;
                    _augval962 = ((_augval962) < (_val964)) ? (_val964) : (_augval962);
                }
                var _child965 = ((_b920)._parent9)._right8;
                if (!((_child965) == null)) {
                    var _val966 = (_child965)._max_ay24;
                    _augval962 = ((_augval962) < (_val966)) ? (_val966) : (_augval962);
                }
                ((_b920)._parent9)._max_ay24 = _augval962;
                ((_b920)._parent9)._height10 = 1 + (((((((_b920)._parent9)._left7) == null) ? (-1) : ((((_b920)._parent9)._left7)._height10)) > (((((_b920)._parent9)._right8) == null) ? (-1) : ((((_b920)._parent9)._right8)._height10))) ? (((((_b920)._parent9)._left7) == null) ? (-1) : ((((_b920)._parent9)._left7)._height10)) : (((((_b920)._parent9)._right8) == null) ? (-1) : ((((_b920)._parent9)._right8)._height10)));
            } else {
                (this)._root1 = _b920;
            }
            _cursor773 = (_cursor773)._parent9;
        }
    }
    (__x).ax1 = ax1;
    (__x).ay1 = ay1;
    (__x).ax2 = ax2;
    (__x).ay2 = ay2;
}
RectangleHolder.prototype.findMatchingRectangles = function (bx1, by1, bx2, by2, __callback) {
    var _root967 = (this)._root1;
    var _x968 = _root967;
    var _descend969 = true;
    var _from_left970 = true;
    while (true) {
        if ((_x968) == null) {
            _x968 = null;
            break;
        }
        if (_descend969) {
            /* too small? */
            if ((false) || (((_x968).ax2) <= (bx1))) {
                if ((!(((_x968)._right8) == null)) && ((((true) && ((((_x968)._right8)._min_ax12) < (bx2))) && ((((_x968)._right8)._min_ay13) < (by2))) && ((((_x968)._right8)._max_ay24) > (by1)))) {
                    if ((_x968) == (_root967)) {
                        _root967 = (_x968)._right8;
                    }
                    _x968 = (_x968)._right8;
                } else if ((_x968) == (_root967)) {
                    _x968 = null;
                    break;
                } else {
                    _descend969 = false;
                    _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                    _x968 = (_x968)._parent9;
                }
            } else if ((!(((_x968)._left7) == null)) && ((((true) && ((((_x968)._left7)._min_ax12) < (bx2))) && ((((_x968)._left7)._min_ay13) < (by2))) && ((((_x968)._left7)._max_ay24) > (by1)))) {
                _x968 = (_x968)._left7;
                /* too large? */
            } else if (false) {
                if ((_x968) == (_root967)) {
                    _x968 = null;
                    break;
                } else {
                    _descend969 = false;
                    _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                    _x968 = (_x968)._parent9;
                }
                /* node ok? */
            } else if ((((true) && (((_x968).ax1) < (bx2))) && (((_x968).ay1) < (by2))) && (((_x968).ay2) > (by1))) {
                break;
            } else if ((_x968) == (_root967)) {
                _root967 = (_x968)._right8;
                _x968 = (_x968)._right8;
            } else {
                if ((!(((_x968)._right8) == null)) && ((((true) && ((((_x968)._right8)._min_ax12) < (bx2))) && ((((_x968)._right8)._min_ay13) < (by2))) && ((((_x968)._right8)._max_ay24) > (by1)))) {
                    if ((_x968) == (_root967)) {
                        _root967 = (_x968)._right8;
                    }
                    _x968 = (_x968)._right8;
                } else {
                    _descend969 = false;
                    _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                    _x968 = (_x968)._parent9;
                }
            }
        } else if (_from_left970) {
            if (false) {
                _x968 = null;
                break;
            } else if ((((true) && (((_x968).ax1) < (bx2))) && (((_x968).ay1) < (by2))) && (((_x968).ay2) > (by1))) {
                break;
            } else if ((!(((_x968)._right8) == null)) && ((((true) && ((((_x968)._right8)._min_ax12) < (bx2))) && ((((_x968)._right8)._min_ay13) < (by2))) && ((((_x968)._right8)._max_ay24) > (by1)))) {
                _descend969 = true;
                if ((_x968) == (_root967)) {
                    _root967 = (_x968)._right8;
                }
                _x968 = (_x968)._right8;
            } else if ((_x968) == (_root967)) {
                _x968 = null;
                break;
            } else {
                _descend969 = false;
                _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                _x968 = (_x968)._parent9;
            }
        } else {
            if ((_x968) == (_root967)) {
                _x968 = null;
                break;
            } else {
                _descend969 = false;
                _from_left970 = (!(((_x968)._parent9) == null)) && ((_x968) == (((_x968)._parent9)._left7));
                _x968 = (_x968)._parent9;
            }
        }
    }
    var _prev_cursor5 = null;
    var _cursor6 = _x968;
    for (; ;) {
        if (!(!((_cursor6) == null))) break;
        var _name971 = _cursor6;
        /* ADVANCE */
        _prev_cursor5 = _cursor6;
        do {
            var _right_min972 = null;
            if ((!(((_cursor6)._right8) == null)) && ((((true) && ((((_cursor6)._right8)._min_ax12) < (bx2))) && ((((_cursor6)._right8)._min_ay13) < (by2))) && ((((_cursor6)._right8)._max_ay24) > (by1)))) {
                var _root973 = (_cursor6)._right8;
                var _x974 = _root973;
                var _descend975 = true;
                var _from_left976 = true;
                while (true) {
                    if ((_x974) == null) {
                        _x974 = null;
                        break;
                    }
                    if (_descend975) {
                        /* too small? */
                        if ((false) || (((_x974).ax2) <= (bx1))) {
                            if ((!(((_x974)._right8) == null)) && ((((true) && ((((_x974)._right8)._min_ax12) < (bx2))) && ((((_x974)._right8)._min_ay13) < (by2))) && ((((_x974)._right8)._max_ay24) > (by1)))) {
                                if ((_x974) == (_root973)) {
                                    _root973 = (_x974)._right8;
                                }
                                _x974 = (_x974)._right8;
                            } else if ((_x974) == (_root973)) {
                                _x974 = null;
                                break;
                            } else {
                                _descend975 = false;
                                _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                                _x974 = (_x974)._parent9;
                            }
                        } else if ((!(((_x974)._left7) == null)) && ((((true) && ((((_x974)._left7)._min_ax12) < (bx2))) && ((((_x974)._left7)._min_ay13) < (by2))) && ((((_x974)._left7)._max_ay24) > (by1)))) {
                            _x974 = (_x974)._left7;
                            /* too large? */
                        } else if (false) {
                            if ((_x974) == (_root973)) {
                                _x974 = null;
                                break;
                            } else {
                                _descend975 = false;
                                _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                                _x974 = (_x974)._parent9;
                            }
                            /* node ok? */
                        } else if ((((true) && (((_x974).ax1) < (bx2))) && (((_x974).ay1) < (by2))) && (((_x974).ay2) > (by1))) {
                            break;
                        } else if ((_x974) == (_root973)) {
                            _root973 = (_x974)._right8;
                            _x974 = (_x974)._right8;
                        } else {
                            if ((!(((_x974)._right8) == null)) && ((((true) && ((((_x974)._right8)._min_ax12) < (bx2))) && ((((_x974)._right8)._min_ay13) < (by2))) && ((((_x974)._right8)._max_ay24) > (by1)))) {
                                if ((_x974) == (_root973)) {
                                    _root973 = (_x974)._right8;
                                }
                                _x974 = (_x974)._right8;
                            } else {
                                _descend975 = false;
                                _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                                _x974 = (_x974)._parent9;
                            }
                        }
                    } else if (_from_left976) {
                        if (false) {
                            _x974 = null;
                            break;
                        } else if ((((true) && (((_x974).ax1) < (bx2))) && (((_x974).ay1) < (by2))) && (((_x974).ay2) > (by1))) {
                            break;
                        } else if ((!(((_x974)._right8) == null)) && ((((true) && ((((_x974)._right8)._min_ax12) < (bx2))) && ((((_x974)._right8)._min_ay13) < (by2))) && ((((_x974)._right8)._max_ay24) > (by1)))) {
                            _descend975 = true;
                            if ((_x974) == (_root973)) {
                                _root973 = (_x974)._right8;
                            }
                            _x974 = (_x974)._right8;
                        } else if ((_x974) == (_root973)) {
                            _x974 = null;
                            break;
                        } else {
                            _descend975 = false;
                            _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                            _x974 = (_x974)._parent9;
                        }
                    } else {
                        if ((_x974) == (_root973)) {
                            _x974 = null;
                            break;
                        } else {
                            _descend975 = false;
                            _from_left976 = (!(((_x974)._parent9) == null)) && ((_x974) == (((_x974)._parent9)._left7));
                            _x974 = (_x974)._parent9;
                        }
                    }
                }
                _right_min972 = _x974;
            }
            if (!((_right_min972) == null)) {
                _cursor6 = _right_min972;
                break;
            } else {
                while ((!(((_cursor6)._parent9) == null)) && ((_cursor6) == (((_cursor6)._parent9)._right8))) {
                    _cursor6 = (_cursor6)._parent9;
                }
                _cursor6 = (_cursor6)._parent9;
                if ((!((_cursor6) == null)) && (false)) {
                    _cursor6 = null;
                }
            }
        } while ((!((_cursor6) == null)) && (!((((true) && (((_cursor6).ax1) < (bx2))) && (((_cursor6).ay1) < (by2))) && (((_cursor6).ay2) > (by1)))));
        if (__callback(_name971)) {
            var _to_remove977 = _prev_cursor5;
            var _parent978 = (_to_remove977)._parent9;
            var _left979 = (_to_remove977)._left7;
            var _right980 = (_to_remove977)._right8;
            var _new_x981;
            if (((_left979) == null) && ((_right980) == null)) {
                _new_x981 = null;
                /* replace _to_remove977 with _new_x981 in _parent978 */
                if (!((_parent978) == null)) {
                    if (((_parent978)._left7) == (_to_remove977)) {
                        (_parent978)._left7 = _new_x981;
                    } else {
                        (_parent978)._right8 = _new_x981;
                    }
                }
                if (!((_new_x981) == null)) {
                    (_new_x981)._parent9 = _parent978;
                }
            } else if ((!((_left979) == null)) && ((_right980) == null)) {
                _new_x981 = _left979;
                /* replace _to_remove977 with _new_x981 in _parent978 */
                if (!((_parent978) == null)) {
                    if (((_parent978)._left7) == (_to_remove977)) {
                        (_parent978)._left7 = _new_x981;
                    } else {
                        (_parent978)._right8 = _new_x981;
                    }
                }
                if (!((_new_x981) == null)) {
                    (_new_x981)._parent9 = _parent978;
                }
            } else if (((_left979) == null) && (!((_right980) == null))) {
                _new_x981 = _right980;
                /* replace _to_remove977 with _new_x981 in _parent978 */
                if (!((_parent978) == null)) {
                    if (((_parent978)._left7) == (_to_remove977)) {
                        (_parent978)._left7 = _new_x981;
                    } else {
                        (_parent978)._right8 = _new_x981;
                    }
                }
                if (!((_new_x981) == null)) {
                    (_new_x981)._parent9 = _parent978;
                }
            } else {
                var _root982 = (_to_remove977)._right8;
                var _x983 = _root982;
                var _descend984 = true;
                var _from_left985 = true;
                while (true) {
                    if ((_x983) == null) {
                        _x983 = null;
                        break;
                    }
                    if (_descend984) {
                        /* too small? */
                        if (false) {
                            if ((!(((_x983)._right8) == null)) && (true)) {
                                if ((_x983) == (_root982)) {
                                    _root982 = (_x983)._right8;
                                }
                                _x983 = (_x983)._right8;
                            } else if ((_x983) == (_root982)) {
                                _x983 = null;
                                break;
                            } else {
                                _descend984 = false;
                                _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                                _x983 = (_x983)._parent9;
                            }
                        } else if ((!(((_x983)._left7) == null)) && (true)) {
                            _x983 = (_x983)._left7;
                            /* too large? */
                        } else if (false) {
                            if ((_x983) == (_root982)) {
                                _x983 = null;
                                break;
                            } else {
                                _descend984 = false;
                                _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                                _x983 = (_x983)._parent9;
                            }
                            /* node ok? */
                        } else if (true) {
                            break;
                        } else if ((_x983) == (_root982)) {
                            _root982 = (_x983)._right8;
                            _x983 = (_x983)._right8;
                        } else {
                            if ((!(((_x983)._right8) == null)) && (true)) {
                                if ((_x983) == (_root982)) {
                                    _root982 = (_x983)._right8;
                                }
                                _x983 = (_x983)._right8;
                            } else {
                                _descend984 = false;
                                _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                                _x983 = (_x983)._parent9;
                            }
                        }
                    } else if (_from_left985) {
                        if (false) {
                            _x983 = null;
                            break;
                        } else if (true) {
                            break;
                        } else if ((!(((_x983)._right8) == null)) && (true)) {
                            _descend984 = true;
                            if ((_x983) == (_root982)) {
                                _root982 = (_x983)._right8;
                            }
                            _x983 = (_x983)._right8;
                        } else if ((_x983) == (_root982)) {
                            _x983 = null;
                            break;
                        } else {
                            _descend984 = false;
                            _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                            _x983 = (_x983)._parent9;
                        }
                    } else {
                        if ((_x983) == (_root982)) {
                            _x983 = null;
                            break;
                        } else {
                            _descend984 = false;
                            _from_left985 = (!(((_x983)._parent9) == null)) && ((_x983) == (((_x983)._parent9)._left7));
                            _x983 = (_x983)._parent9;
                        }
                    }
                }
                _new_x981 = _x983;
                var _mp986 = (_x983)._parent9;
                var _mr987 = (_x983)._right8;
                /* replace _x983 with _mr987 in _mp986 */
                if (!((_mp986) == null)) {
                    if (((_mp986)._left7) == (_x983)) {
                        (_mp986)._left7 = _mr987;
                    } else {
                        (_mp986)._right8 = _mr987;
                    }
                }
                if (!((_mr987) == null)) {
                    (_mr987)._parent9 = _mp986;
                }
                /* replace _to_remove977 with _x983 in _parent978 */
                if (!((_parent978) == null)) {
                    if (((_parent978)._left7) == (_to_remove977)) {
                        (_parent978)._left7 = _x983;
                    } else {
                        (_parent978)._right8 = _x983;
                    }
                }
                if (!((_x983) == null)) {
                    (_x983)._parent9 = _parent978;
                }
                /* replace null with _left979 in _x983 */
                (_x983)._left7 = _left979;
                if (!((_left979) == null)) {
                    (_left979)._parent9 = _x983;
                }
                /* replace _mr987 with (_to_remove977)._right8 in _x983 */
                (_x983)._right8 = (_to_remove977)._right8;
                if (!(((_to_remove977)._right8) == null)) {
                    ((_to_remove977)._right8)._parent9 = _x983;
                }
                /* _min_ax12 is min of ax1 */
                var _augval988 = (_x983).ax1;
                var _child989 = (_x983)._left7;
                if (!((_child989) == null)) {
                    var _val990 = (_child989)._min_ax12;
                    _augval988 = ((_augval988) < (_val990)) ? (_augval988) : (_val990);
                }
                var _child991 = (_x983)._right8;
                if (!((_child991) == null)) {
                    var _val992 = (_child991)._min_ax12;
                    _augval988 = ((_augval988) < (_val992)) ? (_augval988) : (_val992);
                }
                (_x983)._min_ax12 = _augval988;
                /* _min_ay13 is min of ay1 */
                var _augval993 = (_x983).ay1;
                var _child994 = (_x983)._left7;
                if (!((_child994) == null)) {
                    var _val995 = (_child994)._min_ay13;
                    _augval993 = ((_augval993) < (_val995)) ? (_augval993) : (_val995);
                }
                var _child996 = (_x983)._right8;
                if (!((_child996) == null)) {
                    var _val997 = (_child996)._min_ay13;
                    _augval993 = ((_augval993) < (_val997)) ? (_augval993) : (_val997);
                }
                (_x983)._min_ay13 = _augval993;
                /* _max_ay24 is max of ay2 */
                var _augval998 = (_x983).ay2;
                var _child999 = (_x983)._left7;
                if (!((_child999) == null)) {
                    var _val1000 = (_child999)._max_ay24;
                    _augval998 = ((_augval998) < (_val1000)) ? (_val1000) : (_augval998);
                }
                var _child1001 = (_x983)._right8;
                if (!((_child1001) == null)) {
                    var _val1002 = (_child1001)._max_ay24;
                    _augval998 = ((_augval998) < (_val1002)) ? (_val1002) : (_augval998);
                }
                (_x983)._max_ay24 = _augval998;
                (_x983)._height10 = 1 + ((((((_x983)._left7) == null) ? (-1) : (((_x983)._left7)._height10)) > ((((_x983)._right8) == null) ? (-1) : (((_x983)._right8)._height10))) ? ((((_x983)._left7) == null) ? (-1) : (((_x983)._left7)._height10)) : ((((_x983)._right8) == null) ? (-1) : (((_x983)._right8)._height10)));
                var _cursor1003 = _mp986;
                var _changed1004 = true;
                while ((_changed1004) && (!((_cursor1003) == (_parent978)))) {
                    var _old__min_ax121005 = (_cursor1003)._min_ax12;
                    var _old__min_ay131006 = (_cursor1003)._min_ay13;
                    var _old__max_ay241007 = (_cursor1003)._max_ay24;
                    var _old_height1008 = (_cursor1003)._height10;
                    /* _min_ax12 is min of ax1 */
                    var _augval1009 = (_cursor1003).ax1;
                    var _child1010 = (_cursor1003)._left7;
                    if (!((_child1010) == null)) {
                        var _val1011 = (_child1010)._min_ax12;
                        _augval1009 = ((_augval1009) < (_val1011)) ? (_augval1009) : (_val1011);
                    }
                    var _child1012 = (_cursor1003)._right8;
                    if (!((_child1012) == null)) {
                        var _val1013 = (_child1012)._min_ax12;
                        _augval1009 = ((_augval1009) < (_val1013)) ? (_augval1009) : (_val1013);
                    }
                    (_cursor1003)._min_ax12 = _augval1009;
                    /* _min_ay13 is min of ay1 */
                    var _augval1014 = (_cursor1003).ay1;
                    var _child1015 = (_cursor1003)._left7;
                    if (!((_child1015) == null)) {
                        var _val1016 = (_child1015)._min_ay13;
                        _augval1014 = ((_augval1014) < (_val1016)) ? (_augval1014) : (_val1016);
                    }
                    var _child1017 = (_cursor1003)._right8;
                    if (!((_child1017) == null)) {
                        var _val1018 = (_child1017)._min_ay13;
                        _augval1014 = ((_augval1014) < (_val1018)) ? (_augval1014) : (_val1018);
                    }
                    (_cursor1003)._min_ay13 = _augval1014;
                    /* _max_ay24 is max of ay2 */
                    var _augval1019 = (_cursor1003).ay2;
                    var _child1020 = (_cursor1003)._left7;
                    if (!((_child1020) == null)) {
                        var _val1021 = (_child1020)._max_ay24;
                        _augval1019 = ((_augval1019) < (_val1021)) ? (_val1021) : (_augval1019);
                    }
                    var _child1022 = (_cursor1003)._right8;
                    if (!((_child1022) == null)) {
                        var _val1023 = (_child1022)._max_ay24;
                        _augval1019 = ((_augval1019) < (_val1023)) ? (_val1023) : (_augval1019);
                    }
                    (_cursor1003)._max_ay24 = _augval1019;
                    (_cursor1003)._height10 = 1 + ((((((_cursor1003)._left7) == null) ? (-1) : (((_cursor1003)._left7)._height10)) > ((((_cursor1003)._right8) == null) ? (-1) : (((_cursor1003)._right8)._height10))) ? ((((_cursor1003)._left7) == null) ? (-1) : (((_cursor1003)._left7)._height10)) : ((((_cursor1003)._right8) == null) ? (-1) : (((_cursor1003)._right8)._height10)));
                    _changed1004 = false;
                    _changed1004 = (_changed1004) || (!((_old__min_ax121005) == ((_cursor1003)._min_ax12)));
                    _changed1004 = (_changed1004) || (!((_old__min_ay131006) == ((_cursor1003)._min_ay13)));
                    _changed1004 = (_changed1004) || (!((_old__max_ay241007) == ((_cursor1003)._max_ay24)));
                    _changed1004 = (_changed1004) || (!((_old_height1008) == ((_cursor1003)._height10)));
                    _cursor1003 = (_cursor1003)._parent9;
                }
            }
            var _cursor1024 = _parent978;
            var _changed1025 = true;
            while ((_changed1025) && (!((_cursor1024) == (null)))) {
                var _old__min_ax121026 = (_cursor1024)._min_ax12;
                var _old__min_ay131027 = (_cursor1024)._min_ay13;
                var _old__max_ay241028 = (_cursor1024)._max_ay24;
                var _old_height1029 = (_cursor1024)._height10;
                /* _min_ax12 is min of ax1 */
                var _augval1030 = (_cursor1024).ax1;
                var _child1031 = (_cursor1024)._left7;
                if (!((_child1031) == null)) {
                    var _val1032 = (_child1031)._min_ax12;
                    _augval1030 = ((_augval1030) < (_val1032)) ? (_augval1030) : (_val1032);
                }
                var _child1033 = (_cursor1024)._right8;
                if (!((_child1033) == null)) {
                    var _val1034 = (_child1033)._min_ax12;
                    _augval1030 = ((_augval1030) < (_val1034)) ? (_augval1030) : (_val1034);
                }
                (_cursor1024)._min_ax12 = _augval1030;
                /* _min_ay13 is min of ay1 */
                var _augval1035 = (_cursor1024).ay1;
                var _child1036 = (_cursor1024)._left7;
                if (!((_child1036) == null)) {
                    var _val1037 = (_child1036)._min_ay13;
                    _augval1035 = ((_augval1035) < (_val1037)) ? (_augval1035) : (_val1037);
                }
                var _child1038 = (_cursor1024)._right8;
                if (!((_child1038) == null)) {
                    var _val1039 = (_child1038)._min_ay13;
                    _augval1035 = ((_augval1035) < (_val1039)) ? (_augval1035) : (_val1039);
                }
                (_cursor1024)._min_ay13 = _augval1035;
                /* _max_ay24 is max of ay2 */
                var _augval1040 = (_cursor1024).ay2;
                var _child1041 = (_cursor1024)._left7;
                if (!((_child1041) == null)) {
                    var _val1042 = (_child1041)._max_ay24;
                    _augval1040 = ((_augval1040) < (_val1042)) ? (_val1042) : (_augval1040);
                }
                var _child1043 = (_cursor1024)._right8;
                if (!((_child1043) == null)) {
                    var _val1044 = (_child1043)._max_ay24;
                    _augval1040 = ((_augval1040) < (_val1044)) ? (_val1044) : (_augval1040);
                }
                (_cursor1024)._max_ay24 = _augval1040;
                (_cursor1024)._height10 = 1 + ((((((_cursor1024)._left7) == null) ? (-1) : (((_cursor1024)._left7)._height10)) > ((((_cursor1024)._right8) == null) ? (-1) : (((_cursor1024)._right8)._height10))) ? ((((_cursor1024)._left7) == null) ? (-1) : (((_cursor1024)._left7)._height10)) : ((((_cursor1024)._right8) == null) ? (-1) : (((_cursor1024)._right8)._height10)));
                _changed1025 = false;
                _changed1025 = (_changed1025) || (!((_old__min_ax121026) == ((_cursor1024)._min_ax12)));
                _changed1025 = (_changed1025) || (!((_old__min_ay131027) == ((_cursor1024)._min_ay13)));
                _changed1025 = (_changed1025) || (!((_old__max_ay241028) == ((_cursor1024)._max_ay24)));
                _changed1025 = (_changed1025) || (!((_old_height1029) == ((_cursor1024)._height10)));
                _cursor1024 = (_cursor1024)._parent9;
            }
            if (((this)._root1) == (_to_remove977)) {
                (this)._root1 = _new_x981;
            }
            _prev_cursor5 = null;
        }
    };
}
; 
 
 buildViz = function (d3) {
    return function (widthInPixels = 1000,
                     heightInPixels = 600,
                     max_snippets = null,
                     color = null,
                     sortByDist = true,
                     useFullDoc = false,
                     greyZeroScores = false,
                     asianMode = false,
                     nonTextFeaturesMode = false,
                     showCharacteristic = true,
                     wordVecMaxPValue = false,
                     saveSvgButton = false,
                     reverseSortScoresForNotCategory = false,
                     minPVal = 0.1,
                     pValueColors = false,
                     xLabelText = null,
                     yLabelText = null,
                     fullData = null,
                     showTopTerms = true,
                     showNeutral = false,
                     getTooltipContent = null,
                     xAxisValues = null,
                     yAxisValues = null,
                     colorFunc = null,
                     showAxes = true,
                     showExtra = false,
                     doCensorPoints = true,
                     centerLabelsOverPoints = false,
                     xAxisLabels = null,
                     yAxisLabels = null,
                     topic_model_preview_size = 10,
                     verticalLines = null,
                     horizontal_line_y_position = null,
                     vertical_line_x_position = null,
                     unifiedContexts = false,
                     showCategoryHeadings = true,
                     showCrossAxes = true,
                     divName = 'd3-div-1',
                     alternativeTermFunc = null,
                     includeAllContexts = false,
                     showAxesAndCrossHairs = false,
                     x_axis_values_format = '.3f',
                     y_axis_values_format = '.3f',
                     matchFullLine = false,
                     maxOverlapping = -1,
                     showCorpusStats = true,
                     sortDocLabelsByName = false,
                     alwaysJump = true,
                     highlightSelectedCategory = false,
                     showDiagonal = false,
                     useGlobalScale = false,
                     enableTermCategoryDescription = true,
                     getCustomTermHtml = null,
                     headerNames = null,
                     headerSortingAlgos = null,
                     ignoreCategories = false,
                     backgroundLabels = null,
                     labelPriorityColumn = null,
                     textColorColumn = undefined,
                     suppressTextColumn = undefined,
                     backgroundColor = undefined,
                     censorPointColumn = undefined,
                     rightOrderColumn = undefined,
                     subwordEncoding = null,
                     topTermsLength = 14,
                     topTermsLeftBuffer = 0
    ) {
        function formatTermForDisplay(term) {
            if (subwordEncoding === 'RoBERTa' && (term.charCodeAt(0) === 288 || term.charCodeAt(0) === 289))
                term = '_' + term.substr(1, term.length - 1);
            return term;
        }

        //var divName = 'd3-div-1';
        // Set the dimensions of the canvas / graph
        var padding = {top: 30, right: 20, bottom: 30, left: 50};
        if (!showAxes) {
            padding = {top: 30, right: 20, bottom: 30, left: 50};
        }
        var margin = padding,
            width = widthInPixels - margin.left - margin.right,
            height = heightInPixels - margin.top - margin.bottom;
        fullData.data.forEach(function (x, i) {
            x.i = i
        });

        // Set the ranges
        var x = d3.scaleLinear().range([0, width]);
        var y = d3.scaleLinear().range([height, 0]);

        if (unifiedContexts) {
            document.querySelectorAll('#' + divName + '-' + 'notcol')
                .forEach(function (x) {
                    x.style.display = 'none'
                });
            document.querySelectorAll('.' + divName + '-' + 'contexts')
                .forEach(function (x) {
                    x.style.width = '90%'
                });
        } else if (showNeutral) {
            if (showExtra) {
                document.querySelectorAll('.' + divName + '-' + 'contexts')
                    .forEach(function (x) {
                        x.style.width = '25%'
                        x.style.float = 'left'
                    });

                ['notcol', 'neutcol', 'extracol'].forEach(function (columnName) {
                    document.querySelectorAll('#' + divName + '-' + columnName)
                        .forEach(function (x) {
                            x.style.display = 'inline'
                            x.style.float = 'left'
                            x.style.width = '25%'
                        });
                })

            } else {
                document.querySelectorAll('.' + divName + '-' + 'contexts')
                    .forEach(function (x) {
                        x.style.width = '33%'
                        x.style.float = 'left'
                    });

                ['notcol', 'neutcol'].forEach(function (columnName) {
                    document.querySelectorAll('#' + divName + '-' + columnName)
                        .forEach(function (x) {
                            x.style.display = 'inline'
                            x.style.float = 'left'
                            x.style.width = '33%'
                        });
                })


            }
        } else {
            document.querySelectorAll('.' + divName + '-' + 'contexts')
                .forEach(function (x) {
                    x.style.width = '45%'
                    //x.style.display = 'inline'
                    x.style.float = 'left'
                });

            ['notcol'].forEach(function (columnName) {
                document.querySelectorAll('#' + divName + '-' + columnName)
                    .forEach(function (x) {
                        //x.style.display = 'inline'
                        x.style.float = 'left'
                        x.style.width = '45%'
                    });
            })
        }

        var yAxis = null;
        var xAxis = null;

        function axisLabelerFactory(axis) {
            if ((axis == "x" && xLabelText == null)
                || (axis == "y" && yLabelText == null))
                return function (d, i) {
                    return ["Infrequent", "Average", "Frequent"][i];
                };

            return function (d, i) {
                return ["Low", "Medium", "High"][i];
            }
        }


        function bs(ar, x) {
            function bsa(s, e) {
                var mid = Math.floor((s + e) / 2);
                var midval = ar[mid];
                if (s == e) {
                    return s;
                }
                if (midval == x) {
                    return mid;
                } else if (midval < x) {
                    return bsa(mid + 1, e);
                } else {
                    return bsa(s, mid);
                }
            }

            return bsa(0, ar.length);
        }


        console.log("fullData");
        console.log(fullData);


        var sortedX = fullData.data.map(x => x).sort(function (a, b) {
            return a.x < b.x ? -1 : (a.x == b.x ? 0 : 1);
        }).map(function (x) {
            return x.x
        });

        var sortedOx = fullData.data.map(x => x).sort(function (a, b) {
            return a.ox < b.ox ? -1 : (a.ox == b.ox ? 0 : 1);
        }).map(function (x) {
            return x.ox
        });

        var sortedY = fullData.data.map(x => x).sort(function (a, b) {
            return a.y < b.y ? -1 : (a.y == b.y ? 0 : 1);
        }).map(function (x) {
            return x.y
        });

        var sortedOy = fullData.data.map(x => x).sort(function (a, b) {
            return a.oy < b.oy ? -1 : (a.oy == b.oy ? 0 : 1);
        }).map(function (x) {
            return x.oy
        });
        console.log(fullData.data[0])

        function labelWithZScore(axis, axisName, tickPoints, axis_values_format) {
            var myVals = axisName === 'x' ? sortedOx : sortedOy;
            var myPlotedVals = axisName === 'x' ? sortedX : sortedY;
            var ticks = tickPoints.map(function (x) {
                return myPlotedVals[bs(myVals, x)]
            });
            return axis.tickValues(ticks).tickFormat(
                function (d, i) {
                    return d3.format(axis_values_format)(tickPoints[i]);
                })
        }

        if (xAxisValues) {
            xAxis = labelWithZScore(d3.axisBottom(x), 'x', xAxisValues, x_axis_values_format);
        } else if (xAxisLabels) {
            xAxis = d3.axisBottom(x)
                .ticks(xAxisLabels.length)
                .tickFormat(function (d, i) {
                    return xAxisLabels[i];
                });
        } else {
            xAxis = d3.axisBottom(x).ticks(3).tickFormat(axisLabelerFactory('x'));
        }
        if (yAxisValues) {
            yAxis = labelWithZScore(d3.axisLeft(y), 'y', yAxisValues, y_axis_values_format);
        } else if (yAxisLabels) {
            yAxis = d3.axisLeft(y)
                .ticks(yAxisLabels.length)
                .tickFormat(function (d, i) {
                    return yAxisLabels[i];
                });
        } else {
            yAxis = d3.axisLeft(y).ticks(3).tickFormat(axisLabelerFactory('y'));
        }

        // var label = d3.select("body").append("div")
        var label = d3.select('#' + divName).append("div")
            .attr("class", "label");


        var interpolateLightGreys = d3.interpolate(d3.rgb(230, 230, 230),
            d3.rgb(130, 130, 130));
        // setup fill color
        if (color == null) {
            color = d3.interpolateRdYlBu;
        }
        if ((headerNames !== undefined && headerNames !== null)
            && (headerSortingAlgos !== undefined && headerSortingAlgos !== null)) {
            showTopTerms = true;
        }

        var pixelsToAddToWidth = 200;
        if (!showTopTerms && !showCharacteristic) {
            pixelsToAddToWidth = 0;
        }

        if (backgroundColor !== undefined) {
            document.body.style.backgroundColor = backgroundColor;
        }

        // Adds the svg canvas
        // var svg = d3.select("body")
        svg = d3.select('#' + divName)
            .append("svg")
            .attr("width", width + margin.left + margin.right + pixelsToAddToWidth)
            .attr("height", height + margin.top + margin.bottom)
            .append("g")
            .attr("transform",
                "translate(" + margin.left + "," + margin.top + ")");


        origSVGLeft = svg.node().getBoundingClientRect().left;
        origSVGTop = svg.node().getBoundingClientRect().top;
        var lastCircleSelected = null;

        function getCorpusWordCounts() {
            var binaryLabels = fullData.docs.labels.map(function (label) {
                return 1 * (fullData.docs.categories[label] != fullData.info.category_internal_name);
            });
            var wordCounts = {}; // word -> [cat counts, not-cat-counts]
            var wordCountSums = [0, 0];
            fullData.docs.texts.forEach(function (text, i) {
                text.toLowerCase().trim().split(/\W+/).forEach(function (word) {
                    if (word.trim() !== '') {
                        if (!(word in wordCounts))
                            wordCounts[word] = [0, 0];
                        wordCounts[word][binaryLabels[i]]++;
                        wordCountSums[binaryLabels[i]]++;
                    }
                })
            });
            return {
                avgDocLen: (wordCountSums[0] + wordCountSums[1]) / fullData.docs.texts.length,
                counts: wordCounts,
                sums: wordCountSums,
                uniques: [[0, 0]].concat(Object.keys(wordCounts).map(function (key) {
                    return wordCounts[key];
                })).reduce(function (a, b) {
                    return [a[0] + (b[0] > 0), a[1] + (b[1] > 0)]
                })
            };
        }

        function getContextWordCounts(query) {
            var wordCounts = {};
            var wordCountSums = [0, 0];
            var priorCountSums = [0, 0];
            gatherTermContexts(termDict[query])
                .contexts
                .forEach(function (contextSet, categoryIdx) {
                    contextSet.forEach(function (context) {
                        context.snippets.forEach(function (snippet) {
                            var tokens = snippet.toLowerCase().trim().replace('<b>', '').replace('</b>', '').split(/\W+/);
                            var matchIndices = [];
                            tokens.forEach(function (word, i) {
                                if (word === query) matchIndices.push(i)
                            });
                            tokens.forEach(function (word, i) {
                                if (word.trim() !== '') {
                                    var isValid = false;
                                    for (var matchI in matchIndices) {
                                        if (Math.abs(i - matchI) < 3) {
                                            isValid = true;
                                            break
                                        }
                                    }
                                    if (isValid) {
                                        //console.log([word, i, matchI, isValid]);
                                        if (!(word in wordCounts)) {
                                            var priorCounts = corpusWordCounts.counts[word]
                                            wordCounts[word] = [0, 0].concat(priorCounts);
                                            priorCountSums[0] += priorCounts[0];
                                            priorCountSums[1] += priorCounts[1];
                                        }
                                        wordCounts[word][categoryIdx]++;
                                        wordCountSums[categoryIdx]++;
                                    }
                                }
                            })
                        })
                    })
                });
            return {
                counts: wordCounts,
                priorSums: priorCountSums,
                sums: wordCountSums,
                uniques: [[0, 0]].concat(Object.keys(wordCounts).map(function (key) {
                    return wordCounts[key];
                })).reduce(function (a, b) {
                    return [a[0] + (b[0] > 0), a[1] + (b[1] > 0)];
                })
            }

        }

        function denseRank(ar) {
            var markedAr = ar.map((x, i) => [x, i]).sort((a, b) => a[0] - b[0]);
            var curRank = 1
            var rankedAr = markedAr.map(
                function (x, i) {
                    if (i > 0 && x[0] != markedAr[i - 1][0]) {
                        curRank++;
                    }
                    return [curRank, x[0], x[1]];
                }
            )
            return rankedAr.map(x => x).sort((a, b) => (a[2] - b[2])).map(x => x[0]);
        }


        function getDenseRanks(fullData, categoryNum) {
            console.log("GETTING DENSE RANKS")
            console.log("CAT NUM " + categoryNum)
            console.log(fullData)

            var fgFreqs = Array(fullData.data.length).fill(0);
            var bgFreqs = Array(fullData.data.length).fill(0);
            var categoryTermCounts = fullData.termCounts[categoryNum];

            Object.keys(categoryTermCounts).forEach(
                key => fgFreqs[key] = categoryTermCounts[key][0]
            )
            fullData.termCounts.forEach(
                function (categoryTermCounts, otherCategoryNum) {
                    if (otherCategoryNum != categoryNum) {
                        Object.keys(categoryTermCounts).forEach(
                            key => bgFreqs[key] += categoryTermCounts[key][0]
                        )
                    }
                }
            )
            var fgDenseRanks = denseRank(fgFreqs);
            var bgDenseRanks = denseRank(bgFreqs);

            var maxfgDenseRanks = Math.max(...fgDenseRanks);
            var minfgDenseRanks = Math.min(...fgDenseRanks);
            var scalefgDenseRanks = fgDenseRanks.map(
                x => (x - minfgDenseRanks) / (maxfgDenseRanks - minfgDenseRanks)
            )

            var maxbgDenseRanks = Math.max(...bgDenseRanks);
            var minbgDenseRanks = Math.min(...bgDenseRanks);
            var scalebgDenseRanks = bgDenseRanks.map(
                x => (x - minbgDenseRanks) / (maxbgDenseRanks - minbgDenseRanks)
            )

            return {'fg': scalefgDenseRanks,
                'bg': scalebgDenseRanks,
                'bgFreqs': bgFreqs,
                'fgFreqs': fgFreqs,
                'term': fullData.data.map((x)=>x.term)}
        }

        function getCategoryDenseRankScores(fullData, categoryNum) {
            var denseRanks = getDenseRanks(fullData, categoryNum)
            return denseRanks.fg.map((x, i) => x - denseRanks.bg[i]);
        }

        function getTermCounts(fullData) {
            var counts = Array(fullData.data.length).fill(0);
            fullData.termCounts.forEach(
                function (categoryTermCounts) {
                    Object.keys(categoryTermCounts).forEach(
                        key => counts[key] = categoryTermCounts[key][0]
                    )
                }
            )
            return counts;
        }

        function getContextWordLORIPs(query) {
            var contextWordCounts = getContextWordCounts(query);
            var ni_k = contextWordCounts.sums[0];
            var nj_k = contextWordCounts.sums[1];
            var n = ni_k + nj_k;
            //var ai_k0 = contextWordCounts.priorSums[0] + contextWordCounts.priorSums[1];
            //var aj_k0 = contextWordCounts.priorSums[0] + contextWordCounts.priorSums[1];
            var a0 = 0.00001 //corpusWordCounts.avgDocLen;
            var a_k0 = Object.keys(contextWordCounts.counts)
                .map(function (x) {
                    var counts = contextWordCounts.counts[x];
                    return a0 * (counts[2] + counts[3]) /
                        (contextWordCounts.priorSums[0] + contextWordCounts.priorSums[1]);
                })
                .reduce(function (a, b) {
                    return a + b
                });
            var ai_k0 = a_k0 / ni_k;
            var aj_k0 = a_k0 / nj_k;
            var scores = Object.keys(contextWordCounts.counts).map(
                function (word) {
                    var countData = contextWordCounts.counts[word];
                    var yi = countData[0];
                    var yj = countData[1];
                    //var ai = countData[2];
                    //var aj = countData[3];
                    //var ai = countData[2] + countData[3];
                    //var aj = ai;
                    //var ai = (countData[2] + countData[3]) * a0/ni_k;
                    //var aj = (countData[2] + countData[3]) * a0/nj_k;
                    var ai = a0 * (countData[2] + countData[3]) /
                        (contextWordCounts.priorSums[0] + contextWordCounts.priorSums[1]);
                    var aj = ai;
                    var deltahat_i_j =
                        +Math.log((yi + ai) * 1. / (ni_k + ai_k0 - yi - ai))
                        - Math.log((yj + aj) * 1. / (nj_k + aj_k0 - yj - aj));
                    var var_deltahat_i_j = 1. / (yi + ai) + 1. / (ni_k + ai_k0 - yi - ai)
                        + 1. / (yj + aj) + 1. / (nj_k + aj_k0 - yj - aj);
                    var zeta_ij = deltahat_i_j / Math.sqrt(var_deltahat_i_j);
                    return [word, yi, yj, ai, aj, ai_k0, zeta_ij];
                }
            ).sort(function (a, b) {
                return b[5] - a[5];
            });
            return scores;
        }

        function getContextWordSFS(query) {
            // from https://stackoverflow.com/questions/14846767/std-normal-cdf-normal-cdf-or-error-function
            function cdf(x, mean, variance) {
                return 0.5 * (1 + erf((x - mean) / (Math.sqrt(2 * variance))));
            }

            function erf(x) {
                // save the sign of x
                var sign = (x >= 0) ? 1 : -1;
                x = Math.abs(x);

                // constants
                var a1 = 0.254829592;
                var a2 = -0.284496736;
                var a3 = 1.421413741;
                var a4 = -1.453152027;
                var a5 = 1.061405429;
                var p = 0.3275911;

                // A&S formula 7.1.26
                var t = 1.0 / (1.0 + p * x);
                var y = 1.0 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * Math.exp(-x * x);
                return sign * y; // erf(-x) = -erf(x);
            }

            function scale(a) {
                return Math.log(a + 0.0000001);
            }

            var contextWordCounts = getContextWordCounts(query);
            var wordList = Object.keys(contextWordCounts.counts).map(function (word) {
                return contextWordCounts.counts[word].concat([word]);
            });
            var cat_freq_xbar = wordList.map(function (x) {
                return scale(x[0])
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;
            var cat_freq_var = wordList.map(function (x) {
                return Math.pow((scale(x[0]) - cat_freq_xbar), 2);
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;
            var cat_prec_xbar = wordList.map(function (x) {
                return scale(x[0] / (x[0] + x[1]));
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;
            var cat_prec_var = wordList.map(function (x) {
                return Math.pow((scale(x[0] / (x[0] + x[1])) - cat_prec_xbar), 2);
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;

            var ncat_freq_xbar = wordList.map(function (x) {
                return scale(x[0])
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;
            var ncat_freq_var = wordList.map(function (x) {
                return Math.pow((scale(x[0]) - ncat_freq_xbar), 2);
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;
            var ncat_prec_xbar = wordList.map(function (x) {
                return scale(x[0] / (x[0] + x[1]));
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;
            var ncat_prec_var = wordList.map(function (x) {
                return Math.pow((scale(x[0] / (x[0] + x[1])) - ncat_prec_xbar), 2);
            }).reduce(function (a, b) {
                return a + b
            }) / wordList.length;

            function scaledFScore(cnt, other, freq_xbar, freq_var, prec_xbar, prec_var) {
                var beta = 1.5;
                var normFreq = cdf(scale(cnt), freq_xbar, freq_var);
                var normPrec = cdf(scale(cnt / (cnt + other)), prec_xbar, prec_var);
                return (1 + Math.pow(beta, 2)) * normFreq * normPrec / (Math.pow(beta, 2) * normFreq + normPrec);
            }

            var sfs = wordList.map(function (x) {
                cat_sfs = scaledFScore(x[0], x[1], cat_freq_xbar,
                    cat_freq_var, cat_prec_xbar, cat_prec_var);
                ncat_sfs = scaledFScore(x[1], x[0], ncat_freq_xbar,
                    ncat_freq_var, ncat_prec_xbar, ncat_prec_var);
                return [cat_sfs > ncat_sfs ? cat_sfs : -ncat_sfs].concat(x);

            }).sort(function (a, b) {
                return b[0] - a[0];
            });
            return sfs;
        }

        function deselectLastCircle() {
            if (lastCircleSelected) {
                lastCircleSelected.style["stroke"] = null;
                lastCircleSelected = null;
            }
        }

        function getSentenceBoundaries(text) {
            // !!! need to use spacy's sentence splitter
            if (asianMode) {
                var sentenceRe = /\n/gmi;
            } else {
                var sentenceRe = /\(?[^\.\?\!\n\b]+[\n\.!\?]\)?/g;
            }
            var offsets = [];
            var match;
            while ((match = sentenceRe.exec(text)) != null) {
                offsets.push(match.index);
            }
            offsets.push(text.length);
            return offsets;
        }

        function getMatchingSnippet(text, boundaries, start, end) {
            var sentenceStart = null;
            var sentenceEnd = null;
            for (var i in boundaries) {
                var position = boundaries[i];
                if (position <= start && (sentenceStart == null || position > sentenceStart)) {
                    sentenceStart = position;
                }
                if (position >= end) {
                    sentenceEnd = position;
                    break;
                }
            }
            var snippet = (text.slice(sentenceStart, start) + "<b>" + text.slice(start, end)
                + "</b>" + text.slice(end, sentenceEnd)).trim();
            if (sentenceStart == null) {
                sentenceStart = 0;
            }
            return {'snippet': snippet, 'sentenceStart': sentenceStart};
        }

        function gatherTermContexts(d, includeAll = true) {
            var category_name = fullData['info']['category_name'];
            var not_category_name = fullData['info']['not_category_name'];
            var matches = [[], [], [], []];
            console.log("searching")

            if (fullData.docs === undefined) return matches;
            if (!nonTextFeaturesMode) {
                return searchInText(d, includeAll);
            } else {
                return searchInExtraFeatures(d, includeAll);
            }
        }

        function searchInExtraFeatures(d) {
            var matches = [[], [], [], []];
            var term = d.term;
            var categoryNum = fullData.docs.categories.indexOf(fullData.info.category_internal_name);
            var notCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.not_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });
            var neutralCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.neutral_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });
            var extraCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.extra_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });

            var pattern = null;
            if ('metalists' in fullData && term in fullData.metalists) {
                // from https://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
                function escapeRegExp(str) {
                    return str.replace(/[\\?\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|\']/g, "\\$&");
                }

                console.log('term');
                console.log(term);
                pattern = new RegExp(
                    '\\W(' + fullData.metalists[term].map(escapeRegExp).join('|') + ')\\W',
                    'gim'
                );
            }

            for (var i in fullData.docs.extra) {
                if (term in fullData.docs.extra[i]) {
                    var strength = fullData.docs.extra[i][term] /
                        Object.values(fullData.docs.extra[i]).reduce(
                            function (a, b) {
                                return a + b
                            });

                    var docLabel = fullData.docs.labels[i];
                    var numericLabel = -1;
                    if (docLabel == categoryNum) {
                        numericLabel = 0;
                    } else if (notCategoryNumList.indexOf(docLabel) > -1) {
                        numericLabel = 1;
                    } else if (neutralCategoryNumList.indexOf(docLabel) > -1) {
                        numericLabel = 2;
                    } else if (extraCategoryNumList.indexOf(docLabel) > -1) {
                        numericLabel = 3;
                    }
                    if (numericLabel == -1) {
                        continue;
                    }
                    var text = fullData.docs.texts[i];

                    if (fullData.offsets !== undefined) {

                        if (fullData.offsets[term] !== undefined && fullData.offsets[term][i] !== undefined) {
                            var curMatch = {
                                'id': i,
                                'snippets': [],
                                'strength': strength,
                                'docLabel': docLabel,
                                'meta': fullData.docs.meta ? fullData.docs.meta[i] : ""
                            }
                            for (const offset_i in fullData.offsets[term][i]) {
                                var offset = fullData.offsets[term][i][offset_i];
                                var spanStart = Math.max(offset[0] - 50, 0);
                                var spanEnd = Math.min(50, text.length-offset[1]);
                                var leftContext = text.substr(spanStart, offset[0] - spanStart);
                                var matchStr = text.substr(offset[0], offset[1] - offset[0]);
                                var rightContext = text.substr(offset[1], spanEnd);
                                var snippet = leftContext + '<b style="background-color: lightgoldenrodyellow">' + matchStr + '</b>' + rightContext;
                                if(spanStart > 0)
                                    snippet = '...' + snippet;
                                if(text.length - offset[1] > 50)
                                    snippet = snippet + '...'
                                curMatch.snippets.push(snippet)
                            }
                            matches[numericLabel].push(curMatch);
                        }
                    } else {

                        if (!useFullDoc)
                            text = text.slice(0, 300);
                        if (pattern !== null) {
                            text = text.replace(pattern, '<b>$&</b>');
                        }
                        var curMatch = {
                            'id': i,
                            'snippets': [text],
                            'strength': strength,
                            'docLabel': docLabel,
                            'meta': fullData.docs.meta ? fullData.docs.meta[i] : ""
                        }

                        matches[numericLabel].push(curMatch);
                    }
                }
            }
            for (var i in [0, 1]) {
                matches[i] = matches[i].sort(function (a, b) {
                    return a.strength < b.strength ? 1 : -1
                })
            }
            return {'contexts': matches, 'info': d};
        }

        // from https://mathiasbynens.be/notes/es-unicode-property-escapes#emoji
        var emojiRE = (/(?:[\u261D\u26F9\u270A-\u270D]|\uD83C[\uDF85\uDFC2-\uDFC4\uDFC7\uDFCA-\uDFCC]|\uD83D[\uDC42\uDC43\uDC46-\uDC50\uDC66-\uDC69\uDC6E\uDC70-\uDC78\uDC7C\uDC81-\uDC83\uDC85-\uDC87\uDCAA\uDD74\uDD75\uDD7A\uDD90\uDD95\uDD96\uDE45-\uDE47\uDE4B-\uDE4F\uDEA3\uDEB4-\uDEB6\uDEC0\uDECC]|\uD83E[\uDD18-\uDD1C\uDD1E\uDD1F\uDD26\uDD30-\uDD39\uDD3D\uDD3E\uDDD1-\uDDDD])(?:\uD83C[\uDFFB-\uDFFF])?|(?:[\u231A\u231B\u23E9-\u23EC\u23F0\u23F3\u25FD\u25FE\u2614\u2615\u2648-\u2653\u267F\u2693\u26A1\u26AA\u26AB\u26BD\u26BE\u26C4\u26C5\u26CE\u26D4\u26EA\u26F2\u26F3\u26F5\u26FA\u26FD\u2705\u270A\u270B\u2728\u274C\u274E\u2753-\u2755\u2757\u2795-\u2797\u27B0\u27BF\u2B1B\u2B1C\u2B50\u2B55]|\uD83C[\uDC04\uDCCF\uDD8E\uDD91-\uDD9A\uDDE6-\uDDFF\uDE01\uDE1A\uDE2F\uDE32-\uDE36\uDE38-\uDE3A\uDE50\uDE51\uDF00-\uDF20\uDF2D-\uDF35\uDF37-\uDF7C\uDF7E-\uDF93\uDFA0-\uDFCA\uDFCF-\uDFD3\uDFE0-\uDFF0\uDFF4\uDFF8-\uDFFF]|\uD83D[\uDC00-\uDC3E\uDC40\uDC42-\uDCFC\uDCFF-\uDD3D\uDD4B-\uDD4E\uDD50-\uDD67\uDD7A\uDD95\uDD96\uDDA4\uDDFB-\uDE4F\uDE80-\uDEC5\uDECC\uDED0-\uDED2\uDEEB\uDEEC\uDEF4-\uDEF8]|\uD83E[\uDD10-\uDD3A\uDD3C-\uDD3E\uDD40-\uDD45\uDD47-\uDD4C\uDD50-\uDD6B\uDD80-\uDD97\uDDC0\uDDD0-\uDDE6])|(?:[#\*0-9\xA9\xAE\u203C\u2049\u2122\u2139\u2194-\u2199\u21A9\u21AA\u231A\u231B\u2328\u23CF\u23E9-\u23F3\u23F8-\u23FA\u24C2\u25AA\u25AB\u25B6\u25C0\u25FB-\u25FE\u2600-\u2604\u260E\u2611\u2614\u2615\u2618\u261D\u2620\u2622\u2623\u2626\u262A\u262E\u262F\u2638-\u263A\u2640\u2642\u2648-\u2653\u2660\u2663\u2665\u2666\u2668\u267B\u267F\u2692-\u2697\u2699\u269B\u269C\u26A0\u26A1\u26AA\u26AB\u26B0\u26B1\u26BD\u26BE\u26C4\u26C5\u26C8\u26CE\u26CF\u26D1\u26D3\u26D4\u26E9\u26EA\u26F0-\u26F5\u26F7-\u26FA\u26FD\u2702\u2705\u2708-\u270D\u270F\u2712\u2714\u2716\u271D\u2721\u2728\u2733\u2734\u2744\u2747\u274C\u274E\u2753-\u2755\u2757\u2763\u2764\u2795-\u2797\u27A1\u27B0\u27BF\u2934\u2935\u2B05-\u2B07\u2B1B\u2B1C\u2B50\u2B55\u3030\u303D\u3297\u3299]|\uD83C[\uDC04\uDCCF\uDD70\uDD71\uDD7E\uDD7F\uDD8E\uDD91-\uDD9A\uDDE6-\uDDFF\uDE01\uDE02\uDE1A\uDE2F\uDE32-\uDE3A\uDE50\uDE51\uDF00-\uDF21\uDF24-\uDF93\uDF96\uDF97\uDF99-\uDF9B\uDF9E-\uDFF0\uDFF3-\uDFF5\uDFF7-\uDFFF]|\uD83D[\uDC00-\uDCFD\uDCFF-\uDD3D\uDD49-\uDD4E\uDD50-\uDD67\uDD6F\uDD70\uDD73-\uDD7A\uDD87\uDD8A-\uDD8D\uDD90\uDD95\uDD96\uDDA4\uDDA5\uDDA8\uDDB1\uDDB2\uDDBC\uDDC2-\uDDC4\uDDD1-\uDDD3\uDDDC-\uDDDE\uDDE1\uDDE3\uDDE8\uDDEF\uDDF3\uDDFA-\uDE4F\uDE80-\uDEC5\uDECB-\uDED2\uDEE0-\uDEE5\uDEE9\uDEEB\uDEEC\uDEF0\uDEF3-\uDEF8]|\uD83E[\uDD10-\uDD3A\uDD3C-\uDD3E\uDD40-\uDD45\uDD47-\uDD4C\uDD50-\uDD6B\uDD80-\uDD97\uDDC0\uDDD0-\uDDE6])\uFE0F/g);

        function isEmoji(str) {
            if (str.match(emojiRE)) return true;
            return false;
        }

        function displayObscuredTerms(obscuredTerms, data, term, termInfo, div = '#' + divName + '-' + 'overlapped-terms') {
            d3.select('#' + divName + '-' + 'overlapped-terms')
                .selectAll('div')
                .remove();
            d3.select(div)
                .selectAll('div')
                .remove();
            if (obscuredTerms.length > 1 && maxOverlapping !== 0) {
                var obscuredDiv = d3.select(div)
                    .append('div')
                    .attr("class", "obscured")
                    .style('align', 'center')
                    .style('text-align', 'center')
                    .html("<b>\"" + term + "\" obstructs</b>: ");
                obscuredTerms.map(
                    function (term, i) {
                        if (maxOverlapping === -1 || i < maxOverlapping) {
                            makeWordInteractive(
                                data,
                                svg,
                                obscuredDiv.append("text").text(term),
                                term,
                                data.filter(t => t.term === term)[0],//termInfo
                                false
                            );
                            if (i < obscuredTerms.length - 1
                                && (maxOverlapping === -1 || i < maxOverlapping - 1)) {
                                obscuredDiv.append("text").text(", ");
                            }
                        } else if (i === maxOverlapping && i !== obscuredTerms.length - 1) {
                            obscuredDiv.append("text").text("...");
                        }
                    }
                )
            }
        }

        function displayTermContexts(data, termInfo, jump = alwaysJump, includeAll = false) {
            var contexts = termInfo.contexts;
            var info = termInfo.info;
            var notmatches = termInfo.notmatches;
            if (contexts[0].length + contexts[1].length + contexts[2].length + contexts[3].length == 0) {
                //return null;
            }
            //!!! Future feature: context words
            //var contextWords = getContextWordSFS(info.term);
            //var contextWords = getContextWordLORIPs(info.term);
            //var categoryNames = [fullData.info.category_name,
            //    fullData.info.not_category_name];
            var catInternalName = fullData.info.category_internal_name;


            function addSnippets(contexts, divId, isMatch = true) {
                var meta = contexts.meta ? contexts.meta : '&nbsp;';
                var headClass = 'snippet_meta docLabel' + contexts.docLabel;
                var snippetClass = 'snippet docLabel' + contexts.docLabel;
                if (!isMatch) {
                    headClass = 'snippet_meta not_match docLabel' + contexts.docLabel;
                    snippetClass = 'snippet not_match docLabel' + contexts.docLabel;
                }
                d3.select(divId)
                    .append("div")
                    .attr('class', headClass)
                    .html(meta);
                contexts.snippets.forEach(function (snippet) {
                    d3.select(divId)
                        .append("div")
                        .attr('class', snippetClass)
                        .html(snippet);
                })
            }


            if (ignoreCategories) {
                divId = '#' + divName + '-' + 'cat';

                var numMatches = Object.create(null);
                var temp = d3.select(divId).selectAll("div").remove();
                var allContexts = contexts[0].concat(contexts[1]).concat(contexts[2]).concat(contexts[3]);
                var allNotMatches = [];
                if (notmatches !== undefined)
                    allNotMatches = notmatches[0].concat(notmatches[1]).concat(notmatches[2]).concat(notmatches[3]);
                d3.select('#' + divName + '-' + 'categoryinfo').selectAll("div").remove();
                var numDocs = fullData.docs.texts.length.toLocaleString('en');
                var numMatches = allContexts.length;
                d3.select(divId)
                    .append("div")
                    .attr('class', 'topic_preview')
                    .attr('text-align', "center")
                    .html(
                        "Matched " + numMatches + " out of " + numDocs + ' documents: '
                        + (100 * numMatches / numDocs).toFixed(2) + '%'
                    );

                if (allContexts.length > 0) {
                    var headerClassName = 'text_header';
                    allContexts.forEach(function (singleDoc) {
                        addSnippets(singleDoc, divId);
                    });
                    if (includeAll) {
                        allNotMatches.forEach(function (singleDoc) {
                            addSnippets(singleDoc, divId, false);
                        });
                    }
                }

            } else if (unifiedContexts) {
                divId = '#' + divName + '-' + 'cat';
                var docLabelCounts = fullData.docs.labels.reduce(
                    function (map, label) {
                        map[label] = (map[label] || 0) + 1;
                        return map;
                    },
                    Object.create(null)
                );
                var numMatches = Object.create(null);
                var temp = d3.select(divId).selectAll("div").remove();
                var allContexts = contexts[0].concat(contexts[1]).concat(contexts[2]).concat(contexts[3]);
                allContexts.forEach(function (singleDoc) {
                    numMatches[singleDoc.docLabel] = (numMatches[singleDoc.docLabel] || 0) + 1;
                });
                var allNotMatches = [];
                if (notmatches !== undefined)
                    allNotMatches = notmatches[0].concat(notmatches[1]).concat(notmatches[2]).concat(notmatches[3]);

                /*contexts.forEach(function(context) {
                     context.forEach(function (singleDoc) {
                         numMatches[singleDoc.docLabel] = (numMatches[singleDoc.docLabel]||0) + 1;
                         addSnippets(singleDoc, divId);
                     });
                 });*/
                console.log("ORDERING !!!!!");
                console.log(fullData.info.category_name);
                console.log(sortDocLabelsByName);
                var docLabelCountsSorted = Object.keys(docLabelCounts).map(key => (
                    {
                        "label": fullData.docs.categories[key],
                        "labelNum": key,
                        "matches": numMatches[key] || 0,
                        "overall": docLabelCounts[key],
                        'percent': (numMatches[key] || 0) * 100. / docLabelCounts[key]
                    }))
                    .sort(function (a, b) {
                        if (highlightSelectedCategory) {
                            if (a['label'] === fullData.info.category_name) {
                                return -1;
                            }
                            if (b['label'] === fullData.info.category_name) {
                                return 1;
                            }
                        }
                        if (sortDocLabelsByName) {
                            return a['label'] < b['label'] ? 1 : a['label'] > b['label'] ? -1 : 0;
                        } else {
                            return b.percent - a.percent;
                        }
                    });
                console.log("docLabelCountsSorted")
                console.log(docLabelCountsSorted);
                console.log(numMatches)
                console.log('#' + divName + '-' + 'categoryinfo')
                d3.select('#' + divName + '-' + 'categoryinfo').selectAll("div").remove();
                if (showCategoryHeadings) {
                    d3.select('#' + divName + '-' + 'categoryinfo').attr('display', 'inline');
                }

                function getCategoryStatsHTML(counts) {
                    return counts.matches + " document"
                        + (counts.matches == 1 ? "" : "s") + " out of " + counts.overall + ': '
                        + counts['percent'].toFixed(2) + '%';
                }

                function getCategoryInlineHeadingHTML(counts) {
                    return '<a name="' + divName + '-category'
                        + counts.labelNum + '"></a>'
                        + (ignoreCategories ? "" : counts.label + ": ") + "<span class=topic_preview>"
                        + getCategoryStatsHTML(counts)
                        + "</span>";
                }


                docLabelCountsSorted.forEach(function (counts) {

                    var htmlToAdd = "";
                    if (!ignoreCategories) {
                        htmlToAdd += "<b>" + counts.label + "</b>: " + getCategoryStatsHTML(counts);
                        ;
                    }

                    if (counts.matches > 0) {
                        var headerClassName = 'text_header';
                        if ((counts.label === fullData.info.category_name) && highlightSelectedCategory) {
                            d3.select(divId)
                                .append('div')
                                .attr('class', 'separator')
                                .html("<b>Selected category</b>");
                        }
                        d3.select(divId)
                            .append("div")
                            .attr('class', headerClassName)
                            .html(getCategoryInlineHeadingHTML(counts));

                        allContexts
                            .filter(singleDoc => singleDoc.docLabel == counts.labelNum)
                            .forEach(function (singleDoc) {
                                addSnippets(singleDoc, divId);
                            });
                        if (includeAll) {
                            allNotMatches
                                .filter(singleDoc => singleDoc.docLabel == counts.labelNum)
                                .forEach(function (singleDoc) {
                                    addSnippets(singleDoc, divId, false);
                                });
                        }
                        if ((counts.label === fullData.info.category_name) && highlightSelectedCategory) {
                            d3.select(divId).append('div').attr('class', 'separator').html("<b>End selected category</b>");
                            d3.select(divId).append('div').html("<br />");
                        }
                    }


                    if (showCategoryHeadings) {
                        d3.select('#' + divName + '-' + 'categoryinfo')
                            .attr('display', 'inline')
                            .append('div')
                            .html(htmlToAdd)
                            .on("click", function () {
                                window.location.hash = '#' + divName + '-' + 'category' + counts.labelNum
                            });
                    }

                })


            } else {
                var contextColumns = [
                    fullData.info.category_internal_name,
                    fullData.info.not_category_name
                ];
                if (showNeutral) {
                    if ('neutral_category_name' in fullData.info) {
                        contextColumns.push(fullData.info.neutral_category_name)
                    } else {
                        contextColumns.push("Neutral")
                    }
                    if (showExtra) {
                        if ('extra_category_name' in fullData.info) {
                            contextColumns.push(fullData.info.extra_category_name)
                        } else {
                            contextColumns.push("Extra")
                        }
                    }

                }
                contextColumns.map(
                    function (catName, catIndex) {
                        if (max_snippets != null) {
                            var contextsToDisplay = contexts[catIndex].slice(0, max_snippets);
                        }
                        //var divId = catName == catInternalName ? '#cat' : '#notcat';
                        var divId = null
                        if (fullData.info.category_internal_name == catName) {
                            divId = '#' + divName + '-' + 'cat'
                        } else if (fullData.info.not_category_name == catName) {
                            divId = '#' + divName + '-' + 'notcat'
                        } else if (fullData.info.neutral_category_name == catName) {
                            divId = '#' + divName + '-' + 'neut';
                        } else if (fullData.info.extra_category_name == catName) {
                            divId = '#' + divName + '-' + 'extra'
                        } else {
                            return;
                        }

                        var temp = d3.select(divId).selectAll("div").remove();
                        contexts[catIndex].forEach(function (context) {
                            addSnippets(context, divId);
                        });
                        if (includeAll) {
                            notmatches[catIndex].forEach(function (context) {
                                addSnippets(context, divId, false);
                            });
                        }
                    }
                );
            }

            var obscuredTerms = getObscuredTerms(data, termInfo.info);
            displayObscuredTerms(obscuredTerms, data, info.term, info, '#' + divName + '-' + 'overlapped-terms-clicked');

            d3.select('#' + divName + '-' + 'termstats')
                .selectAll("div")
                .remove();
            var termHtml = 'Term: <b>' + formatTermForDisplay(info.term) + '</b>';
            if ('metalists' in fullData && info.term in fullData.metalists) {
                termHtml = 'Topic: <b>' + formatTermForDisplay(info.term) + '</b>';
            }
            if (getCustomTermHtml !== null) {
                termHtml = getCustomTermHtml(info);
            }
            d3.select('#' + divName + '-' + 'termstats')
                .append('div')
                .attr("class", "snippet_header")
                .html(termHtml);
            if ('metalists' in fullData && info.term in fullData.metalists && topic_model_preview_size > 0) {
                d3.select('#' + divName + '-' + 'termstats')
                    .attr("class", "topic_preview")
                    .append('div')
                    .html("<b>Topic preview</b>: "
                        + fullData.metalists[info.term]
                            .slice(0, topic_model_preview_size)
                            .reduce(function (x, y) {
                                return x + ', ' + y
                            }));
            }
            if ('metadescriptions' in fullData && info.term in fullData.metadescriptions) {
                d3.select('#' + divName + '-' + 'termstats')
                    .attr("class", "topic_preview")
                    .append('div')
                    .html("<b>Description</b>: " + fullData.metadescriptions[info.term]);
            }
            var message = '';
            var cat_name = fullData.info.category_name;
            var ncat_name = fullData.info.not_category_name;


            var numCatDocs = fullData.docs.labels
                .map(function (x) {
                    return (x == fullData.docs.categories.indexOf(
                        fullData.info.category_internal_name)) + 0
                })
                .reduce(function (a, b) {
                    return a + b;
                }, 0);

            var notCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.not_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });


            var numNCatDocs = fullData.docs.labels
                .map(function (x) {
                    return notCategoryNumList.indexOf(x) > -1
                })
                .reduce(function (a, b) {
                    return a + b;
                }, 0);

            function getFrequencyDescription(name, count25k, count, ndocs) {
                var desc = name;
                if (!enableTermCategoryDescription) {
                    return desc + ':';
                }
                desc += ' frequency: <div class=text_subhead>' + count25k + ' per 25,000 terms</div>';
                if (!isNaN(Math.round(ndocs))) {
                    desc += '<div class=text_subhead>' + Math.round(ndocs) + ' per 1,000 docs</div>';
                }
                if (count == 0) {
                    desc += '<u>Not found in any ' + name + ' documents.</u>';
                } else {
                    if (!isNaN(Math.round(ndocs))) {
                        desc += '<u>Some of the ' + count + ' mentions:</u>';
                    } else {
                        desc += count + ' mentions';
                    }
                }
                /*
                desc += '<br><b>Discriminative:</b> ';

                desc += contextWords
                    .slice(cat_name === name ? 0 : contextWords.length - 3,
                        cat_name === name ? 3 : contextWords.length)
                    .filter(function (x) {
                        //return Math.abs(x[5]) > 1.96;
                        return true;
                    })
                    .map(function (x) {return x.join(', ')}).join('<br>');
                */
                return desc;
            }

            if (!unifiedContexts && !ignoreCategories) {
                console.log("NOT UNIFIED CONTEXTS")
                d3.select('#' + divName + '-' + 'cathead')
                    .style('fill', color(1))
                    .html(
                        getFrequencyDescription(cat_name,
                            info.cat25k,
                            info.cat,
                            termInfo.contexts[0].length * 1000 / numCatDocs
                        )
                    );
                d3.select('#' + divName + '-' + 'notcathead')
                    .style('fill', color(0))
                    .html(
                        getFrequencyDescription(ncat_name,
                            info.ncat25k,
                            info.ncat,
                            termInfo.contexts[1].length * 1000 / numNCatDocs)
                    );
                if (showNeutral) {
                    var numList = fullData.docs.categories.map(function (x, i) {
                        if (fullData.info.neutral_category_internal_names.indexOf(x) > -1) {
                            return i;
                        } else {
                            return -1;
                        }
                    }).filter(function (x) {
                        return x > -1
                    });

                    var numDocs = fullData.docs.labels
                        .map(function (x) {
                            return numList.indexOf(x) > -1
                        })
                        .reduce(function (a, b) {
                            return a + b;
                        }, 0);

                    d3.select("#" + divName + "-neuthead")
                        .style('fill', color(0))
                        .html(
                            getFrequencyDescription(fullData.info.neutral_category_name,
                                info.neut25k,
                                info.neut,
                                termInfo.contexts[2].length * 1000 / numDocs)
                        );

                    if (showExtra) {
                        var numList = fullData.docs.categories.map(function (x, i) {
                            if (fullData.info.extra_category_internal_names.indexOf(x) > -1) {
                                return i;
                            } else {
                                return -1;
                            }
                        }).filter(function (x) {
                            return x > -1
                        });

                        var numDocs = fullData.docs.labels
                            .map(function (x) {
                                return numList.indexOf(x) > -1
                            })
                            .reduce(function (a, b) {
                                return a + b;
                            }, 0);

                        d3.select("#" + divName + "-extrahead")
                            .style('fill', color(0))
                            .html(
                                getFrequencyDescription(fullData.info.extra_category_name,
                                    info.extra25k,
                                    info.extra,
                                    termInfo.contexts[3].length * 1000 / numDocs)
                            );

                    }
                }
            } else if (unifiedContexts && !ignoreCategories) {
                // extra unified context code goes here
                console.log("docLabelCountsSorted")
                console.log(docLabelCountsSorted)

                docLabelCountsSorted.forEach(function (counts) {
                    var htmlToAdd = (ignoreCategories ? "" : "<b>" + counts.label + "</b>: ") + getCategoryStatsHTML(counts);
                    if (showCategoryHeadings) {
                        d3.select('#' + divName + '-' + 'contexts')
                            .append('div')
                            .html(htmlToAdd)
                            .on("click", function () {
                                window.location.hash = '#' + divName + '-' + 'category' + counts.labelNum
                            });
                    }
                })
            }
            if (jump) {
                if (window.location.hash === '#' + divName + '-' + 'snippets') {
                    window.location.hash = '#' + divName + '-' + 'snippetsalt';
                } else {
                    window.location.hash = '#' + divName + '-' + 'snippets';
                }
            }
        }

        function searchInText(d, includeAll = true) {
            function stripNonWordChars(term) {
                //d.term.replace(" ", "[^\\w]+")
            }

            function removeUnderScoreJoin(term) {
                /*
                '_ _asjdklf_jaksdlf_jaksdfl skld_Jjskld asdfjkl_sjkdlf'
                  ->
                "_ _asjdklf jaksdlf jaksdfl skld Jjskld asdfjkl_sjkdlf"
                 */
                return term.replace(/(\w+)(_)(\w+)/, "$1 $3")
                    .replace(/(\w+)(_)(\w+)/, "$1 $3")
                    .replace(/(\w+)(_)(\w+)/, "$1 $3");
            }

            function buildMatcher(term) {


                var boundary = '(?:\\W|^|$)';
                var wordSep = "[^\\w]+";
                if (asianMode) {
                    boundary = '( |$|^)';
                    wordSep = ' ';
                }
                if (isEmoji(term)) {
                    boundary = '';
                    wordSep = '';
                }
                if (matchFullLine) {
                    boundary = '($|^)';
                }
                var termToRegex = term;


                // https://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
                function escapeRegExp(string) {
                    return string.replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\,\\\^\$\|\'#?]/g, "\\$&");
                    //return string.replace(/[\?#.*+^${}()|[\]\\]'\%/g, '\\$&'); // $& means the whole matched string
                }

                /*
                ['[', ']', '(', ')', '{', '}', '^', '$', '|', '?', '"',
                    '*', '+', '-', '=', '~', '`', '{'].forEach(function (a) {
                    termToRegex = termToRegex.replace(a, '\\\\' + a)
                });
                ['.', '#'].forEach(function(a) {termToRegex = termToRegex.replace(a, '\\' + a)})
                */
                termToRegex = escapeRegExp(termToRegex);
                console.log("termToRegex")
                console.log(termToRegex)

                var regexp = new RegExp(boundary + '('
                    + removeUnderScoreJoin(
                        termToRegex.replace(' ', wordSep, 'gim')
                    ) + ')' + boundary, 'gim');
                console.log(regexp);

                if (subwordEncoding === 'RoBERTa') {
                    if (term.charCodeAt(0) === 288 || term.charCodeAt(0) === 289) {
                        // Starts with character  indicating it's a word start
                        console.log("START")
                        regexp = new RegExp(boundary + escapeRegExp(term.substr(1, term.length)), 'gim');
                    } else {
                        regexp = new RegExp("\w" + escapeRegExp(term), 'gim');
                    }
                    console.log("SP")
                    console.log(regexp)
                }


                try {
                    regexp.exec('X');
                } catch (err) {
                    console.log("Can't search " + term);
                    console.log(err);
                    return null;
                }
                return regexp;
            }

            var matches = [[], [], [], []];
            var notmatches = [[], [], [], []];
            var pattern = buildMatcher(d.term);
            var categoryNum = fullData.docs.categories.indexOf(fullData.info.category_internal_name);
            var notCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.not_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });
            var neutralCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.neutral_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });
            var extraCategoryNumList = fullData.docs.categories.map(function (x, i) {
                if (fullData.info.extra_category_internal_names.indexOf(x) > -1) {
                    return i;
                } else {
                    return -1;
                }
            }).filter(function (x) {
                return x > -1
            });
            console.log('extraCategoryNumList')
            console.log(extraCategoryNumList);
            console.log("categoryNum");
            console.log(categoryNum);
            console.log("categoryNum");
            if (pattern !== null) {
                for (var i in fullData.docs.texts) {
                    //var numericLabel = 1 * (fullData.docs.categories[fullData.docs.labels[i]] != fullData.info.category_internal_name);

                    var docLabel = fullData.docs.labels[i];
                    var numericLabel = -1;
                    if (docLabel == categoryNum) {
                        numericLabel = 0;
                    } else if (notCategoryNumList.indexOf(docLabel) > -1) {
                        numericLabel = 1;
                    } else if (neutralCategoryNumList.indexOf(docLabel) > -1) {
                        numericLabel = 2;
                    } else if (extraCategoryNumList.indexOf(docLabel) > -1) {
                        numericLabel = 3;
                    }
                    if (numericLabel == -1) {
                        continue;
                    }

                    var text = removeUnderScoreJoin(fullData.docs.texts[i]);
                    //var pattern = new RegExp("\\b(" + stripNonWordChars(d.term) + ")\\b", "gim");
                    var match;
                    var sentenceOffsets = null;
                    var lastSentenceStart = null;
                    var matchFound = false;
                    var curMatch = {'id': i, 'snippets': [], 'notsnippets': [], 'docLabel': docLabel};
                    if (fullData.docs.meta) {
                        curMatch['meta'] = fullData.docs.meta[i];
                    }

                    while ((match = pattern.exec(text)) != null) {
                        if (sentenceOffsets == null) {
                            sentenceOffsets = getSentenceBoundaries(text);
                        }
                        var foundSnippet = getMatchingSnippet(text, sentenceOffsets,
                            match.index, pattern.lastIndex);
                        if (foundSnippet.sentenceStart == lastSentenceStart) continue; // ensure we don't duplicate sentences
                        lastSentenceStart = foundSnippet.sentenceStart;
                        curMatch.snippets.push(foundSnippet.snippet);
                        matchFound = true;
                    }
                    if (matchFound) {
                        if (useFullDoc) {
                            curMatch.snippets = [
                                text
                                    .replace(/\n$/g, '\n\n')
                                    .replace(
                                        //new RegExp("\\b(" + d.term.replace(" ", "[^\\w]+") + ")\\b",
                                        //    'gim'),
                                        pattern,
                                        '<b>$&</b>')
                            ];
                        }
                        matches[numericLabel].push(curMatch);
                    } else {
                        if (includeAll) {
                            curMatch.snippets = [
                                text.replace(/\n$/g, '\n\n')
                            ];
                            notmatches[numericLabel].push(curMatch);
                        }

                    }
                }
            }
            var toRet = {
                'contexts': matches,
                'notmatches': notmatches,
                'info': d,
                'docLabel': docLabel
            };
            return toRet;
        }

        function getDefaultTooltipContent(d) {
            var term = formatTermForDisplay(d.term);

            var message = term + "<br/>" + d.cat25k + ":" + d.ncat25k + " per 25k words";
            message += '<br/>score: ' + d.os.toFixed(5);
            return message;
        }

        function getDefaultTooltipContentWithoutScore(d) {
            var term = formatTermForDisplay(d.term);

            var message = term + "<br/>" + d.cat25k + ":" + d.ncat25k + " per 25k words";
            return message;
        }

        function getObscuredTerms(data, d) {
            //data = fullData['data']
            var matches = (data.filter(function (term) {
                    return term.x === d.x && term.y === d.y && (term.display === undefined || term.display === true);
                }).map(function (term) {
                    return formatTermForDisplay(term.term)
                }).sort()
            );
            return matches;
        }

        function showTooltip(data, d, pageX, pageY, showObscured = true) {
            deselectLastCircle();

            var obscuredTerms = getObscuredTerms(data, d);
            var message = '';
            console.log("!!!!! " + obscuredTerms.length)
            console.log(showObscured)
            if (obscuredTerms.length > 1 && showObscured)
                displayObscuredTerms(obscuredTerms, data, d.term, d);
            if (getTooltipContent !== null) {
                message += getTooltipContent(d);
            } else {
                if (sortByDist) {
                    message += getDefaultTooltipContentWithoutScore(d);
                } else {
                    message += getDefaultTooltipContent(d);
                }
            }
            pageX -= (svg.node().getBoundingClientRect().left) - origSVGLeft;
            pageY -= (svg.node().getBoundingClientRect().top) - origSVGTop;
            tooltip.transition()
                .duration(0)
                .style("opacity", 1)
                .style("z-index", 10000000);
            tooltip.html(message)
                .style("left", (pageX - 40) + "px")
                .style("top", (pageY - 85 > 0 ? pageY - 85 : 0) + "px");
            tooltip.on('click', function () {
                tooltip.transition()
                    .style('opacity', 0)
            }).on('mouseout', function () {
                tooltip.transition().style('opacity', 0)
            });
        }

        handleSearch = function (event) {
            var searchTerm = document
                .getElementById(this.divName + "-searchTerm")
                .value;
            handleSearchTerm(searchTerm);
            return false;
        };

        function highlightTerm(searchTerm, showObscured) {
            deselectLastCircle();
            var cleanedTerm = searchTerm.toLowerCase()
                .replace("'", " '")
                .trim();
            if (this.termDict[cleanedTerm] === undefined) {
                cleanedTerm = searchTerm.replace("'", " '").trim();
            }
            if (this.termDict[cleanedTerm] !== undefined) {
                showToolTipForTerm(this.data, this.svg, cleanedTerm, this.termDict[cleanedTerm], showObscured);
            }
            return cleanedTerm;
        }

        function handleSearchTerm(searchTerm, jump = false) {
            console.log("Handle search term.");
            console.log(searchTerm);
            console.log("this");
            console.log(this)
            highlighted = highlightTerm.call(this, searchTerm, true);
            console.log("found searchTerm");
            console.log(searchTerm);
            if (this.termDict[searchTerm] != null) {
                var runDisplayTermContexts = true;
                if (alternativeTermFunc != null) {
                    runDisplayTermContexts = this.alternativeTermFunc(this.termDict[searchTerm]);
                }
                if (runDisplayTermContexts) {
                    displayTermContexts(
                        this.data,
                        this.gatherTermContexts(this.termDict[searchTerm], this.includeAllContexts),
                        alwaysJump,
                        this.includeAllContexts
                    );
                }
            }
        }

        function getCircleForSearchTerm(mysvg, searchTermInfo) {
            var circle = mysvg;
            if (circle.tagName !== "circle") { // need to clean this thing up
                circle = mysvg._groups[0][searchTermInfo.ci];
                if (circle === undefined || circle.tagName != 'circle') {
                    if (mysvg._groups[0].children !== undefined) {
                        circle = mysvg._groups[0].children[searchTermInfo.ci];
                    }
                }
                if (circle === undefined || circle.tagName != 'circle') {
                    if (mysvg._groups[0][0].children !== undefined) {
                        circle = Array.prototype.filter.call(
                            mysvg._groups[0][0].children,
                            x => (x.tagName == "circle" && x.__data__['term'] == searchTermInfo.term)
                        )[0];
                    }
                }
                if ((circle === undefined || circle.tagName != 'circle') && mysvg._groups[0][0].children !== undefined) {
                    circle = mysvg._groups[0][0].children[searchTermInfo.ci];
                }
            }
            return circle;
        }

        function showToolTipForTerm(data, mysvg, searchTerm, searchTermInfo, showObscured = true) {
            //var searchTermInfo = termDict[searchTerm];
            console.log("showing tool tip")
            console.log(searchTerm)
            console.log(searchTermInfo)
            if (searchTermInfo === undefined) {
                console.log("can't show")
                d3.select("#" + divName + "-alertMessage")
                    .text(searchTerm + " didn't make it into the visualization.");
            } else {
                d3.select("#" + divName + "-alertMessage").text("");
                var circle = getCircleForSearchTerm(mysvg, searchTermInfo);
                if (circle) {
                    var mySVGMatrix = circle.getScreenCTM().translate(circle.cx.baseVal.value, circle.cy.baseVal.value);
                    var pageX = mySVGMatrix.e;
                    var pageY = mySVGMatrix.f;
                    circle.style["stroke"] = "black";
                    //var circlePos = circle.position();
                    //var el = circle.node()
                    //showTooltip(searchTermInfo, pageX, pageY, circle.cx.baseVal.value, circle.cx.baseVal.value);
                    showTooltip(
                        data,
                        searchTermInfo,
                        pageX,
                        pageY,
                        showObscured
                    );

                    lastCircleSelected = circle;
                }

            }
        };


        function makeWordInteractive(data, svg, domObj, term, termInfo, showObscured = true) {
            return domObj
                .on("mouseover", function (d) {
                    showToolTipForTerm(data, svg, term, termInfo, showObscured);
                    d3.select(this).style("stroke", "black");
                })
                .on("mouseout", function (d) {
                    tooltip.transition()
                        .duration(0)
                        .style("opacity", 0);
                    d3.select(this).style("stroke", null);
                    if (showObscured) {
                        d3.select('#' + divName + '-' + 'overlapped-terms')
                            .selectAll('div')
                            .remove();
                    }
                })
                .on("click", function (d) {
                    var runDisplayTermContexts = true;
                    if (alternativeTermFunc != null) {
                        runDisplayTermContexts = alternativeTermFunc(termInfo);
                    }
                    if (runDisplayTermContexts) {
                        displayTermContexts(data, gatherTermContexts(termInfo, includeAllContexts), alwaysJump, includeAllContexts);
                    }
                });
        }



        function processData(fullData) {

            modelInfo = fullData['info'];
            /*
             categoryTermList.data(modelInfo['category_terms'])
             .enter()
             .append("li")
             .text(function(d) {return d;});
             */
            var data = fullData['data'];
            termDict = Object();
            data.forEach(function (x, i) {
                termDict[x.term] = x;
                //!!!
                //termDict[x.term].i = i;
            });

            var padding = 0.1;
            if (showAxes || showAxesAndCrossHairs) {
                padding = 0.1;
            }

            // Scale the range of the data.  Add some space on either end.
            if (useGlobalScale) {
                var axisMax = Math.max(
                    d3.max(data, function (d) {
                        return d.x;
                    }),
                    d3.max(data, function (d) {
                        return d.y;
                    }),
                )
                var axisMin = Math.min(
                    d3.min(data, function (d) {
                        return d.x;
                    }),
                    d3.min(data, function (d) {
                        return d.y;
                    }),
                )
                axisMin = axisMin - (axisMax - axisMin) * padding;
                axisMax = axisMax + (axisMax - axisMin) * padding;
                x.domain([axisMin, axisMax]);
                y.domain([axisMin, axisMax]);
            } else {
                var xMax = d3.max(data, function (d) {
                    return d.x;
                });
                var yMax = d3.max(data, function (d) {
                    return d.y;
                })
                x.domain([-1 * padding, xMax + padding]);
                y.domain([-1 * padding, yMax + padding]);
            }

            /*
             data.sort(function (a, b) {
             return Math.abs(b.os) - Math.abs(a.os)
             });
             */


            //var rangeTree = null; // keep boxes of all points and labels here
            var rectHolder = new RectangleHolder();
            var axisRectHolder = new RectangleHolder();
            // Add the scatterplot
            data.forEach(function (d, i) {
                d.ci = i
            });

            //console.log('XXXXX'); console.log(data)


            function getFilter(data) {
                return data.filter(d => d.display === undefined || d.display === true);
            }


            var mysvg = svg
                .selectAll("dot")
                .data(getFilter(data))
                //.filter(function (d) {return d.display === undefined || d.display === true})
                .enter()
                .append("circle")
                .attr("r", function (d) {
                    if (pValueColors && d.p) {
                        return (d.p >= 1 - minPVal || d.p <= minPVal) ? 2 : 1.75;
                    }
                    return 2;
                })
                .attr("cx", function (d) {
                    return x(d.x);
                })
                .attr("cy", function (d) {
                    return y(d.y);
                })
                .style("fill", function (d) {
                    //.attr("fill", function (d) {
                    if (colorFunc) {
                        return colorFunc(d);
                    } else if (greyZeroScores && d.os == 0) {
                        return d3.rgb(230, 230, 230);
                    } else if (pValueColors && d.p) {
                        if (d.p >= 1 - minPVal) {
                            return wordVecMaxPValue ? d3.interpolateYlGnBu(d.s) : color(d.s);
                        } else if (d.p <= minPVal) {
                            return wordVecMaxPValue ? d3.interpolateYlGnBu(d.s) : color(d.s);
                        } else {
                            return interpolateLightGreys(d.s);
                        }
                    } else {
                        if (d.term === "the") {
                            console.log("COLS " + d.s + " " + color(d.s) + " " + d.term)
                            console.log(d)
                            console.log(color)
                        }
                        return color(d.s);
                    }
                })
                .on("mouseover", function (d) {
                    /*var mySVGMatrix = circle.getScreenCTM()n
                        .translate(circle.cx.baseVal.value, circle.cy.baseVal.value);
                    var pageX = mySVGMatrix.e;
                    var pageY = mySVGMatrix.f;*/

                    /*showTooltip(
                        d,
                        d3.event.pageX,
                        d3.event.pageY
                    );*/
                    console.log("point MOUSOEVER")
                    console.log(d)
                    showToolTipForTerm(data, this, d.term, d, true);
                    d3.select(this).style("stroke", "black");
                })
                .on("click", function (d) {
                    var runDisplayTermContexts = true;
                    if (alternativeTermFunc != null) {
                        runDisplayTermContexts = alternativeTermFunc(d);
                    }
                    if (runDisplayTermContexts) {
                        displayTermContexts(data, gatherTermContexts(d), alwaysJump, includeAllContexts);
                    }
                })
                .on("mouseout", function (d) {
                    tooltip.transition()
                        .duration(0)
                        .style("opacity", 0);
                    d3.select(this).style("stroke", null);
                    d3.select('#' + divName + '-' + 'overlapped-terms')
                        .selectAll('div')
                        .remove();
                })


            coords = Object();

            var pointStore = [];
            var pointRects = [];

            function censorPoints(datum, getX, getY) {
                var term = datum.term;
                var curLabel = svg.append("text")
                    .attr("x", x(getX(datum)))
                    .attr("y", y(getY(datum)) + 3)
                    .attr("text-anchor", "middle")
                    .text("x");
                var bbox = curLabel.node().getBBox();
                var borderToRemove = .5;
                var x1 = bbox.x + borderToRemove,
                    y1 = bbox.y + borderToRemove,
                    x2 = bbox.x + bbox.width - borderToRemove,
                    y2 = bbox.y + bbox.height - borderToRemove;
                //rangeTree = insertRangeTree(rangeTree, x1, y1, x2, y2, '~~' + term);
                var pointRect = new Rectangle(x1, y1, x2, y2);
                pointRects.push(pointRect);
                rectHolder.add(pointRect);
                pointStore.push([x1, y1]);
                pointStore.push([x2, y1]);
                pointStore.push([x1, y2]);
                pointStore.push([x2, y2]);
                curLabel.remove();
            }

            function censorCircle(xCoord, yCoord) {
                var curLabel = svg.append("text")
                    .attr("x", x(xCoord))
                    .attr("y", y(yCoord) + 3)
                    .attr("text-anchor", "middle")
                    .text("x");
                var bbox = curLabel.node().getBBox();
                var borderToRemove = .5;
                var x1 = bbox.x + borderToRemove,
                    y1 = bbox.y + borderToRemove,
                    x2 = bbox.x + bbox.width - borderToRemove,
                    y2 = bbox.y + bbox.height - borderToRemove;
                var pointRect = new Rectangle(x1, y1, x2, y2);
                pointRects.push(pointRect);
                rectHolder.add(pointRect);
                pointStore.push([x1, y1]);
                pointStore.push([x2, y1]);
                pointStore.push([x1, y2]);
                pointStore.push([x2, y2]);
                curLabel.remove();
            }

            var configs = [
                {'anchor': 'end', 'group': 1, 'xoff': -5, 'yoff': -3, 'alignment-baseline': 'ideographic'},
                {'anchor': 'end', 'group': 1, 'xoff': -5, 'yoff': 10, 'alignment-baseline': 'ideographic'},

                {'anchor': 'end', 'group': 2, 'xoff': 10, 'yoff': 15, 'alignment-baseline': 'ideographic'},
                {'anchor': 'end', 'group': 2, 'xoff': -10, 'yoff': -15, 'alignment-baseline': 'ideographic'},
                {'anchor': 'end', 'group': 2, 'xoff': 10, 'yoff': -15, 'alignment-baseline': 'ideographic'},
                {'anchor': 'end', 'group': 2, 'xoff': -10, 'yoff': 15, 'alignment-baseline': 'ideographic'},

                {'anchor': 'start', 'group': 1, 'xoff': 3, 'yoff': 10, 'alignment-baseline': 'ideographic'},
                {'anchor': 'start', 'group': 1, 'xoff': 3, 'yoff': -3, 'alignment-baseline': 'ideographic'},

                {'anchor': 'start', 'group': 2, 'xoff': 5, 'yoff': 10, 'alignment-baseline': 'ideographic'},
                {'anchor': 'start', 'group': 2, 'xoff': 5, 'yoff': -3, 'alignment-baseline': 'ideographic'},

                {'anchor': 'start', 'group': 3, 'xoff': 10, 'yoff': 15, 'alignment-baseline': 'ideographic'},
                {'anchor': 'start', 'group': 3, 'xoff': -10, 'yoff': -15, 'alignment-baseline': 'ideographic'},
                {'anchor': 'start', 'group': 3, 'xoff': 10, 'yoff': -15, 'alignment-baseline': 'ideographic'},
                {'anchor': 'start', 'group': 3, 'xoff': -10, 'yoff': 15, 'alignment-baseline': 'ideographic'},
            ];
            if (centerLabelsOverPoints) {
                configs = [{'anchor': 'middle', 'xoff': 0, 'yoff': 0, 'alignment-baseline': 'middle'}];
            }

            function labelPointsIfPossible(datum, myX, myY) {
                if (suppressTextColumn !== undefined
                    && datum.etc !== undefined
                    && datum.etc[suppressTextColumn] === true) {
                    return false;
                }

                var term = datum.term;
                if (datum.x > datum.y) {
                    configs.sort((a, b) => a.anchor == 'end' && b.anchor == 'end'
                        ? a.group - b.group : (a.anchor == 'end') - (b.anchor == 'end'));
                } else {
                    configs.sort((a, b) => a.anchor == 'start' && b.anchor == 'start'
                        ? a.group - b.group : (a.anchor == 'start') - (b.anchor == 'start'));
                }
                var matchedElement = null;

                var termColor = 'rgb(0,0,0)';
                if (textColorColumn !== undefined && datum.etc !== undefined && datum.etc[textColorColumn] !== undefined) {
                    termColor = datum.etc[textColorColumn];
                }
                term = formatTermForDisplay(term);

                for (var configI in configs) {
                    var config = configs[configI];
                    var curLabel = svg.append("text")
                        //.attr("x", x(data[i].x) + config['xoff'])
                        //.attr("y", y(data[i].y) + config['yoff'])
                        .attr("x", x(myX) + config['xoff'])
                        .attr("y", y(myY) + config['yoff'])
                        .attr('class', 'label')
                        .attr('class', 'pointlabel')
                        .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                        .attr('font-size', '10px')
                        .attr("text-anchor", config['anchor'])
                        .attr("alignment-baseline", config['alignment'])
                        .attr("fill", termColor)
                        .text(term);
                    var bbox = curLabel.node().getBBox();
                    var borderToRemove = doCensorPoints ? 0.5 : .25;

                    var x1 = bbox.x + borderToRemove,
                        y1 = bbox.y + borderToRemove,
                        x2 = bbox.x + bbox.width - borderToRemove,
                        y2 = bbox.y + bbox.height - borderToRemove;
                    //matchedElement = searchRangeTree(rangeTree, x1, y1, x2, y2);
                    var matchedElement = false;
                    rectHolder.findMatchingRectangles(x1, y1, x2, y2, function (elem) {
                        matchedElement = true;
                        return false;
                    });
                    if (matchedElement) {
                        curLabel.remove();
                    } else {
                        curLabel = makeWordInteractive(data, svg, curLabel, term, datum);
                        break;
                    }
                }

                if (!matchedElement) {
                    coords[term] = [x1, y1, x2, y2];
                    //rangeTree = insertRangeTree(rangeTree, x1, y1, x2, y2, term);
                    var labelRect = new Rectangle(x1, y1, x2, y2)
                    rectHolder.add(labelRect);
                    pointStore.push([x1, y1]);
                    pointStore.push([x2, y1]);
                    pointStore.push([x1, y2]);
                    pointStore.push([x2, y2]);
                    return {label: curLabel, rect: labelRect};
                } else {
                    //curLabel.remove();
                    return false;
                }

            }

            var radius = 2;

            function euclideanDistanceSort(a, b) {
                var aCatDist = a.x * a.x + (1 - a.y) * (1 - a.y);
                var aNotCatDist = a.y * a.y + (1 - a.x) * (1 - a.x);
                var bCatDist = b.x * b.x + (1 - b.y) * (1 - b.y);
                var bNotCatDist = b.y * b.y + (1 - b.x) * (1 - b.x);
                return (Math.min(aCatDist, aNotCatDist) > Math.min(bCatDist, bNotCatDist)) * 2 - 1;
            }

            function euclideanDistanceSortForCategory(a, b) {
                var aCatDist = a.x * a.x + (1 - a.y) * (1 - a.y);
                var bCatDist = b.x * b.x + (1 - b.y) * (1 - b.y);
                return (aCatDist > bCatDist) * 2 - 1;
            }

            function euclideanDistanceSortForNotCategory(a, b) {
                var aNotCatDist = a.y * a.y + (1 - a.x) * (1 - a.x);
                var bNotCatDist = b.y * b.y + (1 - b.x) * (1 - b.x);
                return (aNotCatDist > bNotCatDist) * 2 - 1;
            }

            function scoreSort(a, b) {
                return a.s - b.s;
            }

            function scoreSortReverse(a, b) {
                return b.s - a.s;
            }

            function backgroundScoreSort(a, b) {
                if (b.bg === a.bg)
                    return (b.cat + b.ncat) - (a.cat + a.ncat);
                return b.bg - a.bg;
            }

            function arePointsPredictiveOfDifferentCategories(a, b) {
                var aCatDist = a.x * a.x + (1 - a.y) * (1 - a.y);
                var bCatDist = b.x * b.x + (1 - b.y) * (1 - b.y);
                var aNotCatDist = a.y * a.y + (1 - a.x) * (1 - a.x);
                var bNotCatDist = b.y * b.y + (1 - b.x) * (1 - b.x);
                var aGood = aCatDist < aNotCatDist;
                var bGood = bCatDist < bNotCatDist;
                return {aGood: aGood, bGood: bGood};
            }

            function scoreSortForCategory(a, b) {
                var __ret = arePointsPredictiveOfDifferentCategories(a, b);
                if (sortByDist) {
                    var aGood = __ret.aGood;
                    var bGood = __ret.bGood;
                    if (aGood && !bGood) return -1;
                    if (!aGood && bGood) return 1;
                }
                return b.s - a.s;
            }

            function scoreSortForNotCategory(a, b) {
                var __ret = arePointsPredictiveOfDifferentCategories(a, b);
                if (sortByDist) {
                    var aGood = __ret.aGood;
                    var bGood = __ret.bGood;
                    if (aGood && !bGood) return 1;
                    if (!aGood && bGood) return -1;
                }
                if (reverseSortScoresForNotCategory)
                    return a.s - b.s;
                else
                    return b.s - a.s;
            }

            var sortedData = data.map(x => x).sort(sortByDist ? euclideanDistanceSort : scoreSort);
            if (doCensorPoints) {
                for (var i in data) {
                    var d = sortedData[i];

                    if (!(censorPointColumn !== undefined
                        && d.etc !== undefined
                        && d.etc[censorPointColumn] === false)) {

                        censorPoints(
                            d,
                            function (d) {
                                return d.x
                            },
                            function (d) {
                                return d.y
                            }
                        );
                    }

                }
            }


            function registerFigureBBox(curLabel, axis = false) {
                var bbox = curLabel.node().getBBox();
                var borderToRemove = 1.5;
                var x1 = bbox.x + borderToRemove,
                    y1 = bbox.y + borderToRemove,
                    x2 = bbox.x + bbox.width - borderToRemove,
                    y2 = bbox.y + bbox.height - borderToRemove;
                var rect = new Rectangle(x1, y1, x2, y2)
                if (axis) {
                    axisRectHolder.add(rect)
                } else {
                    rectHolder.add(rect);
                }
                //return insertRangeTree(rangeTree, x1, y1, x2, y2, '~~_other_');
            }

            function drawXLabel(svg, labelText) {
                return svg.append("text")
                    .attr("class", "x label")
                    .attr("text-anchor", "end")
                    .attr("x", width)
                    .attr("y", height - 6)
                    .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                    .attr('font-size', '10px')
                    .text(labelText);
            }

            function drawYLabel(svg, labelText) {
                return svg.append("text")
                    .attr("class", "y label")
                    .attr("text-anchor", "end")
                    .attr("y", 6)
                    .attr("dy", ".75em")
                    .attr("transform", "rotate(-90)")
                    .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                    .attr('font-size', '10px')
                    .text(labelText);
            }

            d3.selection.prototype.moveToBack = function () {
                return this.each(function () {
                    var firstChild = this.parentNode.firstChild;
                    if (firstChild) {
                        this.parentNode.insertBefore(this, firstChild);
                    }
                });
            };

            if (verticalLines) {
                if (typeof (verticalLines) === "number") {
                    verticalLines = [verticalLines]; // r likes to make single element vectors doubles; this is a hackish workaround
                }
                for (i in verticalLines) {
                    svg.append("g")
                        .attr("transform", "translate(" + x(verticalLines[i]) + ", 1)")
                        .append("line")
                        .attr("y2", height)
                        .style("stroke", "#dddddd")
                        .style("stroke-width", "1px")
                        .moveToBack();
                }
            }

            if (fullData['line'] !== undefined) {
                var valueline = d3.line()
                    .x(function (d) {
                        return x(d.x);
                    })
                    .y(function (d) {
                        return y(d.y);
                    });
                fullData.line = fullData.line.sort((a, b) => b.x - a.x);
                svg.append("path")
                    .attr("class", "line")
                    .style("stroke-width", "1px")
                    .attr("d", valueline(fullData['line'])).moveToBack();
            }
            if (showAxes || showAxesAndCrossHairs) {

                var myXAxis = svg.append("g")
                    .attr("class", "x axis")
                    .attr("transform", "translate(0," + height + ")")
                    .call(xAxis);

                //rangeTree = registerFigureBBox(myXAxis);


                var xLabel = drawXLabel(svg, getLabelText('x'));

                //console.log('xLabel');
                //console.log(xLabel);

                //rangeTree = registerFigureBBox(xLabel);
                // Add the Y Axis

                if (!yAxisValues) {
                    var myYAxis = svg.append("g")
                        .attr("class", "y axis")
                        .call(yAxis)
                        .selectAll("text")
                        .style("text-anchor", "end")
                        .attr("dx", "30px")
                        .attr("dy", "-13px")
                        .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                        .attr('font-size', '10px')
                        .attr("transform", "rotate(-90)");
                } else {
                    var myYAxis = svg.append("g")
                        .attr("class", "y axis")
                        .call(yAxis)
                        .selectAll("text")
                        .style("text-anchor", "end")
                        .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                        .attr('font-size', '10px');
                }
                registerFigureBBox(myYAxis, true);
                registerFigureBBox(myXAxis, true);

                function getLabelText(axis) {
                    if (axis == 'y') {
                        if (yLabelText == null)
                            return modelInfo['category_name'] + " Frequency";
                        else
                            return yLabelText;
                    } else {
                        if (xLabelText == null)
                            return modelInfo['not_category_name'] + " Frequency";
                        else
                            return xLabelText;
                    }
                }

                var yLabel = drawYLabel(svg, getLabelText('y'))

            }

            if (!showAxes || showAxesAndCrossHairs) {
                horizontal_line_y_position_translated = 0.5;
                if (horizontal_line_y_position !== null) {
                    var loOy = null, hiOy = null, loY = null, hiY = null;
                    for (i in fullData.data) {
                        var curOy = fullData.data[i].oy;
                        if (curOy < horizontal_line_y_position && (curOy > loOy || loOy === null)) {
                            loOy = curOy;
                            loY = fullData.data[i].y
                        }
                        if (curOy > horizontal_line_y_position && (curOy < hiOy || hiOy === null)) {
                            hiOy = curOy;
                            hiY = fullData.data[i].y
                        }
                    }
                    horizontal_line_y_position_translated = loY + (hiY - loY) / 2.
                    if (loY === null) {
                        horizontal_line_y_position_translated = 0;
                    }
                }
                if (vertical_line_x_position === null) {
                    vertical_line_x_position_translated = 0.5;
                } else {
                    if (vertical_line_x_position !== null) {
                        var loOx = null, hiOx = null, loX = null, hiX = null;
                        for (i in fullData.data) {
                            var curOx = fullData.data[i].ox;
                            if (curOx < vertical_line_x_position && (curOx > loOx || loOx === null)) {
                                loOx = curOx;
                                loX = fullData.data[i].x;
                            }
                            if (curOx > vertical_line_x_position && (curOx < hiOx || hiOx === null)) {
                                hiOx = curOx;
                                hiX = fullData.data[i].x
                            }
                        }
                        vertical_line_x_position_translated = loX + (hiX - loX) / 2.
                        if (loX === null) {
                            vertical_line_x_position_translated = 0;
                        }
                    }
                }
                if (showCrossAxes) {
                    var x_line = svg.append("g")
                        .attr("transform", "translate(0, " + y(horizontal_line_y_position_translated) + ")")
                        .append("line")
                        .attr("x2", width)
                        .style("stroke", "#cccccc")
                        .style("stroke-width", "1px")
                        .moveToBack();
                    var y_line = svg.append("g")
                        .attr("transform", "translate(" + x(vertical_line_x_position_translated) + ", 0)")
                        .append("line")
                        .attr("y2", height)
                        .style("stroke", "#cccccc")
                        .style("stroke-width", "1px")
                        .moveToBack();
                }
            }

            if (showDiagonal) {
                var diagonal = svg.append("g")
                    .append("line")
                    .attr("x1", 0)
                    .attr("y1", height)
                    .attr("x2", width)
                    .attr("y2", 0)
                    .style("stroke-dasharray", "5,5")
                    .style("stroke", "#cccccc")
                    .style("stroke-width", "1px")
                    .moveToBack();
            }

            function showWordList(word, termDataList, xOffset=null) {
                var maxWidth = word.node().getBBox().width;
                var wordObjList = [];
                for (var i in termDataList) {
                    var datum = termDataList[i];
                    var curTerm = datum.term;
                    word = (function (word, curTerm) {
                        var termColor = 'rgb(0,0,0)';
                        if (textColorColumn !== undefined && datum.etc !== undefined && datum.etc[textColorColumn] !== undefined) {
                            termColor = datum.etc[textColorColumn];
                        }
                        console.log("Show WORD "); console.log(word.node().getBBox().x)
                        var curWordPrinted = svg.append("text")
                            .attr("text-anchor", "start")
                            .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                            .attr('font-size', '12px')
                            .attr("fill", termColor)
                            .attr("x", xOffset == null ? word.node().getBBox().x : xOffset)
                            .attr("y", word.node().getBBox().y
                                + 2 * word.node().getBBox().height)
                            .text(formatTermForDisplay(curTerm));
                        wordObjList.push(curWordPrinted)
                        return makeWordInteractive(
                            termDataList, //data,
                            svg,
                            curWordPrinted,
                            curTerm,
                            termDataList[i]);
                    })(word, curTerm);
                    if (word.node().getBBox().width > maxWidth)
                        maxWidth = word.node().getBBox().width;
                    registerFigureBBox(word);
                }
                return {
                    'word': word,
                    'maxWidth': maxWidth,
                    'wordObjList': wordObjList
                };
            }

            function pickEuclideanDistanceSortAlgo(category) {
                if (category == true) return euclideanDistanceSortForCategory;
                return euclideanDistanceSortForNotCategory;
            }

            function pickScoreSortAlgo(isTopPane) {
                console.log("PICK SCORE ALGO")
                console.log(isTopPane)
                if (isTopPane === true) {
                    if (headerSortingAlgos !== null && headerSortingAlgos['upper'] !== undefined)
                        return headerSortingAlgos['upper'];
                    return scoreSortForCategory;
                } else {
                    if (headerSortingAlgos !== null && headerSortingAlgos['lower'] !== undefined)
                        return headerSortingAlgos['lower'];
                    return scoreSortForNotCategory;
                }

            }

            function pickTermSortingAlgorithm(isUpperPane) {
                if (sortByDist) return pickEuclideanDistanceSortAlgo(isUpperPane);
                return pickScoreSortAlgo(isUpperPane);
            }

            function showAssociatedWordList(data, word, header, isUpperPane, xOffset, length = topTermsLength) {
                var sortedData = null;
                var sortingAlgo = pickTermSortingAlgorithm(isUpperPane);
                console.log("showAssociatedWordList");
                console.log(header);
                console.log("WORD");
                console.log(word)
                sortedData = data.filter(term => (term.display === undefined || term.display === true)).sort(sortingAlgo);
                if (wordVecMaxPValue) {
                    function signifTest(x) {
                        if (isUpperPane)
                            return x.p >= 1 - minPVal;
                        return x.p <= minPVal;
                    }

                    sortedData = sortedData.filter(signifTest)
                }
                return showWordList(word, sortedData.slice(0, length), xOffset);

            }

            var characteristicXOffset = width;

            function showCatHeader(startingOffset, catName, registerFigureBBox) {
                var catHeader = svg.append("text")
                    .attr("text-anchor", "start")
                    .attr("x", startingOffset //width
                    )
                    .attr("dy", "6px")
                    .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                    .attr('font-size', '12px')
                    .attr('font-weight', 'bolder')
                    .attr('font-decoration', 'underline')
                    .text(catName
                        //"Top " + fullData['info']['category_name']
                    );
                registerFigureBBox(catHeader);
                return catHeader;
            }

            function showNotCatHeader(startingOffset, word, notCatName) {
                console.log("showNotCatHeader")
                return svg.append("text")
                    .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                    .attr('font-size', '12px')
                    .attr('font-weight', 'bolder')
                    .attr('font-decoration', 'underline')
                    .attr("text-anchor", "start")
                    .attr("x", startingOffset)
                    .attr("y", word.node().getBBox().y + 3 * word.node().getBBox().height)
                    .text(notCatName);
            }

            function showTopTermsPane(data,
                                      registerFigureBBox,
                                      showAssociatedWordList,
                                      upperHeaderName,
                                      lowerHeaderName,
                                      startingOffset) {
                data = data.filter(term => (term.display === undefined || term.display === true));
                //var catHeader = showCatHeader(startingOffset, catName, registerFigureBBox);
                var catHeader = svg.append("text")
                    .attr("text-anchor", "start")
                    .attr("x", startingOffset)
                    .attr("dy", "6px")
                    .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                    .attr('font-size', '12px')
                    .attr('font-weight', 'bolder')
                    .attr('font-decoration', 'underline')
                    .text(upperHeaderName
                        //"Top " + fullData['info']['category_name']
                    );
                registerFigureBBox(catHeader);
                var word = catHeader;
                var wordListData = showAssociatedWordList(data, word, catHeader, true, startingOffset);
                word = wordListData.word;
                var maxWidth = wordListData.maxWidth;

                var notCatHeader = showNotCatHeader(startingOffset, word, lowerHeaderName);
                word = notCatHeader;
                characteristicXOffset = Math.max(
                    catHeader.node().getBBox().x + maxWidth + 10,
                    notCatHeader.node().getBBox().x + maxWidth + 10
                )
                console.log("characteristicXOffset", characteristicXOffset)
                console.log(catHeader.node().getBBox().x + maxWidth + 10)
                console.log(notCatHeader.node().getBBox().x + maxWidth + 10)

                var notWordListData = showAssociatedWordList(data, word, notCatHeader, false, startingOffset);
                word = wordListData.word;
                if (wordListData.maxWidth > maxWidth) {
                    maxWidth = wordListData.maxWidth;
                }
                return {
                    wordListData, notWordListData,
                    word, maxWidth, characteristicXOffset, startingOffset,
                    catHeader, notCatHeader, registerFigureBBox
                };
            }

            var payload = Object();
            if (showTopTerms) {
                var upperHeaderName = "Top " + fullData['info']['category_name'];
                var lowerHeaderName = "Top " + fullData['info']['not_category_name'];
                if (headerNames !== null) {
                    if (headerNames.upper !== undefined)
                        upperHeaderName = headerNames.upper;
                    if (headerNames.lower !== undefined)
                        lowerHeaderName = headerNames.lower;
                }
                payload.topTermsPane = showTopTermsPane(
                    data,
                    registerFigureBBox,
                    showAssociatedWordList,
                    upperHeaderName,
                    lowerHeaderName,
                    width + topTermsLeftBuffer
                );
                payload.showTopTermsPane = showTopTermsPane;
                payload.showAssociatedWordList = showAssociatedWordList;
                payload.showWordList = showWordList;

                /*var wordListData = topTermsPane.wordListData;
                var word = topTermsPane.word;
                var maxWidth = topTermsPane.maxWidth;
                var catHeader = topTermsPane.catHeader;
                var notCatHeader = topTermsPane.notCatHeader;
                var startingOffset = topTermsPane.startingOffset;*/
                characteristicXOffset = payload.topTermsPane.characteristicXOffset;
            }


            if ((!nonTextFeaturesMode && !asianMode && showCharacteristic)
                || (headerNames !== null && headerNames.right !== undefined)) {
                var sortMethod = backgroundScoreSort;
                var title = 'Characteristic';
                if (headerNames !== null && headerNames.right !== undefined) {
                    title = headerNames.right;
                }
                if (wordVecMaxPValue) {
                    title = 'Most similar';
                    sortMethod = scoreSortReverse;
                } else if (data.reduce(function (a, b) {
                    return a + b.bg
                }, 0) === 0) {
                    title = 'Most frequent';
                }
                word = svg.append("text")
                    .attr('font-family', 'Helvetica, Arial, Sans-Serif')
                    .attr("text-anchor", "start")
                    .attr('font-size', '12px')
                    .attr('font-weight', 'bolder')
                    .attr('font-decoration', 'underline')
                    .attr("x", characteristicXOffset)
                    .attr("dy", "6px")
                    .text(title);

                var rightSortMethod = sortMethod;
                if (rightOrderColumn !== undefined && rightOrderColumn !== null) {
                    rightSortMethod = ((a, b) => b.etc[rightOrderColumn] - a.etc[rightOrderColumn]);
                }

                var wordListData = showWordList(
                    word,
                    data.filter(term => (term.display === undefined || term.display === true))
                        .sort(rightSortMethod).slice(0, topTermsLength * 2 + 2),
                    characteristicXOffset
                );

                word = wordListData.word;
                maxWidth = wordListData.maxWidth;
                console.log(maxWidth);
                console.log(word.node().getBBox().x + maxWidth);

                svg.attr('width', word.node().getBBox().x + 3 * maxWidth + 10);
            }

            function performPartialLabeling(
                data,
                existingLabels,
                getX,
                getY,
                labelPriorityFunction = ((a, b) => Math.min(a.x, 1 - a.x, a.y, 1 - a.y) - Math.min(b.x, 1 - b.x, b.y, 1 - b.y))
            ) {
                for (i in existingLabels) {
                    rectHolder.remove(existingLabels[i].rect);
                    existingLabels[i].label.remove();
                }

                var labeledPoints = [];

                //var filteredData = data.filter(d=>d.display === undefined || d.display === true);
                //for (var i = 0; i < filteredData.length; i++) {
                data.sort(labelPriorityFunction).forEach(function (datum, i) {
                    //console.log(datum.i, datum.ci, i)
                    //var label = labelPointsIfPossible(i, getX(filteredData[i]), getY(filteredData[i]));
                    if (datum.display === undefined || datum.display === true) {
                        var label = labelPointsIfPossible(datum, getX(datum), getY(datum));
                        if (label !== false) {
                            //console.log("labeled")
                            labeledPoints.push(label)
                        }
                    }
                    //if (labelPointsIfPossible(i), true) numPointsLabeled++;
                })
                return labeledPoints;
            }

            //var labeledPoints = performPartialLabeling();
            var labeledPoints = [];
            var labelPriorityFunction = ((a, b) => Math.min(a.x, 1 - a.x, a.y, 1 - a.y) - Math.min(b.x, 1 - b.x, b.y, 1 - b.y))
            if (labelPriorityColumn !== undefined && labelPriorityColumn !== null) {
                labelPriorityFunction = (a, b) => b.etc[labelPriorityColumn] - a.etc[labelPriorityColumn];
            }

            labeledPoints = performPartialLabeling(
                data,
                labeledPoints,
                function (d) {
                    return d.x
                },
                function (d) {
                    return d.y
                },
                labelPriorityFunction
            );

            if (backgroundLabels !== null) {
                backgroundLabels.map(
                    function (label) {
                        svg.append("text")
                            .attr("x", x(label.X))
                            .attr("y", y(label.Y))
                            .attr("text-anchor", "middle")
                            .style("font-size", "30")
                            .style("fill", "rgb(200,200,200)")
                            .text(label.Text)
                            .lower()
                            .on('mouseover', function (d) {
                                d3.select(this).style('stroke', 'black').style('stroke-width', '1px').raise()
                            })
                            .on('mouseout', function (d) {
                                d3.select(this).style('stroke-width', '0px').style('fill', 'rgb(200,200,200)').lower()
                            })
                    }
                )
            }


            /*
            // pointset has to be sorted by X
            function convex(pointset) {
                function _cross(o, a, b) {
                    return (a[0] - o[0]) * (b[1] - o[1]) - (a[1] - o[1]) * (b[0] - o[0]);
                }

                function _upperTangent(pointset) {
                    var lower = [];
                    for (var l = 0; l < pointset.length; l++) {
                        while (lower.length >= 2 && (_cross(lower[lower.length - 2], lower[lower.length - 1], pointset[l]) <= 0)) {
                            lower.pop();
                        }
                        lower.push(pointset[l]);
                    }
                    lower.pop();
                    return lower;
                }

                function _lowerTangent(pointset) {
                    var reversed = pointset.reverse(),
                        upper = [];
                    for (var u = 0; u < reversed.length; u++) {
                        while (upper.length >= 2 && (_cross(upper[upper.length - 2], upper[upper.length - 1], reversed[u]) <= 0)) {
                            upper.pop();
                        }
                        upper.push(reversed[u]);
                    }
                    upper.pop();
                    return upper;
                }

                var convex,
                    upper = _upperTangent(pointset),
                    lower = _lowerTangent(pointset);
                convex = lower.concat(upper);
                convex.push(pointset[0]);
                return convex;
            }

            console.log("POINTSTORE")
            console.log(pointStore);
            pointStore.sort();
            var convexHull = convex(pointStore);
            var minX = convexHull.sort(function (a,b) {
                return a[0] < b[0] ? -1 : 1;
            })[0][0];
            var minY = convexHull.sort(function (a,b) {
                return a[1] < b[1] ? -1 : 1;
            })[0][0];
            //svg.append("text").text("BLAH BLAH").attr("text-anchor", "middle").attr("cx", x(0)).attr("y", minY);
            console.log("POINTSTORE")
            console.log(pointStore);
            console.log(convexHull);
            for (i in convexHull) {
                var i = parseInt(i);
                if (i + 1 == convexHull.length) {
                    var nextI = 0;
                } else {
                    var nextI = i + 1;
                }
                console.log(i, ',', nextI);
                svg.append("line")
                    .attr("x2", width)
                    .style("stroke", "#cc0000")
                    .style("stroke-width", "1px")
                    .attr("x1", convexHull[i][0])     // x position of the first end of the line
                    .attr("y1", convexHull[i][1])      // y position of the first end of the line
                    .attr("x2", convexHull[nextI][0])     // x position of the second end of the line
                    .attr("y2", convexHull[nextI][1]);    // y position of the second end of the line
            }*/

            function populateCorpusStats() {
                var wordCounts = {};
                var docCounts = {}
                fullData.docs.labels.forEach(function (x, i) {
                    var cnt = (
                        fullData.docs.texts[i]
                            .trim()
                            .replace(/['";:,.?\-!]+/g, '')
                            .match(/\S+/g) || []
                    ).length;
                    var name = null;
                    if (unifiedContexts) {
                        var name = fullData.docs.categories[x];
                        wordCounts[name] = wordCounts[name] ? wordCounts[name] + cnt : cnt;
                    } else {
                        if (fullData.docs.categories[x] == fullData.info.category_internal_name) {
                            name = fullData.info.category_name;
                        } else if (fullData.info.not_category_internal_names.indexOf(fullData.docs.categories[x]) > -1) {
                            name = fullData.info.not_category_name;
                        } else if (fullData.info.neutral_category_internal_names.indexOf(fullData.docs.categories[x]) > -1) {
                            name = fullData.info.neutral_category_name;
                        } else if (fullData.info.extra_category_internal_names.indexOf(fullData.docs.categories[x]) > -1) {
                            name = fullData.info.extra_category_name;
                        }
                        if (name) {
                            wordCounts[name] = wordCounts[name] ? wordCounts[name] + cnt : cnt
                        }
                    }
                    //!!!

                });
                fullData.docs.labels.forEach(function (x) {

                    if (unifiedContexts) {
                        var name = fullData.docs.categories[x];
                        docCounts[name] = docCounts[name] ? docCounts[name] + 1 : 1
                    } else {
                        var name = null;
                        if (fullData.docs.categories[x] == fullData.info.category_internal_name) {
                            name = fullData.info.category_name;
                        } else if (fullData.info.not_category_internal_names.indexOf(fullData.docs.categories[x]) > -1) {
                            name = fullData.info.not_category_name;
                        } else if (fullData.info.neutral_category_internal_names.indexOf(fullData.docs.categories[x]) > -1) {
                            name = fullData.info.neutral_category_name;
                        } else if (fullData.info.extra_category_internal_names.indexOf(fullData.docs.categories[x]) > -1) {
                            name = fullData.info.extra_category_name;
                        }
                        if (name) {
                            docCounts[name] = docCounts[name] ? docCounts[name] + 1 : 1
                        }
                    }
                });
                console.log("docCounts");
                console.log(docCounts)
                var messages = [];
                if (ignoreCategories) {
                    var wordCount = getCorpusWordCounts();
                    console.log("wordCount")
                    console.log(wordCount)
                    messages.push(
                        '<b>Document count: </b>' + fullData.docs.texts.length.toLocaleString('en') +
                        '; <b>word count: </b>'
                        + wordCount['sums'].reduce((a, b) => a + b, 0).toLocaleString('en')
                    )
                } else if (unifiedContexts) {
                    fullData.docs.categories.forEach(function (x, i) {
                        if (docCounts[x] > 0) {
                            var message = '<b>' + x + '</b>: ';
                            message += 'document count: '
                                + Number(docCounts[x]).toLocaleString('en')
                                + '; word count: '
                                + Number(wordCounts[x]).toLocaleString('en')
                            messages.push(message);
                        }
                    });
                } else {
                    [fullData.info.category_name,
                        fullData.info.not_category_name,
                        fullData.info.neutral_category_name,
                        fullData.info.extra_category_name].forEach(function (x, i) {
                        if (docCounts[x] > 0) {
                            messages.push('<b>' + x + '</b> document count: '
                                + Number(docCounts[x]).toLocaleString('en')
                                + '; word count: '
                                + Number(wordCounts[x]).toLocaleString('en'));
                        }
                    });
                }

                if (showCorpusStats) {
                    d3.select('#' + divName + '-' + 'corpus-stats')
                        .style('width', width + margin.left + margin.right + 200)
                        .append('div')
                        .html(messages.join('<br />'));
                }
            }


            if (fullData.docs) {
                populateCorpusStats();
            }

            if (saveSvgButton) {
                // from https://stackoverflow.com/questions/23218174/how-do-i-save-export-an-svg-file-after-creating-an-svg-with-d3-js-ie-safari-an
                var svgElement = document.getElementById(divName);

                var serializer = new XMLSerializer();
                var source = serializer.serializeToString(svgElement);

                if (!source.match(/^<svg[^>]+xmlns="http\:\/\/www\.w3\.org\/2000\/svg"/)) {
                    source = source.replace(/^<svg/, '<svg xmlns="https://www.w3.org/2000/svg"');
                }
                if (!source.match(/^<svg[^>]+"http\:\/\/www\.w3\.org\/1999\/xlink"/)) {
                    source = source.replace(/^<svg/, '<svg xmlns:xlink="https://www.w3.org/1999/xlink"');
                }

                source = '<?xml version="1.0" standalone="no"?>\r\n' + source;

                var url = "data:image/svg+xml;charset=utf-8," + encodeURIComponent(source);

                var downloadLink = document.createElement("a");
                downloadLink.href = url;
                downloadLink.download = fullData['info']['category_name'] + ".svg";
                downloadLink.innerText = 'Download SVG';
                document.body.appendChild(downloadLink);

            }

            function rerender(xCoords, yCoords, color) {
                labeledPoints.forEach(function (p) {
                    p.label.remove();
                    rectHolder.remove(p.rect);
                });
                pointRects.forEach(function (rect) {
                    rectHolder.remove(rect);
                });
                pointRects = []
                /*
                var circles = d3.select('#' + divName).selectAll('circle')
                    .attr("cy", function (d) {return y(yCoords[d.i])})
                    .transition(0)
                    .attr("cx", function (d) {return x(xCoords[d.i])})
                    .transition(0);
                */
                d3.select('#' + divName).selectAll("dot").remove();
                d3.select('#' + divName).selectAll("circle").remove();
                console.log(this.fullData)
                console.log(this)
                console.log("X/Y coords")
                console.log(this.fullData.data.filter(d => d.display === undefined || d.display === true).map(d => [d.x, d.y]))
                var circles = this.svg//.select('#' + divName)
                    .selectAll("dot")
                    .data(this.fullData.data.filter(d => d.display === undefined || d.display === true))
                    //.filter(function (d) {return d.display === undefined || d.display === true})
                    .enter()
                    .append("circle")
                    .attr("cy", d => d.y)
                    .attr("cx", d => d.x)
                    .attr("r", d => 2)
                    .on("mouseover", function (d) {
                        /*var mySVGMatrix = circle.getScreenCTM()n
                            .translate(circle.cx.baseVal.value, circle.cy.baseVal.value);
                        var pageX = mySVGMatrix.e;
                        var pageY = mySVGMatrix.f;*/

                        /*showTooltip(
                            d,
                            d3.event.pageX,
                            d3.event.pageY
                        );*/
                        console.log("point MOUSOEVER")
                        console.log(d)
                        showToolTipForTerm(data, this, d.term, d, true);
                        d3.select(this).style("stroke", "black");
                    })
                    .on("click", function (d) {
                        var runDisplayTermContexts = true;
                        if (alternativeTermFunc != null) {
                            runDisplayTermContexts = alternativeTermFunc(d);
                        }
                        if (runDisplayTermContexts) {
                            displayTermContexts(data, gatherTermContexts(d), alwaysJump, includeAllContexts);
                        }
                    })
                    .on("mouseout", function (d) {
                        tooltip.transition()
                            .duration(0)
                            .style("opacity", 0);
                        d3.select(this).style("stroke", null);
                        d3.select('#' + divName + '-' + 'overlapped-terms')
                            .selectAll('div')
                            .remove();
                    });

                if (color !== null) {
                    console.log("COLOR")
                    console.log(color)
                    circles.style("fill", d => color(d));
                }
                xCoords.forEach((xCoord, i) => censorCircle(xCoord, yCoords[i]))
                labeledPoints = [];
                labeledPoints = performPartialLabeling(
                    this.fullData.data,
                    labeledPoints,
                    (d => d.ox), //function (d) {return xCoords[d.ci]},
                    (d => d.oy) //function (d) {return yCoords[d.ci]}

                );
            }

            //return [performPartialLabeling, labeledPoints];
            return {
                ...payload,
                ...{
                    'rerender': rerender,
                    'performPartialLabeling': performPartialLabeling,
                    'showToolTipForTerm': showToolTipForTerm,
                    'svg': svg,
                    'data': data,
                    'xLabel': xLabel,
                    'yLabel': yLabel,
                    'drawXLabel': drawXLabel,
                    'drawYLabel': drawYLabel,
                    'populateCorpusStats': populateCorpusStats
                }
            };
        }


        //fullData = getDataAndInfo();
        if (fullData.docs) {
            var corpusWordCounts = getCorpusWordCounts();
        }
        var payload = processData(fullData);

        // The tool tip is down here in order to make sure it has the highest z-index
        var tooltip = d3.select('#' + divName)
            .append("div")
            //.attr("class", getTooltipContent == null && sortByDist ? "tooltip" : "tooltipscore")
            .attr("class", "tooltipscore")
            .style("opacity", 0);

        plotInterface = {}
        if (payload.topTermsPane) {
            plotInterface.topTermsPane = payload.topTermsPane;
            plotInterface.showTopTermsPane = payload.showTopTermsPane;
            plotInterface.showAssociatedWordList = payload.showAssociatedWordList;
        }
        plotInterface.includeAllContexts = includeAllContexts;
        plotInterface.divName = divName;
        plotInterface.displayTermContexts = displayTermContexts;
        plotInterface.gatherTermContexts = gatherTermContexts;
        plotInterface.xLabel = payload.xLabel;
        plotInterface.yLabel = payload.yLabel;
        plotInterface.drawXLabel = payload.drawXLabel;
        plotInterface.drawYLabel = payload.drawYLabel;
        plotInterface.svg = payload.svg;
        plotInterface.termDict = termDict;
        plotInterface.showToolTipForTerm = payload.showToolTipForTerm;
        plotInterface.fullData = fullData;
        plotInterface.data = payload.data;
        plotInterface.rerender = payload.rerender;
        plotInterface.populateCorpusStats = payload.populateCorpusStats;
        plotInterface.handleSearch = handleSearch;
        plotInterface.handleSearchTerm = handleSearchTerm;
        plotInterface.highlightTerm = highlightTerm;
        plotInterface.y = y;
        plotInterface.x = x;
        plotInterface.tooltip = tooltip;
        plotInterface.alternativeTermFunc = alternativeTermFunc;

        plotInterface.showTooltipSimple = function (term) {
            plotInterface.showToolTipForTerm(
                plotInterface.data,
                plotInterface.svg,
                term.replace("'", "\\'"),
                plotInterface.termDict[term.replace("'", "\\'")]
            )
        };

        plotInterface.drawCategoryAssociation = function (category, otherCategory = null) {
            console.log("+++++++ Entering drawCategoryAssociation")
            console.log("Category: " + category)
            console.log("Other Category: " + otherCategory)
            var categoryNum = this.fullData.info.categories.indexOf(category);

            var otherCategoryNum = null;
            if(otherCategory !== null)
                otherCategoryNum = this.fullData.info.categories.indexOf(otherCategory);

            console.log("cat/other: " + category + "/" + otherCategory + " ::: " + categoryNum + "/" + otherCategoryNum)

            console.log("Full Data")
            console.log(this.fullData)
            /*
            var rawLogTermCounts = getTermCounts(this.fullData).map(Math.log);
            var maxRawLogTermCounts = Math.max(...rawLogTermCounts);
            var minRawLogTermCounts = Math.min(...rawLogTermCounts);
            var logTermCounts = rawLogTermCounts.map(
                x => (x - minRawLogTermCounts) / maxRawLogTermCounts
            )
            */

            //var rawScores = getCategoryDenseRankScores(this.fullData, categoryNum);
            //console.log("RAW SCORES")
            //console.log(rawScores);
            /*
            function logOddsRatioUninformativeDirichletPrior(fgFreqs, bgFreqs, alpha) {
                var fgVocabSize = fgFreqs.reduce((x,y) => x+y);
                var fgL = fgFreqs.map(x => (x + alpha)/((1+alpha)*fgVocabSize - x - alpha))
                var bgVocabSize = bgFreqs.reduce((x,y) => x+y);
                var bgL = bgFreqs.map(x => (x + alpha)/((1+alpha)*bgVocabSize - x - alpha))
                var pooledVar = fgFreqs.map(function(x, i) {
                    return (
                        1/(x + alpha)
                        + 1/((1+alpha)*fgVocabSize - x - alpha)
                        + 1/(bgFreqs[i] + alpha)
                        + 1/((1+alpha)*bgVocabSize - bgFreqs[i] - alpha))
                })
                return pooledVar.map(function(x, i) {
                    return (Math.log(fgL[i]) - Math.log(bgL[i]))/x;
                })
            }
            var rawScores = logOddsRatioUninformativeDirichletPrior(
                denseRanks.fgFreqs, denseRanks.bgFreqs, 0.01);
            */


            var denseRanks = getDenseRanks(this.fullData, categoryNum)
            if (otherCategoryNum !== null) {
                var otherDenseRanks = getDenseRanks(this.fullData, otherCategoryNum);
                denseRanks.bg = otherDenseRanks.fg;
                denseRanks.bgFreqs = otherDenseRanks.fgFreqs;
            }

            var rawScores = denseRanks.fg.map((x, i) => x - denseRanks.bg[i]);
            var minRawScores = Math.min(...rawScores);
            var maxRawScores = Math.max(...rawScores);

            var scores = rawScores.map(
                function (rawScore) {
                    if (rawScore == 0) {
                        return 0.5;
                    } else if (rawScore > 0) {
                        return rawScore / (2. * maxRawScores) + 0.5;
                    } else if (rawScore < 0) {
                        return 0.5 - rawScore / (2. * minRawScores);
                    }
                }
            )
            var fgFreqSum = denseRanks.fgFreqs.reduce((a, b) => a + b, 0)
            var bgFreqSum = denseRanks.bgFreqs.reduce((a, b) => a + b, 0)

            //!!! OLD and good
            var ox = denseRanks.bg;
            var oy = denseRanks.fg;

            var oxmax = Math.max(...ox)
            var oxmin = Math.min(...ox)
            var ox = ox.map(x => (x - oxmin) / (oxmax - oxmin))
            var oymax = Math.max(...oy)
            var oymin = Math.min(...oy)
            var oy = oy.map(x => (x - oymin) / (oymax - oymin))
            //var ox = logTermCounts
            //var oy = scores;
            var xf = this.x;
            var yf = this.y;

            this.fullData.data = this.fullData.data.map(function (term, i) {
                //term.ci = i;
                term.s = scores[term.i];
                term.os = rawScores[term.i];
                term.cat = denseRanks.fgFreqs[term.i];
                term.ncat = denseRanks.bgFreqs[term.i];
                term.cat25k = parseInt(denseRanks.fgFreqs[term.i] * 25000 / fgFreqSum);
                term.ncat25k = parseInt(denseRanks.bgFreqs[term.i] * 25000 / bgFreqSum);
                term.x = xf(ox[term.i]) // logTermCounts[term.i];
                term.y = yf(oy[term.i]) // scores[term.i];
                term.ox = ox[term.i];
                term.oy = oy[term.i];
                term.display = true;
                return term;
            })

            // Feature selection
            var targetTermsToShow = 1500;

            var sortedBg = denseRanks.bg.map((x, i) => [x, i]).sort((a, b) => b[0] - a[0]).map(x => x[1]).slice(0, parseInt(targetTermsToShow / 2));
            var sortedFg = denseRanks.fg.map((x, i) => [x, i]).sort((a, b) => b[0] - a[0]).map(x => x[1]).slice(0, parseInt(targetTermsToShow / 2));
            var sortedScores = denseRanks.fg.map((x, i) => [x, i]).sort((a, b) => b[0] - a[0]).map(x => x[1]);
            var myFullData = this.fullData

            sortedBg.concat(sortedFg)//.concat(sortedScores.slice(0, parseInt(targetTermsToShow/2))).concat(sortedScores.slice(-parseInt(targetTermsToShow/4)))
                .forEach(function (i) {
                    myFullData.data[i].display = true;
                })

            console.log('newly filtered')
            console.log(myFullData)

            // begin rescaling to ignore hidden terms
            /*
            function scaleDenseRanks(ranks) {
                var max = Math.max(...ranks);
                return ranks.map(x=>x/max)
            }
            var filteredData = myFullData.data.filter(d=>d.display);
            var catRanks = scaleDenseRanks(denseRank(filteredData.map(d=>d.cat)))
            var ncatRanks = scaleDenseRanks(denseRank(filteredData.map(d=>d.ncat)))
            var rawScores = catRanks.map((x,i) => x - ncatRanks[i]);
            function stretch_0_1(scores) {
                var max = 1.*Math.max(...rawScores);
                var min = -1.*Math.min(...rawScores);
                return scores.map(function(x, i) {
                    if(x == 0) return 0.5;
                    if(x > 0) return (x/max + 1)/2;
                    return (x/min + 1)/2;
                })
            }
            var scores = stretch_0_1(rawScores);
            console.log(scores)
            filteredData.forEach(function(d, i) {
                d.x = xf(catRanks[i]);
                d.y = yf(ncatRanks[i]);
                d.ox = catRanks[i];
                d.oy = ncatRanks[i];
                d.s = scores[i];
                d.os = rawScores[i];
            });
            console.log("rescaled");
            */
            // end rescaling


            this.rerender(//denseRanks.bg,
                fullData.data.map(x => x.ox), //ox
                //denseRanks.fg,
                fullData.data.map(x => x.oy), //oy,
                d => d3.interpolateRdYlBu(d.s));
            if (this.yLabel !== undefined) {
                this.yLabel.remove()
            }
            if (this.xLabel !== undefined) {
                this.xLabel.remove()
            }
            var leftName = this.fullData.info.categories[categoryNum];
            var bottomName = "Not " + this.fullData.info.categories[categoryNum];
            if (otherCategoryNum !== null) {
                bottomName = this.fullData.info.categories[otherCategoryNum];
            }


            this.yLabel = this.drawYLabel(this.svg, leftName + ' Frequncy Rank')
            this.xLabel = this.drawXLabel(this.svg, bottomName + ' Frequency Rank')
            if (this.topTermsPane !== undefined) {
                this.topTermsPane.catHeader.remove()
                this.topTermsPane.notCatHeader.remove()
                this.topTermsPane.wordListData.wordObjList.map(x => x.remove())
                this.topTermsPane.notWordListData.wordObjList.map(x => x.remove())
            }
            this.showWordList = payload.showWordList;


            this.showAssociatedWordList = function (
                data,
                word,
                header,
                isUpperPane,
                xOffset=this.topTermsPane.startingOffset,
                length = 14
            ) {
                var sortedData = null;
                if (!isUpperPane) {
                    sortedData = data.map(x => x).sort((a, b) => scores[a.i] - scores[b.i])
                } else {
                    sortedData = data.map(x => x).sort((a, b) => scores[b.i] - scores[a.i])
                }
                console.log('sortedData');
                console.log(isUpperPane);
                console.log(sortedData.slice(0, length))
                console.log(payload)
                console.log(word)
                return payload.showWordList(word, sortedData.slice(0, length), xOffset);
            }
            if (this.topTermsPane !== undefined)
                this.topTermsPane = payload.showTopTermsPane(
                    this.data,
                    this.topTermsPane.registerFigureBBox,
                    this.showAssociatedWordList,
                    "Top " + leftName,
                    "Top " + bottomName,
                    this.topTermsPane.startingOffset
                )

            fullData.info.category_name = leftName;
            fullData.info.not_category_name = bottomName;
            fullData.info.category_internal_name = this.fullData.info.categories[categoryNum];
            if (otherCategoryNum === null) {
                fullData.info.not_category_internal_names = this.fullData.info.categories
                    .filter(x => x !== this.fullData.info.categories[categoryNum]);
            } else {
                fullData.info.not_category_internal_names = this.fullData.info.categories
                    .filter(x => x === this.fullData.info.categories[otherCategoryNum]);

                fullData.info.neutral_category_internal_names = this.fullData.info.categories
                    .filter(x => (x !== this.fullData.info.categories[categoryNum]
                        && x !== this.fullData.info.categories[otherCategoryNum]));
                fullData.info.neutral_category_name = "All Others";

            }
            console.log("fullData.info.not_category_internal_names");
            console.log(fullData.info.not_category_internal_names);
            ['snippets', 'snippetsalt', 'termstats',
                'overlapped-terms-clicked', 'categoryinfo',
                'cathead', 'cat', 'corpus-stats', 'notcathead',
                'notcat', 'neuthead', 'neut'
            ].forEach(function (divSubName) {
                var mydiv = '#' + divName + '-' + divSubName;
                console.log("Clearing");
                console.log(mydiv);
                d3.select(mydiv).selectAll("*").remove();
                d3.select(mydiv).html("");

            });
            this.populateCorpusStats();

            console.log(fullData)
        };

        plotInterface.yAxisLogCounts = function (categoryName) {
            var categoryNum = this.fullData.docs.categories.indexOf(categoryName);
            var denseRanks = getDenseRanks(this.fullData, categoryNum)
            console.log("denseRanks")
            console.log(denseRanks);

            var rawScores = denseRanks.fg.map((x, i) => x - denseRanks.bg[i]);
            var minRawScores = Math.min(...rawScores);
            var maxRawScores = Math.max(...rawScores);

            var scores = rawScores.map(
                function (rawScore) {
                    if (rawScore == 0) {
                        return 0.5;
                    } else if (rawScore > 0) {
                        return rawScore / (2. * maxRawScores) + 0.5;
                    } else if (rawScore < 0) {
                        return 0.5 - rawScore / (2. * minRawScores);
                    }
                }
            )
            var fgFreqSum = denseRanks.fgFreqs.reduce((a, b) => a + b, 0)
            var bgFreqSum = denseRanks.bgFreqs.reduce((a, b) => a + b, 0)

            var oy = denseRanks.fgFreqs.map(count => Math.log(count + 1) / Math.log(2))

            var oymax = Math.max(...oy)
            var oymin = Math.min(...oy)
            oy = oy.map(y => (y - oymin) / (oymax - oymin))
            var xf = this.x;
            var yf = this.y;
            var ox = this.fullData.data.map(term => term.ox);
            var oxmax = Math.max(...ox)
            var oxmin = Math.min(...ox)
            ox = ox.map(y => (y - oxmin) / (oxmax - oxmin))


            this.fullData.data = this.fullData.data.map(function (term, i) {
                term.s = 1;//scores[i];
                term.os = rawScores[i];
                term.cat = denseRanks.fgFreqs[i];
                term.ncat = denseRanks.bgFreqs[i];
                term.cat25k = parseInt(denseRanks.fgFreqs[i] * 25000 / fgFreqSum);
                term.ncat25k = parseInt(denseRanks.bgFreqs[i] * 25000 / bgFreqSum);
                //term.x = xf(term.ox) // scores[term.i];
                //term.ox = term.ox;
                term.y = yf(oy[i]) // scores[term.i];
                term.oy = oy[i];
                term.x = xf(ox[i]) // scores[term.i];
                term.ox = ox[i];
                term.display = true;
                return term;
            })


            this.rerender(//denseRanks.bg,
                this.fullData.data.map(point => point.ox), //ox
                this.fullData.data.map(point => point.oy), //oy,
                d => d3.interpolateRdYlBu(d.s)
            );

            if (this.yLabel !== undefined) {
                this.yLabel.remove()
                this.yLabel = this.drawYLabel(this.svg, this.fullData.info.categories[categoryNum] + ' log freq.')
            }

            if (this.topTermsPane !== undefined) {
                this.topTermsPane.catHeader.remove()
                this.topTermsPane.notCatHeader.remove()
                this.topTermsPane.wordListData.wordObjList.map(x => x.remove())
                this.topTermsPane.notWordListData.wordObjList.map(x => x.remove())
            }
            this.showWordList = payload.showWordList;


            this.showAssociatedWordList = function (data, word, header, isUpperPane, xOffset=this.topTermsPane.startingOffset, length = 14) {
                var sortedData = null;
                if (!isUpperPane) {
                    sortedData = data.map(x => x).sort((a, b) => scores[a.i] - scores[b.i])
                } else {
                    sortedData = data.map(x => x).sort((a, b) => scores[b.i] - scores[a.i])
                }
                console.log('sortedData');
                console.log(isUpperPane);
                console.log(sortedData.slice(0, length))
                console.log(payload)
                console.log(word)
                return payload.showWordList(word, sortedData.slice(0, length), xOffset);
            }
            var leftName = this.fullData.info.categories[categoryNum];
            var bottomName = "Not " + this.fullData.info.categories[categoryNum];

            if (this.topTermsPane !== undefined)
                this.topTermsPane = payload.showTopTermsPane(
                    this.data,
                    this.topTermsPane.registerFigureBBox,
                    this.showAssociatedWordList,
                    "Top " + leftName,
                    "Top " + bottomName,
                    this.topTermsPane.startingOffset
                )

            fullData.info.category_name = leftName;
            fullData.info.not_category_name = bottomName;
            fullData.info.category_internal_name = this.fullData.info.categories[categoryNum];
            fullData.info.not_category_internal_names = this.fullData.info.categories
                .filter(x => x !== this.fullData.info.categories[categoryNum]);

            console.log("fullData.info.not_category_internal_names");
            console.log(fullData.info.not_category_internal_names);
            ['snippets', 'snippetsalt', 'termstats',
                'overlapped-terms-clicked', 'categoryinfo',
                'cathead', 'cat', 'corpus-stats', 'notcathead',
                'notcat', 'neuthead', 'neut'
            ].forEach(function (divSubName) {
                var mydiv = '#' + divName + '-' + divSubName;
                console.log("Clearing");
                console.log(mydiv);
                d3.select(mydiv).selectAll("*").remove();
                d3.select(mydiv).html("");

            });
            this.populateCorpusStats();
        };

        return plotInterface
    };
}(d3);

; 
 
 // Adapted from https://www.w3schools.com/howto/howto_js_autocomplete.asp
function autocomplete(inputField, autocompleteValues, myPlotInterface) {
    var currentFocus; // current position in autocomplete list.

    inputField.addEventListener("input", function (e) {
        var matchedCandidateListDiv, matchedCandidateDiv, i, userInput = this.value;

        closeAllLists();
        if (!userInput) {
            return false;
        }
        currentFocus = -1;

        matchedCandidateListDiv = document.createElement("div");
        matchedCandidateListDiv.setAttribute("id", this.id + "autocomplete-list");
        matchedCandidateListDiv.setAttribute("class", "autocomplete-items");

        this.parentNode.appendChild(matchedCandidateListDiv);
        autocompleteValues.map(function (candidate) {
            var candidatePrefix = candidate.substr(0, userInput.length);
            if (candidatePrefix.toLowerCase() === userInput.toLowerCase()) {
                matchedCandidateDiv = document.createElement("div");
                matchedCandidateDiv.innerHTML = "<strong>" + candidatePrefix + "</strong>";
                matchedCandidateDiv.innerHTML += candidate.substr(userInput.length);
                matchedCandidateDiv.innerHTML += '<input type=hidden value="' + encodeURIComponent(candidate) + '">';
                matchedCandidateDiv.addEventListener("click", function (e) {
                    console.log("CLICK")
                    console.log(this.getElementsByTagName("input")[0].value)
                    inputField.value = decodeURIComponent(this.getElementsByTagName("input")[0].value);
                    console.log(inputField.value)
                    closeAllLists();
                    myPlotInterface.handleSearchTerm(inputField.value);
                });
                matchedCandidateListDiv.appendChild(matchedCandidateDiv);
            }
        });
    });

    inputField.addEventListener("keydown", function (keyboardEvent) {

        var candidateDivList = document.getElementById(this.id + "autocomplete-list");

        if (!candidateDivList)
            return true;

        var selectedCandidate = Array.prototype.find.call(
            candidateDivList.children,
            x => x.className !== ""
        );

        if (keyboardEvent.keyCode === 40 || keyboardEvent.keyCode === 9) { // down or tab
            keyboardEvent.preventDefault();
            currentFocus++;
            addActive(candidateDivList.getElementsByTagName("div"));
        } else if (keyboardEvent.keyCode === 38) { //up
            currentFocus--;
            addActive(candidateDivList.getElementsByTagName("div"));
        } else if (keyboardEvent.keyCode === 13) { // enter
            keyboardEvent.preventDefault();
            var selectedTerm = inputField.value;
            console.log("selected term");console.log(selectedTerm);
            console.log(myPlotInterface);
            //if (selectedCandidate)
            //    selectedTerm = selectedCandidate.children[1].value;
            myPlotInterface.handleSearchTerm(selectedTerm);
            closeAllLists(null);
        } else if (keyboardEvent.keyCode === 27) { // esc
            closeAllLists(null);
        }
    });

    function addActive(candidateDivList) {
        if (!candidateDivList) return false;

        removeActive(candidateDivList);

        if (currentFocus >= candidateDivList.length)
            currentFocus = 0;
        if (currentFocus < 0)
            currentFocus = (candidateDivList.length - 1);

        candidateDivList[currentFocus].classList.add("autocomplete-active");

        var selectedCandidate = Array.prototype.find.call(
            candidateDivList,
            x => x.className !== ""
        );

        if (selectedCandidate) {
            var candidateValue = decodeURIComponent(selectedCandidate.children[1].value);

            myPlotInterface.highlightTerm(candidateValue);
            inputField.value = candidateValue;
        }

    }

    function removeActive(candidateDivList) {
        Array.prototype.find.call(
            candidateDivList,
            x => x.classList.remove("autocomplete-active")
        );
    }

    function closeAllLists(elmnt) {
        /*close all autocomplete lists in the document,
        except the one passed as an argument:*/
        var x = document.getElementsByClassName("autocomplete-items");
        for (var i = 0; i < x.length; i++) {
            if (elmnt != x[i] && elmnt != inputField) {
                x[i].parentNode.removeChild(x[i]);
            }
        }
    }

    /*execute a function when someone clicks in the document:*/
    document.addEventListener("click", function (e) {
        closeAllLists(e.target);
    });
}

function getDataAndInfo() { return{"info": {"category_name": "Data scientist", "not_category_name": "Data Engineer", "category_terms": ["Experience", "Python R Javascript Machine", "Google Cloud Platform NET Experience", "related field Computational social science Computer science Data analytics", "OCR Experience", "successful machine learning systems", "Computer science Data analytics Economics Engineering Geospatial", "Cloud ML resources", "Ability work diverse team environment Interest experience science technology engineering mathematics", "Cloud ML"], "not_category_terms": ["career categories", "Apache Flink Spark Streaming Apache Storm Kafka Streams others", "Experience building stream processing applications", "industry experience", "Extras", "Python Go Java Scala", "massive petabyte scale semi structured datasets", "Apache Flink", "data technologies", "least one high level programming language"], "category_internal_name": "data scientist", "not_category_internal_names": ["data engineer"], "categories": ["data scientist", "data engineer"], "neutral_category_internal_names": [], "extra_category_internal_names": [], "neutral_category_name": "Neutral", "extra_category_name": "Extra"}, "metalists": {"Healthcare": ["Healthcare"], "data Ability": ["data Ability"], "Medical dental vision insurance Life disability coverage": ["Medical dental vision insurance Life disability coverage"], "401K Flexible Spending Accounts Apple equipment Daily breakfast lunch dinner": ["401K Flexible Spending Accounts Apple equipment Daily breakfast lunch dinner"], "graduation date": ["graduation date"], "Competitive": ["Competitive"], "Tableau": ["Tableau"], "backgrounds": ["backgrounds"], "novel biomarkers dissect gene disease relationships": ["novel biomarkers dissect gene disease relationships"], "Strong interested biology immunological diseases": ["Strong interested biology immunological diseases"], "Excellent interpersonal team skills": ["Excellent interpersonal team skills"], "Experience Bayesian analysis causal inference": ["Experience Bayesian analysis causal inference"], "PhD MS computational biology computer science statistics": ["PhD MS computational biology computer science statistics"], "benchmark apply predictive algorithms": ["benchmark apply predictive algorithms"], "AI machine learning methods": ["AI machine learning methods"], "non linear regression models": ["non linear regression models"], "dimensionality reduction clustering": ["dimensionality reduction clustering"], "data R": ["data R"], "Immunology Inflammation": ["Immunology Inflammation"], "Proficiency": ["Proficiency"], "Bayesian": ["Bayesian"], "Ability": ["Ability"], "hypotheses": ["hypotheses"], "AI": ["AI"], "Excellent": ["Excellent"], "relevant work experience": ["relevant work experience"], "depth knowledge": ["depth knowledge"], "neural networks": ["neural networks"], "Bachelor degree": ["Bachelor degree"], "Minimum years": ["Minimum years"], "Hadoop Spark": ["Hadoop Spark"], "Proficiency R": ["Proficiency R"], "data": ["data"], "scikit": ["scikit"], "Hadoop": ["Hadoop"], "Experience": ["Experience"], "Java Scala Python": ["Java Scala Python"], "production environments": ["production environments"], "analytical techniques": ["analytical techniques"], "Software": ["Software"], "Self": ["Self"], "algorithms": ["algorithms"], "Experiences": ["Experiences"], "computing frameworks": ["computing frameworks"], "actionable insights": ["actionable insights"], "Python Java R": ["Python Java R"], "Deep learning": ["Deep learning"], "PhD": ["PhD"], "Master": ["Master"], "Master Degree PhD Experience working AWS": ["Master Degree PhD Experience working AWS"], "Master Degree PhD": ["Master Degree PhD"], "Degree PhD": ["Degree PhD"], "large scale data analysis": ["large scale data analysis"], "At least year experience open source programming languages": ["At least year experience open source programming languages"], "Python Scala R": ["Python Scala R"], "At least year experience machine": ["At least year experience machine"], "At least years experience machine": ["At least years experience machine"], "data analytics": ["data analytics"], "Bachelor Degree": ["Bachelor Degree"], "At least year": ["At least year"], "At least years": ["At least years"], "Good English language skills": ["Good English language skills"], "Computer Science related degree years related work experience Experience working Open Source project": ["Computer Science related degree years related work experience Experience working Open Source project"], "English": ["English"], "Spark": ["Spark"], "ability": ["ability"], "Java Scala": ["Java Scala"], "Python Java": ["Python Java"], "strong baselines ability": ["strong baselines ability"], "experimental analytic plans data modeling processes": ["experimental analytic plans data modeling processes"], "Demonstrable track record": ["Demonstrable track record"], "results": ["results"], "well ambiguity": ["well ambiguity"], "effect relations": ["effect relations"], "hands": ["hands"], "Drilling Completion Production Operations": ["Drilling Completion Production Operations"], "Upstream oil gas industry experience": ["Upstream oil gas industry experience"], "year experience data analytics": ["year experience data analytics"], "At least year experience": ["At least year experience"], "Master Degree": ["Master Degree"], "Degree": ["Degree"], "machine": ["machine"], "SQL": ["SQL"], "AWS": ["AWS"], "tools Tableau": ["tools Tableau"], "Experience Data Visualizaiton": ["Experience Data Visualizaiton"], "Experience Data": ["Experience Data"], "Visualizaiton": ["Visualizaiton"], "BA Computer Science Engineering relevant field graduate degree Data Science quantitative field": ["BA Computer Science Engineering relevant field graduate degree Data Science quantitative field"], "Strong math skills": ["Strong math skills"], "Excellent communication presentation": ["Excellent communication presentation"], "Basic knowledge web development Experience data work\ufb02ow management tools advantage Experience big data cloud computing advantage": ["Basic knowledge web development Experience data work\ufb02ow management tools advantage Experience big data cloud computing advantage"], "R Python Linux Experience systems biology research data": ["R Python Linux Experience systems biology research data"], "PhD bioinformatics computer science similar experience Experience relational database management systems": ["PhD bioinformatics computer science similar experience Experience relational database management systems"], "Ability work team": ["Ability work team"], "goals": ["goals"], "consistent research institutes": ["consistent research institutes"], "Employment payment social benefits": ["Employment payment social benefits"], "able work": ["able work"], "Excellent understanding machine": ["Excellent understanding machine"], "techniques": ["techniques"], "data mining machine": ["data mining machine"], "SQL Oracle": ["SQL Oracle"], "large amounts": ["large amounts"], "Possess": ["Possess"], "media mix": ["media mix"], "visualization": ["visualization"], "multi touch attribution": ["multi touch attribution"], "data science": ["data science"], "data scientists": ["data scientists"], "problems": ["problems"], "customers": ["customers"], "Masters": ["Masters"], "bars": ["bars"], "Social environment": ["Social environment"], "Fluency English": ["Fluency English"], "hard questions data": ["hard questions data"], "complex ideas": ["complex ideas"], "skills": ["skills"], "The ability": ["The ability"], "industry experience": ["industry experience"], "AI ML": ["AI ML"], "NLP": ["NLP"], "Experience cleaning visualizing data": ["Experience cleaning visualizing data"], "Mathematics Statistics Physics Computer Science Engineering Background": ["Mathematics Statistics Physics Computer Science Engineering Background"], "algebra multivariable calculus": ["algebra multivariable calculus"], "Experience Python": ["Experience Python"], "Python R": ["Python R"], "Oracle graph": ["Oracle graph"], "techniques ability": ["techniques ability"], "Proven ability": ["Proven ability"], "Math": ["Math"], "Knowledge immunology tumor immunology tumor biology genetics Proficiency Python R": ["Knowledge immunology tumor immunology tumor biology genetics Proficiency Python R"], "D degree Bioinformatics Computer Science Biostatistics Applied": ["D degree Bioinformatics Computer Science Biostatistics Applied"], "Ph D degree Bioinformatics Computer Science Biostatistics": ["Ph D degree Bioinformatics Computer Science Biostatistics"], "environment": ["environment"], "problem": ["problem"], "Agile": ["Agile"], "Expertise": ["Expertise"], "Proven": ["Proven"], "Python": ["Python"], "time": ["time"], "predictive analytics multivariate testing optimization algorithms": ["predictive analytics multivariate testing optimization algorithms"], "Working knowledge upstream data Experience analytical simulation tools field": ["Working knowledge upstream data Experience analytical simulation tools field"], "Google Cloud Platform NET Experience": ["Google Cloud Platform NET Experience"], "OCR Experience": ["OCR Experience"], "successful machine learning systems": ["successful machine learning systems"], "Cloud ML resources": ["Cloud ML resources"], "Cloud ML": ["Cloud ML"], "regression clustering word embeddings": ["regression clustering word embeddings"], "Tensorflow Keras Data Science algorithms decision trees": ["Tensorflow Keras Data Science algorithms decision trees"], "Tensorflow Keras Data Science": ["Tensorflow Keras Data Science"], "Python R Javascript Machine": ["Python R Javascript Machine"], "Development languages": ["Development languages"], "Restaurant Retail industry experience": ["Restaurant Retail industry experience"], "The Best Jobs Retail Time Holiday Shopping Jobs Rated Report": ["The Best Jobs Retail Time Holiday Shopping Jobs Rated Report"], "The Jobs Rated Report The Best Jobs The Toughest Jobs Fill": ["The Jobs Rated Report The Best Jobs The Toughest Jobs Fill"], "The Jobs Rated Report": ["The Jobs Rated Report"], "The Best Jobs Advertising": ["The Best Jobs Advertising"], "The Toughest Jobs Fill": ["The Toughest Jobs Fill"], "The Best Jobs": ["The Best Jobs"], "analytic processes": ["analytic processes"], "best practices": ["best practices"], "BI": ["BI"], "industry": ["industry"], "Working": ["Working"], "recommendations": ["recommendations"], "Complex": ["Complex"], "AI Machine Learning": ["AI Machine Learning"], "Machine Learning": ["Machine Learning"], "Deep Learning": ["Deep Learning"], "Deep": ["Deep"], "Git": ["Git"], "GPU": ["GPU"], "Experience Looker Tableau data visualization software": ["Experience Looker Tableau data visualization software"], "statistical analysis techniques": ["statistical analysis techniques"], "experimental design data": ["experimental design data"], "related field Computational social science Computer science Data analytics": ["related field Computational social science Computer science Data analytics"], "Ability work diverse team environment Interest experience science technology engineering mathematics": ["Ability work diverse team environment Interest experience science technology engineering mathematics"], "Computer science Data analytics Economics Engineering Geospatial": ["Computer science Data analytics Economics Engineering Geospatial"], "Quantitative finance": ["Quantitative finance"], "Economics Engineering Geospatial analysis": ["Economics Engineering Geospatial analysis"], "prior graduation Attending school": ["prior graduation Attending school"], "Availability work": ["Availability work"], "Mathematics Operations research": ["Mathematics Operations research"], "Bachelor degree technical field": ["Bachelor degree technical field"], "internship Creativity Initiative Integrity Leadership": ["internship Creativity Initiative Integrity Leadership"], "Creativity Initiative Integrity Leadership": ["Creativity Initiative Integrity Leadership"], "full time basis": ["full time basis"], "Problem solving skills": ["Problem solving skills"], "Full time student": ["Full time student"], "Mathematics Operations": ["Mathematics Operations"], "Attending": ["Attending"], "Computational": ["Computational"], "scale": ["scale"], "A thorough medical psychological exam": ["A thorough medical psychological exam"], "GPA": ["GPA"], "A comprehensive background investigation": ["A comprehensive background investigation"], "Bachelor": ["Bachelor"], "two day tours": ["two day tours"], "A polygraph interview": ["A polygraph interview"], "two day": ["two day"], "Statistics": ["Statistics"], "complex analytical concepts": ["complex analytical concepts"], "business problems": ["business problems"], "NoSQL": ["NoSQL"], "Knowledge": ["Knowledge"], "people": ["people"], "year": ["year"], "R Python": ["R Python"], "ML": ["ML"], "analytics development industrial applications commercial industrial setting": ["analytics development industrial applications commercial industrial setting"], "college university Ph D STEM field Science Technology Engineering Math": ["college university Ph D STEM field Science Technology Engineering Math"], "Demonstrated skill feature extraction realtime analytics development deployment": ["Demonstrated skill feature extraction realtime analytics development deployment"], "Science Technology Engineering Math": ["Science Technology Engineering Math"], "Bachelor Degree STEM field Science Technology Engineering Math": ["Bachelor Degree STEM field Science Technology Engineering Math"], "Desired Characteristics Master Degree STEM field Science Technology Engineering Math": ["Desired Characteristics Master Degree STEM field Science Technology Engineering Math"], "Demonstrated skill data management methods": ["Demonstrated skill data management methods"], "college university Minimum years": ["college university Minimum years"], "college university": ["college university"], "move equipment pounds assistance Ability": ["move equipment pounds assistance Ability"], "operations equipment": ["operations equipment"], "hours": ["hours"], "business questions": ["business questions"], "deliverables Domain knowledge clinical data real world data life sciences related research data Expertise data science related tools": ["deliverables Domain knowledge clinical data real world data life sciences related research data Expertise data science related tools"], "meaningful solutions life sciences business Task oriented ability": ["meaningful solutions life sciences business Task oriented ability"], "Deep understanding ML": ["Deep understanding ML"], "Deep understanding tools trade": ["Deep understanding tools trade"], "e g SQL Tableau D3": ["e g SQL Tableau D3"], "variety modern programming languages": ["variety modern programming languages"], "PhD computational quantitative discipline e g statistics computer science": ["PhD computational quantitative discipline e g statistics computer science"], "keen eye detail visual communication findings": ["keen eye detail visual communication findings"], "g regression techniques": ["g regression techniques"], "strong knowledge mathematical underpinnings": ["strong knowledge mathematical underpinnings"], "informatics genetics physics epidemiology health economics": ["informatics genetics physics epidemiology health economics"], "non technical teams": ["non technical teams"], "neural networks decision trees": ["neural networks decision trees"], "Linux TensorFlow Hadoop Spark": ["Linux TensorFlow Hadoop Spark"], "various methods": ["various methods"], "D3": ["D3"], "Comfort": ["Comfort"], "source technologies": ["source technologies"], "R Python JavaScript": ["R Python JavaScript"], "PhD Data Science Analytics Statistics Mathematics Physics Economics Computer Science": ["PhD Data Science Analytics Statistics Mathematics Physics Economics Computer Science"], "Bachelor Data Science Analytics Statistics Mathematics Physics Economics Computer Science": ["Bachelor Data Science Analytics Statistics Mathematics Physics Economics Computer Science"], "Master degree PhD Data Science Analytics Statistics Mathematics Physics Economics Computer Science": ["Master degree PhD Data Science Analytics Statistics Mathematics Physics Economics Computer Science"], "data Experience deep learning frameworks": ["data Experience deep learning frameworks"], "Professional experience machine": ["Professional experience machine"], "machine learning models": ["machine learning models"], "Professional experience": ["Professional experience"], "Data Scientist Machine Learning Engineer": ["Data Scientist Machine Learning Engineer"], "real world problems": ["real world problems"], "keras": ["keras"], "statistical concepts": ["statistical concepts"], "libraries": ["libraries"], "Familiarity AWS ecosystem": ["Familiarity AWS ecosystem"], "technology customer operations analytics": ["technology customer operations analytics"], "business performance Journey Analytics clients": ["business performance Journey Analytics clients"], "statistical advanced analytic methods": ["statistical advanced analytic methods"], "senior clients colleagues": ["senior clients colleagues"], "Ability work": ["Ability work"], "collaboratively team environment": ["collaboratively team environment"], "Masters PhD student statistics computer science economics physics quantitative field Internship work experience": ["Masters PhD student statistics computer science economics physics quantitative field Internship work experience"], "Bachelors degree statistics computer science economics physics quantitative field Experience": ["Bachelors degree statistics computer science economics physics quantitative field Experience"], "applied statistics machine": ["applied statistics machine"], "Proficiency Python R Experience working imperfect data Passion eagerness": ["Proficiency Python R Experience working imperfect data Passion eagerness"], "others": ["others"], "statistical techniques": ["statistical techniques"], "Experience MS Office Word Access Excel PowerPoint Outlook": ["Experience MS Office Word Access Excel PowerPoint Outlook"], "non technical audiences": ["non technical audiences"], "Experienced building large scale data analysis system Extensive knowledge experience": ["Experienced building large scale data analysis system Extensive knowledge experience"], "Strong project management leadership skills": ["Strong project management leadership skills"], "Extensive knowledge details": ["Extensive knowledge details"], "Machine": ["Machine"], "Apache Hadoop": ["Apache Hadoop"], "similar Total Cost Ownership Net Present Value analysis Approaches systems biology proteomics analysis": ["similar Total Cost Ownership Net Present Value analysis Approaches systems biology proteomics analysis"], "platforms": ["platforms"], "Data": ["Data"], "MS years": ["MS years"], "research results commercialization": ["research results commercialization"], "Strong knowledge": ["Strong knowledge"], "complex analyses": ["complex analyses"], "simple terms": ["simple terms"], "quantitative field": ["quantitative field"], "equity": ["equity"], "Deep knowledge": ["Deep knowledge"], "work level position": ["work level position"], "minimum acceptable considered position": ["minimum acceptable considered position"], "relevant position": ["relevant position"], "hiring manager organization": ["hiring manager organization"], "account information": ["account information"], "based candidates": ["based candidates"], "Salary": ["Salary"], "The qualifications": ["The qualifications"], "Degrees Physics Mathematics Computer Science Engineering": ["Degrees Physics Mathematics Computer Science Engineering"], "data visualization tools years experience packages": ["data visualization tools years experience packages"], "project management experience years": ["project management experience years"], "multiple data sources Experience": ["multiple data sources Experience"], "role data analysis metrics development years": ["role data analysis metrics development years"], "experience": ["experience"], "large datasets": ["large datasets"], "Hands": ["Hands"], "organization Ability": ["organization Ability"], "SAS R Python": ["SAS R Python"], "Significant experience": ["Significant experience"], "relational databases": ["relational databases"], "depth experience": ["depth experience"], "mathematics computer science physical sciences": ["mathematics computer science physical sciences"], "deep learning solutions": ["deep learning solutions"], "similar technical field Experience": ["similar technical field Experience"], "TensorFlow": ["TensorFlow"], "xgboost": ["xgboost"], "MongoDB Solr Indexes": ["MongoDB Solr Indexes"], "Solr Indexes": ["Solr Indexes"], "Experience SQL": ["Experience SQL"], "Mechanical Engineering Materials Engineering Chemical Engineering Electrical Engineering Chemistry Physics Expertise": ["Mechanical Engineering Materials Engineering Chemical Engineering Electrical Engineering Chemistry Physics Expertise"], "Mechanical Engineering Materials Engineering Chemical Engineering Electrical Engineering Chemistry Physics Expertise engineering analysis tools data analysis scripting methods order automate train standard analytical tasks": ["Mechanical Engineering Materials Engineering Chemical Engineering Electrical Engineering Chemistry Physics Expertise engineering analysis tools data analysis scripting methods order automate train standard analytical tasks"], "numerical computing": ["numerical computing"], "Advanced degree data science equivalent field sub field Experience working data rich problems": ["Advanced degree data science equivalent field sub field Experience working data rich problems"], "research programs Experience computer programming user experience user interface Ability": ["research programs Experience computer programming user experience user interface Ability"], "Experience real world data thesis research internships": ["Experience real world data thesis research internships"], "work experience Creativity Initiative Integrity Leadership": ["work experience Creativity Initiative Integrity Leadership"], "large incomplete data": ["large incomplete data"], "verbal communication": ["verbal communication"], "solutions": ["solutions"], "Strong": ["Strong"], "projects": ["projects"], "proficiency SQL Excellent communication organization analytical skills experience": ["proficiency SQL Excellent communication organization analytical skills experience"], "Background": ["Background"], "SQL Python R SAS preferred Demonstrate familiarity work experience": ["SQL Python R SAS preferred Demonstrate familiarity work experience"], "driving product impact": ["driving product impact"], "SAS": ["SAS"], "OOP": ["OOP"], "Casual Work Environment": ["Casual Work Environment"], "US": ["US"], "seriously huge datasets": ["seriously huge datasets"], "Expertise Python R Expertise": ["Expertise Python R Expertise"], "Master degree": ["Master degree"], "placement different job level": ["placement different job level"], "joy clients": ["joy clients"], "work Stitch Fix": ["work Stitch Fix"], "Stitch Fix": ["Stitch Fix"], "work": ["work"], "every day": ["every day"], "tensorflow R caret Experience curating datasets": ["tensorflow R caret Experience curating datasets"], "Spark MLLib SQL OS Experience Windows Linux Windows Ability": ["Spark MLLib SQL OS Experience Windows Linux Windows Ability"], "Spark MLLib SQL OS Experience Windows Linux Windows Ability compile results": ["Spark MLLib SQL OS Experience Windows Linux Windows Ability compile results"], "modeling Experience scikit": ["modeling Experience scikit"], "Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical": ["Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical"], "related Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical Modeling Geo spatial analytics Data Munging Cleaning Bachelor Degree Ability work datasets": ["related Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical Modeling Geo spatial analytics Data Munging Cleaning Bachelor Degree Ability work datasets"], "unsupervised machine learning methods Experience C": ["unsupervised machine learning methods Experience C"], "spatial analysis Experience PCAP": ["spatial analysis Experience PCAP"], "neural networks cluster analysis feature engineering extraction reduction web scraping decision trees": ["neural networks cluster analysis feature engineering extraction reduction web scraping decision trees"], "working Intelligence Community teams": ["working Intelligence Community teams"], "Intelligence Community": ["Intelligence Community"], "multi TB dataset manipulation cleaning": ["multi TB dataset manipulation cleaning"], "Java R Javascript PhP MatLab Pig Hive Impala PySpark Scala Ruby Pytorch": ["Java R Javascript PhP MatLab Pig Hive Impala PySpark Scala Ruby Pytorch"], "senior level leadership": ["senior level leadership"], "present material audiences": ["present material audiences"], "Elastic Search Hadoop": ["Elastic Search Hadoop"], "different sizes formats": ["different sizes formats"], "specific techniques": ["specific techniques"], "multiple databases": ["multiple databases"], "working fields": ["working fields"], "Impala PySpark": ["Impala PySpark"], "Java R Javascript": ["Java R Javascript"], "CART": ["CART"], "presentations": ["presentations"], "PhP MatLab": ["PhP MatLab"], "TB": ["TB"], "advanced topics analytics artificial intelligence data engineering": ["advanced topics analytics artificial intelligence data engineering"], "professional experience media company": ["professional experience media company"], "SQL Tableau Excel interest": ["SQL Tableau Excel interest"], "analytics tools": ["analytics tools"], "work sweat details": ["work sweat details"], "either R Python Experience building web applications agile development": ["either R Python Experience building web applications agile development"], "learning libraries": ["learning libraries"], "visualization machine": ["visualization machine"], "Excel": ["Excel"], "statistics": ["statistics"], "date thread subject author": ["date thread subject author"], "Messages": ["Messages"], "equal access benefits details training office": ["equal access benefits details training office"], "accommodation": ["accommodation"], "Registered Selective Service": ["Registered Selective Service"], "job": ["job"], "An employee disability": ["An employee disability"], "one year": ["one year"], "online application": ["online application"], "business requirements": ["business requirements"], "applicants": ["applicants"], "requirements": ["requirements"], "position": ["position"], "Develop": ["Develop"], "Provide": ["Provide"], "LA location": ["LA location"], "Gated dog run": ["Gated dog run"], "LA": ["LA"], "large complex data sets": ["large complex data sets"], "Demonstrated ability": ["Demonstrated ability"], "tools": ["tools"], "self": ["self"], "decisions": ["decisions"], "Communicate": ["Communicate"], "statistical modeling techniques": ["statistical modeling techniques"], "Detail Oriented Process": ["Detail Oriented Process"], "Knowledge variety machine": ["Knowledge variety machine"], "new process efficiencies": ["new process efficiencies"], "Data Scientist A Data Geek": ["Data Scientist A Data Geek"], "best technique": ["best technique"], "Mathematics Statistics Computer Science equivalent work experience": ["Mathematics Statistics Computer Science equivalent work experience"], "ML Proficiency Python R scripting languages": ["ML Proficiency Python R scripting languages"], "business setting Ability": ["business setting Ability"], "comfortable working numbers patterns": ["comfortable working numbers patterns"], "looking people": ["looking people"], "work kinds": ["work kinds"], "GCP cloud platforms": ["GCP cloud platforms"], "actionable results": ["actionable results"], "ready code": ["ready code"], "data patterns": ["data patterns"], "Driven looking folks": ["Driven looking folks"], "Mathematics Statistics Computer Science": ["Mathematics Statistics Computer Science"], "Mass relocation": ["Mass relocation"], "toolkits": ["toolkits"], "production": ["production"], "A sense humor perspective": ["A sense humor perspective"], "puzzles": ["puzzles"], "local candidates": ["local candidates"], "Mass": ["Mass"], "pandas NumPy etc Experience": ["pandas NumPy etc Experience"], "Bachelor Degree concentration": ["Bachelor Degree concentration"], "A mindset research": ["A mindset research"], "intelligently passionately interesting challenges projects": ["intelligently passionately interesting challenges projects"], "even solution": ["even solution"], "Preference": ["Preference"], "knowledge system identification statistical inference": ["knowledge system identification statistical inference"], "knowledge MATLAB": ["knowledge MATLAB"], "positive impact livelihood world": ["positive impact livelihood world"], "401k": ["401k"], "C C": ["C C"], "product": ["product"], "information": ["information"], "SQL data exploration tools SAS R Experience data analytics design Experience": ["SQL data exploration tools SAS R Experience data analytics design Experience"], "data analysis Experience": ["data analysis Experience"], "Health care industry experience Demonstrated ability": ["Health care industry experience Demonstrated ability"], "Formulas Bilingual Spanish English Master Degree Experience": ["Formulas Bilingual Spanish English Master Degree Experience"], "Proven organizational skills ability flexible work ambiguity": ["Proven organizational skills ability flexible work ambiguity"], "deep technical concepts": ["deep technical concepts"], "SAS R Python Proficient MS Office applications Excel proficiency Pivots V Lookups": ["SAS R Python Proficient MS Office applications Excel proficiency Pivots V Lookups"], "SAS R Python Proficient MS Office": ["SAS R Python Proficient MS Office"], "Bachelor degree Minimum year experience": ["Bachelor degree Minimum year experience"], "deeper understanding": ["deeper understanding"], "Pivots V Lookups": ["Pivots V Lookups"], "technical well technical senior stakeholders": ["technical well technical senior stakeholders"], "large databases": ["large databases"], "predictive statistical modeling": ["predictive statistical modeling"], "Spanish": ["Spanish"], "Bilingual": ["Bilingual"], "deliverables": ["deliverables"], "Excellent time management skills ability": ["Excellent time management skills ability"], "data elements sources relationships business technical terms": ["data elements sources relationships business technical terms"], "big data technologies Hadoop Spark Familiarity Python R data visualization tools": ["big data technologies Hadoop Spark Familiarity Python R data visualization tools"], "full stack data analysis insight synthesis presentation Ability": ["full stack data analysis insight synthesis presentation Ability"], "complex analysis technical concepts": ["complex analysis technical concepts"], "years recent experience data science data analyst role": ["years recent experience data science data analyst role"], "Hadoop Spark Familiarity Python": ["Hadoop Spark Familiarity Python"], "Strong business mindset": ["Strong business mindset"], "Excellent presentation": ["Excellent presentation"], "AB experiments": ["AB experiments"], "Familiarity": ["Familiarity"], "Comfortable": ["Comfortable"], "United States Preferred": ["United States Preferred"], "advanced optimization methodologies": ["advanced optimization methodologies"], "advanced quantitative analyses": ["advanced quantitative analyses"], "analysis Ability": ["analysis Ability"], "advanced statistical methodologies mixed model random fixed effects": ["advanced statistical methodologies mixed model random fixed effects"], "actual working experience": ["actual working experience"], "mixed integer optimization Ability": ["mixed integer optimization Ability"], "analysis variance correlation techniques": ["analysis variance correlation techniques"], "ARIMA neural networks multinomial discrete choice Ability": ["ARIMA neural networks multinomial discrete choice Ability"], "Demonstrated experience": ["Demonstrated experience"], "features software packages": ["features software packages"], "Utilize complex computer operations": ["Utilize complex computer operations"], "mathematical operations tasks cluster analytics": ["mathematical operations tasks cluster analytics"], "theory design experiments": ["theory design experiments"], "methodologies": ["methodologies"], "Working knowledge": ["Working knowledge"], "A strong passion empirical research": ["A strong passion empirical research"], "3rd": ["3rd"], "Map Reduce": ["Map Reduce"], "Advanced data modeling experience": ["Advanced data modeling experience"], "working data": ["working data"], "trends": ["trends"], "ETL": ["ETL"], "Artificial Neural Nets": ["Artificial Neural Nets"], "models": ["models"], "code": ["code"], "Breadth skills experience machine": ["Breadth skills experience machine"], "business process outsourcing systems transportation systems healthcare systems financial services": ["business process outsourcing systems transportation systems healthcare systems financial services"], "novel solutions problems": ["novel solutions problems"], "real world context Prior experience similar role": ["real world context Prior experience similar role"], "practice Experience knowledge services": ["practice Experience knowledge services"], "feasibility solutions": ["feasibility solutions"], "analytics models": ["analytics models"], "Desired interdisciplinary skills": ["Desired interdisciplinary skills"], "big data technologies ETL statistics causal inference": ["big data technologies ETL statistics causal inference"], "analytics packages": ["analytics packages"], "diverse learning settings": ["diverse learning settings"], "multi disciplinary environments": ["multi disciplinary environments"], "data mining statistical predictive": ["data mining statistical predictive"], "work US employer": ["work US employer"], "Ability inclination": ["Ability inclination"], "different types": ["different types"], "sponsorship": ["sponsorship"], "history driving": ["history driving"], "related field": ["related field"], "Breadth": ["Breadth"], "simulation": ["simulation"], "methods": ["methods"], "experiments": ["experiments"], "ideas": ["ideas"], "desire": ["desire"], "programming languages": ["programming languages"], "multiple data sources": ["multiple data sources"], "metadata": ["metadata"], "explain point": ["explain point"], "story": ["story"], "Visualization": ["Visualization"], "minimal guidance Ability work business system owners": ["minimal guidance Ability work business system owners"], "SQL experience": ["SQL experience"], "Business Objects": ["Business Objects"], "Big Data": ["Big Data"], "United States": ["United States"], "Interested candidates": ["Interested candidates"], "small teams projects": ["small teams projects"], "complex business problems": ["complex business problems"], "business results": ["business results"], "technology roadmaps realization": ["technology roadmaps realization"], "existing problems": ["existing problems"], "new solution methods": ["new solution methods"], "working knowledge": ["working knowledge"], "External Technology Knowledge Keeps": ["External Technology Knowledge Keeps"], "latest technological developments areas": ["latest technological developments areas"], "Analytics": ["Analytics"], "operations": ["operations"], "opportunities": ["opportunities"], "things": ["things"], "sports games": ["sports games"], "analysis impact": ["analysis impact"], "key business product decisions": ["key business product decisions"], "SQL Hive": ["SQL Hive"], "e g filtering morphology": ["e g filtering morphology"], "compression": ["compression"], "Background image processing concepts": ["Background image processing concepts"], "ping pong tournaments": ["ping pong tournaments"], "statistical predictive modeling concepts machine learning approaches": ["statistical predictive modeling concepts machine learning approaches"], "classification techniques recommendation optimization algorithms": ["classification techniques recommendation optimization algorithms"], "big data technologies": ["big data technologies"], "machine learning": ["machine learning"], "Continuous": ["Continuous"], "functional teams": ["functional teams"], "Java C": ["Java C"], "statistical models": ["statistical models"], "analysis": ["analysis"], "new business development proof concepts": ["new business development proof concepts"], "Computer Science Computer Science Engineering Engineering Computer Science Math Computer Science Mathematical": ["Computer Science Computer Science Engineering Engineering Computer Science Math Computer Science Mathematical"], "Computer Science Computer Science Engineering Engineering Computer Science Math Computer Science Mathematical Engineering Mathematical Science Mathematics Statistics Strong data wrangling skills": ["Computer Science Computer Science Engineering Engineering Computer Science Math Computer Science Mathematical Engineering Mathematical Science Mathematics Statistics Strong data wrangling skills"], "Ability manipulate JSON XML data Experience Splunk Experience data manipulation platforms": ["Ability manipulate JSON XML data Experience Splunk Experience data manipulation platforms"], "Experience Ansible Puppet Jenkins Chef": ["Experience Ansible Puppet Jenkins Chef"], "multiple projects": ["multiple projects"], "Excellent problem": ["Excellent problem"], "Java": ["Java"], "Cigna Healthcare MetLife Dental VSP Vision": ["Cigna Healthcare MetLife Dental VSP Vision"], "advanced data analysis": ["advanced data analysis"], "world": ["world"], "data things": ["data things"], "connections": ["connections"], "Reduce Experience working Hadoop Map": ["Reduce Experience working Hadoop Map"], "Substantial data analysis experience": ["Substantial data analysis experience"], "complex problems": ["complex problems"], "new technologies": ["new technologies"], "major impact business": ["major impact business"], "prowess data scientist right": ["prowess data scientist right"], "Proficiency scripting language Python R MATLAB Proficiency": ["Proficiency scripting language Python R MATLAB Proficiency"], "written oral diagram form": ["written oral diagram form"], "carry instructions": ["carry instructions"], "Strong experience": ["Strong experience"], "Computer Science": ["Computer Science"], "software C C": ["software C C"], "large scale data management big data technologies Skilled aspects software project life cycle feasibility requirements": ["large scale data management big data technologies Skilled aspects software project life cycle feasibility requirements"], "important project success Sufficient interpersonal skills necessary interact levels personnel": ["important project success Sufficient interpersonal skills necessary interact levels personnel"], "scientific data analysis statistical analysis knowledge discovery computer security systems": ["scientific data analysis statistical analysis knowledge discovery computer security systems"], "Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules": ["Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules"], "algorithms data management": ["algorithms data management"], "design implementation integration test deployment Fundamental experience": ["design implementation integration test deployment Fundamental experience"], "necessary work": ["necessary work"], "data analysis": ["data analysis"], "Fundamental knowledge": ["Fundamental knowledge"], "project": ["project"], "Bachelor degree computer science computer engineering related field equivalent combination education related experience": ["Bachelor degree computer science computer engineering related field equivalent combination education related experience"], "Linux UNIX Windows environments": ["Linux UNIX Windows environments"], "enthusiasm creativity change": ["enthusiasm creativity change"], "concurrent technical tasks": ["concurrent technical tasks"], "research concepts": ["research concepts"], "conflicting priorities": ["conflicting priorities"], "difficult problems": ["difficult problems"], "Java Python R Matlab software applications": ["Java Python R Matlab software applications"], "Linux UNIX Windows": ["Linux UNIX Windows"], "high performance": ["high performance"], "Skilled": ["Skilled"], "Java Python R Matlab": ["Java Python R Matlab"], "share knowledge others": ["share knowledge others"], "organization": ["organization"], "skill": ["skill"], "Access opportunities": ["Access opportunities"], "volunteer time fuel efficient vehicle purchase assistance transit fare contribution": ["volunteer time fuel efficient vehicle purchase assistance transit fare contribution"], "first": ["first"], "video call": ["video call"], "call": ["call"], "As always interviews": ["As always interviews"], "Matplotlib": ["Matplotlib"], "Plotly ggplot": ["Plotly ggplot"], "An eye great data visualization": ["An eye great data visualization"], "complex data analysis": ["complex data analysis"], "qualitative quantitative clear compelling manner": ["qualitative quantitative clear compelling manner"], "action Strong understanding statistical analysis": ["action Strong understanding statistical analysis"], "Quick learner ability": ["Quick learner ability"], "large data": ["large data"], "production level code Proficiency": ["production level code Proficiency"], "academic institution Expert Python SQL": ["academic institution Expert Python SQL"], "minimal guidance Ability": ["minimal guidance Ability"], "varying levels": ["varying levels"], "quantitative discipline": ["quantitative discipline"], "working Spark process": ["working Spark process"], "Expert Python SQL": ["Expert Python SQL"], "Excellent communication skills": ["Excellent communication skills"], "dynamic fast paced environment Drive change": ["dynamic fast paced environment Drive change"], "initiate drive projects completion": ["initiate drive projects completion"], "Drive": ["Drive"], "comfort ambiguity": ["comfort ambiguity"], "A flexible analytic approach": ["A flexible analytic approach"], "Interest politics educational policy": ["Interest politics educational policy"], "industry experience Experience Python R Experience Tableau Ability model": ["industry experience Experience Python R Experience Tableau Ability model"], "Ability ramp data science manager role": ["Ability ramp data science manager role"], "technical levels Ability": ["technical levels Ability"], "Airflow Ability": ["Airflow Ability"], "sound analytical modeling solutions Ability": ["sound analytical modeling solutions Ability"], "data pipelines": ["data pipelines"], "functional partners": ["functional partners"], "Proficiency SQL": ["Proficiency SQL"], "Java C C SQL relational database experience": ["Java C C SQL relational database experience"], "business plan Experience shelf": ["business plan Experience shelf"], "algorithms Experience visualization tools": ["algorithms Experience visualization tools"], "relevant experience": ["relevant experience"], "Java C C SQL": ["Java C C SQL"], "complex concepts": ["complex concepts"], "Retail eCommerce company": ["Retail eCommerce company"], "NoSQL SQL database experience Experience Google products": ["NoSQL SQL database experience Experience Google products"], "code populate HDFS Hadoop log Kafka data": ["code populate HDFS Hadoop log Kafka data"], "Java Scala Python Hadoop stack HIVE Pig Hadoop streaming MapReduce HBase": ["Java Scala Python Hadoop stack HIVE Pig Hadoop streaming MapReduce HBase"], "Big Data Systems": ["Big Data Systems"], "years experience": ["years experience"], "Build": ["Build"], "Kafka": ["Kafka"], "LAN": ["LAN"], "Parties": ["Parties"], "first year": ["first year"], "one programming languages": ["one programming languages"], "Designing data architecture table dashboard": ["Designing data architecture table dashboard"], "physics related quantitative discipline preferred Experience Hive SQL": ["physics related quantitative discipline preferred Experience Hive SQL"], "statistics data mining machine": ["statistics data mining machine"], "classification techniques recommendation optimization": ["classification techniques recommendation optimization"], "Ph D Master Degree operations research": ["Ph D Master Degree operations research"], "Strong analytical problem": ["Strong analytical problem"], "Collaborative team player values": ["Collaborative team player values"], "passionate Data Science": ["passionate Data Science"], "Data Science": ["Data Science"], "Dog friendly office": ["Dog friendly office"], "field Electrical Engineering Computer Science Data Science Statistics relevant fields": ["field Electrical Engineering Computer Science Data Science Statistics relevant fields"], "Java C scripting language Experience database systems systems": ["Java C scripting language Experience database systems systems"], "MS BS years": ["MS BS years"], "aforementioned fields": ["aforementioned fields"], "PhD aforementioned fields": ["PhD aforementioned fields"], "similar Experience project product program management customer design Excellent storytelling team work": ["similar Experience project product program management customer design Excellent storytelling team work"], "BS MS": ["BS MS"], "probabilistic graphical models": ["probabilistic graphical models"], "degree": ["degree"], "Jobs Fwd inedinfo Fwd JOB Statistician fte": ["Jobs Fwd inedinfo Fwd JOB Statistician fte"], "Next message Jobs NPD Group": ["Next message Jobs NPD Group"], "Fwd JOB Statistician fte Next": ["Fwd JOB Statistician fte Next"], "Jobs NPD Group": ["Jobs NPD Group"], "Jobs Fwd": ["Jobs Fwd"], "Previous message": ["Previous message"], "Experience working data analytics Experience": ["Experience working data analytics Experience"], "e g": ["e g"], "moderate large scale data": ["moderate large scale data"], "innovate state art machine": ["innovate state art machine"], "predictive explanatory models experimentation processes": ["predictive explanatory models experimentation processes"], "R Python programming proficiency Proficiency data integration data quality development Programming experience": ["R Python programming proficiency Proficiency data integration data quality development Programming experience"], "non technical audience Interest educational applications": ["non technical audience Interest educational applications"], "track record Experience": ["track record Experience"], "Experience technologies": ["Experience technologies"], "technical projects database components": ["technical projects database components"], "technical topics": ["technical topics"], "R Shiny Python": ["R Shiny Python"], "Django": ["Django"], "Experience data visualization tools": ["Experience data visualization tools"], "Experience relational databases": ["Experience relational databases"], "R Python Experience working AWS environments": ["R Python Experience working AWS environments"], "common data science toolkits": ["common data science toolkits"], "At least years experience": ["At least years experience"], "Applied": ["Applied"], "Nordstrom Stock Purchase Plan": ["Nordstrom Stock Purchase Plan"], "data science math physics computer science equivalent degree": ["data science math physics computer science equivalent degree"], "Exceptional understanding machine learning concepts data science programming": ["Exceptional understanding machine learning concepts data science programming"], "mobile video games": ["mobile video games"], "product managers": ["product managers"], "Proficiency Python R SQL Authorization work United States": ["Proficiency Python R SQL Authorization work United States"], "Python R SQL Authorization": ["Python R SQL Authorization"], "Ph D M S quantitative discipline graduating Passion machine": ["Ph D M S quantitative discipline graduating Passion machine"], "Experience Spark": ["Experience Spark"], "even new folks": ["even new folks"], "An open work environment": ["An open work environment"], "large knowledge stores Experience information extraction creation application layer Experience developing REST JSON applications": ["large knowledge stores Experience information extraction creation application layer Experience developing REST JSON applications"], "recommendation engines Experience": ["recommendation engines Experience"], "Python Ruby Strong experience": ["Python Ruby Strong experience"], "Knowledge statistics experience": ["Knowledge statistics experience"], "Fluency": ["Fluency"], "Microsoft Azure": ["Microsoft Azure"], "Self starter results": ["Self starter results"], "Data Science Analytics Engineering Mathematics Industrial Engineering Computer Science Information Technology Economics Finance": ["Data Science Analytics Engineering Mathematics Industrial Engineering Computer Science Information Technology Economics Finance"], "Bachelor degree Data Science Analytics Engineering Mathematics Industrial Engineering Computer Science Information Technology Economics Finance": ["Bachelor degree Data Science Analytics Engineering Mathematics Industrial Engineering Computer Science Information Technology Economics Finance"], "Big data experience": ["Big data experience"], "US Citizenship Advanced degree computer science data science business analytics": ["US Citizenship Advanced degree computer science data science business analytics"], "tools Experience": ["tools Experience"], "Hive Spark Pig MapReduce Knowledge industry leading analytics": ["Hive Spark Pig MapReduce Knowledge industry leading analytics"], "oral presentation skills": ["oral presentation skills"], "Hive Spark": ["Hive Spark"], "days": ["days"], "experience familiarity multivariate predictive modeling analytics software": ["experience familiarity multivariate predictive modeling analytics software"], "Deep familiarity analytics actuarial market landscape corresponding information": ["Deep familiarity analytics actuarial market landscape corresponding information"], "Bachelor degree Master degree years work experience completing undergraduate degree years advanced analytics": ["Bachelor degree Master degree years work experience completing undergraduate degree years advanced analytics"], "knowledge insurance industry": ["knowledge insurance industry"], "Experience building deploying cloud based data pipelines": ["Experience building deploying cloud based data pipelines"], "Demonstrated programming experience": ["Demonstrated programming experience"], "team": ["team"], "business processes related client business questions years": ["business processes related client business questions years"], "BI Tool e OBIEE Cognos Business Objects": ["BI Tool e OBIEE Cognos Business Objects"], "role Experience": ["role Experience"], "g Excel Word PowerPoint Experience": ["g Excel Word PowerPoint Experience"], "Microsoft": ["Microsoft"], "implementation integration test deployment Experience developing software C C": ["implementation integration test deployment Experience developing software C C"], "large scale data management big data technologies": ["large scale data management big data technologies"], "important project success Effective interpersonal skills necessary interact levels personnel": ["important project success Effective interpersonal skills necessary interact levels personnel"], "Significant experience demonstrated expertise": ["Significant experience demonstrated expertise"], "technical languages concepts": ["technical languages concepts"], "creative solutions complex problems": ["creative solutions complex problems"], "Effective advanced analytical problem": ["Effective advanced analytical problem"], "advanced areas high performance": ["advanced areas high performance"], "Comprehensive knowledge": ["Comprehensive knowledge"], "decision making skills": ["decision making skills"], "Effective": ["Effective"], "program entrepreneurial environment Top notch health dental vision insurance Stock options fast growing tech company 401k plan matching contribution": ["program entrepreneurial environment Top notch health dental vision insurance Stock options fast growing tech company 401k plan matching contribution"], "Frequent company": ["Frequent company"], "Preferred Master Required United States": ["Preferred Master Required United States"], "Data Science years": ["Data Science years"], "Strong data mining data visualization Ability": ["Strong data mining data visualization Ability"], "Strong least code bases": ["Strong least code bases"], "machine learning models production environment": ["machine learning models production environment"], "Python Healthcare Population Health knowledge preferred Experience": ["Python Healthcare Population Health knowledge preferred Experience"], "Strong working stakeholders": ["Strong working stakeholders"], "Python Healthcare Population Health": ["Python Healthcare Population Health"], "fast paced environment Experience various math statistics methodologies": ["fast paced environment Experience various math statistics methodologies"], "multiple competing priorities": ["multiple competing priorities"], "insights": ["insights"], "basic knowledge statistical concepts regression time series mixed model": ["basic knowledge statistical concepts regression time series mixed model"], "Bayesian methods": ["Bayesian methods"], "BA Computer Science Engineering relevant field graduate degree Data Science quantitative field preferred Experience": ["BA Computer Science Engineering relevant field graduate degree Data Science quantitative field preferred Experience"], "anomaly detection Experience bioinformatics NLP": ["anomaly detection Experience bioinformatics NLP"], "Experience building": ["Experience building"], "Proficient Jupyter Python Spark": ["Proficient Jupyter Python Spark"], "cases": ["cases"], "internal non AI expert business partners": ["internal non AI expert business partners"], "asset drive diffusion AI": ["asset drive diffusion AI"], "execute coordinate innovative data analytics initiatives": ["execute coordinate innovative data analytics initiatives"], "BASF": ["BASF"], "HDFS Hadoop Hive HBase Spark Modern versioning systems git subversion": ["HDFS Hadoop Hive HBase Spark Modern versioning systems git subversion"], "Windows OS Linux OS command line tools": ["Windows OS Linux OS command line tools"], "neural networks recommendation systems": ["neural networks recommendation systems"], "addition time series analysis Modern ML techniques": ["addition time series analysis Modern ML techniques"], "SQL SQL": ["SQL SQL"], "time series regression cluster analysis decision trees": ["time series regression cluster analysis decision trees"], "advanced analytic techniques": ["advanced analytic techniques"], "oral Hands experience manipulating deriving": ["oral Hands experience manipulating deriving"], "unstructured datasets": ["unstructured datasets"], "practical casework agency corporate side Strong knowledge experience wide variety tools": ["practical casework agency corporate side Strong knowledge experience wide variety tools"], "SQL SAS R Alteryx Tableau Proficient Excel PowerPoint presentation communication skills": ["SQL SAS R Alteryx Tableau Proficient Excel PowerPoint presentation communication skills"], "Degree Statistics Information Systems Mathematics Finance": ["Degree Statistics Information Systems Mathematics Finance"], "Data Visualization skills": ["Data Visualization skills"], "Data Visualization": ["Data Visualization"], "SF Financial District": ["SF Financial District"], "Fun puzzle loving office": ["Fun puzzle loving office"], "Required Statistical Algorithms years Required expert usage R Python years": ["Required Statistical Algorithms years Required expert usage R Python years"], "analytic requirement Modern machine learning models expert level years": ["analytic requirement Modern machine learning models expert level years"], "Strong coding skills": ["Strong coding skills"], "technical non technical stakeholders": ["technical non technical stakeholders"], "verbal communication skills ability": ["verbal communication skills ability"], "large data sets": ["large data sets"], "clustering decision trees neural networks": ["clustering decision trees neural networks"], "databases": ["databases"], "computing tools Hive Redshift": ["computing tools Hive Redshift"], "ETL validations Experience Druid columnar data stores Experience BI tools": ["ETL validations Experience Druid columnar data stores Experience BI tools"], "PREFERRED QUALIFICATIONS Experience designing data quality metrics": ["PREFERRED QUALIFICATIONS Experience designing data quality metrics"], "quantitative data analysis years": ["quantitative data analysis years"], "SQL Hive experience years": ["SQL Hive experience years"], "Python R scripting languages": ["Python R scripting languages"], "Experience BI": ["Experience BI"], "statistical data analysis linear models": ["statistical data analysis linear models"], "Machine Learning PhD Data Science Statistics similar technical quantitative field Ability initiate": ["Machine Learning PhD Data Science Statistics similar technical quantitative field Ability initiate"], "Research Economics Computer Science Mathematics Physics Electrical Engineering Industrial Engineering": ["Research Economics Computer Science Mathematics Physics Electrical Engineering Industrial Engineering"], "g Statistics Operations Research Economics Computer Science Mathematics Physics Electrical Engineering Industrial Engineering": ["g Statistics Operations Research Economics Computer Science Mathematics Physics Electrical Engineering Industrial Engineering"], "analysis stochastic models": ["analysis stochastic models"], "commitment drive success teams peers": ["commitment drive success teams peers"], "Previous work experience": ["Previous work experience"], "Experience large scale data analysis": ["Experience large scale data analysis"], "data mining statistical analysis": ["data mining statistical analysis"], "aggressive deadlines": ["aggressive deadlines"], "key Strong communication data presentation": ["key Strong communication data presentation"], "new technologies tools techniques": ["new technologies tools techniques"], "structured unstructured data Strong communication interpersonal skills ability work team environment": ["structured unstructured data Strong communication interpersonal skills ability work team environment"], "statistical analysis software development Solid background machine": ["statistical analysis software development Solid background machine"], "Multivariate Regression Logistic Regression Combinatorial Optimization Stochastic Processes Complex Analysis Principal Component Analysis Time Series Analysis Experience Matlab R Weka Experience": ["Multivariate Regression Logistic Regression Combinatorial Optimization Stochastic Processes Complex Analysis Principal Component Analysis Time Series Analysis Experience Matlab R Weka Experience"], "Multivariate Regression Logistic Regression Combinatorial Optimization Stochastic Processes Complex Analysis Principal Component Analysis Time Series Analysis": ["Multivariate Regression Logistic Regression Combinatorial Optimization Stochastic Processes Complex Analysis Principal Component Analysis Time Series Analysis"], "Strong software development": ["Strong software development"], "Agile software development methodology": ["Agile software development methodology"], "software support continuous integration continuous deployment process": ["software support continuous integration continuous deployment process"], "statistical analysis": ["statistical analysis"], "high throughput data ingestion analysis": ["high throughput data ingestion analysis"], "new things test solutions technologies": ["new things test solutions technologies"], "enterprise products": ["enterprise products"], "deep learning": ["deep learning"], "TensorFlow PyTorch": ["TensorFlow PyTorch"], "unique solutions": ["unique solutions"], "micro managed freedom": ["micro managed freedom"], "cloud console": ["cloud console"], "better path": ["better path"], "frameworks": ["frameworks"], "Data science dynamic evolving profession": ["Data science dynamic evolving profession"], "current area expertise interest related interest positions": ["current area expertise interest related interest positions"], "Bachelor degree Computational social science Computer science Data analytics Economics Engineering Geospatial analysis": ["Bachelor degree Computational social science Computer science Data analytics Economics Engineering Geospatial analysis"], "Bachelor degree Computational social science Computer science Data analytics": ["Bachelor degree Computational social science Computer science Data analytics"], "Quantitative finance Statistics GPA": ["Quantitative finance Statistics GPA"], "CIA": ["CIA"], "continuous improvement data science analytics Presents data insights": ["continuous improvement data science analytics Presents data insights"], "analytics related field Certificate business analytics data mining statistical analysis": ["analytics related field Certificate business analytics data mining statistical analysis"], "Doctoral degree Statistics Economics Analytics Mathematics year experience analytics related field": ["Doctoral degree Statistics Economics Analytics Mathematics year experience analytics related field"], "large data analytics project teams Models compliance company": ["large data analytics project teams Models compliance company"], "analytics insights": ["analytics insights"], "data science experience years": ["data science experience years"], "DB2 Oracle SQL Server years": ["DB2 Oracle SQL Server years"], "Commuter Benefits Flexible Spendi": ["Commuter Benefits Flexible Spendi"], "Demonstrable knowledge healthcare data": ["Demonstrable knowledge healthcare data"], "little supervision Strong oral written presentation skills levels organization Ability": ["little supervision Strong oral written presentation skills levels organization Ability"], "working data science team": ["working data science team"], "R Python preferred ability interest": ["R Python preferred ability interest"], "g": ["g"], "least one scripting language": ["least one scripting language"], "data mining Strong knowledge experiences machine": ["data mining Strong knowledge experiences machine"], "Expertise data warehouse SQL programming": ["Expertise data warehouse SQL programming"], "Math quantitative field strong background machine": ["Math quantitative field strong background machine"], "Python based ML libraries": ["Python based ML libraries"], "Experience payment fraud detection prevention": ["Experience payment fraud detection prevention"], "Python R SAS Base SAS Stats SAS Enterprise": ["Python R SAS Base SAS Stats SAS Enterprise"], "Python R SAS Base SAS Stats SAS Enterprise Miner": ["Python R SAS Base SAS Stats SAS Enterprise Miner"], "mathematics statistics physics": ["mathematics statistics physics"], "computer science artificial intelligence": ["computer science artificial intelligence"], "relevant work experience Experience building": ["relevant work experience Experience building"], "MS Computer Science emphasis Data Science Analytics Machine Learning PhD": ["MS Computer Science emphasis Data Science Analytics Machine Learning PhD"], "ideas efficient elegant code Development experience": ["ideas efficient elegant code Development experience"], "RDF S OWL SPARQL Strong command linear algebra statistics ability": ["RDF S OWL SPARQL Strong command linear algebra statistics ability"], "Python Java Scala good command respective data pipelining matrix algebra statistics": ["Python Java Scala good command respective data pipelining matrix algebra statistics"], "Java Python": ["Java Python"], "common methods data transformation": ["common methods data transformation"], "various data structures": ["various data structures"], "years practical experience SAS ETL data processing database programming data analytics Experience predictive": ["years practical experience SAS ETL data processing database programming data analytics Experience predictive"], "Qlik SAP BO Experience mining Claims EMR data preferably Oncology related data": ["Qlik SAP BO Experience mining Claims EMR data preferably Oncology related data"], "statistical analysis Experience analytics": ["statistical analysis Experience analytics"], "Python SAS Alteryx Angos R Experience programming languages": ["Python SAS Alteryx Angos R Experience programming languages"], "Tableau MS Power BI Tibco": ["Tableau MS Power BI Tibco"], "Extensive": ["Extensive"], "data warehouse data cubes": ["data warehouse data cubes"], "Pentaho data integration experience": ["Pentaho data integration experience"], "ETL ELT processes": ["ETL ELT processes"], "ETL ELT": ["ETL ELT"], "operational data PLAN TRACK VIEW": ["operational data PLAN TRACK VIEW"], "applying structure schema": ["applying structure schema"], "Create": ["Create"], "Mathematics related field": ["Mathematics related field"], "Ph D MS degree": ["Ph D MS degree"], "D MS degree": ["D MS degree"], "HomeAway com Electronic adjustable stand desk": ["HomeAway com Electronic adjustable stand desk"], "talks leadership team": ["talks leadership team"], "Discounted Metro Rail": ["Discounted Metro Rail"], "unstructured data": ["unstructured data"], "real time": ["real time"], "weeks": ["weeks"], "Annual": ["Annual"], "e": ["e"], "Strong statistical knowledge intuition ability": ["Strong statistical knowledge intuition ability"], "Hive Pig Presto Spark Data visualization skills": ["Hive Pig Presto Spark Data visualization skills"], "Strong skills": ["Strong skills"], "massive amounts data drive product innovation": ["massive amounts data drive product innovation"], "Deep product sense": ["Deep product sense"], "predictive modeling time series probabilistic graphical models": ["predictive modeling time series probabilistic graphical models"], "track record": ["track record"], "structured semi structured unstructured data": ["structured semi structured unstructured data"], "millions": ["millions"], "Years": ["Years"], "daily": ["daily"], "Education Computer science Statistics Physics Mathematics Economics Specialization Certification": ["Education Computer science Statistics Physics Mathematics Economics Specialization Certification"], "quantitative trading research role Experience top tier quantitative investment firms": ["quantitative trading research role Experience top tier quantitative investment firms"], "working experience": ["working experience"], "AQR Capital QMS Capital": ["AQR Capital QMS Capital"], "Publications top tier journals": ["Publications top tier journals"], "Professional experience software development practices": ["Professional experience software development practices"], "advanced statistical methodologies multiple regression model mixed models time series models": ["advanced statistical methodologies multiple regression model mixed models time series models"], "prior experience optimization simulation marketing mix multivariate testing ensemble modeling graph": ["prior experience optimization simulation marketing mix multivariate testing ensemble modeling graph"], "Python R SQL": ["Python R SQL"], "Postgres Druid Aerospike Elasticsearch": ["Postgres Druid Aerospike Elasticsearch"], "Nice Experience working Database storage systems": ["Nice Experience working Database storage systems"], "g artificial intelligence operations research": ["g artificial intelligence operations research"], "Familiarity operations research CPLEX": ["Familiarity operations research CPLEX"], "complicated problems": ["complicated problems"], "integer problems": ["integer problems"], "actionable manner Ability": ["actionable manner Ability"], "quantitative research e": ["quantitative research e"], "languages": ["languages"], "key decisions": ["key decisions"], "colleagues": ["colleagues"], "IT systems": ["IT systems"], "preferably Big similar firm Demonstrated expertise business analysis data analysis Experience writing requirements": ["preferably Big similar firm Demonstrated expertise business analysis data analysis Experience writing requirements"], "accessing data years": ["accessing data years"], "working SQL": ["working SQL"], "Master degree computer science computer engineering related field equivalent combination education related experience Experience developing software": ["Master degree computer science computer engineering related field equivalent combination education related experience Experience developing software"], "Broad": ["Broad"], "PhD Masters approved field minimum years": ["PhD Masters approved field minimum years"], "minimum years": ["minimum years"], "PhD Masters": ["PhD Masters"], "Preferred Bachelors Science Computer Science Math Scientific Computing Data Analytics Machine Learning Business Analyst nanodegree equivalent experience": ["Preferred Bachelors Science Computer Science Math Scientific Computing Data Analytics Machine Learning Business Analyst nanodegree equivalent experience"], "data data sources": ["data data sources"], "Advanced knowledge R Experience SAS SPSS Experience": ["Advanced knowledge R Experience SAS SPSS Experience"], "Exposure Big Data technologies Hadoop Hive Advanced knowledge Excel Experience handling": ["Exposure Big Data technologies Hadoop Hive Advanced knowledge Excel Experience handling"], "solid experience marketing analytics": ["solid experience marketing analytics"], "digital behavioural data": ["digital behavioural data"], "segmentation predictive analytics": ["segmentation predictive analytics"], "information webpages product characteristics reviews": ["information webpages product characteristics reviews"], "track record application ML NLP": ["track record application ML NLP"], "global business rely diversity culture": ["global business rely diversity culture"], "Multiple years": ["Multiple years"], "statistical analysis Experience Python development": ["statistical analysis Experience Python development"], "Python SAS R statistical packages": ["Python SAS R statistical packages"], "Master Degree Economics Math Statistics Finance Engineering similar discipline year experience business application machine": ["Master Degree Economics Math Statistics Finance Engineering similar discipline year experience business application machine"], "Comfortable developing statistical models": ["Comfortable developing statistical models"], "Bachelor Degree Economics Math Science Finance": ["Bachelor Degree Economics Math Science Finance"], "similar discipline": ["similar discipline"], "Experience working scientists R D systems": ["Experience working scientists R D systems"], "good organizational communication analytical technical writing skills": ["good organizational communication analytical technical writing skills"], "data science statistics": ["data science statistics"], "Experience scripting languages": ["Experience scripting languages"], "healthcare domain Masters PhD Application data science solutions industrial projects": ["healthcare domain Masters PhD Application data science solutions industrial projects"], "data science problems": ["data science problems"], "Masters PhD Application": ["Masters PhD Application"], "BS MS PhD healthcare related field Minimum years": ["BS MS PhD healthcare related field Minimum years"], "BS MS PhD": ["BS MS PhD"], "A love games": ["A love games"], "related field minimum years general management experience business marketing analytics field equivalent combination experience training": ["related field minimum years general management experience business marketing analytics field equivalent combination experience training"], "Alteryx": ["Alteryx"], "CRM": ["CRM"], "internship school project": ["internship school project"], "Machine Learning Algorithms Statistics": ["Machine Learning Algorithms Statistics"], "Python R Programming": ["Python R Programming"], "engine implementation": ["engine implementation"], "Theoretical knowledge Machine Learning Algorithms Statistics etc Basic coding ability": ["Theoretical knowledge Machine Learning Algorithms Statistics etc Basic coding ability"], "young growing company": ["young growing company"], "today": ["today"], "Fetch": ["Fetch"], "web mobile applications business intelligence tools": ["web mobile applications business intelligence tools"], "Building": ["Building"], "data systems": ["data systems"], "Crown Center": ["Crown Center"], "site cafeteria": ["site cafeteria"], "Machine Learning algorithms models": ["Machine Learning algorithms models"], "Background Machine Learning Statistics Information Retrieval Design": ["Background Machine Learning Statistics Information Retrieval Design"], "Scala Golang Haskell Clojure": ["Scala Golang Haskell Clojure"], "collaborative environment": ["collaborative environment"], "Write": ["Write"], "company": ["company"], "features": ["features"], "Superb": ["Superb"], "new trends data science": ["new trends data science"], "implementation data science project": ["implementation data science project"], "digital marketing data": ["digital marketing data"], "connecting data": ["connecting data"], "new challenges": ["new challenges"], "business": ["business"], "Education": ["Education"], "New York NY": ["New York NY"], "New York": ["New York"], "clients": ["clients"], "real world Experience Python": ["real world Experience Python"], "natural language processing Development deployment software": ["natural language processing Development deployment software"], "related degree equivalent experience years": ["related degree equivalent experience years"], "work ethic passion problem": ["work ethic passion problem"], "Familiar data pipelines": ["Familiar data pipelines"], "knowledge": ["knowledge"], "smartest people": ["smartest people"], "boundaries": ["boundaries"], "Huge technical problems": ["Huge technical problems"], "extensive operational data analysis experience data analysis regression analysis": ["extensive operational data analysis experience data analysis regression analysis"], "industry experience predictive modeling data science analysis Programming experience": ["industry experience predictive modeling data science analysis Programming experience"], "Python R equivalent Demonstrated experience data science data analysis Desire": ["Python R equivalent Demonstrated experience data science data analysis Desire"], "Comfortable Linux environment Experience Amazon Web Services AWS": ["Comfortable Linux environment Experience Amazon Web Services AWS"], "e g Computer Science Operations Research Systems Engineering Physics equivalent experience years": ["e g Computer Science Operations Research Systems Engineering Physics equivalent experience years"], "Desire": ["Desire"], "healthcare data": ["healthcare data"], "Advanced": ["Advanced"], "areas": ["areas"], "five years": ["five years"], "Chief Statistician Next message Jobs Tenure track position University Hawaii Messages": ["Chief Statistician Next message Jobs Tenure track position University Hawaii Messages"], "University Hawaii Messages": ["University Hawaii Messages"], "Jobs Fwd OMB": ["Jobs Fwd OMB"], "Jobs Tenure": ["Jobs Tenure"], "Statistician": ["Statistician"], "Python R similar data science language Advanced proficiency data visualization Prefer financial services industry experience Prefer experience CRM financial analysis financial advisory Bachelors Master degree Computer Science Math Data Science Statistics": ["Python R similar data science language Advanced proficiency data visualization Prefer financial services industry experience Prefer experience CRM financial analysis financial advisory Bachelors Master degree Computer Science Math Data Science Statistics"], "Best Corporate Citizens InformationWeek": ["Best Corporate Citizens InformationWeek"], "FORTUNE World Most Admired Companies Corporate Responsibility Magazine Best Corporate Citizens": ["FORTUNE World Most Admired Companies Corporate Responsibility Magazine Best Corporate Citizens"], "Elite Women Business Enterprise National Council America Top Corporations Women Business Enterprises Reputation Institute World Most Reputable Companies": ["Elite Women Business Enterprise National Council America Top Corporations Women Business Enterprises Reputation Institute World Most Reputable Companies"], "Corporate Responsibility Magazine": ["Corporate Responsibility Magazine"], "FORTUNE World Most Admired Companies": ["FORTUNE World Most Admired Companies"], "diverse technical non technical audiences": ["diverse technical non technical audiences"], "technical concepts": ["technical concepts"], "Doctorate Preferred": ["Doctorate Preferred"], "Python development language emphasis data science Experience Python data analysis packages": ["Python development language emphasis data science Experience Python data analysis packages"], "Postgres Knowledge Bayesian data analysis methods model comparison": ["Postgres Knowledge Bayesian data analysis methods model comparison"], "Technologies Linux Python": ["Technologies Linux Python"], "Numerical topic": ["Numerical topic"], "MS PhD degree Computer Science Artificial Intelligence Machine Learning": ["MS PhD degree Computer Science Artificial Intelligence Machine Learning"], "technical field": ["technical field"], "Spark Hadoop": ["Spark Hadoop"], "analysis Experience machine": ["analysis Experience machine"], "Python scikit computer language experience": ["Python scikit computer language experience"], "statistical software Insurance industry experience": ["statistical software Insurance industry experience"], "progressive experience data science statistical analysis data modeling years": ["progressive experience data science statistical analysis data modeling years"], "regression segmentation decision tree time series design experiments": ["regression segmentation decision tree time series design experiments"], "Advanced Degree": ["Advanced Degree"], "MBA": ["MBA"], "internal data processing visualization tools years": ["internal data processing visualization tools years"], "data sources": ["data sources"], "data warehouses": ["data warehouses"], "Regularization Boosting Random Forests Decision Trees Bayesian": ["Regularization Boosting Random Forests Decision Trees Bayesian"], "Washington DC": ["Washington DC"], "hour": ["hour"], "U S": ["U S"], "Willingness": ["Willingness"], "Designing": ["Designing"], "Health": ["Health"], "Google Analytics Adobe Analytics Experience": ["Google Analytics Adobe Analytics Experience"], "analyzing data 3rd party providers": ["analyzing data 3rd party providers"], "Hadoop Hive Spark Experience visualizing": ["Hadoop Hive Spark Experience visualizing"], "Map Reduce Hadoop Hive": ["Map Reduce Hadoop Hive"], "data computing tools": ["data computing tools"], "etc Experience": ["etc Experience"], "data science analysis": ["data science analysis"], "preferred Excellent communication collaborative skills years": ["preferred Excellent communication collaborative skills years"], "Python R C": ["Python R C"], "Mathematics Physics Engineering MS PhD": ["Mathematics Physics Engineering MS PhD"], "Scikit Learn Keras TensorFlow": ["Scikit Learn Keras TensorFlow"], "ongoing operational needs": ["ongoing operational needs"], "satisfactory job performance continuing availability funds": ["satisfactory job performance continuing availability funds"], "This full time year term appointment possibility extension conversion Career appointment": ["This full time year term appointment possibility extension conversion Career appointment"], "Career": ["Career"], "quantitative methods principles statistics": ["quantitative methods principles statistics"], "masters level degree statistics biostatistics related fields": ["masters level degree statistics biostatistics related fields"], "research setting": ["research setting"], "data sets": ["data sets"], "USAID": ["USAID"], "Design": ["Design"], "modeling data mining years": ["modeling data mining years"], "Millions Billions": ["Millions Billions"], "Interest causal inference": ["Interest causal inference"], "SAS Enterprise Guide manipulate data": ["SAS Enterprise Guide manipulate data"], "SAS Enterprise Guide": ["SAS Enterprise Guide"], "broader goal": ["broader goal"], "Strong interest gaming industry": ["Strong interest gaming industry"], "HiveQL Knowledge data visualization Experience advanced analytics": ["HiveQL Knowledge data visualization Experience advanced analytics"], "software engineer data engineer data scientist Proficiency R": ["software engineer data engineer data scientist Proficiency R"], "Advanced Degree Mathematics Statistics Economics Computer Science related fields": ["Advanced Degree Mathematics Statistics Economics Computer Science related fields"], "Degree Mathematics Statistics Economics Computer Science": ["Degree Mathematics Statistics Economics Computer Science"], "Amazon Web Services AWS": ["Amazon Web Services AWS"], "Proficient R Python": ["Proficient R Python"], "tasks text mining sentiment analysis language": ["tasks text mining sentiment analysis language"], "professional experience Data Scientist NLP experience": ["professional experience Data Scientist NLP experience"], "unstructured text data": ["unstructured text data"], "classification information retrieval": ["classification information retrieval"], "process": ["process"], "initiative": ["initiative"], "U S government U S citizenship": ["U S government U S citizenship"], "Minimum years experience": ["Minimum years experience"], "Familiarity Agile": ["Familiarity Agile"], "k NN Naive Bayes SVM Decision Forests": ["k NN Naive Bayes SVM Decision Forests"], "Intermediate advanced experience": ["Intermediate advanced experience"], "original innovative techniques style Ability": ["original innovative techniques style Ability"], "Python Java B S Computer Science Software Engineering Information Science Mathematics Statistics Electrical Engineering Physics related fields": ["Python Java B S Computer Science Software Engineering Information Science Mathematics Statistics Electrical Engineering Physics related fields"], "Communication": ["Communication"], "seven years": ["seven years"], "data Experience": ["data Experience"], "large volume data Experience": ["large volume data Experience"], "healthcare industry Proven ability experience design development solutions increasing yield Proven analytical skills experience": ["healthcare industry Proven ability experience design development solutions increasing yield Proven analytical skills experience"], "statistical analysis data mining algorithms mathematical segmentation": ["statistical analysis data mining algorithms mathematical segmentation"], "Working knowledge statistical programming languages": ["Working knowledge statistical programming languages"], "Strong SQL experience ability": ["Strong SQL experience ability"], "clear precise actionable manner": ["clear precise actionable manner"], "Experience data": ["Experience data"], "Travel Master Degree statistics actuarial science related field study Experience data mining predictive modeling experience": ["Travel Master Degree statistics actuarial science related field study Experience data mining predictive modeling experience"], "Extensive knowledge tools data mining statistics Experience HR Analytics Strong knowledge MS Office products": ["Extensive knowledge tools data mining statistics Experience HR Analytics Strong knowledge MS Office products"], "statistical modeling programming Experience Tableau": ["statistical modeling programming Experience Tableau"], "team environment": ["team environment"], "MS Office": ["MS Office"], "measurement teams product teams members": ["measurement teams product teams members"], "wider analytical teams": ["wider analytical teams"], "challenges years work experience technology industry": ["challenges years work experience technology industry"], "public speaking engagements Extensive software development experience": ["public speaking engagements Extensive software development experience"], "Extensive experience software development expertise": ["Extensive experience software development expertise"], "Strong customer facing relationship building skills": ["Strong customer facing relationship building skills"], "present big picture offer solutions": ["present big picture offer solutions"], "custom solutions": ["custom solutions"], "Python Experience": ["Python Experience"], "Prior technical paper publications": ["Prior technical paper publications"], "business challenges": ["business challenges"], "bright charismatic people": ["bright charismatic people"], "highly reliable cloud services Experience": ["highly reliable cloud services Experience"], "Strong algorithmic problem": ["Strong algorithmic problem"], "highly reliable service offerings": ["highly reliable service offerings"], "C": ["C"], "uncover": ["uncover"], "Windows Linux": ["Windows Linux"], "JAVA C": ["JAVA C"], "An extraordinarily intelligent rigorous thinker": ["An extraordinarily intelligent rigorous thinker"], "Apple discriminate retaliate applicants inquire": ["Apple discriminate retaliate applicants inquire"], "compensation applicants": ["compensation applicants"], "Apple": ["Apple"], "SQL Proven": ["SQL Proven"], "Prior experience finance": ["Prior experience finance"], "A solid understanding ad networks media campaigns": ["A solid understanding ad networks media campaigns"], "Spark Streaming Experience Data": ["Spark Streaming Experience Data"], "e g Hive Spark Experience": ["e g Hive Spark Experience"], "RNN LSTM GANs Streaming Analytics e": ["RNN LSTM GANs Streaming Analytics e"], "dynamic innovative years applicable experience Experience Digital Media Experience": ["dynamic innovative years applicable experience Experience Digital Media Experience"], "user event data analysis Experience": ["user event data analysis Experience"], "SQL Excel": ["SQL Excel"], "technologies": ["technologies"], "schemas": ["schemas"], "Gym membership compensation": ["Gym membership compensation"], "Git SDLC": ["Git SDLC"], "advanced courses data science machine": ["advanced courses data science machine"], "communicate data driven insight": ["communicate data driven insight"], "Knowledge digital AdTech landscape": ["Knowledge digital AdTech landscape"], "AdTech": ["AdTech"], "Creative analytic problem solver diligent attention detail": ["Creative analytic problem solver diligent attention detail"], "Experience Cloudera": ["Experience Cloudera"], "MPP": ["MPP"], "various data sources": ["various data sources"], "Willingness travel": ["Willingness travel"], "Python Django Flask": ["Python Django Flask"], "Responsible staying current enterprise standards industry standards technologies": ["Responsible staying current enterprise standards industry standards technologies"], "data access data storage techniques": ["data access data storage techniques"], "video person hour": ["video person hour"], "employee benefits": ["employee benefits"], "kitchen": ["kitchen"], "data visualization tools": ["data visualization tools"], "big data data pipelines": ["big data data pipelines"], "data transformation data structures metadata dependency workload management": ["data transformation data structures metadata dependency workload management"], "working familiarity variety": ["working familiarity variety"], "NoSQL databases": ["NoSQL databases"], "third": ["third"], "Mustache Get Mustache": ["Mustache Get Mustache"], "data flows": ["data flows"], "Pet friendly office environment": ["Pet friendly office environment"], "Fixed term contract option perm": ["Fixed term contract option perm"], "Experience Agile Methodologies Scrum Kanban": ["Experience Agile Methodologies Scrum Kanban"], "least one high level programming language": ["least one high level programming language"], "data engineering": ["data engineering"], "millions daily players": ["millions daily players"], "millions daily": ["millions daily"], "cool people": ["cool people"], "unstructured data acquisition Realtime Data Integration Patterns Engagement": ["unstructured data acquisition Realtime Data Integration Patterns Engagement"], "data services": ["data services"], "Operational analytical data provisioning insights data landscape": ["Operational analytical data provisioning insights data landscape"], "Group Data": ["Group Data"], "Assist driving data services strategy": ["Assist driving data services strategy"], "Realtime Data Integration Patterns": ["Realtime Data Integration Patterns"], "Building Big Data Platform": ["Building Big Data Platform"], "next level excellence Building Big Data Platform": ["next level excellence Building Big Data Platform"], "Data Flow Patterns": ["Data Flow Patterns"], "Data Initiatives": ["Data Initiatives"], "Strategic Alignment Group Architecture": ["Strategic Alignment Group Architecture"], "Visualisation Storyboarding experience Stats": ["Visualisation Storyboarding experience Stats"], "Building operation frameworks processes": ["Building operation frameworks processes"], "Net Language experience": ["Net Language experience"], "Banking financial sector experience": ["Banking financial sector experience"], "Assist": ["Assist"], "Apache Flink Spark Streaming Apache Storm Kafka Streams others": ["Apache Flink Spark Streaming Apache Storm Kafka Streams others"], "Experience building stream processing applications": ["Experience building stream processing applications"], "Python Go Java Scala": ["Python Go Java Scala"], "massive petabyte scale semi structured datasets": ["massive petabyte scale semi structured datasets"], "Apache Flink": ["Apache Flink"], "data technologies": ["data technologies"], "growth mindset": ["growth mindset"], "self awareness": ["self awareness"], "large complex highly dimensional data": ["large complex highly dimensional data"], "Extras": ["Extras"], "perfect enemy": ["perfect enemy"], "You curious excellent analytical problem": ["You curious excellent analytical problem"], "career categories": ["career categories"], "realtime streaming compute components Experience data modeling data architecture": ["realtime streaming compute components Experience data modeling data architecture"], "big data patterns": ["big data patterns"], "Knowledgable distributed storage network resources level hosts": ["Knowledgable distributed storage network resources level hosts"], "DCs troubleshoot prevent performance issues": ["DCs troubleshoot prevent performance issues"], "particular MapReduce Spark Spark SQL": ["particular MapReduce Spark Spark SQL"], "large scale data pipelines": ["large scale data pipelines"], "Spark Streaming Hive YARN MR2 Experience building": ["Spark Streaming Hive YARN MR2 Experience building"], "MapReduce Spark": ["MapReduce Spark"], "ie warehousing concepts efficient storage query HDFS data security privacy": ["ie warehousing concepts efficient storage query HDFS data security privacy"], "highly scalable data systems services": ["highly scalable data systems services"], "batch": ["batch"], "commitment data governance Demonstrated ability": ["commitment data governance Demonstrated ability"], "analytics data engineering role": ["analytics data engineering role"], "verbal visual communication capabilities Ability": ["verbal visual communication capabilities Ability"], "relevant business people analytics": ["relevant business people analytics"], "BS MS degree quantitative field equivalent practical experience": ["BS MS degree quantitative field equivalent practical experience"], "data analytics solutions": ["data analytics solutions"], "continuous refinement improvement": ["continuous refinement improvement"], "least years": ["least years"], "e g Linux Mac OS Experience": ["e g Linux Mac OS Experience"], "nice required Data modeling Experience working search engines": ["nice required Data modeling Experience working search engines"], "analytic skills Solid computer science systems foundations ability": ["analytic skills Solid computer science systems foundations ability"], "new domains Proven system development": ["new domains Proven system development"], "Machine learning Natural": ["Machine learning Natural"], "Good communication skills teamwork Passion": ["Good communication skills teamwork Passion"], "Natural language processing": ["Natural language processing"], "Apache": ["Apache"], "Work clients model data landscape": ["Work clients model data landscape"], "data extracts": ["data extracts"], "operational ETL data pipelines": ["operational ETL data pipelines"], "data fields hypotheses": ["data fields hypotheses"], "Collaborate data scientists": ["Collaborate data scientists"], "Strong development background experience": ["Strong development background experience"], "Processing Spark Hadoop EMR": ["Processing Spark Hadoop EMR"], "MPP AWS Redshift Oracle Exadata Teradata IBM Netezza": ["MPP AWS Redshift Oracle Exadata Teradata IBM Netezza"], "Traditional RDBMS MS SQL Server Oracle": ["Traditional RDBMS MS SQL Server Oracle"], "Redshift Oracle": ["Redshift Oracle"], "Distributed Systems": ["Distributed Systems"], "clear timely professional manner": ["clear timely professional manner"], "context data processing Experience proficiency Python Experience design implementation data": ["context data processing Experience proficiency Python Experience design implementation data"], "Google Cloud Platform DevOps Stack development experience Apache Airflow data pipeline tools": ["Google Cloud Platform DevOps Stack development experience Apache Airflow data pipeline tools"], "various sources data Manage": ["various sources data Manage"], "Data Engineering Hadoop Spark Data Processing products": ["Data Engineering Hadoop Spark Data Processing products"], "data science production environments": ["data science production environments"], "working engineering team best track record data": ["working engineering team best track record data"], "third party elements data pipeline": ["third party elements data pipeline"], "key data functions": ["key data functions"], "Support sophisticated predictive data products": ["Support sophisticated predictive data products"], "Data Engineering Hadoop Spark Data": ["Data Engineering Hadoop Spark Data"], "data inconsistencies": ["data inconsistencies"], "Cloud experience": ["Cloud experience"], "outputs Data Science models": ["outputs Data Science models"], "open source tools": ["open source tools"], "similar Software Engineering Data Science etc experience software": ["similar Software Engineering Data Science etc experience software"], "infrastructure layout": ["infrastructure layout"], "cloud service integrations": ["cloud service integrations"], "Big Query Redshift Spectrum S3 Athena Kafka Spark Storm Flink Beam Presto Hive ETL": ["Big Query Redshift Spectrum S3 Athena Kafka Spark Storm Flink Beam Presto Hive ETL"], "Apache Airflow": ["Apache Airflow"], "python": ["python"], "transformations": ["transformations"], "Manage": ["Manage"], "Scala Java": ["Scala Java"], "401K": ["401K"], "Agile projects Data Warehousing experience": ["Agile projects Data Warehousing experience"], "Experience multiple Database technologies": ["Experience multiple Database technologies"], "technical aspects Data Technology industry personal professional development work life": ["technical aspects Data Technology industry personal professional development work life"], "different multiple projects": ["different multiple projects"], "Titan Experience developing solutions": ["Titan Experience developing solutions"], "Cloud": ["Cloud"], "data streaming Design": ["data streaming Design"], "data warehouse data models": ["data warehouse data models"], "source data e g data profiling definition mapping Design": ["source data e g data profiling definition mapping Design"], "data Manage data growth usage": ["data Manage data growth usage"], "data monitoring solutions procedures": ["data monitoring solutions procedures"], "efficient data loads": ["efficient data loads"], "good data governance Work": ["good data governance Work"], "unstructured data loads": ["unstructured data loads"], "functional data team knowledge gathering": ["functional data team knowledge gathering"], "managing data": ["managing data"], "traditional structured data ETL techniques Design": ["traditional structured data ETL techniques Design"], "technical data related support source system teams": ["technical data related support source system teams"], "usability data": ["usability data"], "real time data load solutions": ["real time data load solutions"], "appropriate aggregation data structures": ["appropriate aggregation data structures"], "changes data organisation": ["changes data organisation"], "troubleshoot technical data issues": ["troubleshoot technical data issues"], "working data business intelligence analytics environment": ["working data business intelligence analytics environment"], "SQL Data analysis Data visualisation Data": ["SQL Data analysis Data visualisation Data"], "data management analytics": ["data management analytics"], "meta data solutions": ["meta data solutions"], "team dynamics performance Complex solution service design implementation": ["team dynamics performance Complex solution service design implementation"], "effective efficient data models": ["effective efficient data models"], "Microsoft business intelligence data technologies": ["Microsoft business intelligence data technologies"], "speed access Design": ["speed access Design"], "data processes": ["data processes"], "data elements": ["data elements"], "Work source system owners analysts": ["Work source system owners analysts"], "availability accuracy Design": ["availability accuracy Design"], "Responsible team activities team dynamics performance Manage project task delivery team": ["Responsible team activities team dynamics performance Manage project task delivery team"], "supplement enhance context Design": ["supplement enhance context Design"], "interface monitoring management solutions": ["interface monitoring management solutions"], "solutions Positive engagement team activities": ["solutions Positive engagement team activities"], "data access e g batch exports": ["data access e g batch exports"], "Work analysts": ["Work analysts"], "e g text speech images video Design": ["e g text speech images video Design"], "knowledge share Quality control work Degree information technology engineering mathematics statistics actuarial related discipline": ["knowledge share Quality control work Degree information technology engineering mathematics statistics actuarial related discipline"], "ownership work": ["ownership work"], "business owners analysts": ["business owners analysts"], "load monitoring tools procedures": ["load monitoring tools procedures"], "high quality work time Show initiative": ["high quality work time Show initiative"], "system infrastructure management": ["system infrastructure management"], "real time decision": ["real time decision"], "Manage systems technology tools": ["Manage systems technology tools"], "Information gathering problem analysis": ["Information gathering problem analysis"], "appropriate indexing tables": ["appropriate indexing tables"], "SSAS SQL Server Data warehouse": ["SSAS SQL Server Data warehouse"], "Presenting Communicating information": ["Presenting Communicating information"], "appropriate modelling techniques": ["appropriate modelling techniques"], "appropriate changes": ["appropriate changes"], "internal external Assist development others": ["internal external Assist development others"], "professional specialist technical expertise": ["professional specialist technical expertise"], "Multiple stakeholder management": ["Multiple stakeholder management"], "SQL Data": ["SQL Data"], "skills knowledge application": ["skills knowledge application"], "loads": ["loads"], "ownership career development": ["ownership career development"], "Quality Detail orientation Planning": ["Quality Detail orientation Planning"], "continuous monitoring": ["continuous monitoring"], "sources": ["sources"], "integrity existing environment": ["integrity existing environment"], "IT infrastructure IT Operations": ["IT infrastructure IT Operations"], "Analysing Leadership": ["Analysing Leadership"], "automated decision": ["automated decision"], "value decision": ["value decision"], "active finding opportunities": ["active finding opportunities"], "effective strategies": ["effective strategies"], "Presenting Communicating": ["Presenting Communicating"], "external parties": ["external parties"], "Quality": ["Quality"], "g multi dimensional OLAP structures summary tables": ["g multi dimensional OLAP structures summary tables"], "Take": ["Take"], "interfaces": ["interfaces"], "Cross": ["Cross"], "Positive": ["Positive"], "SSIS": ["SSIS"], "OLAP": ["OLAP"], "etc Design implement": ["etc Design implement"], "ad hoc unstructured data models": ["ad hoc unstructured data models"], "API etc Design": ["API etc Design"], "code Scala Experience working Agile environment Experience building data processing pipelines": ["code Scala Experience working Agile environment Experience building data processing pipelines"], "Amazing working environment Employee referral scheme ETL Scala": ["Amazing working environment Employee referral scheme ETL Scala"], "Competitive Salary Company Bonus Private Healthcare Life Insurance Income protection Pension Scheme company contribution": ["Competitive Salary Company Bonus Private Healthcare Life Insurance Income protection Pension Scheme company contribution"], "analytics pipelines": ["analytics pipelines"], "Competitive Salary Company Bonus Private Healthcare Life Insurance Income": ["Competitive Salary Company Bonus Private Healthcare Life Insurance Income"], "big data experience": ["big data experience"], "Scala Experience": ["Scala Experience"], "sell days": ["sell days"], "production handsoff batch systems": ["production handsoff batch systems"], "Scala": ["Scala"], "social events": ["social events"], "Virtual company": ["Virtual company"], "Virtual": ["Virtual"], "Team player excellent communication skills": ["Team player excellent communication skills"], "Exposure Business Intelligence tools Business Objects": ["Exposure Business Intelligence tools Business Objects"], "Business Objects Informatica": ["Business Objects Informatica"], "developing testing ETL interfaces": ["developing testing ETL interfaces"], "Exposure Business Intelligence": ["Exposure Business Intelligence"], "Teradata Oracle MS SQL": ["Teradata Oracle MS SQL"], "MDM": ["MDM"], "Kinesis Riak": ["Kinesis Riak"], "Aurora Dynamo": ["Aurora Dynamo"], "Python SQL Spark Scala Extensive Experience SQL": ["Python SQL Spark Scala Extensive Experience SQL"], "big data years": ["big data years"], "NoSQL solutions": ["NoSQL solutions"], "display excellent judgment": ["display excellent judgment"], "difficult tradeoffs": ["difficult tradeoffs"], "new information": ["new information"], "BA BS Degree Computer Science Engineering discipline Statistics Information Systems": ["BA BS Degree Computer Science Engineering discipline Statistics Information Systems"], "Statistics Information Systems": ["Statistics Information Systems"], "BA BS Degree Computer Science Engineering": ["BA BS Degree Computer Science Engineering"], "another quantitative field": ["another quantitative field"], "statistical modeling discriminative methods": ["statistical modeling discriminative methods"], "extraction analysis": ["extraction analysis"], "Experience areas data": ["Experience areas data"], "Mathematics Engineering technology": ["Mathematics Engineering technology"], "Possess bachelor degree": ["Possess bachelor degree"], "data stores data": ["data stores data"], "model evaluation validation Enthusiasm big data translating data": ["model evaluation validation Enthusiasm big data translating data"], "unstructured data Proficient building robust data pipelines": ["unstructured data Proficient building robust data pipelines"], "data processing tools": ["data processing tools"], "leading successful data engineering projects": ["leading successful data engineering projects"], "reliable data services stakeholders": ["reliable data services stakeholders"], "Agile project development experience": ["Agile project development experience"], "Data Engineer Machine Learning Engineer": ["Data Engineer Machine Learning Engineer"], "Kafka Apache Spark": ["Kafka Apache Spark"], "analyze present data answer business questions Experience data visualization tools": ["analyze present data answer business questions Experience data visualization tools"], "Experience data induction validation source systems Experience working Capital Projects": ["Experience data induction validation source systems Experience working Capital Projects"], "Advanced SQL knowledge years data extraction experience": ["Advanced SQL knowledge years data extraction experience"], "UAT Expert normalizing data": ["UAT Expert normalizing data"], "Familiarity Finance Operations Retail Contact Center data": ["Familiarity Finance Operations Retail Contact Center data"], "Desire end end ownership work Flexibility balance directional changes ability": ["Desire end end ownership work Flexibility balance directional changes ability"], "Strong analytical skills ability": ["Strong analytical skills ability"], "day day": ["day day"], "business support Ability deal ambiguity Proactive driven individual comfortable working global matrixed fast paced environment": ["business support Ability deal ambiguity Proactive driven individual comfortable working global matrixed fast paced environment"], "multiple deadline specific projects": ["multiple deadline specific projects"], "Oracle Teradata Vertica Hadoop": ["Oracle Teradata Vertica Hadoop"], "k Savings Plan Company Match Paid Vacations": ["k Savings Plan Company Match Paid Vacations"], "Safety Quality First Valuing Ethics Integrity Diversity Passion": ["Safety Quality First Valuing Ethics Integrity Diversity Passion"], "Competitive Salary Comprehensive Health Wellness Income Protection Benefits": ["Competitive Salary Comprehensive Health Wellness Income Protection Benefits"], "Safety Quality First Valuing Ethics Integrity Diversity Passion Serving Our Customers Globally Dedication": ["Safety Quality First Valuing Ethics Integrity Diversity Passion Serving Our Customers Globally Dedication"], "Bachelor Master degree Computer Science": ["Bachelor Master degree Computer Science"], "Servant Leadership": ["Servant Leadership"], "Pig Hive Impala Experience integration data multiple data sources": ["Pig Hive Impala Experience integration data multiple data sources"], "TDD Continuous Integration Experience refactoring code scale production mind": ["TDD Continuous Integration Experience refactoring code scale production mind"], "Solid knowledge data structures": ["Solid knowledge data structures"], "Experience Big Data ML": ["Experience Big Data ML"], "services Experience building stream processing systems": ["services Experience building stream processing systems"], "Good knowledge Big Data querying tools": ["Good knowledge Big Data querying tools"], "Big Data ML": ["Big Data ML"], "Lambda Architecture": ["Lambda Architecture"], "advantages": ["advantages"], "technical data role": ["technical data role"], "good data governance": ["good data governance"], "Unstructured data experience": ["Unstructured data experience"], "Implement meta data solutions": ["Implement meta data solutions"], "Microsoft business intelligence visualisation technologies": ["Microsoft business intelligence visualisation technologies"], "knowledge share Quality control work Degree information technology": ["knowledge share Quality control work Degree information technology"], "Stakeholder management internal external Assist development others": ["Stakeholder management internal external Assist development others"], "SSRS Power BI IT infrastructure e g storage networking servers": ["SSRS Power BI IT infrastructure e g storage networking servers"], "team dynamics performance": ["team dynamics performance"], "mathematics engineering actuarial science related discipline": ["mathematics engineering actuarial science related discipline"], "specifically personal unsecured loans Business process monitoring": ["specifically personal unsecured loans Business process monitoring"], "Quality Detail orientation": ["Quality Detail orientation"], "availability accuracy Monitor": ["availability accuracy Monitor"], "SSRS Power BI": ["SSRS Power BI"], "Stakeholder": ["Stakeholder"], "Unstructured": ["Unstructured"], "data processing systems Experience": ["data processing systems Experience"], "years experience schema": ["years experience schema"], "internal clients Experience designing building": ["internal clients Experience designing building"], "communicating data warehouse": ["communicating data warehouse"], "troubleshooting skills Process oriented great documentation skills": ["troubleshooting skills Process oriented great documentation skills"], "dimensional data": ["dimensional data"], "keen sense customer service BS MS degree": ["keen sense customer service BS MS degree"], "data Optimize tune data warehouse query performance analytical workloads": ["data Optimize tune data warehouse query performance analytical workloads"], "SQL Server Experience developing software code": ["SQL Server Experience developing software code"], "integrations BI tools third party productivity applications years engineering experience Expert SQL": ["integrations BI tools third party productivity applications years engineering experience Expert SQL"], "data warehouse structure table": ["data warehouse structure table"], "Python Java Scala Ruby Experience managing database data warehouse technologies bonus Redshift Snowflake Experience": ["Python Java Scala Ruby Experience managing database data warehouse technologies bonus Redshift Snowflake Experience"], "robust data": ["robust data"], "resolve data quality issues": ["resolve data quality issues"], "Bonus Stitch Fivetran Matillion Understanding data analytics ecosystem": ["Bonus Stitch Fivetran Matillion Understanding data analytics ecosystem"], "data analysis Design": ["data analysis Design"], "visualization tools based requirements": ["visualization tools based requirements"], "Business Intelligence tools": ["Business Intelligence tools"], "ETL tools": ["ETL tools"], "Spark Kafka AWS Glue Amazon Kinesis Sqoop Flume Flink Experience": ["Spark Kafka AWS Glue Amazon Kinesis Sqoop Flume Flink Experience"], "Bonus Looker Experience": ["Bonus Looker Experience"], "Snowflake Redshift PostgreSQL": ["Snowflake Redshift PostgreSQL"], "Bonus Stitch Fivetran Matillion Understanding": ["Bonus Stitch Fivetran Matillion Understanding"], "Redshift Snowflake": ["Redshift Snowflake"], "Snowflake Redshift": ["Snowflake Redshift"], "Bonus Looker": ["Bonus Looker"], "Kinesis Sqoop": ["Kinesis Sqoop"], "Business Intelligence": ["Business Intelligence"], "Spark Kafka": ["Spark Kafka"], "one relevant tools": ["one relevant tools"], "troubleshoot": ["troubleshoot"], "users": ["users"], "Architect": ["Architect"], "JSON ProtocolBuffers XML": ["JSON ProtocolBuffers XML"], "Numpy Scipy Experience query APIs": ["Numpy Scipy Experience query APIs"], "JSON ProtocolBuffers": ["JSON ProtocolBuffers"], "Numpy Scipy": ["Numpy Scipy"], "algebra ML": ["algebra ML"], "RDB MPP DB": ["RDB MPP DB"], "Oozie Big data warehousing RDB": ["Oozie Big data warehousing RDB"], "Apple benefits programmes": ["Apple benefits programmes"], "Apple benefits": ["Apple benefits"], "Apple programmes": ["Apple programmes"], "Apple important resource soul people": ["Apple important resource soul people"], "Apple chance share company success": ["Apple chance share company success"], "Supporting data collection curation data provenance": ["Supporting data collection curation data provenance"], "stock grants employees levels company": ["stock grants employees levels company"], "special employee pricing": ["special employee pricing"], "benefits privileges": ["benefits privileges"], "many benefits": ["many benefits"], "distributed systems blob storage elastic compute virtual instances Familiarity Software Development Life Cycles tools methodologies": ["distributed systems blob storage elastic compute virtual instances Familiarity Software Development Life Cycles tools methodologies"], "reasonable accommodation applicants": ["reasonable accommodation applicants"], "Familiarity Software Development Life Cycles": ["Familiarity Software Development Life Cycles"], "reasonable accommodation": ["reasonable accommodation"], "employees": ["employees"], "charitable contributions reimburse continuing education": ["charitable contributions reimburse continuing education"], "programmes": ["programmes"], "country subject eligibility requirements": ["country subject eligibility requirements"], "Apple products": ["Apple products"], "meaningful ways": ["meaningful ways"], "Experience Scala": ["Experience Scala"], "option": ["option"], "source systems data": ["source systems data"], "published data sources": ["published data sources"], "Create manage data sources": ["Create manage data sources"], "ETL programs data pipelines": ["ETL programs data pipelines"], "AWS Redshift Python R Hadoop Spark technologies Work": ["AWS Redshift Python R Hadoop Spark technologies Work"], "unstructured data Competitive wages": ["unstructured data Competitive wages"], "practical demonstrable hands work experience SQL": ["practical demonstrable hands work experience SQL"], "relational NoSQL columnar data stores": ["relational NoSQL columnar data stores"], "open source cloud based environment": ["open source cloud based environment"], "Python Java Scala R Sharp attention detail ability": ["Python Java Scala R Sharp attention detail ability"], "Health Savings Account Medical Dependent Care Flexible Spending Accounts Wellness Program Membership TPC": ["Health Savings Account Medical Dependent Care Flexible Spending Accounts Wellness Program Membership TPC"], "database design execution Work": ["database design execution Work"], "Health Savings Account Medical Dependent Care Flexible Spending Accounts": ["Health Savings Account Medical Dependent Care Flexible Spending Accounts"], "Redshift Python R Hadoop": ["Redshift Python R Hadoop"], "data release testing processes": ["data release testing processes"], "multiple tasks": ["multiple tasks"], "Data Engineering": ["Data Engineering"], "Spark development years": ["Spark development years"], "data engineering ETL pipeline development years": ["data engineering ETL pipeline development years"], "preferred years": ["preferred years"], "Python preferred Experience": ["Python preferred Experience"], "Big Data Technologies Hadoop MapReduce Hive": ["Big Data Technologies Hadoop MapReduce Hive"], "Big Data Technologies Hadoop MapReduce Hive etc Spark experience": ["Big Data Technologies Hadoop MapReduce Hive etc Spark experience"], "SSAS SSRS Degree Information Technology": ["SSAS SSRS Degree Information Technology"], "Full SQL Stack": ["Full SQL Stack"], "SQL knowledge experience": ["SQL knowledge experience"], "Five seven years": ["Five seven years"], "SQL NoSQL database experience": ["SQL NoSQL database experience"], "challenge": ["challenge"], "data analytic pipelines": ["data analytic pipelines"], "Experience data movement management Pharmaceutical industry": ["Experience data movement management Pharmaceutical industry"], "Computer Science Bioinformatics related degree years experience data movement data wrangling delivery data analytics pipelines": ["Computer Science Bioinformatics related degree years experience data movement data wrangling delivery data analytics pipelines"], "diverse omic data types": ["diverse omic data types"], "RNA Seq DNA Seq Chip Seq WES WGS ATAC seq microbiome proteomic metabolomic data": ["RNA Seq DNA Seq Chip Seq WES WGS ATAC seq microbiome proteomic metabolomic data"], "Familiarity data mining machine": ["Familiarity data mining machine"], "RNA Seq DNA Seq Chip Seq WES WGS ATAC": ["RNA Seq DNA Seq Chip Seq WES WGS ATAC"], "scientific fields Experience core components Hadoop stack": ["scientific fields Experience core components Hadoop stack"], "judgement balance pace": ["judgement balance pace"], "honest open conversations": ["honest open conversations"], "Operating pace": ["Operating pace"], "rigour risk": ["rigour risk"], "agile decision making": ["agile decision making"], "Cloud computing HPC systems": ["Cloud computing HPC systems"], "artificial intelligence techniques": ["artificial intelligence techniques"], "HDFS Apache Spark": ["HDFS Apache Spark"], "Agile Engineering Kanban Lean Hybrid agile experience": ["Agile Engineering Kanban Lean Hybrid agile experience"], "Python SQL Elastic visualise data surfacing tool Experience developing machine learning systems Experience Amazon Quicksite advantage": ["Python SQL Elastic visualise data surfacing tool Experience developing machine learning systems Experience Amazon Quicksite advantage"], "exploration visualisation Experience statistical models times": ["exploration visualisation Experience statistical models times"], "Degree educated Data Science similar Strong experience data preparation techniques": ["Degree educated Data Science similar Strong experience data preparation techniques"], "regression classification Strong skills": ["regression classification Strong skills"], "Python SQL Elastic": ["Python SQL Elastic"], "series analysis": ["series analysis"], "Splunk Hadoop": ["Splunk Hadoop"], "insightful data performance visualizations": ["insightful data performance visualizations"], "optimized pipelines data acquisition": ["optimized pipelines data acquisition"], "algorithm variants": ["algorithm variants"], "Expertise Python programming functional object": ["Expertise Python programming functional object"], "limited personnel policies policies": ["limited personnel policies policies"], "University Administrative Guide http": ["University Administrative Guide http"], "comply applicable University policies procedures": ["comply applicable University policies procedures"], "University Administrative Guide": ["University Administrative Guide"], "unsolicited services": ["unsolicited services"], "Linux system administration command line tools": ["Linux system administration command line tools"], "Strong analytical thinking": ["Strong analytical thinking"], "Excellent programming skills C C Python Java": ["Excellent programming skills C C Python Java"], "minimum experience": ["minimum experience"], "production software": ["production software"], "Experience data tools": ["Experience data tools"], "streaming data processing Ability": ["streaming data processing Ability"], "Scala preferred Proficient schema design data": ["Scala preferred Proficient schema design data"], "analytic skills Ability program several scripting languages Python Perl Bash Experience workflow management tools": ["analytic skills Ability program several scripting languages Python Perl Bash Experience workflow management tools"], "high volume data Apache Hadoop ecosystem": ["high volume data Apache Hadoop ecosystem"], "Oozie Airflow Azkaban": ["Oozie Airflow Azkaban"], "Python Perl Bash": ["Python Perl Bash"], "Oozie Airflow Azkaban etc Experience": ["Oozie Airflow Azkaban etc Experience"], "working cross functional projects": ["working cross functional projects"], "one object oriented programming languages": ["one object oriented programming languages"], "Passion customer privacy Strong interpersonal skills": ["Passion customer privacy Strong interpersonal skills"], "Cassandra Neo4J": ["Cassandra Neo4J"], "MongoDB Cassandra": ["MongoDB Cassandra"], "SSIS standard ETL": ["SSIS standard ETL"], "strong Stored Procs": ["strong Stored Procs"], "Stored Procs": ["Stored Procs"], "serious interest": ["serious interest"], "SQL Dev": ["SQL Dev"], "MapReduce Spark Spark SQL": ["MapReduce Spark Spark SQL"], "Java Scala Extensive experience Hadoop ecosystem technologies": ["Java Scala Extensive experience Hadoop ecosystem technologies"], "Spark Streaming Hive YARN MR2 Expertise building": ["Spark Streaming Hive YARN MR2 Expertise building"], "Java Scala Extensive": ["Java Scala Extensive"], "Scala Python Apple": ["Scala Python Apple"], "Scala Python Apple important resource soul people": ["Scala Python Apple important resource soul people"], "self sufficient Experience": ["self sufficient Experience"], "distributed systems services scale Experience": ["distributed systems services scale Experience"], "Preference experience": ["Preference experience"], "health wellness resources time": ["health wellness resources time"], "similar technologies production contexts": ["similar technologies production contexts"], "SOLR Spark Hadoop Kafka": ["SOLR Spark Hadoop Kafka"], "years software engineering experience": ["years software engineering experience"], "responsible self": ["responsible self"], "Redis Apache Spark similar tools Experience regression testing data pipelines": ["Redis Apache Spark similar tools Experience regression testing data pipelines"], "instance Docker Kubernetes Terraform CloudFormation Ansible Chef Puppet Salt Splunk Elastic ELK Stack Sentry Datadog similar tools Knowledge Machine Learning Computer Vision": ["instance Docker Kubernetes Terraform CloudFormation Ansible Chef Puppet Salt Splunk Elastic ELK Stack Sentry Datadog similar tools Knowledge Machine Learning Computer Vision"], "Experience DevOps application monitoring tools": ["Experience DevOps application monitoring tools"], "AWS RDS Apache Kafka AWS Kinesis": ["AWS RDS Apache Kafka AWS Kinesis"], "Knowledge Machine Learning Computer Vision": ["Knowledge Machine Learning Computer Vision"], "Proficient scripting functional programming languages": ["Proficient scripting functional programming languages"], "Docker Kubernetes Terraform CloudFormation Ansible": ["Docker Kubernetes Terraform CloudFormation Ansible"], "RDS Apache Kafka": ["RDS Apache Kafka"], "Redis Apache": ["Redis Apache"], "streaming solutions instance": ["streaming solutions instance"], "Kinesis RabbitMQ": ["Kinesis RabbitMQ"], "Python Scala Bash Groovy Ruby Experience database message": ["Python Scala Bash Groovy Ruby Experience database message"], "working Batch Real Time data processing systems Ability work": ["working Batch Real Time data processing systems Ability work"], "large scale data processing": ["large scale data processing"], "machine learning solutions scale Experience": ["machine learning solutions scale Experience"], "based systems Experience custom ETL design implementation maintenance Experience": ["based systems Experience custom ETL design implementation maintenance Experience"], "data storage principles": ["data storage principles"], "Knowledge distributed systems": ["Knowledge distributed systems"], "data management": ["data management"], "data storage cloud computing Understanding administration AWS Docker Linux": ["data storage cloud computing Understanding administration AWS Docker Linux"], "Hadoop Spark Dataflow Airflow Knowledge practical experience machine": ["Hadoop Spark Dataflow Airflow Knowledge practical experience machine"], "traditional distributed systems": ["traditional distributed systems"], "Competitive Salary Equity 401k Company Match Gym Public Transportation Subsidy Student Loan Assistance Relocation Assistance Unlimited PTO": ["Competitive Salary Equity 401k Company Match Gym Public Transportation Subsidy Student Loan Assistance Relocation Assistance Unlimited PTO"], "Competitive Salary Equity 401k Company Match Gym Public Transportation Subsidy Student Loan Assistance Relocation Assistance": ["Competitive Salary Equity 401k Company Match Gym Public Transportation Subsidy Student Loan Assistance Relocation Assistance"], "Unlimited PTO": ["Unlimited PTO"], "Opportunity work": ["Opportunity work"], "AI fundamentals": ["AI fundamentals"], "Batch Real Time": ["Batch Real Time"], "Computer Science Statistics Engineering": ["Computer Science Statistics Engineering"], "higher quantitative technical field": ["higher quantitative technical field"], "Working knowledge data design architecture": ["Working knowledge data design architecture"], "401K Gym public transportation subsidy Relocation assistance": ["401K Gym public transportation subsidy Relocation assistance"], "fastest growing financial startups Competitive salary equity Health dental vision insurance": ["fastest growing financial startups Competitive salary equity Health dental vision insurance"], "K Gym": ["K Gym"], "data ingest enrichment analysis visualization dissemination": ["data ingest enrichment analysis visualization dissemination"], "Spark Knime Exposure AWS Data Services Experience Architect design implement": ["Spark Knime Exposure AWS Data Services Experience Architect design implement"], "Spark Knime Exposure AWS Data Services": ["Spark Knime Exposure AWS Data Services"], "Data transformation experience": ["Data transformation experience"], "data repositories": ["data repositories"], "largest growth": ["largest growth"], "indices": ["indices"], "Graph Databases": ["Graph Databases"], "enhancements": ["enhancements"], "working day year": ["working day year"], "data enterprise systems SAP Security management Data modelling ETL development": ["data enterprise systems SAP Security management Data modelling ETL development"], "Annual Bonus Plan Discretionary Cash Award Group Personal Pension Plan": ["Annual Bonus Plan Discretionary Cash Award Group Personal Pension Plan"], "additional days": ["additional days"], "tools Data Integrator Services Experience experience": ["tools Data Integrator Services Experience experience"], "agile project management": ["agile project management"], "Medical Travel Health Life Insurances": ["Medical Travel Health Life Insurances"], "data engineering domain": ["data engineering domain"], "Data Integrator Services": ["Data Integrator Services"], "free car parking gym site team": ["free car parking gym site team"], "schemas dimensional modelling normalisation": ["schemas dimensional modelling normalisation"], "Strong knowledge concepts": ["Strong knowledge concepts"], "yearly basis taxable benefit Employee Stock Purchase Program Free snacks": ["yearly basis taxable benefit Employee Stock Purchase Program Free snacks"], "spark Experience Scala Python Experience building batch pipelines data event data": ["spark Experience Scala Python Experience building batch pipelines data event data"], "Employee Stock Purchase Program Free": ["Employee Stock Purchase Program Free"], "Experience building data pipelines": ["Experience building data pipelines"], "data systems AWS": ["data systems AWS"], "NoSQL APIs Competitive health insurance benefits Competitive salary Annual target bonus commission": ["NoSQL APIs Competitive health insurance benefits Competitive salary Annual target bonus commission"], "Vacation": ["Vacation"], "scalable data pipelines data processing frameworks": ["scalable data pipelines data processing frameworks"], "Depth knowledge Data Operations Data Quality management space Experience layered geospatial data structures data representations": ["Depth knowledge Data Operations Data Quality management space Experience layered geospatial data structures data representations"], "modern cloud native processing frameworks": ["modern cloud native processing frameworks"], "high volume data processing organization business division": ["high volume data processing organization business division"], "computing frameworks geospatial processing indexing": ["computing frameworks geospatial processing indexing"], "data quality management": ["data quality management"], "Expertise processing": ["Expertise processing"], "scalable cloud native backend compute capabilities REST APIs microservices": ["scalable cloud native backend compute capabilities REST APIs microservices"], "distributed computing environment years": ["distributed computing environment years"], "Inspire": ["Inspire"], "intellectual curiosity Show passion innovation continuous improvement initiate efforts": ["intellectual curiosity Show passion innovation continuous improvement initiate efforts"], "Extensive experience relational database development": ["Extensive experience relational database development"], "Experience scripting automation language": ["Experience scripting automation language"], "technical direction problem": ["technical direction problem"], "organisation best practice quality standards": ["organisation best practice quality standards"], "Ensure third party development": ["Ensure third party development"], "exceptional problem": ["exceptional problem"], "Knowledge investment management": ["Knowledge investment management"], "support team": ["support team"], "Interest NoSQL database": ["Interest NoSQL database"], "Embrace": ["Embrace"], "functional team environment Apple Equal Opportunity Employer": ["functional team environment Apple Equal Opportunity Employer"], "relationships Ability": ["relationships Ability"], "HTML CSS Javascript Strong interpersonal skills verbal written Ability": ["HTML CSS Javascript Strong interpersonal skills verbal written Ability"], "day day business support": ["day day business support"], "directional changes ability": ["directional changes ability"], "Apple Equal Opportunity Employer": ["Apple Equal Opportunity Employer"], "similar Proficient data access preparation methods": ["similar Proficient data access preparation methods"], "Proficient scripting glue languages": ["Proficient scripting glue languages"], "data elements sources": ["data elements sources"], "PHP Python web technologies": ["PHP Python web technologies"], "PHP": ["PHP"], "Minimum five years data analytics programming database administration data management experience": ["Minimum five years data analytics programming database administration data management experience"], "requisite skills": ["requisite skills"], "less experience": ["less experience"], "applications candidates": ["applications candidates"], "The stated experience level guide": ["The stated experience level guide"], "Medical Health Insurance Onsite Wellness Clinic Long Term Disability Life Insurance Dental Vision Coverage": ["Medical Health Insurance Onsite Wellness Clinic Long Term Disability Life Insurance Dental Vision Coverage"], "cruises anniversary Medical Health Insurance Onsite Wellness Clinic Long Term Disability Life Insurance Dental Vision Coverage": ["cruises anniversary Medical Health Insurance Onsite Wellness Clinic Long Term Disability Life Insurance Dental Vision Coverage"], "Legal Insurance": ["Legal Insurance"], "K Plan Pet Care Insurance": ["K Plan Pet Care Insurance"], "Data design experience Experience data cleansing optimization data consumption Experience source control tools Git TFS": ["Data design experience Experience data cleansing optimization data consumption Experience source control tools Git TFS"], "Consumer Websites Experience consumer facing": ["Consumer Websites Experience consumer facing"], "data management systems": ["data management systems"], "Experience Azure Service Fabric": ["Experience Azure Service Fabric"], "Working familiarity front end web framework": ["Working familiarity front end web framework"], "CSV JSON XML data formats": ["CSV JSON XML data formats"], "Dedicated Employee Enrichment Recognition Programs": ["Dedicated Employee Enrichment Recognition Programs"], "mobile systems": ["mobile systems"], "data engineering tasks": ["data engineering tasks"], "Expertise Hadoop related technologies": ["Expertise Hadoop related technologies"], "large scale data warehousing mining analytic systems Ability work analysts": ["large scale data warehousing mining analytic systems Ability work analysts"], "Spark Streaming Spark SQL Map": ["Spark Streaming Spark SQL Map"], "big data pipelines": ["big data pipelines"], "Azkaban Oozie Impala Hive Pig Expertise": ["Azkaban Oozie Impala Hive Pig Expertise"], "Proficiency data processing": ["Proficiency data processing"], "Map Reduce Expertise Hadoop": ["Map Reduce Expertise Hadoop"], "Kafka Flume Storm Experience": ["Kafka Flume Storm Experience"], "Spark Streaming": ["Spark Streaming"], "Kafka Flume Storm": ["Kafka Flume Storm"], "HDFS Azkaban Oozie": ["HDFS Azkaban Oozie"], "broad variety audiences": ["broad variety audiences"], "complex technical concepts": ["complex technical concepts"], "object oriented programming languages": ["object oriented programming languages"], "BS BA Technical Field Computer Science Mathematics Knowledge Python Java Experience": ["BS BA Technical Field Computer Science Mathematics Knowledge Python Java Experience"], "BA Technical Field Computer Science Mathematics Knowledge Python": ["BA Technical Field Computer Science Mathematics Knowledge Python"], "SQL ETL": ["SQL ETL"], "MapReduce MPP": ["MapReduce MPP"], "Large scale ETL Apache beam Apache spark High scale Restful Services Cloud experience": ["Large scale ETL Apache beam Apache spark High scale Restful Services Cloud experience"], "B Tech Computer Science IT": ["B Tech Computer Science IT"], "Google Cloud Platform Azure AWS": ["Google Cloud Platform Azure AWS"], "ETL Apache": ["ETL Apache"], "SQL document stores": ["SQL document stores"], "BSc B": ["BSc B"], "Python Data": ["Python Data"], "Experience Azure Data Factory Data Bricks Data Lake": ["Experience Azure Data Factory Data Bricks Data Lake"], "Bricks Data Lake": ["Bricks Data Lake"], "solid understanding relational NoSQL database technologies Experience visualization data mining statistical tools": ["solid understanding relational NoSQL database technologies Experience visualization data mining statistical tools"], "massive complex datasets": ["massive complex datasets"], "metrics statistical information": ["metrics statistical information"], "familiar ETL tools": ["familiar ETL tools"], "robust data analytic pipelines": ["robust data analytic pipelines"], "Expertise various ETL technologies": ["Expertise various ETL technologies"], "e g Python Scala comfortable developing code": ["e g Python Scala comfortable developing code"], "Solr Kafka": ["Solr Kafka"], "e g Oozie Airflow": ["e g Oozie Airflow"], "Oozie Airflow Have": ["Oozie Airflow Have"], "relational data Postgres programming experience": ["relational data Postgres programming experience"], "unstructured data APIs Experience ETL integration": ["unstructured data APIs Experience ETL integration"], "DMS Stitch Experience data analysis visualization tools Mode Working knowledge message": ["DMS Stitch Experience data analysis visualization tools Mode Working knowledge message"], "tech debt Experience business operations tools": ["tech debt Experience business operations tools"], "technology landscape Experience AWS services": ["technology landscape Experience AWS services"], "data science machine": ["data science machine"], "positive attitude empathy Self awareness desire": ["positive attitude empathy Self awareness desire"], "Dog Friendly Office": ["Dog Friendly Office"], "deep understanding data engineering concepts database": ["deep understanding data engineering concepts database"], "Lambda DynamoDB etc Competitive salary Employee Stock Option Plan Generous health commuter benefits": ["Lambda DynamoDB etc Competitive salary Employee Stock Option Plan Generous health commuter benefits"], "Advanced SQL knowledge": ["Advanced SQL knowledge"], "Informatica Talend Pentaho DataStage Experience interest Big Data technologies": ["Informatica Talend Pentaho DataStage Experience interest Big Data technologies"], "Azure Strong SQL experience": ["Azure Strong SQL experience"], "Data security governance expertise": ["Data security governance expertise"], "structured unstructured data Extensive AWS Experience": ["structured unstructured data Extensive AWS Experience"], "Python preferred Experience designing data architecture ground Experience": ["Python preferred Experience designing data architecture ground Experience"], "working data systems years": ["working data systems years"], "Spark Hadoop years": ["Spark Hadoop years"], "Bachelor Degree computer science engineering mathematics related fields equivalent experience Expert SQL knowledge experience": ["Bachelor Degree computer science engineering mathematics related fields equivalent experience Expert SQL knowledge experience"], "large datasets Masters Degree computer science engineering mathematics related fields equivalent experience": ["large datasets Masters Degree computer science engineering mathematics related fields equivalent experience"], "large scale data warehouse platform Hands experience": ["large scale data warehouse platform Hands experience"], "engineering experience years": ["engineering experience years"], "Python C C Experience data visualization presentation": ["Python C C Experience data visualization presentation"], "familiar data analysis tools": ["familiar data analysis tools"], "large scale data": ["large scale data"], "online caches real time systems BA BS Degree Computer Science Engineering discipline Statistics Information Systems": ["online caches real time systems BA BS Degree Computer Science Engineering discipline Statistics Information Systems"], "Data Warehouse": ["Data Warehouse"], "Travel": ["Travel"], "sit shoulder shoulder": ["sit shoulder shoulder"], "challenging encouraging": ["challenging encouraging"], "New Hire Orientation": ["New Hire Orientation"], "Robust Perks generous PTO 401k contributions tuition assistance entertainment discounts": ["Robust Perks generous PTO 401k contributions tuition assistance entertainment discounts"], "massage volunteer opportunities": ["massage volunteer opportunities"], "Vibrancy Wellness Program Yoga fitness classes": ["Vibrancy Wellness Program Yoga fitness classes"], "employee coverage": ["employee coverage"], "monthly": ["monthly"], "healthy food utmost convenience": ["healthy food utmost convenience"], "market boundaries": ["market boundaries"], "phenomenal team individuals": ["phenomenal team individuals"], "Previously healthcare experience": ["Previously healthcare experience"], "g Storm Spark Streaming ETL tools": ["g Storm Spark Streaming ETL tools"], "sensitive available time resource constraints": ["sensitive available time resource constraints"], "g Cassandra MongoDB Stream processing systems": ["g Cassandra MongoDB Stream processing systems"], "g MapReduce Hive Pig SQL": ["g MapReduce Hive Pig SQL"], "Hadoop based technologies": ["Hadoop based technologies"], "data storage retrieval specific use cases": ["data storage retrieval specific use cases"], "Cloud computing architectures": ["Cloud computing architectures"], "NoSQL technologies": ["NoSQL technologies"], "Legacy modern database": ["Legacy modern database"], "user defined functions table functions": ["user defined functions table functions"], "career growth": ["career growth"], "smart people": ["smart people"], "Data Platform Administration Engineering": ["Data Platform Administration Engineering"], "Bachelor Degree Computer Science related field years": ["Bachelor Degree Computer Science related field years"], "Bachelor Degree Computer Science": ["Bachelor Degree Computer Science"], "Excellent understanding manipulation analysis": ["Excellent understanding manipulation analysis"], "modern tech tools hi tech equipment": ["modern tech tools hi tech equipment"], "extra cash pocket": ["extra cash pocket"], "opportunity work friends": ["opportunity work friends"], "A commitment open inclusive diverse work culture": ["A commitment open inclusive diverse work culture"], "Data Warehouse Big Data": ["Data Warehouse Big Data"], "SQL Data Warehouse Data Catalog Azure Analysis Services Data Bricks Storage Account": ["SQL Data Warehouse Data Catalog Azure Analysis Services Data Bricks Storage Account"], "SQL Server preferable multi dimensional Data Warehousing environment": ["SQL Server preferable multi dimensional Data Warehousing environment"], "Data Warehousing": ["Data Warehousing"], "Enterprise Data Analytics solution architecture years": ["Enterprise Data Analytics solution architecture years"], "SQL Programming PL SQL": ["SQL Programming PL SQL"], "Python SQL Strong": ["Python SQL Strong"], "SQL Programming PL SQL T": ["SQL Programming PL SQL T"], "Spark Pyspark Python Scala Pig Experience Big Data Management BDM relational non relational data formats": ["Spark Pyspark Python Scala Pig Experience Big Data Management BDM relational non relational data formats"], "Python SQL Strong analytical abilities": ["Python SQL Strong analytical abilities"], "Microsoft SQL Server preferable expert MDX DAX": ["Microsoft SQL Server preferable expert MDX DAX"], "Azure": ["Azure"], "SQL U": ["SQL U"], "mobile solutions years": ["mobile solutions years"], "Power BI": ["Power BI"], "Hive Hadoop": ["Hive Hadoop"], "Hackathons": ["Hackathons"], "metrics consumers": ["metrics consumers"], "Work data science teams": ["Work data science teams"], "data curation management strategies": ["data curation management strategies"], "laboratory research data management processes procedures": ["laboratory research data management processes procedures"], "biomedical data management data engineering quality assurance": ["biomedical data management data engineering quality assurance"], "Excellent skills R programming experience": ["Excellent skills R programming experience"], "development specimen data management related discipline Demonstrated proficiency molecular biology concepts ability support": ["development specimen data management related discipline Demonstrated proficiency molecular biology concepts ability support"], "systematic relational approaches data integration data processing": ["systematic relational approaches data integration data processing"], "Detailed knowledge experience case report form design central laboratories": ["Detailed knowledge experience case report form design central laboratories"], "Working knowledge Windows Linux operating systems": ["Working knowledge Windows Linux operating systems"], "query resolution data validation Computer": ["query resolution data validation Computer"], "SAS data": ["SAS data"], "detailed knowledge": ["detailed knowledge"], "action patient response Proven ability work team environment clinical personnel study monitors": ["action patient response Proven ability work team environment clinical personnel study monitors"], "strong capacity independent thinking ability": ["strong capacity independent thinking ability"], "Oracle Clinical Clintrial preferred experience": ["Oracle Clinical Clintrial preferred experience"], "Strong understanding LIMS systems": ["Strong understanding LIMS systems"], "Java C C Extensive practical experience": ["Java C C Extensive practical experience"], "database design implementation": ["database design implementation"], "complex dynamic environment": ["complex dynamic environment"], "Along programming proficiency": ["Along programming proficiency"], "least one data management system": ["least one data management system"], "additional computer languages": ["additional computer languages"], "high level scientific datasets": ["high level scientific datasets"], "medical writers": ["medical writers"], "organizational skills": ["organizational skills"], "direct assess implementation": ["direct assess implementation"], "computational biologists biostatisticians": ["computational biologists biostatisticians"], "Familiarity Amazon Web Services": ["Familiarity Amazon Web Services"], "research hypotheses": ["research hypotheses"], "underlying biological questions": ["underlying biological questions"], "query interfaces": ["query interfaces"], "diverse highly connected scientific knowledge collections": ["diverse highly connected scientific knowledge collections"], "Perl Python PHP S": ["Perl Python PHP S"], "Experience integration data": ["Experience integration data"], "Enriched Tuition reimbursement training learning programs": ["Enriched Tuition reimbursement training learning programs"], "multiple partners": ["multiple partners"], "Track record": ["Track record"], "Knowledge sharing activities": ["Knowledge sharing activities"], "preferred Data modeling experience": ["preferred Data modeling experience"], "advantageous Pair programming experience Scrum agile experience Kanban agile experience JIRA experience Release search applications cloud environment": ["advantageous Pair programming experience Scrum agile experience Kanban agile experience JIRA experience Release search applications cloud environment"], "Experience graph database": ["Experience graph database"], "Kafka Apache Spark Experience big data technologies Hadoop Kafka Akka Mesos": ["Kafka Apache Spark Experience big data technologies Hadoop Kafka Akka Mesos"], "highly desirable Experience Semantic Web RDF OWL SPARQL": ["highly desirable Experience Semantic Web RDF OWL SPARQL"], "dev ops": ["dev ops"], "specific Big Data DevOps roles": ["specific Big Data DevOps roles"], "Most Big Data Engineers": ["Most Big Data Engineers"], "Machine Learning Big Data": ["Machine Learning Big Data"], "Machine Learning Big Data infrastructure": ["Machine Learning Big Data infrastructure"], "Flume Experience various messaging systems": ["Flume Experience various messaging systems"], "GCP AWS Azure year experience": ["GCP AWS Azure year experience"], "Python Scala Golang R year experience provisioned demand cloud computing platforms": ["Python Scala Golang R year experience provisioned demand cloud computing platforms"], "computing fundamentals ability design scalability": ["computing fundamentals ability design scalability"], "g Git Jira": ["g Git Jira"], "etc Knowledge": ["etc Knowledge"], "Git Jira": ["Git Jira"], "year experience working data lake environment Experience collecting transforming": ["year experience working data lake environment Experience collecting transforming"], "working data engineering": ["working data engineering"], "data pipelines machine": ["data pipelines machine"], "large amounts data": ["large amounts data"], "Bachelor degree experience": ["Bachelor degree experience"], "year experience": ["year experience"], "Java Python Knowledge Hadoop Spark big data processing frameworks": ["Java Python Knowledge Hadoop Spark big data processing frameworks"], "Bachelor degree Master degree computer science field Computer Science Information Sciences Informatics Experience": ["Bachelor degree Master degree computer science field Computer Science Information Sciences Informatics Experience"], "Relevant degree work experience": ["Relevant degree work experience"], "This full time exempt position": ["This full time exempt position"], "real world experience AWS EMR E2 Kinesis S3": ["real world experience AWS EMR E2 Kinesis S3"], "Bonus points": ["Bonus points"], "agile methodologies": ["agile methodologies"], "Scala Java C": ["Scala Java C"], "Data serialization JSON avro parquet": ["Data serialization JSON avro parquet"], "Building Cube Cube": ["Building Cube Cube"], "products": ["products"], "Docker Apache Mesos Kubernetes": ["Docker Apache Mesos Kubernetes"], "Cluster managers eg Docker Apache Mesos Kubernetes": ["Cluster managers eg Docker Apache Mesos Kubernetes"], "401k retirement savings plan": ["401k retirement savings plan"], "LA best restaurants": ["LA best restaurants"], "Daily catered lunches": ["Daily catered lunches"], "profile": ["profile"], "Indemnity": ["Indemnity"], "meet business processes priorities": ["meet business processes priorities"], "application enhancements": ["application enhancements"], "3rd party vendors": ["3rd party vendors"], "3rd party": ["3rd party"], "academic experience data engineering capacity Experience Docker Apache Spark ElasticSearch": ["academic experience data engineering capacity Experience Docker Apache Spark ElasticSearch"], "similar Hands experience": ["similar Hands experience"], "queue technology Apache Kafka": ["queue technology Apache Kafka"], "real time systems production stage years": ["real time systems production stage years"], "Excellent experience": ["Excellent experience"], "Apache Kafka": ["Apache Kafka"], "Google Analytics": ["Google Analytics"], "Agile Scrum working practices": ["Agile Scrum working practices"], "Masters degree years experience Experience proficiency Scala Experience proficiency": ["Masters degree years experience Experience proficiency Scala Experience proficiency"], "interest applying scale Experience data cleaning preparation feature building selection techniques": ["interest applying scale Experience data cleaning preparation feature building selection techniques"], "random effect models": ["random effect models"], "Effective communication interpersonal teamwork skills Ability": ["Effective communication interpersonal teamwork skills Ability"], "duties": ["duties"], "Information Technology experience": ["Information Technology experience"], "years Information Technology experience Proficiency domain driven design domain modeling Experience NoSql solutions Gemfire Cassandra HBase": ["years Information Technology experience Proficiency domain driven design domain modeling Experience NoSql solutions Gemfire Cassandra HBase"], "CI CD tools": ["CI CD tools"], "Bachelor Degree years Information Technology experience": ["Bachelor Degree years Information Technology experience"], "MySQL SQL Server Oracle": ["MySQL SQL Server Oracle"], "A good understanding adherence data security standards": ["A good understanding adherence data security standards"], "Python Golang Clojure R year experience provisioned demand cloud computing platforms GCP AWS Azure year experience": ["Python Golang Clojure R year experience provisioned demand cloud computing platforms GCP AWS Azure year experience"], "data solutions AWS Experience building data vision strategy": ["data solutions AWS Experience building data vision strategy"], "FinTech related area": ["FinTech related area"], "Chicago Top Company Culture Entrepreneur Top Workplace Chicago Tribune": ["Chicago Top Company Culture Entrepreneur Top Workplace Chicago Tribune"], "Crain Chicago Business": ["Crain Chicago Business"], "Best Consumer Web Company": ["Best Consumer Web Company"], "one Chicago Best Places Work Women": ["one Chicago Best Places Work Women"], "Best Consumer": ["Best Consumer"], "Experience HTTP REST SSL identity authentication": ["Experience HTTP REST SSL identity authentication"], "data infrastructure cloud": ["data infrastructure cloud"], "Comfortable building": ["Comfortable building"], "happy hours wind": ["happy hours wind"], "Spontaneous nerf gun wars": ["Spontaneous nerf gun wars"], "Thursday": ["Thursday"], "Excellent verbal written communication skills": ["Excellent verbal written communication skills"], "Java PHP Years database work mysql Postgres RedShift Experience": ["Java PHP Years database work mysql Postgres RedShift Experience"], "Oriented Programming Python Java Database Technologies Redshift Postgres Spark Presto Amazon Web Services S3 SQS Kinesis ECS ECR EMR": ["Oriented Programming Python Java Database Technologies Redshift Postgres Spark Presto Amazon Web Services S3 SQS Kinesis ECS ECR EMR"], "B S Computer Science Object": ["B S Computer Science Object"], "System availability Data Availability Data Quality": ["System availability Data Availability Data Quality"], "SAP Data Services Talend": ["SAP Data Services Talend"], "SAP Data Services": ["SAP Data Services"], "MS SQL Server Strong programming experience": ["MS SQL Server Strong programming experience"], "hard promote change industry": ["hard promote change industry"], "Share success": ["Share success"], "success": ["success"], "way": ["way"], "RDS redshift S3 Experience consuming cleaning data third party APIs sources": ["RDS redshift S3 Experience consuming cleaning data third party APIs sources"], "Hive Hadoop Spark": ["Hive Hadoop Spark"], "data Strong communication skills": ["data Strong communication skills"], "various AWS services": ["various AWS services"], "unlimited vacation k plan": ["unlimited vacation k plan"], "benefits health vision life dental insurance": ["benefits health vision life dental insurance"], "cupcakes": ["cupcakes"], "competitive compensation equity packages": ["competitive compensation equity packages"], "A collaborative nature entrepreneurial spirit": ["A collaborative nature entrepreneurial spirit"], "SVN C unit test strategy": ["SVN C unit test strategy"], "internal tools utilities Set unit test strategy": ["internal tools utilities Set unit test strategy"], "revision control": ["revision control"], "disk Experience Large Scale Big Data methods MapReduce Hadoop Spark Hive Impala Storm Strong": ["disk Experience Large Scale Big Data methods MapReduce Hadoop Spark Hive Impala Storm Strong"], "automated reports data visualisation solutions": ["automated reports data visualisation solutions"], "modern data solutions": ["modern data solutions"], "Python applications data": ["Python applications data"], "SQL Comfort": ["SQL Comfort"], "LI PA1": ["LI PA1"], "truly global company offices countries": ["truly global company offices countries"], "Ball games": ["Ball games"], "Monthly team": ["Monthly team"], "Teradata MS SQL": ["Teradata MS SQL"], "SSRS": ["SSRS"]}, "metadescriptions": {"Healthcare": "<br/><b>data scientist</b> TextRank score rank: 580/2000<br/><b>data engineer</b> TextRank score rank: 1122/2000", "data Ability": "<br/><b>data scientist</b> TextRank score rank: 392/2000<br/><b>data engineer</b> TextRank score rank: 1420/2000", "Medical dental vision insurance Life disability coverage": "<br/><b>data scientist</b> TextRank score rank: 477/2000<br/><b>data engineer</b> TextRank score rank: 1419/2000", "401K Flexible Spending Accounts Apple equipment Daily breakfast lunch dinner": "<br/><b>data scientist</b> TextRank score rank: 590/2000<br/><b>data engineer</b> TextRank score rank: 1418/2000", "graduation date": "<br/><b>data scientist</b> TextRank score rank: 769/2000<br/><b>data engineer</b> TextRank score rank: 1417/2000", "Competitive": "<br/><b>data scientist</b> TextRank score rank: 385/2000<br/><b>data engineer</b> TextRank score rank: 189/2000", "Tableau": "<br/><b>data scientist</b> TextRank score rank: 31/2000<br/><b>data engineer</b> TextRank score rank: 33/2000", "backgrounds": "<br/><b>data scientist</b> TextRank score rank: 1143/2000<br/><b>data engineer</b> TextRank score rank: 1082/2000", "novel biomarkers dissect gene disease relationships": "<br/><b>data scientist</b> TextRank score rank: 456/2000<br/><b>data engineer</b> TextRank score rank: 1416/2000", "Strong interested biology immunological diseases": "<br/><b>data scientist</b> TextRank score rank: 461/2000<br/><b>data engineer</b> TextRank score rank: 1415/2000", "Excellent interpersonal team skills": "<br/><b>data scientist</b> TextRank score rank: 466/2000<br/><b>data engineer</b> TextRank score rank: 1414/2000", "Experience Bayesian analysis causal inference": "<br/><b>data scientist</b> TextRank score rank: 481/2000<br/><b>data engineer</b> TextRank score rank: 1413/2000", "PhD MS computational biology computer science statistics": "<br/><b>data scientist</b> TextRank score rank: 487/2000<br/><b>data engineer</b> TextRank score rank: 1412/2000", "benchmark apply predictive algorithms": "<br/><b>data scientist</b> TextRank score rank: 532/2000<br/><b>data engineer</b> TextRank score rank: 1411/2000", "AI machine learning methods": "<br/><b>data scientist</b> TextRank score rank: 549/2000<br/><b>data engineer</b> TextRank score rank: 1410/2000", "non linear regression models": "<br/><b>data scientist</b> TextRank score rank: 603/2000<br/><b>data engineer</b> TextRank score rank: 1409/2000", "dimensionality reduction clustering": "<br/><b>data scientist</b> TextRank score rank: 638/2000<br/><b>data engineer</b> TextRank score rank: 1408/2000", "data R": "<br/><b>data scientist</b> TextRank score rank: 775/2000<br/><b>data engineer</b> TextRank score rank: 1407/2000", "Immunology Inflammation": "<br/><b>data scientist</b> TextRank score rank: 768/2000<br/><b>data engineer</b> TextRank score rank: 1406/2000", "Proficiency": "<br/><b>data scientist</b> TextRank score rank: 212/2000<br/><b>data engineer</b> TextRank score rank: 1066/2000", "Bayesian": "<br/><b>data scientist</b> TextRank score rank: 166/2000<br/><b>data engineer</b> TextRank score rank: 1405/2000", "Ability": "<br/><b>data scientist</b> TextRank score rank: 32/2000<br/><b>data engineer</b> TextRank score rank: 31/2000", "hypotheses": "<br/><b>data scientist</b> TextRank score rank: 726/2000<br/><b>data engineer</b> TextRank score rank: 1404/2000", "AI": "<br/><b>data scientist</b> TextRank score rank: 143/2000<br/><b>data engineer</b> TextRank score rank: 601/2000", "Excellent": "<br/><b>data scientist</b> TextRank score rank: 303/2000<br/><b>data engineer</b> TextRank score rank: 1095/2000", "relevant work experience": "<br/><b>data scientist</b> TextRank score rank: 1047/2000<br/><b>data engineer</b> TextRank score rank: 750/2000", "depth knowledge": "<br/><b>data scientist</b> TextRank score rank: 505/2000<br/><b>data engineer</b> TextRank score rank: 1403/2000", "neural networks": "<br/><b>data scientist</b> TextRank score rank: 564/2000<br/><b>data engineer</b> TextRank score rank: 1402/2000", "Bachelor degree": "<br/><b>data scientist</b> TextRank score rank: 465/2000<br/><b>data engineer</b> TextRank score rank: 508/2000", "Minimum years": "<br/><b>data scientist</b> TextRank score rank: 90/2000<br/><b>data engineer</b> TextRank score rank: 76/2000", "Hadoop Spark": "<br/><b>data scientist</b> TextRank score rank: 160/2000<br/><b>data engineer</b> TextRank score rank: 41/2000", "Proficiency R": "<br/><b>data scientist</b> TextRank score rank: 503/2000<br/><b>data engineer</b> TextRank score rank: 1401/2000", "data": "<br/><b>data scientist</b> TextRank score rank: 26/2000<br/><b>data engineer</b> TextRank score rank: 23/2000", "scikit": "<br/><b>data scientist</b> TextRank score rank: 444/2000<br/><b>data engineer</b> TextRank score rank: 1400/2000", "Hadoop": "<br/><b>data scientist</b> TextRank score rank: 219/2000<br/><b>data engineer</b> TextRank score rank: 44/2000", "Experience": "<br/><b>data scientist</b> TextRank score rank: 1/2000<br/><b>data engineer</b> TextRank score rank: 22/2000", "Java Scala Python": "<br/><b>data scientist</b> TextRank score rank: 1093/2000<br/><b>data engineer</b> TextRank score rank: 399/2000", "production environments": "<br/><b>data scientist</b> TextRank score rank: 1095/2000<br/><b>data engineer</b> TextRank score rank: 1053/2000", "analytical techniques": "<br/><b>data scientist</b> TextRank score rank: 1096/2000<br/><b>data engineer</b> TextRank score rank: 1029/2000", "Software": "<br/><b>data scientist</b> TextRank score rank: 1054/2000<br/><b>data engineer</b> TextRank score rank: 574/2000", "Self": "<br/><b>data scientist</b> TextRank score rank: 538/2000<br/><b>data engineer</b> TextRank score rank: 792/2000", "algorithms": "<br/><b>data scientist</b> TextRank score rank: 102/2000<br/><b>data engineer</b> TextRank score rank: 326/2000", "Experiences": "<br/><b>data scientist</b> TextRank score rank: 515/2000<br/><b>data engineer</b> TextRank score rank: 1399/2000", "computing frameworks": "<br/><b>data scientist</b> TextRank score rank: 163/2000<br/><b>data engineer</b> TextRank score rank: 1084/2000", "actionable insights": "<br/><b>data scientist</b> TextRank score rank: 368/2000<br/><b>data engineer</b> TextRank score rank: 1074/2000", "Python Java R": "<br/><b>data scientist</b> TextRank score rank: 699/2000<br/><b>data engineer</b> TextRank score rank: 1398/2000", "Deep learning": "<br/><b>data scientist</b> TextRank score rank: 759/2000<br/><b>data engineer</b> TextRank score rank: 1421/2000", "PhD": "<br/><b>data scientist</b> TextRank score rank: 78/2000<br/><b>data engineer</b> TextRank score rank: 410/2000", "Master": "<br/><b>data scientist</b> TextRank score rank: 91/2000<br/><b>data engineer</b> TextRank score rank: 1422/2000", "Master Degree PhD Experience working AWS": "<br/><b>data scientist</b> TextRank score rank: 491/2000<br/><b>data engineer</b> TextRank score rank: 1423/2000", "Master Degree PhD": "<br/><b>data scientist</b> TextRank score rank: 263/2000<br/><b>data engineer</b> TextRank score rank: 1424/2000", "Degree PhD": "<br/><b>data scientist</b> TextRank score rank: 301/2000<br/><b>data engineer</b> TextRank score rank: 1448/2000", "large scale data analysis": "<br/><b>data scientist</b> TextRank score rank: 288/2000<br/><b>data engineer</b> TextRank score rank: 1447/2000", "At least year experience open source programming languages": "<br/><b>data scientist</b> TextRank score rank: 299/2000<br/><b>data engineer</b> TextRank score rank: 1446/2000", "Python Scala R": "<br/><b>data scientist</b> TextRank score rank: 312/2000<br/><b>data engineer</b> TextRank score rank: 1445/2000", "At least year experience machine": "<br/><b>data scientist</b> TextRank score rank: 310/2000<br/><b>data engineer</b> TextRank score rank: 1444/2000", "At least years experience machine": "<br/><b>data scientist</b> TextRank score rank: 817/2000<br/><b>data engineer</b> TextRank score rank: 1443/2000", "data analytics": "<br/><b>data scientist</b> TextRank score rank: 156/2000<br/><b>data engineer</b> TextRank score rank: 720/2000", "Bachelor Degree": "<br/><b>data scientist</b> TextRank score rank: 411/2000<br/><b>data engineer</b> TextRank score rank: 302/2000", "At least year": "<br/><b>data scientist</b> TextRank score rank: 151/2000<br/><b>data engineer</b> TextRank score rank: 475/2000", "At least years": "<br/><b>data scientist</b> TextRank score rank: 89/2000<br/><b>data engineer</b> TextRank score rank: 170/2000", "Good English language skills": "<br/><b>data scientist</b> TextRank score rank: 389/2000<br/><b>data engineer</b> TextRank score rank: 1442/2000", "Computer Science related degree years related work experience Experience working Open Source project": "<br/><b>data scientist</b> TextRank score rank: 445/2000<br/><b>data engineer</b> TextRank score rank: 1441/2000", "English": "<br/><b>data scientist</b> TextRank score rank: 96/2000<br/><b>data engineer</b> TextRank score rank: 50/2000", "Spark": "<br/><b>data scientist</b> TextRank score rank: 331/2000<br/><b>data engineer</b> TextRank score rank: 43/2000", "ability": "<br/><b>data scientist</b> TextRank score rank: 66/2000<br/><b>data engineer</b> TextRank score rank: 69/2000", "Java Scala": "<br/><b>data scientist</b> TextRank score rank: 150/2000<br/><b>data engineer</b> TextRank score rank: 70/2000", "Python Java": "<br/><b>data scientist</b> TextRank score rank: 1148/2000<br/><b>data engineer</b> TextRank score rank: 577/2000", "strong baselines ability": "<br/><b>data scientist</b> TextRank score rank: 308/2000<br/><b>data engineer</b> TextRank score rank: 1440/2000", "experimental analytic plans data modeling processes": "<br/><b>data scientist</b> TextRank score rank: 258/2000<br/><b>data engineer</b> TextRank score rank: 1439/2000", "Demonstrable track record": "<br/><b>data scientist</b> TextRank score rank: 574/2000<br/><b>data engineer</b> TextRank score rank: 1438/2000", "results": "<br/><b>data scientist</b> TextRank score rank: 139/2000<br/><b>data engineer</b> TextRank score rank: 333/2000", "well ambiguity": "<br/><b>data scientist</b> TextRank score rank: 679/2000<br/><b>data engineer</b> TextRank score rank: 1449/2000", "effect relations": "<br/><b>data scientist</b> TextRank score rank: 700/2000<br/><b>data engineer</b> TextRank score rank: 1437/2000", "hands": "<br/><b>data scientist</b> TextRank score rank: 313/2000<br/><b>data engineer</b> TextRank score rank: 11/2000", "Drilling Completion Production Operations": "<br/><b>data scientist</b> TextRank score rank: 144/2000<br/><b>data engineer</b> TextRank score rank: 1435/2000", "Upstream oil gas industry experience": "<br/><b>data scientist</b> TextRank score rank: 524/2000<br/><b>data engineer</b> TextRank score rank: 1434/2000", "year experience data analytics": "<br/><b>data scientist</b> TextRank score rank: 441/2000<br/><b>data engineer</b> TextRank score rank: 1433/2000", "At least year experience": "<br/><b>data scientist</b> TextRank score rank: 329/2000<br/><b>data engineer</b> TextRank score rank: 768/2000", "Master Degree": "<br/><b>data scientist</b> TextRank score rank: 548/2000<br/><b>data engineer</b> TextRank score rank: 360/2000", "Degree": "<br/><b>data scientist</b> TextRank score rank: 372/2000<br/><b>data engineer</b> TextRank score rank: 324/2000", "machine": "<br/><b>data scientist</b> TextRank score rank: 116/2000<br/><b>data engineer</b> TextRank score rank: 1432/2000", "SQL": "<br/><b>data scientist</b> TextRank score rank: 39/2000<br/><b>data engineer</b> TextRank score rank: 18/2000", "AWS": "<br/><b>data scientist</b> TextRank score rank: 1100/2000<br/><b>data engineer</b> TextRank score rank: 138/2000", "tools Tableau": "<br/><b>data scientist</b> TextRank score rank: 238/2000<br/><b>data engineer</b> TextRank score rank: 1431/2000", "Experience Data Visualizaiton": "<br/><b>data scientist</b> TextRank score rank: 401/2000<br/><b>data engineer</b> TextRank score rank: 1430/2000", "Experience Data": "<br/><b>data scientist</b> TextRank score rank: 327/2000<br/><b>data engineer</b> TextRank score rank: 1429/2000", "Visualizaiton": "<br/><b>data scientist</b> TextRank score rank: 596/2000<br/><b>data engineer</b> TextRank score rank: 1428/2000", "BA Computer Science Engineering relevant field graduate degree Data Science quantitative field": "<br/><b>data scientist</b> TextRank score rank: 488/2000<br/><b>data engineer</b> TextRank score rank: 1427/2000", "Strong math skills": "<br/><b>data scientist</b> TextRank score rank: 763/2000<br/><b>data engineer</b> TextRank score rank: 1426/2000", "Excellent communication presentation": "<br/><b>data scientist</b> TextRank score rank: 421/2000<br/><b>data engineer</b> TextRank score rank: 1425/2000", "Basic knowledge web development Experience data work\ufb02ow management tools advantage Experience big data cloud computing advantage": "<br/><b>data scientist</b> TextRank score rank: 652/2000<br/><b>data engineer</b> TextRank score rank: 1397/2000", "R Python Linux Experience systems biology research data": "<br/><b>data scientist</b> TextRank score rank: 795/2000<br/><b>data engineer</b> TextRank score rank: 1436/2000", "PhD bioinformatics computer science similar experience Experience relational database management systems": "<br/><b>data scientist</b> TextRank score rank: 835/2000<br/><b>data engineer</b> TextRank score rank: 1396/2000", "Ability work team": "<br/><b>data scientist</b> TextRank score rank: 248/2000<br/><b>data engineer</b> TextRank score rank: 1381/2000", "goals": "<br/><b>data scientist</b> TextRank score rank: 172/2000<br/><b>data engineer</b> TextRank score rank: 1078/2000", "consistent research institutes": "<br/><b>data scientist</b> TextRank score rank: 244/2000<br/><b>data engineer</b> TextRank score rank: 1365/2000", "Employment payment social benefits": "<br/><b>data scientist</b> TextRank score rank: 383/2000<br/><b>data engineer</b> TextRank score rank: 1364/2000", "able work": "<br/><b>data scientist</b> TextRank score rank: 179/2000<br/><b>data engineer</b> TextRank score rank: 468/2000", "Excellent understanding machine": "<br/><b>data scientist</b> TextRank score rank: 272/2000<br/><b>data engineer</b> TextRank score rank: 1363/2000", "techniques": "<br/><b>data scientist</b> TextRank score rank: 100/2000<br/><b>data engineer</b> TextRank score rank: 113/2000", "data mining machine": "<br/><b>data scientist</b> TextRank score rank: 793/2000<br/><b>data engineer</b> TextRank score rank: 1362/2000", "SQL Oracle": "<br/><b>data scientist</b> TextRank score rank: 664/2000<br/><b>data engineer</b> TextRank score rank: 1361/2000", "large amounts": "<br/><b>data scientist</b> TextRank score rank: 1089/2000<br/><b>data engineer</b> TextRank score rank: 676/2000", "Possess": "<br/><b>data scientist</b> TextRank score rank: 650/2000<br/><b>data engineer</b> TextRank score rank: 1360/2000", "media mix": "<br/><b>data scientist</b> TextRank score rank: 490/2000<br/><b>data engineer</b> TextRank score rank: 1359/2000", "visualization": "<br/><b>data scientist</b> TextRank score rank: 334/2000<br/><b>data engineer</b> TextRank score rank: 1358/2000", "multi touch attribution": "<br/><b>data scientist</b> TextRank score rank: 623/2000<br/><b>data engineer</b> TextRank score rank: 1357/2000", "data science": "<br/><b>data scientist</b> TextRank score rank: 468/2000<br/><b>data engineer</b> TextRank score rank: 1356/2000", "data scientists": "<br/><b>data scientist</b> TextRank score rank: 182/2000<br/><b>data engineer</b> TextRank score rank: 914/2000", "problems": "<br/><b>data scientist</b> TextRank score rank: 155/2000<br/><b>data engineer</b> TextRank score rank: 121/2000", "customers": "<br/><b>data scientist</b> TextRank score rank: 420/2000<br/><b>data engineer</b> TextRank score rank: 1355/2000", "Masters": "<br/><b>data scientist</b> TextRank score rank: 152/2000<br/><b>data engineer</b> TextRank score rank: 1085/2000", "bars": "<br/><b>data scientist</b> TextRank score rank: 253/2000<br/><b>data engineer</b> TextRank score rank: 1354/2000", "Social environment": "<br/><b>data scientist</b> TextRank score rank: 340/2000<br/><b>data engineer</b> TextRank score rank: 1353/2000", "Fluency English": "<br/><b>data scientist</b> TextRank score rank: 1141/2000<br/><b>data engineer</b> TextRank score rank: 103/2000", "hard questions data": "<br/><b>data scientist</b> TextRank score rank: 158/2000<br/><b>data engineer</b> TextRank score rank: 1352/2000", "complex ideas": "<br/><b>data scientist</b> TextRank score rank: 698/2000<br/><b>data engineer</b> TextRank score rank: 1351/2000", "skills": "<br/><b>data scientist</b> TextRank score rank: 121/2000<br/><b>data engineer</b> TextRank score rank: 17/2000", "The ability": "<br/><b>data scientist</b> TextRank score rank: 713/2000<br/><b>data engineer</b> TextRank score rank: 1106/2000", "industry experience": "<br/><b>data scientist</b> TextRank score rank: 533/2000<br/><b>data engineer</b> TextRank score rank: 4/2000", "AI ML": "<br/><b>data scientist</b> TextRank score rank: 195/2000<br/><b>data engineer</b> TextRank score rank: 1350/2000", "NLP": "<br/><b>data scientist</b> TextRank score rank: 352/2000<br/><b>data engineer</b> TextRank score rank: 1349/2000", "Experience cleaning visualizing data": "<br/><b>data scientist</b> TextRank score rank: 438/2000<br/><b>data engineer</b> TextRank score rank: 1348/2000", "Mathematics Statistics Physics Computer Science Engineering Background": "<br/><b>data scientist</b> TextRank score rank: 241/2000<br/><b>data engineer</b> TextRank score rank: 1347/2000", "algebra multivariable calculus": "<br/><b>data scientist</b> TextRank score rank: 604/2000<br/><b>data engineer</b> TextRank score rank: 1346/2000", "Experience Python": "<br/><b>data scientist</b> TextRank score rank: 270/2000<br/><b>data engineer</b> TextRank score rank: 1093/2000", "Python R": "<br/><b>data scientist</b> TextRank score rank: 213/2000<br/><b>data engineer</b> TextRank score rank: 1345/2000", "Oracle graph": "<br/><b>data scientist</b> TextRank score rank: 794/2000<br/><b>data engineer</b> TextRank score rank: 1344/2000", "techniques ability": "<br/><b>data scientist</b> TextRank score rank: 499/2000<br/><b>data engineer</b> TextRank score rank: 1343/2000", "Proven ability": "<br/><b>data scientist</b> TextRank score rank: 120/2000<br/><b>data engineer</b> TextRank score rank: 1063/2000", "Math": "<br/><b>data scientist</b> TextRank score rank: 756/2000<br/><b>data engineer</b> TextRank score rank: 1366/2000", "Knowledge immunology tumor immunology tumor biology genetics Proficiency Python R": "<br/><b>data scientist</b> TextRank score rank: 668/2000<br/><b>data engineer</b> TextRank score rank: 1367/2000", "D degree Bioinformatics Computer Science Biostatistics Applied": "<br/><b>data scientist</b> TextRank score rank: 687/2000<br/><b>data engineer</b> TextRank score rank: 1368/2000", "Ph D degree Bioinformatics Computer Science Biostatistics": "<br/><b>data scientist</b> TextRank score rank: 819/2000<br/><b>data engineer</b> TextRank score rank: 1369/2000", "environment": "<br/><b>data scientist</b> TextRank score rank: 479/2000<br/><b>data engineer</b> TextRank score rank: 1041/2000", "problem": "<br/><b>data scientist</b> TextRank score rank: 73/2000<br/><b>data engineer</b> TextRank score rank: 1393/2000", "Agile": "<br/><b>data scientist</b> TextRank score rank: 1058/2000<br/><b>data engineer</b> TextRank score rank: 443/2000", "Expertise": "<br/><b>data scientist</b> TextRank score rank: 135/2000<br/><b>data engineer</b> TextRank score rank: 379/2000", "Proven": "<br/><b>data scientist</b> TextRank score rank: 84/2000<br/><b>data engineer</b> TextRank score rank: 95/2000", "Python": "<br/><b>data scientist</b> TextRank score rank: 322/2000<br/><b>data engineer</b> TextRank score rank: 30/2000", "time": "<br/><b>data scientist</b> TextRank score rank: 1149/2000<br/><b>data engineer</b> TextRank score rank: 996/2000", "predictive analytics multivariate testing optimization algorithms": "<br/><b>data scientist</b> TextRank score rank: 706/2000<br/><b>data engineer</b> TextRank score rank: 1392/2000", "Working knowledge upstream data Experience analytical simulation tools field": "<br/><b>data scientist</b> TextRank score rank: 733/2000<br/><b>data engineer</b> TextRank score rank: 1391/2000", "Google Cloud Platform NET Experience": "<br/><b>data scientist</b> TextRank score rank: 3/2000<br/><b>data engineer</b> TextRank score rank: 1390/2000", "OCR Experience": "<br/><b>data scientist</b> TextRank score rank: 5/2000<br/><b>data engineer</b> TextRank score rank: 1389/2000", "successful machine learning systems": "<br/><b>data scientist</b> TextRank score rank: 6/2000<br/><b>data engineer</b> TextRank score rank: 1388/2000", "Cloud ML resources": "<br/><b>data scientist</b> TextRank score rank: 8/2000<br/><b>data engineer</b> TextRank score rank: 1387/2000", "Cloud ML": "<br/><b>data scientist</b> TextRank score rank: 10/2000<br/><b>data engineer</b> TextRank score rank: 1386/2000", "regression clustering word embeddings": "<br/><b>data scientist</b> TextRank score rank: 11/2000<br/><b>data engineer</b> TextRank score rank: 1385/2000", "Tensorflow Keras Data Science algorithms decision trees": "<br/><b>data scientist</b> TextRank score rank: 12/2000<br/><b>data engineer</b> TextRank score rank: 1384/2000", "Tensorflow Keras Data Science": "<br/><b>data scientist</b> TextRank score rank: 17/2000<br/><b>data engineer</b> TextRank score rank: 1383/2000", "Python R Javascript Machine": "<br/><b>data scientist</b> TextRank score rank: 2/2000<br/><b>data engineer</b> TextRank score rank: 1394/2000", "Development languages": "<br/><b>data scientist</b> TextRank score rank: 59/2000<br/><b>data engineer</b> TextRank score rank: 1382/2000", "Restaurant Retail industry experience": "<br/><b>data scientist</b> TextRank score rank: 280/2000<br/><b>data engineer</b> TextRank score rank: 1380/2000", "The Best Jobs Retail Time Holiday Shopping Jobs Rated Report": "<br/><b>data scientist</b> TextRank score rank: 397/2000<br/><b>data engineer</b> TextRank score rank: 1379/2000", "The Jobs Rated Report The Best Jobs The Toughest Jobs Fill": "<br/><b>data scientist</b> TextRank score rank: 582/2000<br/><b>data engineer</b> TextRank score rank: 1378/2000", "The Jobs Rated Report": "<br/><b>data scientist</b> TextRank score rank: 636/2000<br/><b>data engineer</b> TextRank score rank: 1377/2000", "The Best Jobs Advertising": "<br/><b>data scientist</b> TextRank score rank: 665/2000<br/><b>data engineer</b> TextRank score rank: 1376/2000", "The Toughest Jobs Fill": "<br/><b>data scientist</b> TextRank score rank: 676/2000<br/><b>data engineer</b> TextRank score rank: 1375/2000", "The Best Jobs": "<br/><b>data scientist</b> TextRank score rank: 302/2000<br/><b>data engineer</b> TextRank score rank: 1374/2000", "analytic processes": "<br/><b>data scientist</b> TextRank score rank: 690/2000<br/><b>data engineer</b> TextRank score rank: 1373/2000", "best practices": "<br/><b>data scientist</b> TextRank score rank: 1092/2000<br/><b>data engineer</b> TextRank score rank: 74/2000", "BI": "<br/><b>data scientist</b> TextRank score rank: 305/2000<br/><b>data engineer</b> TextRank score rank: 167/2000", "industry": "<br/><b>data scientist</b> TextRank score rank: 1114/2000<br/><b>data engineer</b> TextRank score rank: 762/2000", "Working": "<br/><b>data scientist</b> TextRank score rank: 1081/2000<br/><b>data engineer</b> TextRank score rank: 306/2000", "recommendations": "<br/><b>data scientist</b> TextRank score rank: 608/2000<br/><b>data engineer</b> TextRank score rank: 1372/2000", "Complex": "<br/><b>data scientist</b> TextRank score rank: 1132/2000<br/><b>data engineer</b> TextRank score rank: 990/2000", "AI Machine Learning": "<br/><b>data scientist</b> TextRank score rank: 344/2000<br/><b>data engineer</b> TextRank score rank: 1371/2000", "Machine Learning": "<br/><b>data scientist</b> TextRank score rank: 124/2000<br/><b>data engineer</b> TextRank score rank: 1370/2000", "Deep Learning": "<br/><b>data scientist</b> TextRank score rank: 53/2000<br/><b>data engineer</b> TextRank score rank: 1395/2000", "Deep": "<br/><b>data scientist</b> TextRank score rank: 64/2000<br/><b>data engineer</b> TextRank score rank: 1051/2000", "Git": "<br/><b>data scientist</b> TextRank score rank: 1084/2000<br/><b>data engineer</b> TextRank score rank: 479/2000", "GPU": "<br/><b>data scientist</b> TextRank score rank: 715/2000<br/><b>data engineer</b> TextRank score rank: 1451/2000", "Experience Looker Tableau data visualization software": "<br/><b>data scientist</b> TextRank score rank: 316/2000<br/><b>data engineer</b> TextRank score rank: 1505/2000", "statistical analysis techniques": "<br/><b>data scientist</b> TextRank score rank: 436/2000<br/><b>data engineer</b> TextRank score rank: 1452/2000", "experimental design data": "<br/><b>data scientist</b> TextRank score rank: 530/2000<br/><b>data engineer</b> TextRank score rank: 1530/2000", "related field Computational social science Computer science Data analytics": "<br/><b>data scientist</b> TextRank score rank: 4/2000<br/><b>data engineer</b> TextRank score rank: 1529/2000", "Ability work diverse team environment Interest experience science technology engineering mathematics": "<br/><b>data scientist</b> TextRank score rank: 9/2000<br/><b>data engineer</b> TextRank score rank: 1528/2000", "Computer science Data analytics Economics Engineering Geospatial": "<br/><b>data scientist</b> TextRank score rank: 7/2000<br/><b>data engineer</b> TextRank score rank: 1527/2000", "Quantitative finance": "<br/><b>data scientist</b> TextRank score rank: 15/2000<br/><b>data engineer</b> TextRank score rank: 1526/2000", "Economics Engineering Geospatial analysis": "<br/><b>data scientist</b> TextRank score rank: 14/2000<br/><b>data engineer</b> TextRank score rank: 1525/2000", "prior graduation Attending school": "<br/><b>data scientist</b> TextRank score rank: 18/2000<br/><b>data engineer</b> TextRank score rank: 1524/2000", "Availability work": "<br/><b>data scientist</b> TextRank score rank: 21/2000<br/><b>data engineer</b> TextRank score rank: 1523/2000", "Mathematics Operations research": "<br/><b>data scientist</b> TextRank score rank: 16/2000<br/><b>data engineer</b> TextRank score rank: 1522/2000", "Bachelor degree technical field": "<br/><b>data scientist</b> TextRank score rank: 23/2000<br/><b>data engineer</b> TextRank score rank: 1521/2000", "internship Creativity Initiative Integrity Leadership": "<br/><b>data scientist</b> TextRank score rank: 20/2000<br/><b>data engineer</b> TextRank score rank: 1520/2000", "Creativity Initiative Integrity Leadership": "<br/><b>data scientist</b> TextRank score rank: 19/2000<br/><b>data engineer</b> TextRank score rank: 1519/2000", "full time basis": "<br/><b>data scientist</b> TextRank score rank: 25/2000<br/><b>data engineer</b> TextRank score rank: 1518/2000", "Problem solving skills": "<br/><b>data scientist</b> TextRank score rank: 22/2000<br/><b>data engineer</b> TextRank score rank: 1517/2000", "Full time student": "<br/><b>data scientist</b> TextRank score rank: 27/2000<br/><b>data engineer</b> TextRank score rank: 1516/2000", "Mathematics Operations": "<br/><b>data scientist</b> TextRank score rank: 24/2000<br/><b>data engineer</b> TextRank score rank: 1515/2000", "Attending": "<br/><b>data scientist</b> TextRank score rank: 34/2000<br/><b>data engineer</b> TextRank score rank: 1514/2000", "Computational": "<br/><b>data scientist</b> TextRank score rank: 30/2000<br/><b>data engineer</b> TextRank score rank: 1513/2000", "scale": "<br/><b>data scientist</b> TextRank score rank: 38/2000<br/><b>data engineer</b> TextRank score rank: 1512/2000", "A thorough medical psychological exam": "<br/><b>data scientist</b> TextRank score rank: 37/2000<br/><b>data engineer</b> TextRank score rank: 1511/2000", "GPA": "<br/><b>data scientist</b> TextRank score rank: 13/2000<br/><b>data engineer</b> TextRank score rank: 1510/2000", "A comprehensive background investigation": "<br/><b>data scientist</b> TextRank score rank: 48/2000<br/><b>data engineer</b> TextRank score rank: 1509/2000", "Bachelor": "<br/><b>data scientist</b> TextRank score rank: 45/2000<br/><b>data engineer</b> TextRank score rank: 446/2000", "two day tours": "<br/><b>data scientist</b> TextRank score rank: 62/2000<br/><b>data engineer</b> TextRank score rank: 1508/2000", "A polygraph interview": "<br/><b>data scientist</b> TextRank score rank: 79/2000<br/><b>data engineer</b> TextRank score rank: 1531/2000", "two day": "<br/><b>data scientist</b> TextRank score rank: 106/2000<br/><b>data engineer</b> TextRank score rank: 1532/2000", "Statistics": "<br/><b>data scientist</b> TextRank score rank: 105/2000<br/><b>data engineer</b> TextRank score rank: 1533/2000", "complex analytical concepts": "<br/><b>data scientist</b> TextRank score rank: 197/2000<br/><b>data engineer</b> TextRank score rank: 1534/2000", "business problems": "<br/><b>data scientist</b> TextRank score rank: 176/2000<br/><b>data engineer</b> TextRank score rank: 517/2000", "NoSQL": "<br/><b>data scientist</b> TextRank score rank: 502/2000<br/><b>data engineer</b> TextRank score rank: 29/2000", "Knowledge": "<br/><b>data scientist</b> TextRank score rank: 209/2000<br/><b>data engineer</b> TextRank score rank: 102/2000", "people": "<br/><b>data scientist</b> TextRank score rank: 95/2000<br/><b>data engineer</b> TextRank score rank: 619/2000", "year": "<br/><b>data scientist</b> TextRank score rank: 1135/2000<br/><b>data engineer</b> TextRank score rank: 168/2000", "R Python": "<br/><b>data scientist</b> TextRank score rank: 613/2000<br/><b>data engineer</b> TextRank score rank: 1558/2000", "ML": "<br/><b>data scientist</b> TextRank score rank: 94/2000<br/><b>data engineer</b> TextRank score rank: 156/2000", "analytics development industrial applications commercial industrial setting": "<br/><b>data scientist</b> TextRank score rank: 483/2000<br/><b>data engineer</b> TextRank score rank: 1557/2000", "college university Ph D STEM field Science Technology Engineering Math": "<br/><b>data scientist</b> TextRank score rank: 663/2000<br/><b>data engineer</b> TextRank score rank: 1556/2000", "Demonstrated skill feature extraction realtime analytics development deployment": "<br/><b>data scientist</b> TextRank score rank: 669/2000<br/><b>data engineer</b> TextRank score rank: 1555/2000", "Science Technology Engineering Math": "<br/><b>data scientist</b> TextRank score rank: 291/2000<br/><b>data engineer</b> TextRank score rank: 1554/2000", "Bachelor Degree STEM field Science Technology Engineering Math": "<br/><b>data scientist</b> TextRank score rank: 732/2000<br/><b>data engineer</b> TextRank score rank: 1553/2000", "Desired Characteristics Master Degree STEM field Science Technology Engineering Math": "<br/><b>data scientist</b> TextRank score rank: 777/2000<br/><b>data engineer</b> TextRank score rank: 1552/2000", "Demonstrated skill data management methods": "<br/><b>data scientist</b> TextRank score rank: 811/2000<br/><b>data engineer</b> TextRank score rank: 1551/2000", "college university Minimum years": "<br/><b>data scientist</b> TextRank score rank: 854/2000<br/><b>data engineer</b> TextRank score rank: 1550/2000", "college university": "<br/><b>data scientist</b> TextRank score rank: 879/2000<br/><b>data engineer</b> TextRank score rank: 1549/2000", "move equipment pounds assistance Ability": "<br/><b>data scientist</b> TextRank score rank: 830/2000<br/><b>data engineer</b> TextRank score rank: 1548/2000", "operations equipment": "<br/><b>data scientist</b> TextRank score rank: 872/2000<br/><b>data engineer</b> TextRank score rank: 1559/2000", "hours": "<br/><b>data scientist</b> TextRank score rank: 228/2000<br/><b>data engineer</b> TextRank score rank: 62/2000", "business questions": "<br/><b>data scientist</b> TextRank score rank: 136/2000<br/><b>data engineer</b> TextRank score rank: 1547/2000", "deliverables Domain knowledge clinical data real world data life sciences related research data Expertise data science related tools": "<br/><b>data scientist</b> TextRank score rank: 181/2000<br/><b>data engineer</b> TextRank score rank: 1545/2000", "meaningful solutions life sciences business Task oriented ability": "<br/><b>data scientist</b> TextRank score rank: 223/2000<br/><b>data engineer</b> TextRank score rank: 1544/2000", "Deep understanding ML": "<br/><b>data scientist</b> TextRank score rank: 224/2000<br/><b>data engineer</b> TextRank score rank: 1543/2000", "Deep understanding tools trade": "<br/><b>data scientist</b> TextRank score rank: 227/2000<br/><b>data engineer</b> TextRank score rank: 1542/2000", "e g SQL Tableau D3": "<br/><b>data scientist</b> TextRank score rank: 233/2000<br/><b>data engineer</b> TextRank score rank: 1541/2000", "variety modern programming languages": "<br/><b>data scientist</b> TextRank score rank: 267/2000<br/><b>data engineer</b> TextRank score rank: 1540/2000", "PhD computational quantitative discipline e g statistics computer science": "<br/><b>data scientist</b> TextRank score rank: 268/2000<br/><b>data engineer</b> TextRank score rank: 1539/2000", "keen eye detail visual communication findings": "<br/><b>data scientist</b> TextRank score rank: 273/2000<br/><b>data engineer</b> TextRank score rank: 1538/2000", "g regression techniques": "<br/><b>data scientist</b> TextRank score rank: 292/2000<br/><b>data engineer</b> TextRank score rank: 1537/2000", "strong knowledge mathematical underpinnings": "<br/><b>data scientist</b> TextRank score rank: 295/2000<br/><b>data engineer</b> TextRank score rank: 1536/2000", "informatics genetics physics epidemiology health economics": "<br/><b>data scientist</b> TextRank score rank: 298/2000<br/><b>data engineer</b> TextRank score rank: 1535/2000", "non technical teams": "<br/><b>data scientist</b> TextRank score rank: 300/2000<br/><b>data engineer</b> TextRank score rank: 1507/2000", "neural networks decision trees": "<br/><b>data scientist</b> TextRank score rank: 210/2000<br/><b>data engineer</b> TextRank score rank: 1546/2000", "Linux TensorFlow Hadoop Spark": "<br/><b>data scientist</b> TextRank score rank: 377/2000<br/><b>data engineer</b> TextRank score rank: 1506/2000", "various methods": "<br/><b>data scientist</b> TextRank score rank: 408/2000<br/><b>data engineer</b> TextRank score rank: 1491/2000", "D3": "<br/><b>data scientist</b> TextRank score rank: 419/2000<br/><b>data engineer</b> TextRank score rank: 1475/2000", "Comfort": "<br/><b>data scientist</b> TextRank score rank: 342/2000<br/><b>data engineer</b> TextRank score rank: 1474/2000", "source technologies": "<br/><b>data scientist</b> TextRank score rank: 597/2000<br/><b>data engineer</b> TextRank score rank: 1473/2000", "R Python JavaScript": "<br/><b>data scientist</b> TextRank score rank: 807/2000<br/><b>data engineer</b> TextRank score rank: 1472/2000", "PhD Data Science Analytics Statistics Mathematics Physics Economics Computer Science": "<br/><b>data scientist</b> TextRank score rank: 671/2000<br/><b>data engineer</b> TextRank score rank: 1471/2000", "Bachelor Data Science Analytics Statistics Mathematics Physics Economics Computer Science": "<br/><b>data scientist</b> TextRank score rank: 681/2000<br/><b>data engineer</b> TextRank score rank: 1470/2000", "Master degree PhD Data Science Analytics Statistics Mathematics Physics Economics Computer Science": "<br/><b>data scientist</b> TextRank score rank: 692/2000<br/><b>data engineer</b> TextRank score rank: 1469/2000", "data Experience deep learning frameworks": "<br/><b>data scientist</b> TextRank score rank: 827/2000<br/><b>data engineer</b> TextRank score rank: 1468/2000", "Professional experience machine": "<br/><b>data scientist</b> TextRank score rank: 839/2000<br/><b>data engineer</b> TextRank score rank: 1467/2000", "machine learning models": "<br/><b>data scientist</b> TextRank score rank: 252/2000<br/><b>data engineer</b> TextRank score rank: 1466/2000", "Professional experience": "<br/><b>data scientist</b> TextRank score rank: 165/2000<br/><b>data engineer</b> TextRank score rank: 1465/2000", "Data Scientist Machine Learning Engineer": "<br/><b>data scientist</b> TextRank score rank: 435/2000<br/><b>data engineer</b> TextRank score rank: 1464/2000", "real world problems": "<br/><b>data scientist</b> TextRank score rank: 216/2000<br/><b>data engineer</b> TextRank score rank: 1463/2000", "keras": "<br/><b>data scientist</b> TextRank score rank: 902/2000<br/><b>data engineer</b> TextRank score rank: 1462/2000", "statistical concepts": "<br/><b>data scientist</b> TextRank score rank: 539/2000<br/><b>data engineer</b> TextRank score rank: 1461/2000", "libraries": "<br/><b>data scientist</b> TextRank score rank: 486/2000<br/><b>data engineer</b> TextRank score rank: 462/2000", "Familiarity AWS ecosystem": "<br/><b>data scientist</b> TextRank score rank: 188/2000<br/><b>data engineer</b> TextRank score rank: 1460/2000", "technology customer operations analytics": "<br/><b>data scientist</b> TextRank score rank: 771/2000<br/><b>data engineer</b> TextRank score rank: 1459/2000", "business performance Journey Analytics clients": "<br/><b>data scientist</b> TextRank score rank: 782/2000<br/><b>data engineer</b> TextRank score rank: 1458/2000", "statistical advanced analytic methods": "<br/><b>data scientist</b> TextRank score rank: 792/2000<br/><b>data engineer</b> TextRank score rank: 1457/2000", "senior clients colleagues": "<br/><b>data scientist</b> TextRank score rank: 882/2000<br/><b>data engineer</b> TextRank score rank: 1456/2000", "Ability work": "<br/><b>data scientist</b> TextRank score rank: 154/2000<br/><b>data engineer</b> TextRank score rank: 1043/2000", "collaboratively team environment": "<br/><b>data scientist</b> TextRank score rank: 712/2000<br/><b>data engineer</b> TextRank score rank: 1455/2000", "Masters PhD student statistics computer science economics physics quantitative field Internship work experience": "<br/><b>data scientist</b> TextRank score rank: 552/2000<br/><b>data engineer</b> TextRank score rank: 1454/2000", "Bachelors degree statistics computer science economics physics quantitative field Experience": "<br/><b>data scientist</b> TextRank score rank: 568/2000<br/><b>data engineer</b> TextRank score rank: 1453/2000", "applied statistics machine": "<br/><b>data scientist</b> TextRank score rank: 589/2000<br/><b>data engineer</b> TextRank score rank: 1476/2000", "Proficiency Python R Experience working imperfect data Passion eagerness": "<br/><b>data scientist</b> TextRank score rank: 639/2000<br/><b>data engineer</b> TextRank score rank: 1477/2000", "others": "<br/><b>data scientist</b> TextRank score rank: 168/2000<br/><b>data engineer</b> TextRank score rank: 252/2000", "statistical techniques": "<br/><b>data scientist</b> TextRank score rank: 396/2000<br/><b>data engineer</b> TextRank score rank: 1478/2000", "Experience MS Office Word Access Excel PowerPoint Outlook": "<br/><b>data scientist</b> TextRank score rank: 621/2000<br/><b>data engineer</b> TextRank score rank: 1479/2000", "non technical audiences": "<br/><b>data scientist</b> TextRank score rank: 484/2000<br/><b>data engineer</b> TextRank score rank: 1503/2000", "Experienced building large scale data analysis system Extensive knowledge experience": "<br/><b>data scientist</b> TextRank score rank: 786/2000<br/><b>data engineer</b> TextRank score rank: 1502/2000", "Strong project management leadership skills": "<br/><b>data scientist</b> TextRank score rank: 887/2000<br/><b>data engineer</b> TextRank score rank: 1501/2000", "Extensive knowledge details": "<br/><b>data scientist</b> TextRank score rank: 899/2000<br/><b>data engineer</b> TextRank score rank: 1500/2000", "Machine": "<br/><b>data scientist</b> TextRank score rank: 526/2000<br/><b>data engineer</b> TextRank score rank: 265/2000", "Apache Hadoop": "<br/><b>data scientist</b> TextRank score rank: 1091/2000<br/><b>data engineer</b> TextRank score rank: 986/2000", "similar Total Cost Ownership Net Present Value analysis Approaches systems biology proteomics analysis": "<br/><b>data scientist</b> TextRank score rank: 843/2000<br/><b>data engineer</b> TextRank score rank: 1499/2000", "platforms": "<br/><b>data scientist</b> TextRank score rank: 1111/2000<br/><b>data engineer</b> TextRank score rank: 657/2000", "Data": "<br/><b>data scientist</b> TextRank score rank: 1014/2000<br/><b>data engineer</b> TextRank score rank: 26/2000", "MS years": "<br/><b>data scientist</b> TextRank score rank: 137/2000<br/><b>data engineer</b> TextRank score rank: 1498/2000", "research results commercialization": "<br/><b>data scientist</b> TextRank score rank: 294/2000<br/><b>data engineer</b> TextRank score rank: 1497/2000", "Strong knowledge": "<br/><b>data scientist</b> TextRank score rank: 1076/2000<br/><b>data engineer</b> TextRank score rank: 132/2000", "complex analyses": "<br/><b>data scientist</b> TextRank score rank: 269/2000<br/><b>data engineer</b> TextRank score rank: 1496/2000", "simple terms": "<br/><b>data scientist</b> TextRank score rank: 721/2000<br/><b>data engineer</b> TextRank score rank: 1495/2000", "quantitative field": "<br/><b>data scientist</b> TextRank score rank: 455/2000<br/><b>data engineer</b> TextRank score rank: 1494/2000", "equity": "<br/><b>data scientist</b> TextRank score rank: 1115/2000<br/><b>data engineer</b> TextRank score rank: 1075/2000", "Deep knowledge": "<br/><b>data scientist</b> TextRank score rank: 108/2000<br/><b>data engineer</b> TextRank score rank: 781/2000", "work level position": "<br/><b>data scientist</b> TextRank score rank: 28/2000<br/><b>data engineer</b> TextRank score rank: 1493/2000", "minimum acceptable considered position": "<br/><b>data scientist</b> TextRank score rank: 33/2000<br/><b>data engineer</b> TextRank score rank: 1504/2000", "relevant position": "<br/><b>data scientist</b> TextRank score rank: 35/2000<br/><b>data engineer</b> TextRank score rank: 1492/2000", "hiring manager organization": "<br/><b>data scientist</b> TextRank score rank: 49/2000<br/><b>data engineer</b> TextRank score rank: 1490/2000", "account information": "<br/><b>data scientist</b> TextRank score rank: 55/2000<br/><b>data engineer</b> TextRank score rank: 1489/2000", "based candidates": "<br/><b>data scientist</b> TextRank score rank: 57/2000<br/><b>data engineer</b> TextRank score rank: 1488/2000", "Salary": "<br/><b>data scientist</b> TextRank score rank: 71/2000<br/><b>data engineer</b> TextRank score rank: 1487/2000", "The qualifications": "<br/><b>data scientist</b> TextRank score rank: 169/2000<br/><b>data engineer</b> TextRank score rank: 1486/2000", "Degrees Physics Mathematics Computer Science Engineering": "<br/><b>data scientist</b> TextRank score rank: 130/2000<br/><b>data engineer</b> TextRank score rank: 1485/2000", "data visualization tools years experience packages": "<br/><b>data scientist</b> TextRank score rank: 709/2000<br/><b>data engineer</b> TextRank score rank: 1484/2000", "project management experience years": "<br/><b>data scientist</b> TextRank score rank: 803/2000<br/><b>data engineer</b> TextRank score rank: 1483/2000", "multiple data sources Experience": "<br/><b>data scientist</b> TextRank score rank: 834/2000<br/><b>data engineer</b> TextRank score rank: 1482/2000", "role data analysis metrics development years": "<br/><b>data scientist</b> TextRank score rank: 841/2000<br/><b>data engineer</b> TextRank score rank: 1481/2000", "experience": "<br/><b>data scientist</b> TextRank score rank: 141/2000<br/><b>data engineer</b> TextRank score rank: 96/2000", "large datasets": "<br/><b>data scientist</b> TextRank score rank: 146/2000<br/><b>data engineer</b> TextRank score rank: 353/2000", "Hands": "<br/><b>data scientist</b> TextRank score rank: 1122/2000<br/><b>data engineer</b> TextRank score rank: 557/2000", "organization Ability": "<br/><b>data scientist</b> TextRank score rank: 470/2000<br/><b>data engineer</b> TextRank score rank: 1480/2000", "SAS R Python": "<br/><b>data scientist</b> TextRank score rank: 376/2000<br/><b>data engineer</b> TextRank score rank: 1342/2000", "Significant experience": "<br/><b>data scientist</b> TextRank score rank: 555/2000<br/><b>data engineer</b> TextRank score rank: 1341/2000", "relational databases": "<br/><b>data scientist</b> TextRank score rank: 162/2000<br/><b>data engineer</b> TextRank score rank: 71/2000", "depth experience": "<br/><b>data scientist</b> TextRank score rank: 517/2000<br/><b>data engineer</b> TextRank score rank: 1340/2000", "mathematics computer science physical sciences": "<br/><b>data scientist</b> TextRank score rank: 637/2000<br/><b>data engineer</b> TextRank score rank: 1285/2000", "deep learning solutions": "<br/><b>data scientist</b> TextRank score rank: 691/2000<br/><b>data engineer</b> TextRank score rank: 1200/2000", "similar technical field Experience": "<br/><b>data scientist</b> TextRank score rank: 705/2000<br/><b>data engineer</b> TextRank score rank: 1199/2000", "TensorFlow": "<br/><b>data scientist</b> TextRank score rank: 167/2000<br/><b>data engineer</b> TextRank score rank: 1198/2000", "xgboost": "<br/><b>data scientist</b> TextRank score rank: 450/2000<br/><b>data engineer</b> TextRank score rank: 1197/2000", "MongoDB Solr Indexes": "<br/><b>data scientist</b> TextRank score rank: 226/2000<br/><b>data engineer</b> TextRank score rank: 1196/2000", "Solr Indexes": "<br/><b>data scientist</b> TextRank score rank: 239/2000<br/><b>data engineer</b> TextRank score rank: 1195/2000", "Experience SQL": "<br/><b>data scientist</b> TextRank score rank: 504/2000<br/><b>data engineer</b> TextRank score rank: 712/2000", "Mechanical Engineering Materials Engineering Chemical Engineering Electrical Engineering Chemistry Physics Expertise": "<br/><b>data scientist</b> TextRank score rank: 594/2000<br/><b>data engineer</b> TextRank score rank: 1194/2000", "Mechanical Engineering Materials Engineering Chemical Engineering Electrical Engineering Chemistry Physics Expertise engineering analysis tools data analysis scripting methods order automate train standard analytical tasks": "<br/><b>data scientist</b> TextRank score rank: 612/2000<br/><b>data engineer</b> TextRank score rank: 1193/2000", "numerical computing": "<br/><b>data scientist</b> TextRank score rank: 791/2000<br/><b>data engineer</b> TextRank score rank: 1192/2000", "Advanced degree data science equivalent field sub field Experience working data rich problems": "<br/><b>data scientist</b> TextRank score rank: 365/2000<br/><b>data engineer</b> TextRank score rank: 1191/2000", "research programs Experience computer programming user experience user interface Ability": "<br/><b>data scientist</b> TextRank score rank: 373/2000<br/><b>data engineer</b> TextRank score rank: 1190/2000", "Experience real world data thesis research internships": "<br/><b>data scientist</b> TextRank score rank: 410/2000<br/><b>data engineer</b> TextRank score rank: 1189/2000", "work experience Creativity Initiative Integrity Leadership": "<br/><b>data scientist</b> TextRank score rank: 458/2000<br/><b>data engineer</b> TextRank score rank: 1188/2000", "large incomplete data": "<br/><b>data scientist</b> TextRank score rank: 559/2000<br/><b>data engineer</b> TextRank score rank: 1187/2000", "verbal communication": "<br/><b>data scientist</b> TextRank score rank: 714/2000<br/><b>data engineer</b> TextRank score rank: 1186/2000", "solutions": "<br/><b>data scientist</b> TextRank score rank: 29/2000<br/><b>data engineer</b> TextRank score rank: 369/2000", "Strong": "<br/><b>data scientist</b> TextRank score rank: 388/2000<br/><b>data engineer</b> TextRank score rank: 1060/2000", "projects": "<br/><b>data scientist</b> TextRank score rank: 261/2000<br/><b>data engineer</b> TextRank score rank: 215/2000", "proficiency SQL Excellent communication organization analytical skills experience": "<br/><b>data scientist</b> TextRank score rank: 850/2000<br/><b>data engineer</b> TextRank score rank: 1185/2000", "Background": "<br/><b>data scientist</b> TextRank score rank: 500/2000<br/><b>data engineer</b> TextRank score rank: 504/2000", "SQL Python R SAS preferred Demonstrate familiarity work experience": "<br/><b>data scientist</b> TextRank score rank: 722/2000<br/><b>data engineer</b> TextRank score rank: 1184/2000", "driving product impact": "<br/><b>data scientist</b> TextRank score rank: 773/2000<br/><b>data engineer</b> TextRank score rank: 1183/2000", "SAS": "<br/><b>data scientist</b> TextRank score rank: 60/2000<br/><b>data engineer</b> TextRank score rank: 727/2000", "OOP": "<br/><b>data scientist</b> TextRank score rank: 1102/2000<br/><b>data engineer</b> TextRank score rank: 1002/2000", "Casual Work Environment": "<br/><b>data scientist</b> TextRank score rank: 507/2000<br/><b>data engineer</b> TextRank score rank: 1182/2000", "US": "<br/><b>data scientist</b> TextRank score rank: 113/2000<br/><b>data engineer</b> TextRank score rank: 623/2000", "seriously huge datasets": "<br/><b>data scientist</b> TextRank score rank: 424/2000<br/><b>data engineer</b> TextRank score rank: 1181/2000", "Expertise Python R Expertise": "<br/><b>data scientist</b> TextRank score rank: 359/2000<br/><b>data engineer</b> TextRank score rank: 1180/2000", "Master degree": "<br/><b>data scientist</b> TextRank score rank: 1024/2000<br/><b>data engineer</b> TextRank score rank: 481/2000", "placement different job level": "<br/><b>data scientist</b> TextRank score rank: 225/2000<br/><b>data engineer</b> TextRank score rank: 1179/2000", "joy clients": "<br/><b>data scientist</b> TextRank score rank: 127/2000<br/><b>data engineer</b> TextRank score rank: 1178/2000", "work Stitch Fix": "<br/><b>data scientist</b> TextRank score rank: 134/2000<br/><b>data engineer</b> TextRank score rank: 1201/2000", "Stitch Fix": "<br/><b>data scientist</b> TextRank score rank: 157/2000<br/><b>data engineer</b> TextRank score rank: 1202/2000", "work": "<br/><b>data scientist</b> TextRank score rank: 128/2000<br/><b>data engineer</b> TextRank score rank: 1038/2000", "every day": "<br/><b>data scientist</b> TextRank score rank: 255/2000<br/><b>data engineer</b> TextRank score rank: 1203/2000", "tensorflow R caret Experience curating datasets": "<br/><b>data scientist</b> TextRank score rank: 192/2000<br/><b>data engineer</b> TextRank score rank: 1204/2000", "Spark MLLib SQL OS Experience Windows Linux Windows Ability": "<br/><b>data scientist</b> TextRank score rank: 194/2000<br/><b>data engineer</b> TextRank score rank: 1228/2000", "Spark MLLib SQL OS Experience Windows Linux Windows Ability compile results": "<br/><b>data scientist</b> TextRank score rank: 200/2000<br/><b>data engineer</b> TextRank score rank: 1227/2000", "modeling Experience scikit": "<br/><b>data scientist</b> TextRank score rank: 207/2000<br/><b>data engineer</b> TextRank score rank: 1226/2000", "Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical": "<br/><b>data scientist</b> TextRank score rank: 208/2000<br/><b>data engineer</b> TextRank score rank: 1225/2000", "related Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical Modeling Geo spatial analytics Data Munging Cleaning Bachelor Degree Ability work datasets": "<br/><b>data scientist</b> TextRank score rank: 211/2000<br/><b>data engineer</b> TextRank score rank: 1224/2000", "unsupervised machine learning methods Experience C": "<br/><b>data scientist</b> TextRank score rank: 214/2000<br/><b>data engineer</b> TextRank score rank: 1223/2000", "spatial analysis Experience PCAP": "<br/><b>data scientist</b> TextRank score rank: 246/2000<br/><b>data engineer</b> TextRank score rank: 1222/2000", "neural networks cluster analysis feature engineering extraction reduction web scraping decision trees": "<br/><b>data scientist</b> TextRank score rank: 249/2000<br/><b>data engineer</b> TextRank score rank: 1221/2000", "working Intelligence Community teams": "<br/><b>data scientist</b> TextRank score rank: 304/2000<br/><b>data engineer</b> TextRank score rank: 1220/2000", "Intelligence Community": "<br/><b>data scientist</b> TextRank score rank: 311/2000<br/><b>data engineer</b> TextRank score rank: 1219/2000", "multi TB dataset manipulation cleaning": "<br/><b>data scientist</b> TextRank score rank: 318/2000<br/><b>data engineer</b> TextRank score rank: 1218/2000", "Java R Javascript PhP MatLab Pig Hive Impala PySpark Scala Ruby Pytorch": "<br/><b>data scientist</b> TextRank score rank: 325/2000<br/><b>data engineer</b> TextRank score rank: 1229/2000", "senior level leadership": "<br/><b>data scientist</b> TextRank score rank: 335/2000<br/><b>data engineer</b> TextRank score rank: 1217/2000", "present material audiences": "<br/><b>data scientist</b> TextRank score rank: 339/2000<br/><b>data engineer</b> TextRank score rank: 1215/2000", "Elastic Search Hadoop": "<br/><b>data scientist</b> TextRank score rank: 353/2000<br/><b>data engineer</b> TextRank score rank: 1214/2000", "different sizes formats": "<br/><b>data scientist</b> TextRank score rank: 360/2000<br/><b>data engineer</b> TextRank score rank: 1213/2000", "specific techniques": "<br/><b>data scientist</b> TextRank score rank: 402/2000<br/><b>data engineer</b> TextRank score rank: 1212/2000", "multiple databases": "<br/><b>data scientist</b> TextRank score rank: 414/2000<br/><b>data engineer</b> TextRank score rank: 850/2000", "working fields": "<br/><b>data scientist</b> TextRank score rank: 495/2000<br/><b>data engineer</b> TextRank score rank: 1211/2000", "Impala PySpark": "<br/><b>data scientist</b> TextRank score rank: 509/2000<br/><b>data engineer</b> TextRank score rank: 1210/2000", "Java R Javascript": "<br/><b>data scientist</b> TextRank score rank: 510/2000<br/><b>data engineer</b> TextRank score rank: 1209/2000", "CART": "<br/><b>data scientist</b> TextRank score rank: 563/2000<br/><b>data engineer</b> TextRank score rank: 1208/2000", "presentations": "<br/><b>data scientist</b> TextRank score rank: 474/2000<br/><b>data engineer</b> TextRank score rank: 1207/2000", "PhP MatLab": "<br/><b>data scientist</b> TextRank score rank: 631/2000<br/><b>data engineer</b> TextRank score rank: 1206/2000", "TB": "<br/><b>data scientist</b> TextRank score rank: 654/2000<br/><b>data engineer</b> TextRank score rank: 1101/2000", "advanced topics analytics artificial intelligence data engineering": "<br/><b>data scientist</b> TextRank score rank: 358/2000<br/><b>data engineer</b> TextRank score rank: 1205/2000", "professional experience media company": "<br/><b>data scientist</b> TextRank score rank: 374/2000<br/><b>data engineer</b> TextRank score rank: 1177/2000", "SQL Tableau Excel interest": "<br/><b>data scientist</b> TextRank score rank: 459/2000<br/><b>data engineer</b> TextRank score rank: 1176/2000", "analytics tools": "<br/><b>data scientist</b> TextRank score rank: 460/2000<br/><b>data engineer</b> TextRank score rank: 1175/2000", "work sweat details": "<br/><b>data scientist</b> TextRank score rank: 511/2000<br/><b>data engineer</b> TextRank score rank: 1148/2000", "either R Python Experience building web applications agile development": "<br/><b>data scientist</b> TextRank score rank: 522/2000<br/><b>data engineer</b> TextRank score rank: 1146/2000", "learning libraries": "<br/><b>data scientist</b> TextRank score rank: 610/2000<br/><b>data engineer</b> TextRank score rank: 1145/2000", "visualization machine": "<br/><b>data scientist</b> TextRank score rank: 626/2000<br/><b>data engineer</b> TextRank score rank: 1144/2000", "Excel": "<br/><b>data scientist</b> TextRank score rank: 193/2000<br/><b>data engineer</b> TextRank score rank: 1103/2000", "statistics": "<br/><b>data scientist</b> TextRank score rank: 440/2000<br/><b>data engineer</b> TextRank score rank: 1143/2000", "date thread subject author": "<br/><b>data scientist</b> TextRank score rank: 69/2000<br/><b>data engineer</b> TextRank score rank: 1142/2000", "Messages": "<br/><b>data scientist</b> TextRank score rank: 201/2000<br/><b>data engineer</b> TextRank score rank: 1141/2000", "equal access benefits details training office": "<br/><b>data scientist</b> TextRank score rank: 659/2000<br/><b>data engineer</b> TextRank score rank: 1140/2000", "accommodation": "<br/><b>data scientist</b> TextRank score rank: 317/2000<br/><b>data engineer</b> TextRank score rank: 1139/2000", "Registered Selective Service": "<br/><b>data scientist</b> TextRank score rank: 620/2000<br/><b>data engineer</b> TextRank score rank: 1138/2000", "job": "<br/><b>data scientist</b> TextRank score rank: 462/2000<br/><b>data engineer</b> TextRank score rank: 1137/2000", "An employee disability": "<br/><b>data scientist</b> TextRank score rank: 666/2000<br/><b>data engineer</b> TextRank score rank: 1136/2000", "one year": "<br/><b>data scientist</b> TextRank score rank: 1156/2000<br/><b>data engineer</b> TextRank score rank: 1049/2000", "online application": "<br/><b>data scientist</b> TextRank score rank: 616/2000<br/><b>data engineer</b> TextRank score rank: 1135/2000", "business requirements": "<br/><b>data scientist</b> TextRank score rank: 1113/2000<br/><b>data engineer</b> TextRank score rank: 818/2000", "applicants": "<br/><b>data scientist</b> TextRank score rank: 399/2000<br/><b>data engineer</b> TextRank score rank: 832/2000", "requirements": "<br/><b>data scientist</b> TextRank score rank: 107/2000<br/><b>data engineer</b> TextRank score rank: 547/2000", "position": "<br/><b>data scientist</b> TextRank score rank: 72/2000<br/><b>data engineer</b> TextRank score rank: 1079/2000", "Develop": "<br/><b>data scientist</b> TextRank score rank: 1080/2000<br/><b>data engineer</b> TextRank score rank: 49/2000", "Provide": "<br/><b>data scientist</b> TextRank score rank: 1026/2000<br/><b>data engineer</b> TextRank score rank: 388/2000", "LA location": "<br/><b>data scientist</b> TextRank score rank: 240/2000<br/><b>data engineer</b> TextRank score rank: 1134/2000", "Gated dog run": "<br/><b>data scientist</b> TextRank score rank: 400/2000<br/><b>data engineer</b> TextRank score rank: 1133/2000", "LA": "<br/><b>data scientist</b> TextRank score rank: 422/2000<br/><b>data engineer</b> TextRank score rank: 543/2000", "large complex data sets": "<br/><b>data scientist</b> TextRank score rank: 1107/2000<br/><b>data engineer</b> TextRank score rank: 203/2000", "Demonstrated ability": "<br/><b>data scientist</b> TextRank score rank: 70/2000<br/><b>data engineer</b> TextRank score rank: 127/2000", "tools": "<br/><b>data scientist</b> TextRank score rank: 412/2000<br/><b>data engineer</b> TextRank score rank: 480/2000", "self": "<br/><b>data scientist</b> TextRank score rank: 1068/2000<br/><b>data engineer</b> TextRank score rank: 190/2000", "decisions": "<br/><b>data scientist</b> TextRank score rank: 1069/2000<br/><b>data engineer</b> TextRank score rank: 803/2000", "Communicate": "<br/><b>data scientist</b> TextRank score rank: 1090/2000<br/><b>data engineer</b> TextRank score rank: 563/2000", "statistical modeling techniques": "<br/><b>data scientist</b> TextRank score rank: 36/2000<br/><b>data engineer</b> TextRank score rank: 1132/2000", "Detail Oriented Process": "<br/><b>data scientist</b> TextRank score rank: 40/2000<br/><b>data engineer</b> TextRank score rank: 1131/2000", "Knowledge variety machine": "<br/><b>data scientist</b> TextRank score rank: 41/2000<br/><b>data engineer</b> TextRank score rank: 1130/2000", "new process efficiencies": "<br/><b>data scientist</b> TextRank score rank: 42/2000<br/><b>data engineer</b> TextRank score rank: 1129/2000", "Data Scientist A Data Geek": "<br/><b>data scientist</b> TextRank score rank: 43/2000<br/><b>data engineer</b> TextRank score rank: 1128/2000", "best technique": "<br/><b>data scientist</b> TextRank score rank: 44/2000<br/><b>data engineer</b> TextRank score rank: 1127/2000", "Mathematics Statistics Computer Science equivalent work experience": "<br/><b>data scientist</b> TextRank score rank: 46/2000<br/><b>data engineer</b> TextRank score rank: 1126/2000", "ML Proficiency Python R scripting languages": "<br/><b>data scientist</b> TextRank score rank: 47/2000<br/><b>data engineer</b> TextRank score rank: 1125/2000", "business setting Ability": "<br/><b>data scientist</b> TextRank score rank: 50/2000<br/><b>data engineer</b> TextRank score rank: 1124/2000", "comfortable working numbers patterns": "<br/><b>data scientist</b> TextRank score rank: 52/2000<br/><b>data engineer</b> TextRank score rank: 1147/2000", "looking people": "<br/><b>data scientist</b> TextRank score rank: 54/2000<br/><b>data engineer</b> TextRank score rank: 1149/2000", "work kinds": "<br/><b>data scientist</b> TextRank score rank: 56/2000<br/><b>data engineer</b> TextRank score rank: 1174/2000", "GCP cloud platforms": "<br/><b>data scientist</b> TextRank score rank: 58/2000<br/><b>data engineer</b> TextRank score rank: 1150/2000", "actionable results": "<br/><b>data scientist</b> TextRank score rank: 63/2000<br/><b>data engineer</b> TextRank score rank: 1173/2000", "ready code": "<br/><b>data scientist</b> TextRank score rank: 65/2000<br/><b>data engineer</b> TextRank score rank: 1172/2000", "data patterns": "<br/><b>data scientist</b> TextRank score rank: 61/2000<br/><b>data engineer</b> TextRank score rank: 1171/2000", "Driven looking folks": "<br/><b>data scientist</b> TextRank score rank: 68/2000<br/><b>data engineer</b> TextRank score rank: 1170/2000", "Mathematics Statistics Computer Science": "<br/><b>data scientist</b> TextRank score rank: 81/2000<br/><b>data engineer</b> TextRank score rank: 1169/2000", "Mass relocation": "<br/><b>data scientist</b> TextRank score rank: 85/2000<br/><b>data engineer</b> TextRank score rank: 1168/2000", "toolkits": "<br/><b>data scientist</b> TextRank score rank: 87/2000<br/><b>data engineer</b> TextRank score rank: 1167/2000", "production": "<br/><b>data scientist</b> TextRank score rank: 76/2000<br/><b>data engineer</b> TextRank score rank: 1166/2000", "A sense humor perspective": "<br/><b>data scientist</b> TextRank score rank: 92/2000<br/><b>data engineer</b> TextRank score rank: 1165/2000", "puzzles": "<br/><b>data scientist</b> TextRank score rank: 98/2000<br/><b>data engineer</b> TextRank score rank: 1164/2000", "local candidates": "<br/><b>data scientist</b> TextRank score rank: 103/2000<br/><b>data engineer</b> TextRank score rank: 1163/2000", "Mass": "<br/><b>data scientist</b> TextRank score rank: 114/2000<br/><b>data engineer</b> TextRank score rank: 1162/2000", "pandas NumPy etc Experience": "<br/><b>data scientist</b> TextRank score rank: 119/2000<br/><b>data engineer</b> TextRank score rank: 1161/2000", "Bachelor Degree concentration": "<br/><b>data scientist</b> TextRank score rank: 122/2000<br/><b>data engineer</b> TextRank score rank: 1160/2000", "A mindset research": "<br/><b>data scientist</b> TextRank score rank: 123/2000<br/><b>data engineer</b> TextRank score rank: 1159/2000", "intelligently passionately interesting challenges projects": "<br/><b>data scientist</b> TextRank score rank: 138/2000<br/><b>data engineer</b> TextRank score rank: 1158/2000", "even solution": "<br/><b>data scientist</b> TextRank score rank: 171/2000<br/><b>data engineer</b> TextRank score rank: 1157/2000", "Preference": "<br/><b>data scientist</b> TextRank score rank: 110/2000<br/><b>data engineer</b> TextRank score rank: 719/2000", "knowledge system identification statistical inference": "<br/><b>data scientist</b> TextRank score rank: 346/2000<br/><b>data engineer</b> TextRank score rank: 1156/2000", "knowledge MATLAB": "<br/><b>data scientist</b> TextRank score rank: 427/2000<br/><b>data engineer</b> TextRank score rank: 1155/2000", "positive impact livelihood world": "<br/><b>data scientist</b> TextRank score rank: 618/2000<br/><b>data engineer</b> TextRank score rank: 1154/2000", "401k": "<br/><b>data scientist</b> TextRank score rank: 728/2000<br/><b>data engineer</b> TextRank score rank: 78/2000", "C C": "<br/><b>data scientist</b> TextRank score rank: 413/2000<br/><b>data engineer</b> TextRank score rank: 221/2000", "product": "<br/><b>data scientist</b> TextRank score rank: 1120/2000<br/><b>data engineer</b> TextRank score rank: 540/2000", "information": "<br/><b>data scientist</b> TextRank score rank: 1034/2000<br/><b>data engineer</b> TextRank score rank: 494/2000", "SQL data exploration tools SAS R Experience data analytics design Experience": "<br/><b>data scientist</b> TextRank score rank: 174/2000<br/><b>data engineer</b> TextRank score rank: 1153/2000", "data analysis Experience": "<br/><b>data scientist</b> TextRank score rank: 178/2000<br/><b>data engineer</b> TextRank score rank: 1152/2000", "Health care industry experience Demonstrated ability": "<br/><b>data scientist</b> TextRank score rank: 199/2000<br/><b>data engineer</b> TextRank score rank: 1151/2000", "Formulas Bilingual Spanish English Master Degree Experience": "<br/><b>data scientist</b> TextRank score rank: 218/2000<br/><b>data engineer</b> TextRank score rank: 1216/2000", "Proven organizational skills ability flexible work ambiguity": "<br/><b>data scientist</b> TextRank score rank: 231/2000<br/><b>data engineer</b> TextRank score rank: 1230/2000", "deep technical concepts": "<br/><b>data scientist</b> TextRank score rank: 247/2000<br/><b>data engineer</b> TextRank score rank: 1231/2000", "SAS R Python Proficient MS Office applications Excel proficiency Pivots V Lookups": "<br/><b>data scientist</b> TextRank score rank: 262/2000<br/><b>data engineer</b> TextRank score rank: 1232/2000", "SAS R Python Proficient MS Office": "<br/><b>data scientist</b> TextRank score rank: 283/2000<br/><b>data engineer</b> TextRank score rank: 1310/2000", "Bachelor degree Minimum year experience": "<br/><b>data scientist</b> TextRank score rank: 289/2000<br/><b>data engineer</b> TextRank score rank: 1309/2000", "deeper understanding": "<br/><b>data scientist</b> TextRank score rank: 323/2000<br/><b>data engineer</b> TextRank score rank: 1308/2000", "Pivots V Lookups": "<br/><b>data scientist</b> TextRank score rank: 332/2000<br/><b>data engineer</b> TextRank score rank: 1307/2000", "technical well technical senior stakeholders": "<br/><b>data scientist</b> TextRank score rank: 404/2000<br/><b>data engineer</b> TextRank score rank: 1306/2000", "large databases": "<br/><b>data scientist</b> TextRank score rank: 260/2000<br/><b>data engineer</b> TextRank score rank: 1305/2000", "predictive statistical modeling": "<br/><b>data scientist</b> TextRank score rank: 452/2000<br/><b>data engineer</b> TextRank score rank: 1304/2000", "Spanish": "<br/><b>data scientist</b> TextRank score rank: 558/2000<br/><b>data engineer</b> TextRank score rank: 1303/2000", "Bilingual": "<br/><b>data scientist</b> TextRank score rank: 562/2000<br/><b>data engineer</b> TextRank score rank: 1302/2000", "deliverables": "<br/><b>data scientist</b> TextRank score rank: 601/2000<br/><b>data engineer</b> TextRank score rank: 1042/2000", "Excellent time management skills ability": "<br/><b>data scientist</b> TextRank score rank: 429/2000<br/><b>data engineer</b> TextRank score rank: 1301/2000", "data elements sources relationships business technical terms": "<br/><b>data scientist</b> TextRank score rank: 443/2000<br/><b>data engineer</b> TextRank score rank: 1300/2000", "big data technologies Hadoop Spark Familiarity Python R data visualization tools": "<br/><b>data scientist</b> TextRank score rank: 448/2000<br/><b>data engineer</b> TextRank score rank: 1299/2000", "full stack data analysis insight synthesis presentation Ability": "<br/><b>data scientist</b> TextRank score rank: 453/2000<br/><b>data engineer</b> TextRank score rank: 1298/2000", "complex analysis technical concepts": "<br/><b>data scientist</b> TextRank score rank: 498/2000<br/><b>data engineer</b> TextRank score rank: 1297/2000", "years recent experience data science data analyst role": "<br/><b>data scientist</b> TextRank score rank: 528/2000<br/><b>data engineer</b> TextRank score rank: 1296/2000", "Hadoop Spark Familiarity Python": "<br/><b>data scientist</b> TextRank score rank: 551/2000<br/><b>data engineer</b> TextRank score rank: 1295/2000", "Strong business mindset": "<br/><b>data scientist</b> TextRank score rank: 579/2000<br/><b>data engineer</b> TextRank score rank: 1294/2000", "Excellent presentation": "<br/><b>data scientist</b> TextRank score rank: 586/2000<br/><b>data engineer</b> TextRank score rank: 1293/2000", "AB experiments": "<br/><b>data scientist</b> TextRank score rank: 651/2000<br/><b>data engineer</b> TextRank score rank: 1292/2000", "Familiarity": "<br/><b>data scientist</b> TextRank score rank: 229/2000<br/><b>data engineer</b> TextRank score rank: 546/2000", "Comfortable": "<br/><b>data scientist</b> TextRank score rank: 696/2000<br/><b>data engineer</b> TextRank score rank: 506/2000", "United States Preferred": "<br/><b>data scientist</b> TextRank score rank: 51/2000<br/><b>data engineer</b> TextRank score rank: 1291/2000", "advanced optimization methodologies": "<br/><b>data scientist</b> TextRank score rank: 259/2000<br/><b>data engineer</b> TextRank score rank: 1290/2000", "advanced quantitative analyses": "<br/><b>data scientist</b> TextRank score rank: 153/2000<br/><b>data engineer</b> TextRank score rank: 1289/2000", "analysis Ability": "<br/><b>data scientist</b> TextRank score rank: 485/2000<br/><b>data engineer</b> TextRank score rank: 1288/2000", "advanced statistical methodologies mixed model random fixed effects": "<br/><b>data scientist</b> TextRank score rank: 494/2000<br/><b>data engineer</b> TextRank score rank: 1311/2000", "actual working experience": "<br/><b>data scientist</b> TextRank score rank: 543/2000<br/><b>data engineer</b> TextRank score rank: 1312/2000", "mixed integer optimization Ability": "<br/><b>data scientist</b> TextRank score rank: 297/2000<br/><b>data engineer</b> TextRank score rank: 1313/2000", "analysis variance correlation techniques": "<br/><b>data scientist</b> TextRank score rank: 278/2000<br/><b>data engineer</b> TextRank score rank: 1314/2000", "ARIMA neural networks multinomial discrete choice Ability": "<br/><b>data scientist</b> TextRank score rank: 550/2000<br/><b>data engineer</b> TextRank score rank: 1338/2000", "Demonstrated experience": "<br/><b>data scientist</b> TextRank score rank: 379/2000<br/><b>data engineer</b> TextRank score rank: 1337/2000", "features software packages": "<br/><b>data scientist</b> TextRank score rank: 649/2000<br/><b>data engineer</b> TextRank score rank: 1336/2000", "Utilize complex computer operations": "<br/><b>data scientist</b> TextRank score rank: 641/2000<br/><b>data engineer</b> TextRank score rank: 1335/2000", "mathematical operations tasks cluster analytics": "<br/><b>data scientist</b> TextRank score rank: 330/2000<br/><b>data engineer</b> TextRank score rank: 1334/2000", "theory design experiments": "<br/><b>data scientist</b> TextRank score rank: 398/2000<br/><b>data engineer</b> TextRank score rank: 1333/2000", "methodologies": "<br/><b>data scientist</b> TextRank score rank: 682/2000<br/><b>data engineer</b> TextRank score rank: 532/2000", "Working knowledge": "<br/><b>data scientist</b> TextRank score rank: 349/2000<br/><b>data engineer</b> TextRank score rank: 1332/2000", "A strong passion empirical research": "<br/><b>data scientist</b> TextRank score rank: 274/2000<br/><b>data engineer</b> TextRank score rank: 1331/2000", "3rd": "<br/><b>data scientist</b> TextRank score rank: 640/2000<br/><b>data engineer</b> TextRank score rank: 1330/2000", "Map Reduce": "<br/><b>data scientist</b> TextRank score rank: 583/2000<br/><b>data engineer</b> TextRank score rank: 596/2000", "Advanced data modeling experience": "<br/><b>data scientist</b> TextRank score rank: 457/2000<br/><b>data engineer</b> TextRank score rank: 1329/2000", "working data": "<br/><b>data scientist</b> TextRank score rank: 567/2000<br/><b>data engineer</b> TextRank score rank: 1328/2000", "trends": "<br/><b>data scientist</b> TextRank score rank: 635/2000<br/><b>data engineer</b> TextRank score rank: 1339/2000", "ETL": "<br/><b>data scientist</b> TextRank score rank: 82/2000<br/><b>data engineer</b> TextRank score rank: 20/2000", "Artificial Neural Nets": "<br/><b>data scientist</b> TextRank score rank: 366/2000<br/><b>data engineer</b> TextRank score rank: 1327/2000", "models": "<br/><b>data scientist</b> TextRank score rank: 115/2000<br/><b>data engineer</b> TextRank score rank: 1325/2000", "code": "<br/><b>data scientist</b> TextRank score rank: 1104/2000<br/><b>data engineer</b> TextRank score rank: 1001/2000", "Breadth skills experience machine": "<br/><b>data scientist</b> TextRank score rank: 67/2000<br/><b>data engineer</b> TextRank score rank: 1324/2000", "business process outsourcing systems transportation systems healthcare systems financial services": "<br/><b>data scientist</b> TextRank score rank: 74/2000<br/><b>data engineer</b> TextRank score rank: 1323/2000", "novel solutions problems": "<br/><b>data scientist</b> TextRank score rank: 75/2000<br/><b>data engineer</b> TextRank score rank: 1322/2000", "real world context Prior experience similar role": "<br/><b>data scientist</b> TextRank score rank: 77/2000<br/><b>data engineer</b> TextRank score rank: 1321/2000", "practice Experience knowledge services": "<br/><b>data scientist</b> TextRank score rank: 80/2000<br/><b>data engineer</b> TextRank score rank: 1320/2000", "feasibility solutions": "<br/><b>data scientist</b> TextRank score rank: 83/2000<br/><b>data engineer</b> TextRank score rank: 1319/2000", "analytics models": "<br/><b>data scientist</b> TextRank score rank: 86/2000<br/><b>data engineer</b> TextRank score rank: 1318/2000", "Desired interdisciplinary skills": "<br/><b>data scientist</b> TextRank score rank: 88/2000<br/><b>data engineer</b> TextRank score rank: 1317/2000", "big data technologies ETL statistics causal inference": "<br/><b>data scientist</b> TextRank score rank: 93/2000<br/><b>data engineer</b> TextRank score rank: 1316/2000", "analytics packages": "<br/><b>data scientist</b> TextRank score rank: 97/2000<br/><b>data engineer</b> TextRank score rank: 1315/2000", "diverse learning settings": "<br/><b>data scientist</b> TextRank score rank: 99/2000<br/><b>data engineer</b> TextRank score rank: 1287/2000", "multi disciplinary environments": "<br/><b>data scientist</b> TextRank score rank: 101/2000<br/><b>data engineer</b> TextRank score rank: 1326/2000", "data mining statistical predictive": "<br/><b>data scientist</b> TextRank score rank: 104/2000<br/><b>data engineer</b> TextRank score rank: 1286/2000", "work US employer": "<br/><b>data scientist</b> TextRank score rank: 109/2000<br/><b>data engineer</b> TextRank score rank: 1271/2000", "Ability inclination": "<br/><b>data scientist</b> TextRank score rank: 111/2000<br/><b>data engineer</b> TextRank score rank: 1255/2000", "different types": "<br/><b>data scientist</b> TextRank score rank: 112/2000<br/><b>data engineer</b> TextRank score rank: 1254/2000", "sponsorship": "<br/><b>data scientist</b> TextRank score rank: 117/2000<br/><b>data engineer</b> TextRank score rank: 1253/2000", "history driving": "<br/><b>data scientist</b> TextRank score rank: 133/2000<br/><b>data engineer</b> TextRank score rank: 1252/2000", "related field": "<br/><b>data scientist</b> TextRank score rank: 129/2000<br/><b>data engineer</b> TextRank score rank: 89/2000", "Breadth": "<br/><b>data scientist</b> TextRank score rank: 148/2000<br/><b>data engineer</b> TextRank score rank: 1251/2000", "simulation": "<br/><b>data scientist</b> TextRank score rank: 149/2000<br/><b>data engineer</b> TextRank score rank: 1250/2000", "methods": "<br/><b>data scientist</b> TextRank score rank: 140/2000<br/><b>data engineer</b> TextRank score rank: 1249/2000", "experiments": "<br/><b>data scientist</b> TextRank score rank: 131/2000<br/><b>data engineer</b> TextRank score rank: 1248/2000", "ideas": "<br/><b>data scientist</b> TextRank score rank: 191/2000<br/><b>data engineer</b> TextRank score rank: 235/2000", "desire": "<br/><b>data scientist</b> TextRank score rank: 357/2000<br/><b>data engineer</b> TextRank score rank: 638/2000", "programming languages": "<br/><b>data scientist</b> TextRank score rank: 587/2000<br/><b>data engineer</b> TextRank score rank: 1247/2000", "multiple data sources": "<br/><b>data scientist</b> TextRank score rank: 1072/2000<br/><b>data engineer</b> TextRank score rank: 161/2000", "metadata": "<br/><b>data scientist</b> TextRank score rank: 1101/2000<br/><b>data engineer</b> TextRank score rank: 270/2000", "explain point": "<br/><b>data scientist</b> TextRank score rank: 222/2000<br/><b>data engineer</b> TextRank score rank: 1246/2000", "story": "<br/><b>data scientist</b> TextRank score rank: 489/2000<br/><b>data engineer</b> TextRank score rank: 1245/2000", "Visualization": "<br/><b>data scientist</b> TextRank score rank: 566/2000<br/><b>data engineer</b> TextRank score rank: 1244/2000", "minimal guidance Ability work business system owners": "<br/><b>data scientist</b> TextRank score rank: 672/2000<br/><b>data engineer</b> TextRank score rank: 1243/2000", "SQL experience": "<br/><b>data scientist</b> TextRank score rank: 147/2000<br/><b>data engineer</b> TextRank score rank: 1242/2000", "Business Objects": "<br/><b>data scientist</b> TextRank score rank: 387/2000<br/><b>data engineer</b> TextRank score rank: 1241/2000", "Big Data": "<br/><b>data scientist</b> TextRank score rank: 276/2000<br/><b>data engineer</b> TextRank score rank: 28/2000", "United States": "<br/><b>data scientist</b> TextRank score rank: 189/2000<br/><b>data engineer</b> TextRank score rank: 1240/2000", "Interested candidates": "<br/><b>data scientist</b> TextRank score rank: 1124/2000<br/><b>data engineer</b> TextRank score rank: 1076/2000", "small teams projects": "<br/><b>data scientist</b> TextRank score rank: 217/2000<br/><b>data engineer</b> TextRank score rank: 1239/2000", "complex business problems": "<br/><b>data scientist</b> TextRank score rank: 177/2000<br/><b>data engineer</b> TextRank score rank: 1238/2000", "business results": "<br/><b>data scientist</b> TextRank score rank: 767/2000<br/><b>data engineer</b> TextRank score rank: 1237/2000", "technology roadmaps realization": "<br/><b>data scientist</b> TextRank score rank: 409/2000<br/><b>data engineer</b> TextRank score rank: 1236/2000", "existing problems": "<br/><b>data scientist</b> TextRank score rank: 333/2000<br/><b>data engineer</b> TextRank score rank: 1235/2000", "new solution methods": "<br/><b>data scientist</b> TextRank score rank: 386/2000<br/><b>data engineer</b> TextRank score rank: 1234/2000", "working knowledge": "<br/><b>data scientist</b> TextRank score rank: 350/2000<br/><b>data engineer</b> TextRank score rank: 1233/2000", "External Technology Knowledge Keeps": "<br/><b>data scientist</b> TextRank score rank: 356/2000<br/><b>data engineer</b> TextRank score rank: 1256/2000", "latest technological developments areas": "<br/><b>data scientist</b> TextRank score rank: 501/2000<br/><b>data engineer</b> TextRank score rank: 1257/2000", "Analytics": "<br/><b>data scientist</b> TextRank score rank: 1145/2000<br/><b>data engineer</b> TextRank score rank: 1007/2000", "operations": "<br/><b>data scientist</b> TextRank score rank: 1147/2000<br/><b>data engineer</b> TextRank score rank: 1065/2000", "opportunities": "<br/><b>data scientist</b> TextRank score rank: 190/2000<br/><b>data engineer</b> TextRank score rank: 376/2000", "things": "<br/><b>data scientist</b> TextRank score rank: 1025/2000<br/><b>data engineer</b> TextRank score rank: 693/2000", "sports games": "<br/><b>data scientist</b> TextRank score rank: 314/2000<br/><b>data engineer</b> TextRank score rank: 1258/2000", "analysis impact": "<br/><b>data scientist</b> TextRank score rank: 464/2000<br/><b>data engineer</b> TextRank score rank: 1259/2000", "key business product decisions": "<br/><b>data scientist</b> TextRank score rank: 434/2000<br/><b>data engineer</b> TextRank score rank: 1283/2000", "SQL Hive": "<br/><b>data scientist</b> TextRank score rank: 315/2000<br/><b>data engineer</b> TextRank score rank: 1282/2000", "e g filtering morphology": "<br/><b>data scientist</b> TextRank score rank: 391/2000<br/><b>data engineer</b> TextRank score rank: 1281/2000", "compression": "<br/><b>data scientist</b> TextRank score rank: 557/2000<br/><b>data engineer</b> TextRank score rank: 1280/2000", "Background image processing concepts": "<br/><b>data scientist</b> TextRank score rank: 609/2000<br/><b>data engineer</b> TextRank score rank: 1279/2000", "ping pong tournaments": "<br/><b>data scientist</b> TextRank score rank: 204/2000<br/><b>data engineer</b> TextRank score rank: 1278/2000", "statistical predictive modeling concepts machine learning approaches": "<br/><b>data scientist</b> TextRank score rank: 279/2000<br/><b>data engineer</b> TextRank score rank: 1277/2000", "classification techniques recommendation optimization algorithms": "<br/><b>data scientist</b> TextRank score rank: 628/2000<br/><b>data engineer</b> TextRank score rank: 1276/2000", "big data technologies": "<br/><b>data scientist</b> TextRank score rank: 370/2000<br/><b>data engineer</b> TextRank score rank: 500/2000", "machine learning": "<br/><b>data scientist</b> TextRank score rank: 697/2000<br/><b>data engineer</b> TextRank score rank: 1275/2000", "Continuous": "<br/><b>data scientist</b> TextRank score rank: 1125/2000<br/><b>data engineer</b> TextRank score rank: 703/2000", "functional teams": "<br/><b>data scientist</b> TextRank score rank: 1061/2000<br/><b>data engineer</b> TextRank score rank: 885/2000", "Java C": "<br/><b>data scientist</b> TextRank score rank: 695/2000<br/><b>data engineer</b> TextRank score rank: 1050/2000", "statistical models": "<br/><b>data scientist</b> TextRank score rank: 624/2000<br/><b>data engineer</b> TextRank score rank: 1274/2000", "analysis": "<br/><b>data scientist</b> TextRank score rank: 615/2000<br/><b>data engineer</b> TextRank score rank: 987/2000", "new business development proof concepts": "<br/><b>data scientist</b> TextRank score rank: 688/2000<br/><b>data engineer</b> TextRank score rank: 1273/2000", "Computer Science Computer Science Engineering Engineering Computer Science Math Computer Science Mathematical": "<br/><b>data scientist</b> TextRank score rank: 508/2000<br/><b>data engineer</b> TextRank score rank: 1284/2000", "Computer Science Computer Science Engineering Engineering Computer Science Math Computer Science Mathematical Engineering Mathematical Science Mathematics Statistics Strong data wrangling skills": "<br/><b>data scientist</b> TextRank score rank: 521/2000<br/><b>data engineer</b> TextRank score rank: 1272/2000", "Ability manipulate JSON XML data Experience Splunk Experience data manipulation platforms": "<br/><b>data scientist</b> TextRank score rank: 556/2000<br/><b>data engineer</b> TextRank score rank: 1270/2000", "Experience Ansible Puppet Jenkins Chef": "<br/><b>data scientist</b> TextRank score rank: 634/2000<br/><b>data engineer</b> TextRank score rank: 1269/2000", "multiple projects": "<br/><b>data scientist</b> TextRank score rank: 617/2000<br/><b>data engineer</b> TextRank score rank: 1011/2000", "Excellent problem": "<br/><b>data scientist</b> TextRank score rank: 560/2000<br/><b>data engineer</b> TextRank score rank: 398/2000", "Java": "<br/><b>data scientist</b> TextRank score rank: 161/2000<br/><b>data engineer</b> TextRank score rank: 117/2000", "Cigna Healthcare MetLife Dental VSP Vision": "<br/><b>data scientist</b> TextRank score rank: 446/2000<br/><b>data engineer</b> TextRank score rank: 1268/2000", "advanced data analysis": "<br/><b>data scientist</b> TextRank score rank: 606/2000<br/><b>data engineer</b> TextRank score rank: 1267/2000", "world": "<br/><b>data scientist</b> TextRank score rank: 355/2000<br/><b>data engineer</b> TextRank score rank: 125/2000", "data things": "<br/><b>data scientist</b> TextRank score rank: 475/2000<br/><b>data engineer</b> TextRank score rank: 1266/2000", "connections": "<br/><b>data scientist</b> TextRank score rank: 577/2000<br/><b>data engineer</b> TextRank score rank: 1265/2000", "Reduce Experience working Hadoop Map": "<br/><b>data scientist</b> TextRank score rank: 593/2000<br/><b>data engineer</b> TextRank score rank: 1264/2000", "Substantial data analysis experience": "<br/><b>data scientist</b> TextRank score rank: 739/2000<br/><b>data engineer</b> TextRank score rank: 1263/2000", "complex problems": "<br/><b>data scientist</b> TextRank score rank: 569/2000<br/><b>data engineer</b> TextRank score rank: 1262/2000", "new technologies": "<br/><b>data scientist</b> TextRank score rank: 1067/2000<br/><b>data engineer</b> TextRank score rank: 32/2000", "major impact business": "<br/><b>data scientist</b> TextRank score rank: 345/2000<br/><b>data engineer</b> TextRank score rank: 1261/2000", "prowess data scientist right": "<br/><b>data scientist</b> TextRank score rank: 525/2000<br/><b>data engineer</b> TextRank score rank: 1260/2000", "Proficiency scripting language Python R MATLAB Proficiency": "<br/><b>data scientist</b> TextRank score rank: 561/2000<br/><b>data engineer</b> TextRank score rank: 1450/2000", "written oral diagram form": "<br/><b>data scientist</b> TextRank score rank: 307/2000<br/><b>data engineer</b> TextRank score rank: 1560/2000", "carry instructions": "<br/><b>data scientist</b> TextRank score rank: 536/2000<br/><b>data engineer</b> TextRank score rank: 1561/2000", "Strong experience": "<br/><b>data scientist</b> TextRank score rank: 442/2000<br/><b>data engineer</b> TextRank score rank: 1562/2000", "Computer Science": "<br/><b>data scientist</b> TextRank score rank: 170/2000<br/><b>data engineer</b> TextRank score rank: 106/2000", "software C C": "<br/><b>data scientist</b> TextRank score rank: 236/2000<br/><b>data engineer</b> TextRank score rank: 1860/2000", "large scale data management big data technologies Skilled aspects software project life cycle feasibility requirements": "<br/><b>data scientist</b> TextRank score rank: 215/2000<br/><b>data engineer</b> TextRank score rank: 1859/2000", "important project success Sufficient interpersonal skills necessary interact levels personnel": "<br/><b>data scientist</b> TextRank score rank: 512/2000<br/><b>data engineer</b> TextRank score rank: 1858/2000", "scientific data analysis statistical analysis knowledge discovery computer security systems": "<br/><b>data scientist</b> TextRank score rank: 142/2000<br/><b>data engineer</b> TextRank score rank: 1857/2000", "Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules": "<br/><b>data scientist</b> TextRank score rank: 196/2000<br/><b>data engineer</b> TextRank score rank: 1856/2000", "algorithms data management": "<br/><b>data scientist</b> TextRank score rank: 230/2000<br/><b>data engineer</b> TextRank score rank: 1855/2000", "design implementation integration test deployment Fundamental experience": "<br/><b>data scientist</b> TextRank score rank: 575/2000<br/><b>data engineer</b> TextRank score rank: 1854/2000", "necessary work": "<br/><b>data scientist</b> TextRank score rank: 275/2000<br/><b>data engineer</b> TextRank score rank: 1853/2000", "data analysis": "<br/><b>data scientist</b> TextRank score rank: 237/2000<br/><b>data engineer</b> TextRank score rank: 466/2000", "Fundamental knowledge": "<br/><b>data scientist</b> TextRank score rank: 716/2000<br/><b>data engineer</b> TextRank score rank: 1852/2000", "project": "<br/><b>data scientist</b> TextRank score rank: 251/2000<br/><b>data engineer</b> TextRank score rank: 1851/2000", "Bachelor degree computer science computer engineering related field equivalent combination education related experience": "<br/><b>data scientist</b> TextRank score rank: 285/2000<br/><b>data engineer</b> TextRank score rank: 1850/2000", "Linux UNIX Windows environments": "<br/><b>data scientist</b> TextRank score rank: 320/2000<br/><b>data engineer</b> TextRank score rank: 1849/2000", "enthusiasm creativity change": "<br/><b>data scientist</b> TextRank score rank: 347/2000<br/><b>data engineer</b> TextRank score rank: 1848/2000", "concurrent technical tasks": "<br/><b>data scientist</b> TextRank score rank: 256/2000<br/><b>data engineer</b> TextRank score rank: 1847/2000", "research concepts": "<br/><b>data scientist</b> TextRank score rank: 361/2000<br/><b>data engineer</b> TextRank score rank: 1846/2000", "conflicting priorities": "<br/><b>data scientist</b> TextRank score rank: 403/2000<br/><b>data engineer</b> TextRank score rank: 1845/2000", "difficult problems": "<br/><b>data scientist</b> TextRank score rank: 271/2000<br/><b>data engineer</b> TextRank score rank: 1844/2000", "Java Python R Matlab software applications": "<br/><b>data scientist</b> TextRank score rank: 406/2000<br/><b>data engineer</b> TextRank score rank: 1843/2000", "Linux UNIX Windows": "<br/><b>data scientist</b> TextRank score rank: 431/2000<br/><b>data engineer</b> TextRank score rank: 1842/2000", "high performance": "<br/><b>data scientist</b> TextRank score rank: 367/2000<br/><b>data engineer</b> TextRank score rank: 1841/2000", "Skilled": "<br/><b>data scientist</b> TextRank score rank: 720/2000<br/><b>data engineer</b> TextRank score rank: 1840/2000", "Java Python R Matlab": "<br/><b>data scientist</b> TextRank score rank: 745/2000<br/><b>data engineer</b> TextRank score rank: 1839/2000", "share knowledge others": "<br/><b>data scientist</b> TextRank score rank: 321/2000<br/><b>data engineer</b> TextRank score rank: 1838/2000", "organization": "<br/><b>data scientist</b> TextRank score rank: 354/2000<br/><b>data engineer</b> TextRank score rank: 1104/2000", "skill": "<br/><b>data scientist</b> TextRank score rank: 751/2000<br/><b>data engineer</b> TextRank score rank: 1861/2000", "Access opportunities": "<br/><b>data scientist</b> TextRank score rank: 770/2000<br/><b>data engineer</b> TextRank score rank: 1862/2000", "volunteer time fuel efficient vehicle purchase assistance transit fare contribution": "<br/><b>data scientist</b> TextRank score rank: 407/2000<br/><b>data engineer</b> TextRank score rank: 1863/2000", "first": "<br/><b>data scientist</b> TextRank score rank: 573/2000<br/><b>data engineer</b> TextRank score rank: 1094/2000", "video call": "<br/><b>data scientist</b> TextRank score rank: 203/2000<br/><b>data engineer</b> TextRank score rank: 147/2000", "call": "<br/><b>data scientist</b> TextRank score rank: 242/2000<br/><b>data engineer</b> TextRank score rank: 197/2000", "As always interviews": "<br/><b>data scientist</b> TextRank score rank: 1155/2000<br/><b>data engineer</b> TextRank score rank: 1102/2000", "Matplotlib": "<br/><b>data scientist</b> TextRank score rank: 164/2000<br/><b>data engineer</b> TextRank score rank: 1864/2000", "Plotly ggplot": "<br/><b>data scientist</b> TextRank score rank: 535/2000<br/><b>data engineer</b> TextRank score rank: 1888/2000", "An eye great data visualization": "<br/><b>data scientist</b> TextRank score rank: 660/2000<br/><b>data engineer</b> TextRank score rank: 1887/2000", "complex data analysis": "<br/><b>data scientist</b> TextRank score rank: 415/2000<br/><b>data engineer</b> TextRank score rank: 1886/2000", "qualitative quantitative clear compelling manner": "<br/><b>data scientist</b> TextRank score rank: 447/2000<br/><b>data engineer</b> TextRank score rank: 1885/2000", "action Strong understanding statistical analysis": "<br/><b>data scientist</b> TextRank score rank: 449/2000<br/><b>data engineer</b> TextRank score rank: 1884/2000", "Quick learner ability": "<br/><b>data scientist</b> TextRank score rank: 514/2000<br/><b>data engineer</b> TextRank score rank: 1883/2000", "large data": "<br/><b>data scientist</b> TextRank score rank: 198/2000<br/><b>data engineer</b> TextRank score rank: 1882/2000", "production level code Proficiency": "<br/><b>data scientist</b> TextRank score rank: 531/2000<br/><b>data engineer</b> TextRank score rank: 1881/2000", "academic institution Expert Python SQL": "<br/><b>data scientist</b> TextRank score rank: 584/2000<br/><b>data engineer</b> TextRank score rank: 1880/2000", "minimal guidance Ability": "<br/><b>data scientist</b> TextRank score rank: 600/2000<br/><b>data engineer</b> TextRank score rank: 1879/2000", "varying levels": "<br/><b>data scientist</b> TextRank score rank: 337/2000<br/><b>data engineer</b> TextRank score rank: 1878/2000", "quantitative discipline": "<br/><b>data scientist</b> TextRank score rank: 371/2000<br/><b>data engineer</b> TextRank score rank: 1889/2000", "working Spark process": "<br/><b>data scientist</b> TextRank score rank: 670/2000<br/><b>data engineer</b> TextRank score rank: 1877/2000", "Expert Python SQL": "<br/><b>data scientist</b> TextRank score rank: 684/2000<br/><b>data engineer</b> TextRank score rank: 1875/2000", "Excellent communication skills": "<br/><b>data scientist</b> TextRank score rank: 394/2000<br/><b>data engineer</b> TextRank score rank: 1874/2000", "dynamic fast paced environment Drive change": "<br/><b>data scientist</b> TextRank score rank: 810/2000<br/><b>data engineer</b> TextRank score rank: 1873/2000", "initiate drive projects completion": "<br/><b>data scientist</b> TextRank score rank: 845/2000<br/><b>data engineer</b> TextRank score rank: 1872/2000", "Drive": "<br/><b>data scientist</b> TextRank score rank: 619/2000<br/><b>data engineer</b> TextRank score rank: 1871/2000", "comfort ambiguity": "<br/><b>data scientist</b> TextRank score rank: 924/2000<br/><b>data engineer</b> TextRank score rank: 1870/2000", "A flexible analytic approach": "<br/><b>data scientist</b> TextRank score rank: 765/2000<br/><b>data engineer</b> TextRank score rank: 1869/2000", "Interest politics educational policy": "<br/><b>data scientist</b> TextRank score rank: 206/2000<br/><b>data engineer</b> TextRank score rank: 1868/2000", "industry experience Experience Python R Experience Tableau Ability model": "<br/><b>data scientist</b> TextRank score rank: 885/2000<br/><b>data engineer</b> TextRank score rank: 1867/2000", "Ability ramp data science manager role": "<br/><b>data scientist</b> TextRank score rank: 978/2000<br/><b>data engineer</b> TextRank score rank: 1866/2000", "technical levels Ability": "<br/><b>data scientist</b> TextRank score rank: 996/2000<br/><b>data engineer</b> TextRank score rank: 1865/2000", "Airflow Ability": "<br/><b>data scientist</b> TextRank score rank: 405/2000<br/><b>data engineer</b> TextRank score rank: 1837/2000", "sound analytical modeling solutions Ability": "<br/><b>data scientist</b> TextRank score rank: 1030/2000<br/><b>data engineer</b> TextRank score rank: 1876/2000", "data pipelines": "<br/><b>data scientist</b> TextRank score rank: 598/2000<br/><b>data engineer</b> TextRank score rank: 27/2000", "functional partners": "<br/><b>data scientist</b> TextRank score rank: 708/2000<br/><b>data engineer</b> TextRank score rank: 1836/2000", "Proficiency SQL": "<br/><b>data scientist</b> TextRank score rank: 607/2000<br/><b>data engineer</b> TextRank score rank: 1821/2000", "Java C C SQL relational database experience": "<br/><b>data scientist</b> TextRank score rank: 825/2000<br/><b>data engineer</b> TextRank score rank: 1805/2000", "business plan Experience shelf": "<br/><b>data scientist</b> TextRank score rank: 871/2000<br/><b>data engineer</b> TextRank score rank: 1804/2000", "algorithms Experience visualization tools": "<br/><b>data scientist</b> TextRank score rank: 896/2000<br/><b>data engineer</b> TextRank score rank: 1803/2000", "relevant experience": "<br/><b>data scientist</b> TextRank score rank: 159/2000<br/><b>data engineer</b> TextRank score rank: 930/2000", "Java C C SQL": "<br/><b>data scientist</b> TextRank score rank: 1008/2000<br/><b>data engineer</b> TextRank score rank: 1802/2000", "complex concepts": "<br/><b>data scientist</b> TextRank score rank: 787/2000<br/><b>data engineer</b> TextRank score rank: 1086/2000", "Retail eCommerce company": "<br/><b>data scientist</b> TextRank score rank: 243/2000<br/><b>data engineer</b> TextRank score rank: 1801/2000", "NoSQL SQL database experience Experience Google products": "<br/><b>data scientist</b> TextRank score rank: 869/2000<br/><b>data engineer</b> TextRank score rank: 1800/2000", "code populate HDFS Hadoop log Kafka data": "<br/><b>data scientist</b> TextRank score rank: 951/2000<br/><b>data engineer</b> TextRank score rank: 1799/2000", "Java Scala Python Hadoop stack HIVE Pig Hadoop streaming MapReduce HBase": "<br/><b>data scientist</b> TextRank score rank: 966/2000<br/><b>data engineer</b> TextRank score rank: 1798/2000", "Big Data Systems": "<br/><b>data scientist</b> TextRank score rank: 432/2000<br/><b>data engineer</b> TextRank score rank: 1797/2000", "years experience": "<br/><b>data scientist</b> TextRank score rank: 245/2000<br/><b>data engineer</b> TextRank score rank: 216/2000", "Build": "<br/><b>data scientist</b> TextRank score rank: 545/2000<br/><b>data engineer</b> TextRank score rank: 1098/2000", "Kafka": "<br/><b>data scientist</b> TextRank score rank: 1029/2000<br/><b>data engineer</b> TextRank score rank: 36/2000", "LAN": "<br/><b>data scientist</b> TextRank score rank: 126/2000<br/><b>data engineer</b> TextRank score rank: 1796/2000", "Parties": "<br/><b>data scientist</b> TextRank score rank: 430/2000<br/><b>data engineer</b> TextRank score rank: 1795/2000", "first year": "<br/><b>data scientist</b> TextRank score rank: 776/2000<br/><b>data engineer</b> TextRank score rank: 1794/2000", "one programming languages": "<br/><b>data scientist</b> TextRank score rank: 1140/2000<br/><b>data engineer</b> TextRank score rank: 723/2000", "Designing data architecture table dashboard": "<br/><b>data scientist</b> TextRank score rank: 221/2000<br/><b>data engineer</b> TextRank score rank: 1793/2000", "physics related quantitative discipline preferred Experience Hive SQL": "<br/><b>data scientist</b> TextRank score rank: 736/2000<br/><b>data engineer</b> TextRank score rank: 1792/2000", "statistics data mining machine": "<br/><b>data scientist</b> TextRank score rank: 847/2000<br/><b>data engineer</b> TextRank score rank: 1791/2000", "classification techniques recommendation optimization": "<br/><b>data scientist</b> TextRank score rank: 478/2000<br/><b>data engineer</b> TextRank score rank: 1790/2000", "Ph D Master Degree operations research": "<br/><b>data scientist</b> TextRank score rank: 940/2000<br/><b>data engineer</b> TextRank score rank: 1789/2000", "Strong analytical problem": "<br/><b>data scientist</b> TextRank score rank: 947/2000<br/><b>data engineer</b> TextRank score rank: 743/2000", "Collaborative team player values": "<br/><b>data scientist</b> TextRank score rank: 326/2000<br/><b>data engineer</b> TextRank score rank: 1788/2000", "passionate Data Science": "<br/><b>data scientist</b> TextRank score rank: 454/2000<br/><b>data engineer</b> TextRank score rank: 1787/2000", "Data Science": "<br/><b>data scientist</b> TextRank score rank: 480/2000<br/><b>data engineer</b> TextRank score rank: 448/2000", "Dog friendly office": "<br/><b>data scientist</b> TextRank score rank: 186/2000<br/><b>data engineer</b> TextRank score rank: 1786/2000", "field Electrical Engineering Computer Science Data Science Statistics relevant fields": "<br/><b>data scientist</b> TextRank score rank: 971/2000<br/><b>data engineer</b> TextRank score rank: 1785/2000", "Java C scripting language Experience database systems systems": "<br/><b>data scientist</b> TextRank score rank: 986/2000<br/><b>data engineer</b> TextRank score rank: 1784/2000", "MS BS years": "<br/><b>data scientist</b> TextRank score rank: 395/2000<br/><b>data engineer</b> TextRank score rank: 1783/2000", "aforementioned fields": "<br/><b>data scientist</b> TextRank score rank: 989/2000<br/><b>data engineer</b> TextRank score rank: 1806/2000", "PhD aforementioned fields": "<br/><b>data scientist</b> TextRank score rank: 1001/2000<br/><b>data engineer</b> TextRank score rank: 1807/2000", "similar Experience project product program management customer design Excellent storytelling team work": "<br/><b>data scientist</b> TextRank score rank: 1007/2000<br/><b>data engineer</b> TextRank score rank: 1808/2000", "BS MS": "<br/><b>data scientist</b> TextRank score rank: 254/2000<br/><b>data engineer</b> TextRank score rank: 560/2000", "probabilistic graphical models": "<br/><b>data scientist</b> TextRank score rank: 846/2000<br/><b>data engineer</b> TextRank score rank: 1809/2000", "degree": "<br/><b>data scientist</b> TextRank score rank: 1138/2000<br/><b>data engineer</b> TextRank score rank: 1080/2000", "Jobs Fwd inedinfo Fwd JOB Statistician fte": "<br/><b>data scientist</b> TextRank score rank: 319/2000<br/><b>data engineer</b> TextRank score rank: 1833/2000", "Next message Jobs NPD Group": "<br/><b>data scientist</b> TextRank score rank: 324/2000<br/><b>data engineer</b> TextRank score rank: 1832/2000", "Fwd JOB Statistician fte Next": "<br/><b>data scientist</b> TextRank score rank: 351/2000<br/><b>data engineer</b> TextRank score rank: 1831/2000", "Jobs NPD Group": "<br/><b>data scientist</b> TextRank score rank: 369/2000<br/><b>data engineer</b> TextRank score rank: 1830/2000", "Jobs Fwd": "<br/><b>data scientist</b> TextRank score rank: 417/2000<br/><b>data engineer</b> TextRank score rank: 1829/2000", "Previous message": "<br/><b>data scientist</b> TextRank score rank: 625/2000<br/><b>data engineer</b> TextRank score rank: 1828/2000", "Experience working data analytics Experience": "<br/><b>data scientist</b> TextRank score rank: 799/2000<br/><b>data engineer</b> TextRank score rank: 1827/2000", "e g": "<br/><b>data scientist</b> TextRank score rank: 425/2000<br/><b>data engineer</b> TextRank score rank: 1826/2000", "moderate large scale data": "<br/><b>data scientist</b> TextRank score rank: 943/2000<br/><b>data engineer</b> TextRank score rank: 1825/2000", "innovate state art machine": "<br/><b>data scientist</b> TextRank score rank: 974/2000<br/><b>data engineer</b> TextRank score rank: 1824/2000", "predictive explanatory models experimentation processes": "<br/><b>data scientist</b> TextRank score rank: 1036/2000<br/><b>data engineer</b> TextRank score rank: 1823/2000", "R Python programming proficiency Proficiency data integration data quality development Programming experience": "<br/><b>data scientist</b> TextRank score rank: 657/2000<br/><b>data engineer</b> TextRank score rank: 1834/2000", "non technical audience Interest educational applications": "<br/><b>data scientist</b> TextRank score rank: 750/2000<br/><b>data engineer</b> TextRank score rank: 1822/2000", "track record Experience": "<br/><b>data scientist</b> TextRank score rank: 802/2000<br/><b>data engineer</b> TextRank score rank: 1820/2000", "Experience technologies": "<br/><b>data scientist</b> TextRank score rank: 856/2000<br/><b>data engineer</b> TextRank score rank: 1819/2000", "technical projects database components": "<br/><b>data scientist</b> TextRank score rank: 861/2000<br/><b>data engineer</b> TextRank score rank: 1818/2000", "technical topics": "<br/><b>data scientist</b> TextRank score rank: 894/2000<br/><b>data engineer</b> TextRank score rank: 1817/2000", "R Shiny Python": "<br/><b>data scientist</b> TextRank score rank: 922/2000<br/><b>data engineer</b> TextRank score rank: 1816/2000", "Django": "<br/><b>data scientist</b> TextRank score rank: 1011/2000<br/><b>data engineer</b> TextRank score rank: 1815/2000", "Experience data visualization tools": "<br/><b>data scientist</b> TextRank score rank: 719/2000<br/><b>data engineer</b> TextRank score rank: 1814/2000", "Experience relational databases": "<br/><b>data scientist</b> TextRank score rank: 742/2000<br/><b>data engineer</b> TextRank score rank: 1813/2000", "R Python Experience working AWS environments": "<br/><b>data scientist</b> TextRank score rank: 796/2000<br/><b>data engineer</b> TextRank score rank: 1812/2000", "common data science toolkits": "<br/><b>data scientist</b> TextRank score rank: 1031/2000<br/><b>data engineer</b> TextRank score rank: 1811/2000", "At least years experience": "<br/><b>data scientist</b> TextRank score rank: 926/2000<br/><b>data engineer</b> TextRank score rank: 767/2000", "Applied": "<br/><b>data scientist</b> TextRank score rank: 1154/2000<br/><b>data engineer</b> TextRank score rank: 1100/2000", "Nordstrom Stock Purchase Plan": "<br/><b>data scientist</b> TextRank score rank: 118/2000<br/><b>data engineer</b> TextRank score rank: 1810/2000", "data science math physics computer science equivalent degree": "<br/><b>data scientist</b> TextRank score rank: 707/2000<br/><b>data engineer</b> TextRank score rank: 1835/2000", "Exceptional understanding machine learning concepts data science programming": "<br/><b>data scientist</b> TextRank score rank: 778/2000<br/><b>data engineer</b> TextRank score rank: 1891/2000", "mobile video games": "<br/><b>data scientist</b> TextRank score rank: 801/2000<br/><b>data engineer</b> TextRank score rank: 1945/2000", "product managers": "<br/><b>data scientist</b> TextRank score rank: 886/2000<br/><b>data engineer</b> TextRank score rank: 538/2000", "Proficiency Python R SQL Authorization work United States": "<br/><b>data scientist</b> TextRank score rank: 375/2000<br/><b>data engineer</b> TextRank score rank: 1892/2000", "Python R SQL Authorization": "<br/><b>data scientist</b> TextRank score rank: 476/2000<br/><b>data engineer</b> TextRank score rank: 1970/2000", "Ph D M S quantitative discipline graduating Passion machine": "<br/><b>data scientist</b> TextRank score rank: 605/2000<br/><b>data engineer</b> TextRank score rank: 1969/2000", "Experience Spark": "<br/><b>data scientist</b> TextRank score rank: 433/2000<br/><b>data engineer</b> TextRank score rank: 1968/2000", "even new folks": "<br/><b>data scientist</b> TextRank score rank: 737/2000<br/><b>data engineer</b> TextRank score rank: 1967/2000", "An open work environment": "<br/><b>data scientist</b> TextRank score rank: 821/2000<br/><b>data engineer</b> TextRank score rank: 1966/2000", "large knowledge stores Experience information extraction creation application layer Experience developing REST JSON applications": "<br/><b>data scientist</b> TextRank score rank: 836/2000<br/><b>data engineer</b> TextRank score rank: 1965/2000", "recommendation engines Experience": "<br/><b>data scientist</b> TextRank score rank: 903/2000<br/><b>data engineer</b> TextRank score rank: 1964/2000", "Python Ruby Strong experience": "<br/><b>data scientist</b> TextRank score rank: 948/2000<br/><b>data engineer</b> TextRank score rank: 1963/2000", "Knowledge statistics experience": "<br/><b>data scientist</b> TextRank score rank: 953/2000<br/><b>data engineer</b> TextRank score rank: 1962/2000", "Fluency": "<br/><b>data scientist</b> TextRank score rank: 1063/2000<br/><b>data engineer</b> TextRank score rank: 876/2000", "Microsoft Azure": "<br/><b>data scientist</b> TextRank score rank: 991/2000<br/><b>data engineer</b> TextRank score rank: 655/2000", "Self starter results": "<br/><b>data scientist</b> TextRank score rank: 523/2000<br/><b>data engineer</b> TextRank score rank: 1961/2000", "Data Science Analytics Engineering Mathematics Industrial Engineering Computer Science Information Technology Economics Finance": "<br/><b>data scientist</b> TextRank score rank: 976/2000<br/><b>data engineer</b> TextRank score rank: 1960/2000", "Bachelor degree Data Science Analytics Engineering Mathematics Industrial Engineering Computer Science Information Technology Economics Finance": "<br/><b>data scientist</b> TextRank score rank: 1010/2000<br/><b>data engineer</b> TextRank score rank: 1959/2000", "Big data experience": "<br/><b>data scientist</b> TextRank score rank: 702/2000<br/><b>data engineer</b> TextRank score rank: 1958/2000", "US Citizenship Advanced degree computer science data science business analytics": "<br/><b>data scientist</b> TextRank score rank: 784/2000<br/><b>data engineer</b> TextRank score rank: 1957/2000", "tools Experience": "<br/><b>data scientist</b> TextRank score rank: 853/2000<br/><b>data engineer</b> TextRank score rank: 1956/2000", "Hive Spark Pig MapReduce Knowledge industry leading analytics": "<br/><b>data scientist</b> TextRank score rank: 855/2000<br/><b>data engineer</b> TextRank score rank: 1955/2000", "oral presentation skills": "<br/><b>data scientist</b> TextRank score rank: 944/2000<br/><b>data engineer</b> TextRank score rank: 1954/2000", "Hive Spark": "<br/><b>data scientist</b> TextRank score rank: 537/2000<br/><b>data engineer</b> TextRank score rank: 1061/2000", "days": "<br/><b>data scientist</b> TextRank score rank: 1129/2000<br/><b>data engineer</b> TextRank score rank: 495/2000", "experience familiarity multivariate predictive modeling analytics software": "<br/><b>data scientist</b> TextRank score rank: 909/2000<br/><b>data engineer</b> TextRank score rank: 1953/2000", "Deep familiarity analytics actuarial market landscape corresponding information": "<br/><b>data scientist</b> TextRank score rank: 920/2000<br/><b>data engineer</b> TextRank score rank: 1952/2000", "Bachelor degree Master degree years work experience completing undergraduate degree years advanced analytics": "<br/><b>data scientist</b> TextRank score rank: 961/2000<br/><b>data engineer</b> TextRank score rank: 1951/2000", "knowledge insurance industry": "<br/><b>data scientist</b> TextRank score rank: 967/2000<br/><b>data engineer</b> TextRank score rank: 1950/2000", "Experience building deploying cloud based data pipelines": "<br/><b>data scientist</b> TextRank score rank: 897/2000<br/><b>data engineer</b> TextRank score rank: 1949/2000", "Demonstrated programming experience": "<br/><b>data scientist</b> TextRank score rank: 1009/2000<br/><b>data engineer</b> TextRank score rank: 1948/2000", "team": "<br/><b>data scientist</b> TextRank score rank: 493/2000<br/><b>data engineer</b> TextRank score rank: 1069/2000", "business processes related client business questions years": "<br/><b>data scientist</b> TextRank score rank: 833/2000<br/><b>data engineer</b> TextRank score rank: 1971/2000", "BI Tool e OBIEE Cognos Business Objects": "<br/><b>data scientist</b> TextRank score rank: 364/2000<br/><b>data engineer</b> TextRank score rank: 1972/2000", "role Experience": "<br/><b>data scientist</b> TextRank score rank: 979/2000<br/><b>data engineer</b> TextRank score rank: 1973/2000", "g Excel Word PowerPoint Experience": "<br/><b>data scientist</b> TextRank score rank: 1000/2000<br/><b>data engineer</b> TextRank score rank: 1974/2000", "Microsoft": "<br/><b>data scientist</b> TextRank score rank: 667/2000<br/><b>data engineer</b> TextRank score rank: 40/2000", "implementation integration test deployment Experience developing software C C": "<br/><b>data scientist</b> TextRank score rank: 328/2000<br/><b>data engineer</b> TextRank score rank: 1998/2000", "large scale data management big data technologies": "<br/><b>data scientist</b> TextRank score rank: 520/2000<br/><b>data engineer</b> TextRank score rank: 1997/2000", "important project success Effective interpersonal skills necessary interact levels personnel": "<br/><b>data scientist</b> TextRank score rank: 571/2000<br/><b>data engineer</b> TextRank score rank: 1996/2000", "Significant experience demonstrated expertise": "<br/><b>data scientist</b> TextRank score rank: 710/2000<br/><b>data engineer</b> TextRank score rank: 1995/2000", "technical languages concepts": "<br/><b>data scientist</b> TextRank score rank: 730/2000<br/><b>data engineer</b> TextRank score rank: 1994/2000", "creative solutions complex problems": "<br/><b>data scientist</b> TextRank score rank: 738/2000<br/><b>data engineer</b> TextRank score rank: 1993/2000", "Effective advanced analytical problem": "<br/><b>data scientist</b> TextRank score rank: 744/2000<br/><b>data engineer</b> TextRank score rank: 1992/2000", "advanced areas high performance": "<br/><b>data scientist</b> TextRank score rank: 754/2000<br/><b>data engineer</b> TextRank score rank: 1991/2000", "Comprehensive knowledge": "<br/><b>data scientist</b> TextRank score rank: 860/2000<br/><b>data engineer</b> TextRank score rank: 1990/2000", "decision making skills": "<br/><b>data scientist</b> TextRank score rank: 888/2000<br/><b>data engineer</b> TextRank score rank: 1989/2000", "Effective": "<br/><b>data scientist</b> TextRank score rank: 1074/2000<br/><b>data engineer</b> TextRank score rank: 658/2000", "program entrepreneurial environment Top notch health dental vision insurance Stock options fast growing tech company 401k plan matching contribution": "<br/><b>data scientist</b> TextRank score rank: 999/2000<br/><b>data engineer</b> TextRank score rank: 1988/2000", "Frequent company": "<br/><b>data scientist</b> TextRank score rank: 578/2000<br/><b>data engineer</b> TextRank score rank: 946/2000", "Preferred Master Required United States": "<br/><b>data scientist</b> TextRank score rank: 264/2000<br/><b>data engineer</b> TextRank score rank: 1999/2000", "Data Science years": "<br/><b>data scientist</b> TextRank score rank: 540/2000<br/><b>data engineer</b> TextRank score rank: 1987/2000", "Strong data mining data visualization Ability": "<br/><b>data scientist</b> TextRank score rank: 748/2000<br/><b>data engineer</b> TextRank score rank: 1985/2000", "Strong least code bases": "<br/><b>data scientist</b> TextRank score rank: 783/2000<br/><b>data engineer</b> TextRank score rank: 1984/2000", "machine learning models production environment": "<br/><b>data scientist</b> TextRank score rank: 823/2000<br/><b>data engineer</b> TextRank score rank: 1983/2000", "Python Healthcare Population Health knowledge preferred Experience": "<br/><b>data scientist</b> TextRank score rank: 832/2000<br/><b>data engineer</b> TextRank score rank: 1982/2000", "Strong working stakeholders": "<br/><b>data scientist</b> TextRank score rank: 900/2000<br/><b>data engineer</b> TextRank score rank: 1981/2000", "Python Healthcare Population Health": "<br/><b>data scientist</b> TextRank score rank: 930/2000<br/><b>data engineer</b> TextRank score rank: 1980/2000", "fast paced environment Experience various math statistics methodologies": "<br/><b>data scientist</b> TextRank score rank: 984/2000<br/><b>data engineer</b> TextRank score rank: 1979/2000", "multiple competing priorities": "<br/><b>data scientist</b> TextRank score rank: 599/2000<br/><b>data engineer</b> TextRank score rank: 1055/2000", "insights": "<br/><b>data scientist</b> TextRank score rank: 257/2000<br/><b>data engineer</b> TextRank score rank: 1978/2000", "basic knowledge statistical concepts regression time series mixed model": "<br/><b>data scientist</b> TextRank score rank: 546/2000<br/><b>data engineer</b> TextRank score rank: 1977/2000", "Bayesian methods": "<br/><b>data scientist</b> TextRank score rank: 380/2000<br/><b>data engineer</b> TextRank score rank: 1976/2000", "BA Computer Science Engineering relevant field graduate degree Data Science quantitative field preferred Experience": "<br/><b>data scientist</b> TextRank score rank: 816/2000<br/><b>data engineer</b> TextRank score rank: 1975/2000", "anomaly detection Experience bioinformatics NLP": "<br/><b>data scientist</b> TextRank score rank: 831/2000<br/><b>data engineer</b> TextRank score rank: 1947/2000", "Experience building": "<br/><b>data scientist</b> TextRank score rank: 863/2000<br/><b>data engineer</b> TextRank score rank: 201/2000", "Proficient Jupyter Python Spark": "<br/><b>data scientist</b> TextRank score rank: 987/2000<br/><b>data engineer</b> TextRank score rank: 1986/2000", "cases": "<br/><b>data scientist</b> TextRank score rank: 1106/2000<br/><b>data engineer</b> TextRank score rank: 839/2000", "internal non AI expert business partners": "<br/><b>data scientist</b> TextRank score rank: 858/2000<br/><b>data engineer</b> TextRank score rank: 1946/2000", "asset drive diffusion AI": "<br/><b>data scientist</b> TextRank score rank: 923/2000<br/><b>data engineer</b> TextRank score rank: 1931/2000", "execute coordinate innovative data analytics initiatives": "<br/><b>data scientist</b> TextRank score rank: 994/2000<br/><b>data engineer</b> TextRank score rank: 1915/2000", "BASF": "<br/><b>data scientist</b> TextRank score rank: 891/2000<br/><b>data engineer</b> TextRank score rank: 1914/2000", "HDFS Hadoop Hive HBase Spark Modern versioning systems git subversion": "<br/><b>data scientist</b> TextRank score rank: 838/2000<br/><b>data engineer</b> TextRank score rank: 1913/2000", "Windows OS Linux OS command line tools": "<br/><b>data scientist</b> TextRank score rank: 929/2000<br/><b>data engineer</b> TextRank score rank: 1912/2000", "neural networks recommendation systems": "<br/><b>data scientist</b> TextRank score rank: 964/2000<br/><b>data engineer</b> TextRank score rank: 1911/2000", "addition time series analysis Modern ML techniques": "<br/><b>data scientist</b> TextRank score rank: 993/2000<br/><b>data engineer</b> TextRank score rank: 1910/2000", "SQL SQL": "<br/><b>data scientist</b> TextRank score rank: 595/2000<br/><b>data engineer</b> TextRank score rank: 1909/2000", "time series regression cluster analysis decision trees": "<br/><b>data scientist</b> TextRank score rank: 935/2000<br/><b>data engineer</b> TextRank score rank: 1908/2000", "advanced analytic techniques": "<br/><b>data scientist</b> TextRank score rank: 960/2000<br/><b>data engineer</b> TextRank score rank: 1907/2000", "oral Hands experience manipulating deriving": "<br/><b>data scientist</b> TextRank score rank: 968/2000<br/><b>data engineer</b> TextRank score rank: 1906/2000", "unstructured datasets": "<br/><b>data scientist</b> TextRank score rank: 972/2000<br/><b>data engineer</b> TextRank score rank: 1905/2000", "practical casework agency corporate side Strong knowledge experience wide variety tools": "<br/><b>data scientist</b> TextRank score rank: 1017/2000<br/><b>data engineer</b> TextRank score rank: 1904/2000", "SQL SAS R Alteryx Tableau Proficient Excel PowerPoint presentation communication skills": "<br/><b>data scientist</b> TextRank score rank: 1019/2000<br/><b>data engineer</b> TextRank score rank: 1903/2000", "Degree Statistics Information Systems Mathematics Finance": "<br/><b>data scientist</b> TextRank score rank: 1013/2000<br/><b>data engineer</b> TextRank score rank: 1902/2000", "Data Visualization skills": "<br/><b>data scientist</b> TextRank score rank: 185/2000<br/><b>data engineer</b> TextRank score rank: 1901/2000", "Data Visualization": "<br/><b>data scientist</b> TextRank score rank: 202/2000<br/><b>data engineer</b> TextRank score rank: 1900/2000", "SF Financial District": "<br/><b>data scientist</b> TextRank score rank: 132/2000<br/><b>data engineer</b> TextRank score rank: 1899/2000", "Fun puzzle loving office": "<br/><b>data scientist</b> TextRank score rank: 384/2000<br/><b>data engineer</b> TextRank score rank: 1898/2000", "Required Statistical Algorithms years Required expert usage R Python years": "<br/><b>data scientist</b> TextRank score rank: 874/2000<br/><b>data engineer</b> TextRank score rank: 1897/2000", "analytic requirement Modern machine learning models expert level years": "<br/><b>data scientist</b> TextRank score rank: 945/2000<br/><b>data engineer</b> TextRank score rank: 1896/2000", "Strong coding skills": "<br/><b>data scientist</b> TextRank score rank: 1066/2000<br/><b>data engineer</b> TextRank score rank: 363/2000", "technical non technical stakeholders": "<br/><b>data scientist</b> TextRank score rank: 1038/2000<br/><b>data engineer</b> TextRank score rank: 837/2000", "verbal communication skills ability": "<br/><b>data scientist</b> TextRank score rank: 1079/2000<br/><b>data engineer</b> TextRank score rank: 796/2000", "large data sets": "<br/><b>data scientist</b> TextRank score rank: 175/2000<br/><b>data engineer</b> TextRank score rank: 774/2000", "clustering decision trees neural networks": "<br/><b>data scientist</b> TextRank score rank: 541/2000<br/><b>data engineer</b> TextRank score rank: 1895/2000", "databases": "<br/><b>data scientist</b> TextRank score rank: 1083/2000<br/><b>data engineer</b> TextRank score rank: 293/2000", "computing tools Hive Redshift": "<br/><b>data scientist</b> TextRank score rank: 282/2000<br/><b>data engineer</b> TextRank score rank: 1894/2000", "ETL validations Experience Druid columnar data stores Experience BI tools": "<br/><b>data scientist</b> TextRank score rank: 570/2000<br/><b>data engineer</b> TextRank score rank: 1893/2000", "PREFERRED QUALIFICATIONS Experience designing data quality metrics": "<br/><b>data scientist</b> TextRank score rank: 674/2000<br/><b>data engineer</b> TextRank score rank: 1916/2000", "quantitative data analysis years": "<br/><b>data scientist</b> TextRank score rank: 788/2000<br/><b>data engineer</b> TextRank score rank: 1917/2000", "SQL Hive experience years": "<br/><b>data scientist</b> TextRank score rank: 789/2000<br/><b>data engineer</b> TextRank score rank: 1918/2000", "Python R scripting languages": "<br/><b>data scientist</b> TextRank score rank: 818/2000<br/><b>data engineer</b> TextRank score rank: 1919/2000", "Experience BI": "<br/><b>data scientist</b> TextRank score rank: 826/2000<br/><b>data engineer</b> TextRank score rank: 1943/2000", "statistical data analysis linear models": "<br/><b>data scientist</b> TextRank score rank: 857/2000<br/><b>data engineer</b> TextRank score rank: 1942/2000", "Machine Learning PhD Data Science Statistics similar technical quantitative field Ability initiate": "<br/><b>data scientist</b> TextRank score rank: 865/2000<br/><b>data engineer</b> TextRank score rank: 1941/2000", "Research Economics Computer Science Mathematics Physics Electrical Engineering Industrial Engineering": "<br/><b>data scientist</b> TextRank score rank: 876/2000<br/><b>data engineer</b> TextRank score rank: 1940/2000", "g Statistics Operations Research Economics Computer Science Mathematics Physics Electrical Engineering Industrial Engineering": "<br/><b>data scientist</b> TextRank score rank: 877/2000<br/><b>data engineer</b> TextRank score rank: 1939/2000", "analysis stochastic models": "<br/><b>data scientist</b> TextRank score rank: 892/2000<br/><b>data engineer</b> TextRank score rank: 1938/2000", "commitment drive success teams peers": "<br/><b>data scientist</b> TextRank score rank: 952/2000<br/><b>data engineer</b> TextRank score rank: 1937/2000", "Previous work experience": "<br/><b>data scientist</b> TextRank score rank: 779/2000<br/><b>data engineer</b> TextRank score rank: 1936/2000", "Experience large scale data analysis": "<br/><b>data scientist</b> TextRank score rank: 805/2000<br/><b>data engineer</b> TextRank score rank: 1935/2000", "data mining statistical analysis": "<br/><b>data scientist</b> TextRank score rank: 980/2000<br/><b>data engineer</b> TextRank score rank: 1934/2000", "aggressive deadlines": "<br/><b>data scientist</b> TextRank score rank: 995/2000<br/><b>data engineer</b> TextRank score rank: 1933/2000", "key Strong communication data presentation": "<br/><b>data scientist</b> TextRank score rank: 1022/2000<br/><b>data engineer</b> TextRank score rank: 1944/2000", "new technologies tools techniques": "<br/><b>data scientist</b> TextRank score rank: 1023/2000<br/><b>data engineer</b> TextRank score rank: 1932/2000", "structured unstructured data Strong communication interpersonal skills ability work team environment": "<br/><b>data scientist</b> TextRank score rank: 1049/2000<br/><b>data engineer</b> TextRank score rank: 1930/2000", "statistical analysis software development Solid background machine": "<br/><b>data scientist</b> TextRank score rank: 864/2000<br/><b>data engineer</b> TextRank score rank: 1929/2000", "Multivariate Regression Logistic Regression Combinatorial Optimization Stochastic Processes Complex Analysis Principal Component Analysis Time Series Analysis Experience Matlab R Weka Experience": "<br/><b>data scientist</b> TextRank score rank: 942/2000<br/><b>data engineer</b> TextRank score rank: 1928/2000", "Multivariate Regression Logistic Regression Combinatorial Optimization Stochastic Processes Complex Analysis Principal Component Analysis Time Series Analysis": "<br/><b>data scientist</b> TextRank score rank: 954/2000<br/><b>data engineer</b> TextRank score rank: 1927/2000", "Strong software development": "<br/><b>data scientist</b> TextRank score rank: 962/2000<br/><b>data engineer</b> TextRank score rank: 1926/2000", "Agile software development methodology": "<br/><b>data scientist</b> TextRank score rank: 1016/2000<br/><b>data engineer</b> TextRank score rank: 1925/2000", "software support continuous integration continuous deployment process": "<br/><b>data scientist</b> TextRank score rank: 1040/2000<br/><b>data engineer</b> TextRank score rank: 1924/2000", "statistical analysis": "<br/><b>data scientist</b> TextRank score rank: 382/2000<br/><b>data engineer</b> TextRank score rank: 157/2000", "high throughput data ingestion analysis": "<br/><b>data scientist</b> TextRank score rank: 309/2000<br/><b>data engineer</b> TextRank score rank: 1923/2000", "new things test solutions technologies": "<br/><b>data scientist</b> TextRank score rank: 341/2000<br/><b>data engineer</b> TextRank score rank: 1922/2000", "enterprise products": "<br/><b>data scientist</b> TextRank score rank: 463/2000<br/><b>data engineer</b> TextRank score rank: 1921/2000", "deep learning": "<br/><b>data scientist</b> TextRank score rank: 588/2000<br/><b>data engineer</b> TextRank score rank: 1920/2000", "TensorFlow PyTorch": "<br/><b>data scientist</b> TextRank score rank: 286/2000<br/><b>data engineer</b> TextRank score rank: 1782/2000", "unique solutions": "<br/><b>data scientist</b> TextRank score rank: 451/2000<br/><b>data engineer</b> TextRank score rank: 1890/2000", "micro managed freedom": "<br/><b>data scientist</b> TextRank score rank: 467/2000<br/><b>data engineer</b> TextRank score rank: 1781/2000", "cloud console": "<br/><b>data scientist</b> TextRank score rank: 473/2000<br/><b>data engineer</b> TextRank score rank: 1670/2000", "better path": "<br/><b>data scientist</b> TextRank score rank: 497/2000<br/><b>data engineer</b> TextRank score rank: 1640/2000", "frameworks": "<br/><b>data scientist</b> TextRank score rank: 529/2000<br/><b>data engineer</b> TextRank score rank: 646/2000", "Data science dynamic evolving profession": "<br/><b>data scientist</b> TextRank score rank: 642/2000<br/><b>data engineer</b> TextRank score rank: 1639/2000", "current area expertise interest related interest positions": "<br/><b>data scientist</b> TextRank score rank: 895/2000<br/><b>data engineer</b> TextRank score rank: 1638/2000", "Bachelor degree Computational social science Computer science Data analytics Economics Engineering Geospatial analysis": "<br/><b>data scientist</b> TextRank score rank: 1035/2000<br/><b>data engineer</b> TextRank score rank: 1637/2000", "Bachelor degree Computational social science Computer science Data analytics": "<br/><b>data scientist</b> TextRank score rank: 1046/2000<br/><b>data engineer</b> TextRank score rank: 1636/2000", "Quantitative finance Statistics GPA": "<br/><b>data scientist</b> TextRank score rank: 581/2000<br/><b>data engineer</b> TextRank score rank: 1635/2000", "CIA": "<br/><b>data scientist</b> TextRank score rank: 985/2000<br/><b>data engineer</b> TextRank score rank: 1634/2000", "continuous improvement data science analytics Presents data insights": "<br/><b>data scientist</b> TextRank score rank: 761/2000<br/><b>data engineer</b> TextRank score rank: 1633/2000", "analytics related field Certificate business analytics data mining statistical analysis": "<br/><b>data scientist</b> TextRank score rank: 829/2000<br/><b>data engineer</b> TextRank score rank: 1632/2000", "Doctoral degree Statistics Economics Analytics Mathematics year experience analytics related field": "<br/><b>data scientist</b> TextRank score rank: 868/2000<br/><b>data engineer</b> TextRank score rank: 1631/2000", "large data analytics project teams Models compliance company": "<br/><b>data scientist</b> TextRank score rank: 884/2000<br/><b>data engineer</b> TextRank score rank: 1630/2000", "analytics insights": "<br/><b>data scientist</b> TextRank score rank: 908/2000<br/><b>data engineer</b> TextRank score rank: 1629/2000", "data science experience years": "<br/><b>data scientist</b> TextRank score rank: 956/2000<br/><b>data engineer</b> TextRank score rank: 1628/2000", "DB2 Oracle SQL Server years": "<br/><b>data scientist</b> TextRank score rank: 1042/2000<br/><b>data engineer</b> TextRank score rank: 1627/2000", "Commuter Benefits Flexible Spendi": "<br/><b>data scientist</b> TextRank score rank: 205/2000<br/><b>data engineer</b> TextRank score rank: 1626/2000", "Demonstrable knowledge healthcare data": "<br/><b>data scientist</b> TextRank score rank: 958/2000<br/><b>data engineer</b> TextRank score rank: 1625/2000", "little supervision Strong oral written presentation skills levels organization Ability": "<br/><b>data scientist</b> TextRank score rank: 1043/2000<br/><b>data engineer</b> TextRank score rank: 1624/2000", "working data science team": "<br/><b>data scientist</b> TextRank score rank: 1044/2000<br/><b>data engineer</b> TextRank score rank: 1623/2000", "R Python preferred ability interest": "<br/><b>data scientist</b> TextRank score rank: 1051/2000<br/><b>data engineer</b> TextRank score rank: 1622/2000", "g": "<br/><b>data scientist</b> TextRank score rank: 781/2000<br/><b>data engineer</b> TextRank score rank: 178/2000", "least one scripting language": "<br/><b>data scientist</b> TextRank score rank: 1157/2000<br/><b>data engineer</b> TextRank score rank: 1081/2000", "data mining Strong knowledge experiences machine": "<br/><b>data scientist</b> TextRank score rank: 881/2000<br/><b>data engineer</b> TextRank score rank: 1621/2000", "Expertise data warehouse SQL programming": "<br/><b>data scientist</b> TextRank score rank: 912/2000<br/><b>data engineer</b> TextRank score rank: 1620/2000", "Math quantitative field strong background machine": "<br/><b>data scientist</b> TextRank score rank: 977/2000<br/><b>data engineer</b> TextRank score rank: 1619/2000", "Python based ML libraries": "<br/><b>data scientist</b> TextRank score rank: 983/2000<br/><b>data engineer</b> TextRank score rank: 1618/2000", "Experience payment fraud detection prevention": "<br/><b>data scientist</b> TextRank score rank: 1004/2000<br/><b>data engineer</b> TextRank score rank: 1641/2000", "Python R SAS Base SAS Stats SAS Enterprise": "<br/><b>data scientist</b> TextRank score rank: 1018/2000<br/><b>data engineer</b> TextRank score rank: 1642/2000", "Python R SAS Base SAS Stats SAS Enterprise Miner": "<br/><b>data scientist</b> TextRank score rank: 1021/2000<br/><b>data engineer</b> TextRank score rank: 1643/2000", "mathematics statistics physics": "<br/><b>data scientist</b> TextRank score rank: 683/2000<br/><b>data engineer</b> TextRank score rank: 1644/2000", "computer science artificial intelligence": "<br/><b>data scientist</b> TextRank score rank: 774/2000<br/><b>data engineer</b> TextRank score rank: 1668/2000", "relevant work experience Experience building": "<br/><b>data scientist</b> TextRank score rank: 919/2000<br/><b>data engineer</b> TextRank score rank: 1667/2000", "MS Computer Science emphasis Data Science Analytics Machine Learning PhD": "<br/><b>data scientist</b> TextRank score rank: 973/2000<br/><b>data engineer</b> TextRank score rank: 1666/2000", "ideas efficient elegant code Development experience": "<br/><b>data scientist</b> TextRank score rank: 1006/2000<br/><b>data engineer</b> TextRank score rank: 1665/2000", "RDF S OWL SPARQL Strong command linear algebra statistics ability": "<br/><b>data scientist</b> TextRank score rank: 1039/2000<br/><b>data engineer</b> TextRank score rank: 1664/2000", "Python Java Scala good command respective data pipelining matrix algebra statistics": "<br/><b>data scientist</b> TextRank score rank: 1050/2000<br/><b>data engineer</b> TextRank score rank: 1663/2000", "Java Python": "<br/><b>data scientist</b> TextRank score rank: 293/2000<br/><b>data engineer</b> TextRank score rank: 90/2000", "common methods data transformation": "<br/><b>data scientist</b> TextRank score rank: 685/2000<br/><b>data engineer</b> TextRank score rank: 1662/2000", "various data structures": "<br/><b>data scientist</b> TextRank score rank: 686/2000<br/><b>data engineer</b> TextRank score rank: 1661/2000", "years practical experience SAS ETL data processing database programming data analytics Experience predictive": "<br/><b>data scientist</b> TextRank score rank: 693/2000<br/><b>data engineer</b> TextRank score rank: 1660/2000", "Qlik SAP BO Experience mining Claims EMR data preferably Oncology related data": "<br/><b>data scientist</b> TextRank score rank: 812/2000<br/><b>data engineer</b> TextRank score rank: 1659/2000", "statistical analysis Experience analytics": "<br/><b>data scientist</b> TextRank score rank: 814/2000<br/><b>data engineer</b> TextRank score rank: 1658/2000", "Python SAS Alteryx Angos R Experience programming languages": "<br/><b>data scientist</b> TextRank score rank: 842/2000<br/><b>data engineer</b> TextRank score rank: 1669/2000", "Tableau MS Power BI Tibco": "<br/><b>data scientist</b> TextRank score rank: 988/2000<br/><b>data engineer</b> TextRank score rank: 1657/2000", "Extensive": "<br/><b>data scientist</b> TextRank score rank: 611/2000<br/><b>data engineer</b> TextRank score rank: 1068/2000", "data warehouse data cubes": "<br/><b>data scientist</b> TextRank score rank: 506/2000<br/><b>data engineer</b> TextRank score rank: 1655/2000", "Pentaho data integration experience": "<br/><b>data scientist</b> TextRank score rank: 572/2000<br/><b>data engineer</b> TextRank score rank: 1654/2000", "ETL ELT processes": "<br/><b>data scientist</b> TextRank score rank: 760/2000<br/><b>data engineer</b> TextRank score rank: 1653/2000", "ETL ELT": "<br/><b>data scientist</b> TextRank score rank: 859/2000<br/><b>data engineer</b> TextRank score rank: 1652/2000", "operational data PLAN TRACK VIEW": "<br/><b>data scientist</b> TextRank score rank: 937/2000<br/><b>data engineer</b> TextRank score rank: 1651/2000", "applying structure schema": "<br/><b>data scientist</b> TextRank score rank: 1048/2000<br/><b>data engineer</b> TextRank score rank: 1650/2000", "Create": "<br/><b>data scientist</b> TextRank score rank: 527/2000<br/><b>data engineer</b> TextRank score rank: 1092/2000", "Mathematics related field": "<br/><b>data scientist</b> TextRank score rank: 287/2000<br/><b>data engineer</b> TextRank score rank: 1649/2000", "Ph D MS degree": "<br/><b>data scientist</b> TextRank score rank: 544/2000<br/><b>data engineer</b> TextRank score rank: 1648/2000", "D MS degree": "<br/><b>data scientist</b> TextRank score rank: 554/2000<br/><b>data engineer</b> TextRank score rank: 1647/2000", "HomeAway com Electronic adjustable stand desk": "<br/><b>data scientist</b> TextRank score rank: 1070/2000<br/><b>data engineer</b> TextRank score rank: 754/2000", "talks leadership team": "<br/><b>data scientist</b> TextRank score rank: 1073/2000<br/><b>data engineer</b> TextRank score rank: 874/2000", "Discounted Metro Rail": "<br/><b>data scientist</b> TextRank score rank: 646/2000<br/><b>data engineer</b> TextRank score rank: 404/2000", "unstructured data": "<br/><b>data scientist</b> TextRank score rank: 1087/2000<br/><b>data engineer</b> TextRank score rank: 729/2000", "real time": "<br/><b>data scientist</b> TextRank score rank: 1094/2000<br/><b>data engineer</b> TextRank score rank: 115/2000", "weeks": "<br/><b>data scientist</b> TextRank score rank: 1055/2000<br/><b>data engineer</b> TextRank score rank: 483/2000", "Annual": "<br/><b>data scientist</b> TextRank score rank: 1130/2000<br/><b>data engineer</b> TextRank score rank: 1070/2000", "e": "<br/><b>data scientist</b> TextRank score rank: 1086/2000<br/><b>data engineer</b> TextRank score rank: 123/2000", "Strong statistical knowledge intuition ability": "<br/><b>data scientist</b> TextRank score rank: 914/2000<br/><b>data engineer</b> TextRank score rank: 1646/2000", "Hive Pig Presto Spark Data visualization skills": "<br/><b>data scientist</b> TextRank score rank: 975/2000<br/><b>data engineer</b> TextRank score rank: 1645/2000", "Strong skills": "<br/><b>data scientist</b> TextRank score rank: 981/2000<br/><b>data engineer</b> TextRank score rank: 1617/2000", "massive amounts data drive product innovation": "<br/><b>data scientist</b> TextRank score rank: 992/2000<br/><b>data engineer</b> TextRank score rank: 1656/2000", "Deep product sense": "<br/><b>data scientist</b> TextRank score rank: 1027/2000<br/><b>data engineer</b> TextRank score rank: 1616/2000", "predictive modeling time series probabilistic graphical models": "<br/><b>data scientist</b> TextRank score rank: 1037/2000<br/><b>data engineer</b> TextRank score rank: 1601/2000", "track record": "<br/><b>data scientist</b> TextRank score rank: 482/2000<br/><b>data engineer</b> TextRank score rank: 1585/2000", "structured semi structured unstructured data": "<br/><b>data scientist</b> TextRank score rank: 1060/2000<br/><b>data engineer</b> TextRank score rank: 267/2000", "millions": "<br/><b>data scientist</b> TextRank score rank: 1126/2000<br/><b>data engineer</b> TextRank score rank: 1034/2000", "Years": "<br/><b>data scientist</b> TextRank score rank: 1158/2000<br/><b>data engineer</b> TextRank score rank: 491/2000", "daily": "<br/><b>data scientist</b> TextRank score rank: 1713/2000<br/><b>data engineer</b> TextRank score rank: 1105/2000", "Education Computer science Statistics Physics Mathematics Economics Specialization Certification": "<br/><b>data scientist</b> TextRank score rank: 145/2000<br/><b>data engineer</b> TextRank score rank: 1584/2000", "quantitative trading research role Experience top tier quantitative investment firms": "<br/><b>data scientist</b> TextRank score rank: 703/2000<br/><b>data engineer</b> TextRank score rank: 1583/2000", "working experience": "<br/><b>data scientist</b> TextRank score rank: 809/2000<br/><b>data engineer</b> TextRank score rank: 1582/2000", "AQR Capital QMS Capital": "<br/><b>data scientist</b> TextRank score rank: 898/2000<br/><b>data engineer</b> TextRank score rank: 1581/2000", "Publications top tier journals": "<br/><b>data scientist</b> TextRank score rank: 938/2000<br/><b>data engineer</b> TextRank score rank: 1580/2000", "Professional experience software development practices": "<br/><b>data scientist</b> TextRank score rank: 963/2000<br/><b>data engineer</b> TextRank score rank: 1579/2000", "advanced statistical methodologies multiple regression model mixed models time series models": "<br/><b>data scientist</b> TextRank score rank: 969/2000<br/><b>data engineer</b> TextRank score rank: 1578/2000", "prior experience optimization simulation marketing mix multivariate testing ensemble modeling graph": "<br/><b>data scientist</b> TextRank score rank: 1015/2000<br/><b>data engineer</b> TextRank score rank: 1577/2000", "Python R SQL": "<br/><b>data scientist</b> TextRank score rank: 680/2000<br/><b>data engineer</b> TextRank score rank: 1576/2000", "Postgres Druid Aerospike Elasticsearch": "<br/><b>data scientist</b> TextRank score rank: 281/2000<br/><b>data engineer</b> TextRank score rank: 1575/2000", "Nice Experience working Database storage systems": "<br/><b>data scientist</b> TextRank score rank: 439/2000<br/><b>data engineer</b> TextRank score rank: 1574/2000", "g artificial intelligence operations research": "<br/><b>data scientist</b> TextRank score rank: 867/2000<br/><b>data engineer</b> TextRank score rank: 1573/2000", "Familiarity operations research CPLEX": "<br/><b>data scientist</b> TextRank score rank: 941/2000<br/><b>data engineer</b> TextRank score rank: 1572/2000", "complicated problems": "<br/><b>data scientist</b> TextRank score rank: 997/2000<br/><b>data engineer</b> TextRank score rank: 1571/2000", "integer problems": "<br/><b>data scientist</b> TextRank score rank: 1012/2000<br/><b>data engineer</b> TextRank score rank: 1570/2000", "actionable manner Ability": "<br/><b>data scientist</b> TextRank score rank: 1028/2000<br/><b>data engineer</b> TextRank score rank: 1569/2000", "quantitative research e": "<br/><b>data scientist</b> TextRank score rank: 1033/2000<br/><b>data engineer</b> TextRank score rank: 1568/2000", "languages": "<br/><b>data scientist</b> TextRank score rank: 648/2000<br/><b>data engineer</b> TextRank score rank: 779/2000", "key decisions": "<br/><b>data scientist</b> TextRank score rank: 677/2000<br/><b>data engineer</b> TextRank score rank: 1567/2000", "colleagues": "<br/><b>data scientist</b> TextRank score rank: 1108/2000<br/><b>data engineer</b> TextRank score rank: 1015/2000", "IT systems": "<br/><b>data scientist</b> TextRank score rank: 553/2000<br/><b>data engineer</b> TextRank score rank: 1566/2000", "preferably Big similar firm Demonstrated expertise business analysis data analysis Experience writing requirements": "<br/><b>data scientist</b> TextRank score rank: 565/2000<br/><b>data engineer</b> TextRank score rank: 1565/2000", "accessing data years": "<br/><b>data scientist</b> TextRank score rank: 643/2000<br/><b>data engineer</b> TextRank score rank: 1564/2000", "working SQL": "<br/><b>data scientist</b> TextRank score rank: 633/2000<br/><b>data engineer</b> TextRank score rank: 1563/2000", "Master degree computer science computer engineering related field equivalent combination education related experience Experience developing software": "<br/><b>data scientist</b> TextRank score rank: 1041/2000<br/><b>data engineer</b> TextRank score rank: 1586/2000", "Broad": "<br/><b>data scientist</b> TextRank score rank: 1139/2000<br/><b>data engineer</b> TextRank score rank: 1087/2000", "PhD Masters approved field minimum years": "<br/><b>data scientist</b> TextRank score rank: 418/2000<br/><b>data engineer</b> TextRank score rank: 1587/2000", "minimum years": "<br/><b>data scientist</b> TextRank score rank: 513/2000<br/><b>data engineer</b> TextRank score rank: 1097/2000", "PhD Masters": "<br/><b>data scientist</b> TextRank score rank: 632/2000<br/><b>data engineer</b> TextRank score rank: 1588/2000", "Preferred Bachelors Science Computer Science Math Scientific Computing Data Analytics Machine Learning Business Analyst nanodegree equivalent experience": "<br/><b>data scientist</b> TextRank score rank: 678/2000<br/><b>data engineer</b> TextRank score rank: 1589/2000", "data data sources": "<br/><b>data scientist</b> TextRank score rank: 645/2000<br/><b>data engineer</b> TextRank score rank: 1613/2000", "Advanced knowledge R Experience SAS SPSS Experience": "<br/><b>data scientist</b> TextRank score rank: 724/2000<br/><b>data engineer</b> TextRank score rank: 1612/2000", "Exposure Big Data technologies Hadoop Hive Advanced knowledge Excel Experience handling": "<br/><b>data scientist</b> TextRank score rank: 828/2000<br/><b>data engineer</b> TextRank score rank: 1611/2000", "solid experience marketing analytics": "<br/><b>data scientist</b> TextRank score rank: 840/2000<br/><b>data engineer</b> TextRank score rank: 1610/2000", "digital behavioural data": "<br/><b>data scientist</b> TextRank score rank: 844/2000<br/><b>data engineer</b> TextRank score rank: 1609/2000", "segmentation predictive analytics": "<br/><b>data scientist</b> TextRank score rank: 1005/2000<br/><b>data engineer</b> TextRank score rank: 1608/2000", "information webpages product characteristics reviews": "<br/><b>data scientist</b> TextRank score rank: 1020/2000<br/><b>data engineer</b> TextRank score rank: 1607/2000", "track record application ML NLP": "<br/><b>data scientist</b> TextRank score rank: 393/2000<br/><b>data engineer</b> TextRank score rank: 1606/2000", "global business rely diversity culture": "<br/><b>data scientist</b> TextRank score rank: 627/2000<br/><b>data engineer</b> TextRank score rank: 1605/2000", "Multiple years": "<br/><b>data scientist</b> TextRank score rank: 428/2000<br/><b>data engineer</b> TextRank score rank: 1604/2000", "statistical analysis Experience Python development": "<br/><b>data scientist</b> TextRank score rank: 630/2000<br/><b>data engineer</b> TextRank score rank: 1603/2000", "Python SAS R statistical packages": "<br/><b>data scientist</b> TextRank score rank: 689/2000<br/><b>data engineer</b> TextRank score rank: 1614/2000", "Master Degree Economics Math Statistics Finance Engineering similar discipline year experience business application machine": "<br/><b>data scientist</b> TextRank score rank: 743/2000<br/><b>data engineer</b> TextRank score rank: 1602/2000", "Comfortable developing statistical models": "<br/><b>data scientist</b> TextRank score rank: 790/2000<br/><b>data engineer</b> TextRank score rank: 1600/2000", "Bachelor Degree Economics Math Science Finance": "<br/><b>data scientist</b> TextRank score rank: 348/2000<br/><b>data engineer</b> TextRank score rank: 1599/2000", "similar discipline": "<br/><b>data scientist</b> TextRank score rank: 949/2000<br/><b>data engineer</b> TextRank score rank: 1598/2000", "Experience working scientists R D systems": "<br/><b>data scientist</b> TextRank score rank: 808/2000<br/><b>data engineer</b> TextRank score rank: 1597/2000", "good organizational communication analytical technical writing skills": "<br/><b>data scientist</b> TextRank score rank: 852/2000<br/><b>data engineer</b> TextRank score rank: 1596/2000", "data science statistics": "<br/><b>data scientist</b> TextRank score rank: 907/2000<br/><b>data engineer</b> TextRank score rank: 1595/2000", "Experience scripting languages": "<br/><b>data scientist</b> TextRank score rank: 933/2000<br/><b>data engineer</b> TextRank score rank: 1594/2000", "healthcare domain Masters PhD Application data science solutions industrial projects": "<br/><b>data scientist</b> TextRank score rank: 423/2000<br/><b>data engineer</b> TextRank score rank: 1593/2000", "data science problems": "<br/><b>data scientist</b> TextRank score rank: 235/2000<br/><b>data engineer</b> TextRank score rank: 1592/2000", "Masters PhD Application": "<br/><b>data scientist</b> TextRank score rank: 250/2000<br/><b>data engineer</b> TextRank score rank: 1591/2000", "BS MS PhD healthcare related field Minimum years": "<br/><b>data scientist</b> TextRank score rank: 675/2000<br/><b>data engineer</b> TextRank score rank: 1590/2000", "BS MS PhD": "<br/><b>data scientist</b> TextRank score rank: 889/2000<br/><b>data engineer</b> TextRank score rank: 1615/2000", "A love games": "<br/><b>data scientist</b> TextRank score rank: 363/2000<br/><b>data engineer</b> TextRank score rank: 1671/2000", "related field minimum years general management experience business marketing analytics field equivalent combination experience training": "<br/><b>data scientist</b> TextRank score rank: 998/2000<br/><b>data engineer</b> TextRank score rank: 1725/2000", "Alteryx": "<br/><b>data scientist</b> TextRank score rank: 1128/2000<br/><b>data engineer</b> TextRank score rank: 1083/2000", "CRM": "<br/><b>data scientist</b> TextRank score rank: 1002/2000<br/><b>data engineer</b> TextRank score rank: 1672/2000", "internship school project": "<br/><b>data scientist</b> TextRank score rank: 591/2000<br/><b>data engineer</b> TextRank score rank: 1750/2000", "Machine Learning Algorithms Statistics": "<br/><b>data scientist</b> TextRank score rank: 749/2000<br/><b>data engineer</b> TextRank score rank: 1749/2000", "Python R Programming": "<br/><b>data scientist</b> TextRank score rank: 822/2000<br/><b>data engineer</b> TextRank score rank: 1748/2000", "engine implementation": "<br/><b>data scientist</b> TextRank score rank: 851/2000<br/><b>data engineer</b> TextRank score rank: 1747/2000", "Theoretical knowledge Machine Learning Algorithms Statistics etc Basic coding ability": "<br/><b>data scientist</b> TextRank score rank: 932/2000<br/><b>data engineer</b> TextRank score rank: 1746/2000", "young growing company": "<br/><b>data scientist</b> TextRank score rank: 338/2000<br/><b>data engineer</b> TextRank score rank: 1745/2000", "today": "<br/><b>data scientist</b> TextRank score rank: 813/2000<br/><b>data engineer</b> TextRank score rank: 1744/2000", "Fetch": "<br/><b>data scientist</b> TextRank score rank: 883/2000<br/><b>data engineer</b> TextRank score rank: 1743/2000", "web mobile applications business intelligence tools": "<br/><b>data scientist</b> TextRank score rank: 284/2000<br/><b>data engineer</b> TextRank score rank: 1742/2000", "Building": "<br/><b>data scientist</b> TextRank score rank: 381/2000<br/><b>data engineer</b> TextRank score rank: 1741/2000", "data systems": "<br/><b>data scientist</b> TextRank score rank: 1082/2000<br/><b>data engineer</b> TextRank score rank: 911/2000", "Crown Center": "<br/><b>data scientist</b> TextRank score rank: 426/2000<br/><b>data engineer</b> TextRank score rank: 1740/2000", "site cafeteria": "<br/><b>data scientist</b> TextRank score rank: 731/2000<br/><b>data engineer</b> TextRank score rank: 1739/2000", "Machine Learning algorithms models": "<br/><b>data scientist</b> TextRank score rank: 780/2000<br/><b>data engineer</b> TextRank score rank: 1738/2000", "Background Machine Learning Statistics Information Retrieval Design": "<br/><b>data scientist</b> TextRank score rank: 873/2000<br/><b>data engineer</b> TextRank score rank: 1737/2000", "Scala Golang Haskell Clojure": "<br/><b>data scientist</b> TextRank score rank: 904/2000<br/><b>data engineer</b> TextRank score rank: 1736/2000", "collaborative environment": "<br/><b>data scientist</b> TextRank score rank: 1134/2000<br/><b>data engineer</b> TextRank score rank: 974/2000", "Write": "<br/><b>data scientist</b> TextRank score rank: 1045/2000<br/><b>data engineer</b> TextRank score rank: 457/2000", "company": "<br/><b>data scientist</b> TextRank score rank: 1151/2000<br/><b>data engineer</b> TextRank score rank: 656/2000", "features": "<br/><b>data scientist</b> TextRank score rank: 1152/2000<br/><b>data engineer</b> TextRank score rank: 1059/2000", "Superb": "<br/><b>data scientist</b> TextRank score rank: 1153/2000<br/><b>data engineer</b> TextRank score rank: 1091/2000", "new trends data science": "<br/><b>data scientist</b> TextRank score rank: 806/2000<br/><b>data engineer</b> TextRank score rank: 2000/2000", "implementation data science project": "<br/><b>data scientist</b> TextRank score rank: 893/2000<br/><b>data engineer</b> TextRank score rank: 1735/2000", "digital marketing data": "<br/><b>data scientist</b> TextRank score rank: 931/2000<br/><b>data engineer</b> TextRank score rank: 1734/2000", "connecting data": "<br/><b>data scientist</b> TextRank score rank: 939/2000<br/><b>data engineer</b> TextRank score rank: 1733/2000", "new challenges": "<br/><b>data scientist</b> TextRank score rank: 1057/2000<br/><b>data engineer</b> TextRank score rank: 800/2000", "business": "<br/><b>data scientist</b> TextRank score rank: 1098/2000<br/><b>data engineer</b> TextRank score rank: 598/2000", "Education": "<br/><b>data scientist</b> TextRank score rank: 1117/2000<br/><b>data engineer</b> TextRank score rank: 1064/2000", "New York NY": "<br/><b>data scientist</b> TextRank score rank: 184/2000<br/><b>data engineer</b> TextRank score rank: 1058/2000", "New York": "<br/><b>data scientist</b> TextRank score rank: 265/2000<br/><b>data engineer</b> TextRank score rank: 997/2000", "clients": "<br/><b>data scientist</b> TextRank score rank: 1032/2000<br/><b>data engineer</b> TextRank score rank: 552/2000", "real world Experience Python": "<br/><b>data scientist</b> TextRank score rank: 785/2000<br/><b>data engineer</b> TextRank score rank: 1732/2000", "natural language processing Development deployment software": "<br/><b>data scientist</b> TextRank score rank: 890/2000<br/><b>data engineer</b> TextRank score rank: 1731/2000", "related degree equivalent experience years": "<br/><b>data scientist</b> TextRank score rank: 921/2000<br/><b>data engineer</b> TextRank score rank: 1730/2000", "work ethic passion problem": "<br/><b>data scientist</b> TextRank score rank: 928/2000<br/><b>data engineer</b> TextRank score rank: 1729/2000", "Familiar data pipelines": "<br/><b>data scientist</b> TextRank score rank: 866/2000<br/><b>data engineer</b> TextRank score rank: 1728/2000", "knowledge": "<br/><b>data scientist</b> TextRank score rank: 416/2000<br/><b>data engineer</b> TextRank score rank: 361/2000", "smartest people": "<br/><b>data scientist</b> TextRank score rank: 306/2000<br/><b>data engineer</b> TextRank score rank: 1751/2000", "boundaries": "<br/><b>data scientist</b> TextRank score rank: 653/2000<br/><b>data engineer</b> TextRank score rank: 1752/2000", "Huge technical problems": "<br/><b>data scientist</b> TextRank score rank: 673/2000<br/><b>data engineer</b> TextRank score rank: 1753/2000", "extensive operational data analysis experience data analysis regression analysis": "<br/><b>data scientist</b> TextRank score rank: 592/2000<br/><b>data engineer</b> TextRank score rank: 1754/2000", "industry experience predictive modeling data science analysis Programming experience": "<br/><b>data scientist</b> TextRank score rank: 662/2000<br/><b>data engineer</b> TextRank score rank: 1778/2000", "Python R equivalent Demonstrated experience data science data analysis Desire": "<br/><b>data scientist</b> TextRank score rank: 764/2000<br/><b>data engineer</b> TextRank score rank: 1777/2000", "Comfortable Linux environment Experience Amazon Web Services AWS": "<br/><b>data scientist</b> TextRank score rank: 906/2000<br/><b>data engineer</b> TextRank score rank: 1776/2000", "e g Computer Science Operations Research Systems Engineering Physics equivalent experience years": "<br/><b>data scientist</b> TextRank score rank: 911/2000<br/><b>data engineer</b> TextRank score rank: 1775/2000", "Desire": "<br/><b>data scientist</b> TextRank score rank: 1121/2000<br/><b>data engineer</b> TextRank score rank: 240/2000", "healthcare data": "<br/><b>data scientist</b> TextRank score rank: 602/2000<br/><b>data engineer</b> TextRank score rank: 1774/2000", "Advanced": "<br/><b>data scientist</b> TextRank score rank: 1131/2000<br/><b>data engineer</b> TextRank score rank: 1067/2000", "areas": "<br/><b>data scientist</b> TextRank score rank: 1099/2000<br/><b>data engineer</b> TextRank score rank: 489/2000", "five years": "<br/><b>data scientist</b> TextRank score rank: 1160/2000<br/><b>data engineer</b> TextRank score rank: 944/2000", "Chief Statistician Next message Jobs Tenure track position University Hawaii Messages": "<br/><b>data scientist</b> TextRank score rank: 492/2000<br/><b>data engineer</b> TextRank score rank: 1773/2000", "University Hawaii Messages": "<br/><b>data scientist</b> TextRank score rank: 658/2000<br/><b>data engineer</b> TextRank score rank: 1772/2000", "Jobs Fwd OMB": "<br/><b>data scientist</b> TextRank score rank: 290/2000<br/><b>data engineer</b> TextRank score rank: 1771/2000", "Jobs Tenure": "<br/><b>data scientist</b> TextRank score rank: 752/2000<br/><b>data engineer</b> TextRank score rank: 1770/2000", "Statistician": "<br/><b>data scientist</b> TextRank score rank: 644/2000<br/><b>data engineer</b> TextRank score rank: 1769/2000", "Python R similar data science language Advanced proficiency data visualization Prefer financial services industry experience Prefer experience CRM financial analysis financial advisory Bachelors Master degree Computer Science Math Data Science Statistics": "<br/><b>data scientist</b> TextRank score rank: 734/2000<br/><b>data engineer</b> TextRank score rank: 1768/2000", "Best Corporate Citizens InformationWeek": "<br/><b>data scientist</b> TextRank score rank: 496/2000<br/><b>data engineer</b> TextRank score rank: 1779/2000", "FORTUNE World Most Admired Companies Corporate Responsibility Magazine Best Corporate Citizens": "<br/><b>data scientist</b> TextRank score rank: 519/2000<br/><b>data engineer</b> TextRank score rank: 1767/2000", "Elite Women Business Enterprise National Council America Top Corporations Women Business Enterprises Reputation Institute World Most Reputable Companies": "<br/><b>data scientist</b> TextRank score rank: 534/2000<br/><b>data engineer</b> TextRank score rank: 1765/2000", "Corporate Responsibility Magazine": "<br/><b>data scientist</b> TextRank score rank: 622/2000<br/><b>data engineer</b> TextRank score rank: 1764/2000", "FORTUNE World Most Admired Companies": "<br/><b>data scientist</b> TextRank score rank: 741/2000<br/><b>data engineer</b> TextRank score rank: 1763/2000", "diverse technical non technical audiences": "<br/><b>data scientist</b> TextRank score rank: 740/2000<br/><b>data engineer</b> TextRank score rank: 1762/2000", "technical concepts": "<br/><b>data scientist</b> TextRank score rank: 362/2000<br/><b>data engineer</b> TextRank score rank: 840/2000", "Doctorate Preferred": "<br/><b>data scientist</b> TextRank score rank: 173/2000<br/><b>data engineer</b> TextRank score rank: 1761/2000", "Python development language emphasis data science Experience Python data analysis packages": "<br/><b>data scientist</b> TextRank score rank: 824/2000<br/><b>data engineer</b> TextRank score rank: 1760/2000", "Postgres Knowledge Bayesian data analysis methods model comparison": "<br/><b>data scientist</b> TextRank score rank: 875/2000<br/><b>data engineer</b> TextRank score rank: 1759/2000", "Technologies Linux Python": "<br/><b>data scientist</b> TextRank score rank: 180/2000<br/><b>data engineer</b> TextRank score rank: 1758/2000", "Numerical topic": "<br/><b>data scientist</b> TextRank score rank: 647/2000<br/><b>data engineer</b> TextRank score rank: 1757/2000", "MS PhD degree Computer Science Artificial Intelligence Machine Learning": "<br/><b>data scientist</b> TextRank score rank: 701/2000<br/><b>data engineer</b> TextRank score rank: 1756/2000", "technical field": "<br/><b>data scientist</b> TextRank score rank: 718/2000<br/><b>data engineer</b> TextRank score rank: 684/2000", "Spark Hadoop": "<br/><b>data scientist</b> TextRank score rank: 378/2000<br/><b>data engineer</b> TextRank score rank: 185/2000", "analysis Experience machine": "<br/><b>data scientist</b> TextRank score rank: 723/2000<br/><b>data engineer</b> TextRank score rank: 1755/2000", "Python scikit computer language experience": "<br/><b>data scientist</b> TextRank score rank: 757/2000<br/><b>data engineer</b> TextRank score rank: 1727/2000", "statistical software Insurance industry experience": "<br/><b>data scientist</b> TextRank score rank: 762/2000<br/><b>data engineer</b> TextRank score rank: 1766/2000", "progressive experience data science statistical analysis data modeling years": "<br/><b>data scientist</b> TextRank score rank: 800/2000<br/><b>data engineer</b> TextRank score rank: 1726/2000", "regression segmentation decision tree time series design experiments": "<br/><b>data scientist</b> TextRank score rank: 918/2000<br/><b>data engineer</b> TextRank score rank: 1711/2000", "Advanced Degree": "<br/><b>data scientist</b> TextRank score rank: 336/2000<br/><b>data engineer</b> TextRank score rank: 1695/2000", "MBA": "<br/><b>data scientist</b> TextRank score rank: 576/2000<br/><b>data engineer</b> TextRank score rank: 1694/2000", "internal data processing visualization tools years": "<br/><b>data scientist</b> TextRank score rank: 913/2000<br/><b>data engineer</b> TextRank score rank: 1693/2000", "data sources": "<br/><b>data scientist</b> TextRank score rank: 1110/2000<br/><b>data engineer</b> TextRank score rank: 46/2000", "data warehouses": "<br/><b>data scientist</b> TextRank score rank: 1118/2000<br/><b>data engineer</b> TextRank score rank: 758/2000", "Regularization Boosting Random Forests Decision Trees Bayesian": "<br/><b>data scientist</b> TextRank score rank: 804/2000<br/><b>data engineer</b> TextRank score rank: 1692/2000", "Washington DC": "<br/><b>data scientist</b> TextRank score rank: 905/2000<br/><b>data engineer</b> TextRank score rank: 1691/2000", "hour": "<br/><b>data scientist</b> TextRank score rank: 1119/2000<br/><b>data engineer</b> TextRank score rank: 264/2000", "U S": "<br/><b>data scientist</b> TextRank score rank: 277/2000<br/><b>data engineer</b> TextRank score rank: 1690/2000", "Willingness": "<br/><b>data scientist</b> TextRank score rank: 1137/2000<br/><b>data engineer</b> TextRank score rank: 1088/2000", "Designing": "<br/><b>data scientist</b> TextRank score rank: 1146/2000<br/><b>data engineer</b> TextRank score rank: 682/2000", "Health": "<br/><b>data scientist</b> TextRank score rank: 1150/2000<br/><b>data engineer</b> TextRank score rank: 364/2000", "Google Analytics Adobe Analytics Experience": "<br/><b>data scientist</b> TextRank score rank: 266/2000<br/><b>data engineer</b> TextRank score rank: 1689/2000", "analyzing data 3rd party providers": "<br/><b>data scientist</b> TextRank score rank: 758/2000<br/><b>data engineer</b> TextRank score rank: 1688/2000", "Hadoop Hive Spark Experience visualizing": "<br/><b>data scientist</b> TextRank score rank: 797/2000<br/><b>data engineer</b> TextRank score rank: 1687/2000", "Map Reduce Hadoop Hive": "<br/><b>data scientist</b> TextRank score rank: 916/2000<br/><b>data engineer</b> TextRank score rank: 1686/2000", "data computing tools": "<br/><b>data scientist</b> TextRank score rank: 970/2000<br/><b>data engineer</b> TextRank score rank: 1685/2000", "etc Experience": "<br/><b>data scientist</b> TextRank score rank: 1123/2000<br/><b>data engineer</b> TextRank score rank: 1072/2000", "data science analysis": "<br/><b>data scientist</b> TextRank score rank: 656/2000<br/><b>data engineer</b> TextRank score rank: 1684/2000", "preferred Excellent communication collaborative skills years": "<br/><b>data scientist</b> TextRank score rank: 766/2000<br/><b>data engineer</b> TextRank score rank: 1683/2000", "Python R C": "<br/><b>data scientist</b> TextRank score rank: 798/2000<br/><b>data engineer</b> TextRank score rank: 1682/2000", "Mathematics Physics Engineering MS PhD": "<br/><b>data scientist</b> TextRank score rank: 955/2000<br/><b>data engineer</b> TextRank score rank: 1681/2000", "Scikit Learn Keras TensorFlow": "<br/><b>data scientist</b> TextRank score rank: 390/2000<br/><b>data engineer</b> TextRank score rank: 1680/2000", "ongoing operational needs": "<br/><b>data scientist</b> TextRank score rank: 472/2000<br/><b>data engineer</b> TextRank score rank: 1679/2000", "satisfactory job performance continuing availability funds": "<br/><b>data scientist</b> TextRank score rank: 516/2000<br/><b>data engineer</b> TextRank score rank: 1678/2000", "This full time year term appointment possibility extension conversion Career appointment": "<br/><b>data scientist</b> TextRank score rank: 735/2000<br/><b>data engineer</b> TextRank score rank: 1677/2000", "Career": "<br/><b>data scientist</b> TextRank score rank: 1052/2000<br/><b>data engineer</b> TextRank score rank: 510/2000", "quantitative methods principles statistics": "<br/><b>data scientist</b> TextRank score rank: 437/2000<br/><b>data engineer</b> TextRank score rank: 1676/2000", "masters level degree statistics biostatistics related fields": "<br/><b>data scientist</b> TextRank score rank: 518/2000<br/><b>data engineer</b> TextRank score rank: 1675/2000", "research setting": "<br/><b>data scientist</b> TextRank score rank: 661/2000<br/><b>data engineer</b> TextRank score rank: 1674/2000", "data sets": "<br/><b>data scientist</b> TextRank score rank: 629/2000<br/><b>data engineer</b> TextRank score rank: 1673/2000", "USAID": "<br/><b>data scientist</b> TextRank score rank: 655/2000<br/><b>data engineer</b> TextRank score rank: 1696/2000", "Design": "<br/><b>data scientist</b> TextRank score rank: 1136/2000<br/><b>data engineer</b> TextRank score rank: 24/2000", "modeling data mining years": "<br/><b>data scientist</b> TextRank score rank: 990/2000<br/><b>data engineer</b> TextRank score rank: 1697/2000", "Millions Billions": "<br/><b>data scientist</b> TextRank score rank: 917/2000<br/><b>data engineer</b> TextRank score rank: 1698/2000", "Interest causal inference": "<br/><b>data scientist</b> TextRank score rank: 187/2000<br/><b>data engineer</b> TextRank score rank: 1699/2000", "SAS Enterprise Guide manipulate data": "<br/><b>data scientist</b> TextRank score rank: 815/2000<br/><b>data engineer</b> TextRank score rank: 1723/2000", "SAS Enterprise Guide": "<br/><b>data scientist</b> TextRank score rank: 957/2000<br/><b>data engineer</b> TextRank score rank: 1722/2000", "broader goal": "<br/><b>data scientist</b> TextRank score rank: 959/2000<br/><b>data engineer</b> TextRank score rank: 1721/2000", "Strong interest gaming industry": "<br/><b>data scientist</b> TextRank score rank: 471/2000<br/><b>data engineer</b> TextRank score rank: 1720/2000", "HiveQL Knowledge data visualization Experience advanced analytics": "<br/><b>data scientist</b> TextRank score rank: 614/2000<br/><b>data engineer</b> TextRank score rank: 1719/2000", "software engineer data engineer data scientist Proficiency R": "<br/><b>data scientist</b> TextRank score rank: 729/2000<br/><b>data engineer</b> TextRank score rank: 1718/2000", "Advanced Degree Mathematics Statistics Economics Computer Science related fields": "<br/><b>data scientist</b> TextRank score rank: 296/2000<br/><b>data engineer</b> TextRank score rank: 1717/2000", "Degree Mathematics Statistics Economics Computer Science": "<br/><b>data scientist</b> TextRank score rank: 343/2000<br/><b>data engineer</b> TextRank score rank: 1716/2000", "Amazon Web Services AWS": "<br/><b>data scientist</b> TextRank score rank: 125/2000<br/><b>data engineer</b> TextRank score rank: 1715/2000", "Proficient R Python": "<br/><b>data scientist</b> TextRank score rank: 547/2000<br/><b>data engineer</b> TextRank score rank: 1714/2000", "tasks text mining sentiment analysis language": "<br/><b>data scientist</b> TextRank score rank: 585/2000<br/><b>data engineer</b> TextRank score rank: 1713/2000", "professional experience Data Scientist NLP experience": "<br/><b>data scientist</b> TextRank score rank: 694/2000<br/><b>data engineer</b> TextRank score rank: 1724/2000", "unstructured text data": "<br/><b>data scientist</b> TextRank score rank: 704/2000<br/><b>data engineer</b> TextRank score rank: 1712/2000", "classification information retrieval": "<br/><b>data scientist</b> TextRank score rank: 711/2000<br/><b>data engineer</b> TextRank score rank: 1710/2000", "process": "<br/><b>data scientist</b> TextRank score rank: 1065/2000<br/><b>data engineer</b> TextRank score rank: 724/2000", "initiative": "<br/><b>data scientist</b> TextRank score rank: 1133/2000<br/><b>data engineer</b> TextRank score rank: 1073/2000", "U S government U S citizenship": "<br/><b>data scientist</b> TextRank score rank: 946/2000<br/><b>data engineer</b> TextRank score rank: 1709/2000", "Minimum years experience": "<br/><b>data scientist</b> TextRank score rank: 1064/2000<br/><b>data engineer</b> TextRank score rank: 864/2000", "Familiarity Agile": "<br/><b>data scientist</b> TextRank score rank: 542/2000<br/><b>data engineer</b> TextRank score rank: 1708/2000", "k NN Naive Bayes SVM Decision Forests": "<br/><b>data scientist</b> TextRank score rank: 232/2000<br/><b>data engineer</b> TextRank score rank: 1707/2000", "Intermediate advanced experience": "<br/><b>data scientist</b> TextRank score rank: 837/2000<br/><b>data engineer</b> TextRank score rank: 1706/2000", "original innovative techniques style Ability": "<br/><b>data scientist</b> TextRank score rank: 880/2000<br/><b>data engineer</b> TextRank score rank: 1705/2000", "Python Java B S Computer Science Software Engineering Information Science Mathematics Statistics Electrical Engineering Physics related fields": "<br/><b>data scientist</b> TextRank score rank: 725/2000<br/><b>data engineer</b> TextRank score rank: 1704/2000", "Communication": "<br/><b>data scientist</b> TextRank score rank: 901/2000<br/><b>data engineer</b> TextRank score rank: 1099/2000", "seven years": "<br/><b>data scientist</b> TextRank score rank: 1159/2000<br/><b>data engineer</b> TextRank score rank: 1089/2000", "data Experience": "<br/><b>data scientist</b> TextRank score rank: 717/2000<br/><b>data engineer</b> TextRank score rank: 923/2000", "large volume data Experience": "<br/><b>data scientist</b> TextRank score rank: 746/2000<br/><b>data engineer</b> TextRank score rank: 1703/2000", "healthcare industry Proven ability experience design development solutions increasing yield Proven analytical skills experience": "<br/><b>data scientist</b> TextRank score rank: 755/2000<br/><b>data engineer</b> TextRank score rank: 1702/2000", "statistical analysis data mining algorithms mathematical segmentation": "<br/><b>data scientist</b> TextRank score rank: 915/2000<br/><b>data engineer</b> TextRank score rank: 1701/2000", "Working knowledge statistical programming languages": "<br/><b>data scientist</b> TextRank score rank: 925/2000<br/><b>data engineer</b> TextRank score rank: 1700/2000", "Strong SQL experience ability": "<br/><b>data scientist</b> TextRank score rank: 950/2000<br/><b>data engineer</b> TextRank score rank: 1123/2000", "clear precise actionable manner": "<br/><b>data scientist</b> TextRank score rank: 862/2000<br/><b>data engineer</b> TextRank score rank: 1780/2000", "Experience data": "<br/><b>data scientist</b> TextRank score rank: 820/2000<br/><b>data engineer</b> TextRank score rank: 1121/2000", "Travel Master Degree statistics actuarial science related field study Experience data mining predictive modeling experience": "<br/><b>data scientist</b> TextRank score rank: 910/2000<br/><b>data engineer</b> TextRank score rank: 1120/2000", "Extensive knowledge tools data mining statistics Experience HR Analytics Strong knowledge MS Office products": "<br/><b>data scientist</b> TextRank score rank: 927/2000<br/><b>data engineer</b> TextRank score rank: 1110/2000", "statistical modeling programming Experience Tableau": "<br/><b>data scientist</b> TextRank score rank: 936/2000<br/><b>data engineer</b> TextRank score rank: 1108/2000", "team environment": "<br/><b>data scientist</b> TextRank score rank: 1097/2000<br/><b>data engineer</b> TextRank score rank: 991/2000", "MS Office": "<br/><b>data scientist</b> TextRank score rank: 1103/2000<br/><b>data engineer</b> TextRank score rank: 660/2000", "measurement teams product teams members": "<br/><b>data scientist</b> TextRank score rank: 220/2000<br/><b>data engineer</b> TextRank score rank: 1107/2000", "wider analytical teams": "<br/><b>data scientist</b> TextRank score rank: 234/2000<br/><b>data engineer</b> TextRank score rank: 1109/2000", "challenges years work experience technology industry": "<br/><b>data scientist</b> TextRank score rank: 965/2000<br/><b>data engineer</b> TextRank score rank: 741/2000", "public speaking engagements Extensive software development experience": "<br/><b>data scientist</b> TextRank score rank: 982/2000<br/><b>data engineer</b> TextRank score rank: 756/2000", "Extensive experience software development expertise": "<br/><b>data scientist</b> TextRank score rank: 1003/2000<br/><b>data engineer</b> TextRank score rank: 773/2000", "Strong customer facing relationship building skills": "<br/><b>data scientist</b> TextRank score rank: 1053/2000<br/><b>data engineer</b> TextRank score rank: 834/2000", "present big picture offer solutions": "<br/><b>data scientist</b> TextRank score rank: 1056/2000<br/><b>data engineer</b> TextRank score rank: 856/2000", "custom solutions": "<br/><b>data scientist</b> TextRank score rank: 1059/2000<br/><b>data engineer</b> TextRank score rank: 888/2000", "Python Experience": "<br/><b>data scientist</b> TextRank score rank: 1062/2000<br/><b>data engineer</b> TextRank score rank: 897/2000", "Prior technical paper publications": "<br/><b>data scientist</b> TextRank score rank: 1071/2000<br/><b>data engineer</b> TextRank score rank: 947/2000", "business challenges": "<br/><b>data scientist</b> TextRank score rank: 1075/2000<br/><b>data engineer</b> TextRank score rank: 956/2000", "bright charismatic people": "<br/><b>data scientist</b> TextRank score rank: 1078/2000<br/><b>data engineer</b> TextRank score rank: 962/2000", "highly reliable cloud services Experience": "<br/><b>data scientist</b> TextRank score rank: 1085/2000<br/><b>data engineer</b> TextRank score rank: 1008/2000", "Strong algorithmic problem": "<br/><b>data scientist</b> TextRank score rank: 1105/2000<br/><b>data engineer</b> TextRank score rank: 1057/2000", "highly reliable service offerings": "<br/><b>data scientist</b> TextRank score rank: 1109/2000<br/><b>data engineer</b> TextRank score rank: 1062/2000", "C": "<br/><b>data scientist</b> TextRank score rank: 1112/2000<br/><b>data engineer</b> TextRank score rank: 607/2000", "uncover": "<br/><b>data scientist</b> TextRank score rank: 1116/2000<br/><b>data engineer</b> TextRank score rank: 1071/2000", "Windows Linux": "<br/><b>data scientist</b> TextRank score rank: 1127/2000<br/><b>data engineer</b> TextRank score rank: 716/2000", "JAVA C": "<br/><b>data scientist</b> TextRank score rank: 1142/2000<br/><b>data engineer</b> TextRank score rank: 1090/2000", "An extraordinarily intelligent rigorous thinker": "<br/><b>data scientist</b> TextRank score rank: 1144/2000<br/><b>data engineer</b> TextRank score rank: 1096/2000", "Apple discriminate retaliate applicants inquire": "<br/><b>data scientist</b> TextRank score rank: 753/2000<br/><b>data engineer</b> TextRank score rank: 736/2000", "compensation applicants": "<br/><b>data scientist</b> TextRank score rank: 772/2000<br/><b>data engineer</b> TextRank score rank: 759/2000", "Apple": "<br/><b>data scientist</b> TextRank score rank: 1077/2000<br/><b>data engineer</b> TextRank score rank: 25/2000", "SQL Proven": "<br/><b>data scientist</b> TextRank score rank: 747/2000<br/><b>data engineer</b> TextRank score rank: 1113/2000", "Prior experience finance": "<br/><b>data scientist</b> TextRank score rank: 183/2000<br/><b>data engineer</b> TextRank score rank: 1114/2000", "A solid understanding ad networks media campaigns": "<br/><b>data scientist</b> TextRank score rank: 469/2000<br/><b>data engineer</b> TextRank score rank: 1115/2000", "Spark Streaming Experience Data": "<br/><b>data scientist</b> TextRank score rank: 848/2000<br/><b>data engineer</b> TextRank score rank: 1116/2000", "e g Hive Spark Experience": "<br/><b>data scientist</b> TextRank score rank: 878/2000<br/><b>data engineer</b> TextRank score rank: 1118/2000", "RNN LSTM GANs Streaming Analytics e": "<br/><b>data scientist</b> TextRank score rank: 934/2000<br/><b>data engineer</b> TextRank score rank: 1119/2000", "dynamic innovative years applicable experience Experience Digital Media Experience": "<br/><b>data scientist</b> TextRank score rank: 727/2000<br/><b>data engineer</b> TextRank score rank: 1111/2000", "user event data analysis Experience": "<br/><b>data scientist</b> TextRank score rank: 849/2000<br/><b>data engineer</b> TextRank score rank: 1112/2000", "SQL Excel": "<br/><b>data scientist</b> TextRank score rank: 870/2000<br/><b>data engineer</b> TextRank score rank: 1117/2000", "technologies": "<br/><b>data scientist</b> TextRank score rank: 1088/2000<br/><b>data engineer</b> TextRank score rank: 34/2000", "schemas": "<br/><b>data scientist</b> TextRank score rank: 1715/2000<br/><b>data engineer</b> TextRank score rank: 346/2000", "Gym membership compensation": "<br/><b>data scientist</b> TextRank score rank: 1716/2000<br/><b>data engineer</b> TextRank score rank: 13/2000", "Git SDLC": "<br/><b>data scientist</b> TextRank score rank: 1717/2000<br/><b>data engineer</b> TextRank score rank: 237/2000", "advanced courses data science machine": "<br/><b>data scientist</b> TextRank score rank: 1718/2000<br/><b>data engineer</b> TextRank score rank: 246/2000", "communicate data driven insight": "<br/><b>data scientist</b> TextRank score rank: 1719/2000<br/><b>data engineer</b> TextRank score rank: 226/2000", "Knowledge digital AdTech landscape": "<br/><b>data scientist</b> TextRank score rank: 1720/2000<br/><b>data engineer</b> TextRank score rank: 149/2000", "AdTech": "<br/><b>data scientist</b> TextRank score rank: 1721/2000<br/><b>data engineer</b> TextRank score rank: 321/2000", "Creative analytic problem solver diligent attention detail": "<br/><b>data scientist</b> TextRank score rank: 1722/2000<br/><b>data engineer</b> TextRank score rank: 319/2000", "Experience Cloudera": "<br/><b>data scientist</b> TextRank score rank: 1724/2000<br/><b>data engineer</b> TextRank score rank: 122/2000", "MPP": "<br/><b>data scientist</b> TextRank score rank: 1735/2000<br/><b>data engineer</b> TextRank score rank: 87/2000", "various data sources": "<br/><b>data scientist</b> TextRank score rank: 1725/2000<br/><b>data engineer</b> TextRank score rank: 223/2000", "Willingness travel": "<br/><b>data scientist</b> TextRank score rank: 1726/2000<br/><b>data engineer</b> TextRank score rank: 38/2000", "Python Django Flask": "<br/><b>data scientist</b> TextRank score rank: 1727/2000<br/><b>data engineer</b> TextRank score rank: 135/2000", "Responsible staying current enterprise standards industry standards technologies": "<br/><b>data scientist</b> TextRank score rank: 1728/2000<br/><b>data engineer</b> TextRank score rank: 292/2000", "data access data storage techniques": "<br/><b>data scientist</b> TextRank score rank: 1729/2000<br/><b>data engineer</b> TextRank score rank: 354/2000", "video person hour": "<br/><b>data scientist</b> TextRank score rank: 1730/2000<br/><b>data engineer</b> TextRank score rank: 199/2000", "employee benefits": "<br/><b>data scientist</b> TextRank score rank: 1731/2000<br/><b>data engineer</b> TextRank score rank: 158/2000", "kitchen": "<br/><b>data scientist</b> TextRank score rank: 1732/2000<br/><b>data engineer</b> TextRank score rank: 153/2000", "data visualization tools": "<br/><b>data scientist</b> TextRank score rank: 1733/2000<br/><b>data engineer</b> TextRank score rank: 107/2000", "big data data pipelines": "<br/><b>data scientist</b> TextRank score rank: 1734/2000<br/><b>data engineer</b> TextRank score rank: 72/2000", "data transformation data structures metadata dependency workload management": "<br/><b>data scientist</b> TextRank score rank: 1712/2000<br/><b>data engineer</b> TextRank score rank: 180/2000", "working familiarity variety": "<br/><b>data scientist</b> TextRank score rank: 1723/2000<br/><b>data engineer</b> TextRank score rank: 108/2000", "NoSQL databases": "<br/><b>data scientist</b> TextRank score rank: 1711/2000<br/><b>data engineer</b> TextRank score rank: 104/2000", "third": "<br/><b>data scientist</b> TextRank score rank: 1697/2000<br/><b>data engineer</b> TextRank score rank: 83/2000", "Mustache Get Mustache": "<br/><b>data scientist</b> TextRank score rank: 1687/2000<br/><b>data engineer</b> TextRank score rank: 101/2000", "data flows": "<br/><b>data scientist</b> TextRank score rank: 1688/2000<br/><b>data engineer</b> TextRank score rank: 195/2000", "Pet friendly office environment": "<br/><b>data scientist</b> TextRank score rank: 1689/2000<br/><b>data engineer</b> TextRank score rank: 150/2000", "Fixed term contract option perm": "<br/><b>data scientist</b> TextRank score rank: 1690/2000<br/><b>data engineer</b> TextRank score rank: 171/2000", "Experience Agile Methodologies Scrum Kanban": "<br/><b>data scientist</b> TextRank score rank: 1691/2000<br/><b>data engineer</b> TextRank score rank: 173/2000", "least one high level programming language": "<br/><b>data scientist</b> TextRank score rank: 1692/2000<br/><b>data engineer</b> TextRank score rank: 10/2000", "data engineering": "<br/><b>data scientist</b> TextRank score rank: 1693/2000<br/><b>data engineer</b> TextRank score rank: 179/2000", "millions daily players": "<br/><b>data scientist</b> TextRank score rank: 1694/2000<br/><b>data engineer</b> TextRank score rank: 35/2000", "millions daily": "<br/><b>data scientist</b> TextRank score rank: 1695/2000<br/><b>data engineer</b> TextRank score rank: 52/2000", "cool people": "<br/><b>data scientist</b> TextRank score rank: 1696/2000<br/><b>data engineer</b> TextRank score rank: 82/2000", "unstructured data acquisition Realtime Data Integration Patterns Engagement": "<br/><b>data scientist</b> TextRank score rank: 1698/2000<br/><b>data engineer</b> TextRank score rank: 613/2000", "data services": "<br/><b>data scientist</b> TextRank score rank: 1709/2000<br/><b>data engineer</b> TextRank score rank: 621/2000", "Operational analytical data provisioning insights data landscape": "<br/><b>data scientist</b> TextRank score rank: 1699/2000<br/><b>data engineer</b> TextRank score rank: 637/2000", "Group Data": "<br/><b>data scientist</b> TextRank score rank: 1700/2000<br/><b>data engineer</b> TextRank score rank: 644/2000", "Assist driving data services strategy": "<br/><b>data scientist</b> TextRank score rank: 1701/2000<br/><b>data engineer</b> TextRank score rank: 651/2000", "Realtime Data Integration Patterns": "<br/><b>data scientist</b> TextRank score rank: 1702/2000<br/><b>data engineer</b> TextRank score rank: 670/2000", "Building Big Data Platform": "<br/><b>data scientist</b> TextRank score rank: 1703/2000<br/><b>data engineer</b> TextRank score rank: 688/2000", "next level excellence Building Big Data Platform": "<br/><b>data scientist</b> TextRank score rank: 1704/2000<br/><b>data engineer</b> TextRank score rank: 692/2000", "Data Flow Patterns": "<br/><b>data scientist</b> TextRank score rank: 1705/2000<br/><b>data engineer</b> TextRank score rank: 701/2000", "Data Initiatives": "<br/><b>data scientist</b> TextRank score rank: 1706/2000<br/><b>data engineer</b> TextRank score rank: 710/2000", "Strategic Alignment Group Architecture": "<br/><b>data scientist</b> TextRank score rank: 1707/2000<br/><b>data engineer</b> TextRank score rank: 812/2000", "Visualisation Storyboarding experience Stats": "<br/><b>data scientist</b> TextRank score rank: 1708/2000<br/><b>data engineer</b> TextRank score rank: 880/2000", "Building operation frameworks processes": "<br/><b>data scientist</b> TextRank score rank: 1710/2000<br/><b>data engineer</b> TextRank score rank: 881/2000", "Net Language experience": "<br/><b>data scientist</b> TextRank score rank: 1736/2000<br/><b>data engineer</b> TextRank score rank: 908/2000", "Banking financial sector experience": "<br/><b>data scientist</b> TextRank score rank: 1737/2000<br/><b>data engineer</b> TextRank score rank: 913/2000", "Assist": "<br/><b>data scientist</b> TextRank score rank: 1738/2000<br/><b>data engineer</b> TextRank score rank: 260/2000", "Apache Flink Spark Streaming Apache Storm Kafka Streams others": "<br/><b>data scientist</b> TextRank score rank: 1765/2000<br/><b>data engineer</b> TextRank score rank: 2/2000", "Experience building stream processing applications": "<br/><b>data scientist</b> TextRank score rank: 1766/2000<br/><b>data engineer</b> TextRank score rank: 3/2000", "Python Go Java Scala": "<br/><b>data scientist</b> TextRank score rank: 1767/2000<br/><b>data engineer</b> TextRank score rank: 6/2000", "massive petabyte scale semi structured datasets": "<br/><b>data scientist</b> TextRank score rank: 1768/2000<br/><b>data engineer</b> TextRank score rank: 7/2000", "Apache Flink": "<br/><b>data scientist</b> TextRank score rank: 1769/2000<br/><b>data engineer</b> TextRank score rank: 8/2000", "data technologies": "<br/><b>data scientist</b> TextRank score rank: 1770/2000<br/><b>data engineer</b> TextRank score rank: 9/2000", "growth mindset": "<br/><b>data scientist</b> TextRank score rank: 1771/2000<br/><b>data engineer</b> TextRank score rank: 12/2000", "self awareness": "<br/><b>data scientist</b> TextRank score rank: 1772/2000<br/><b>data engineer</b> TextRank score rank: 14/2000", "large complex highly dimensional data": "<br/><b>data scientist</b> TextRank score rank: 1773/2000<br/><b>data engineer</b> TextRank score rank: 15/2000", "Extras": "<br/><b>data scientist</b> TextRank score rank: 1774/2000<br/><b>data engineer</b> TextRank score rank: 5/2000", "perfect enemy": "<br/><b>data scientist</b> TextRank score rank: 1775/2000<br/><b>data engineer</b> TextRank score rank: 19/2000", "You curious excellent analytical problem": "<br/><b>data scientist</b> TextRank score rank: 1776/2000<br/><b>data engineer</b> TextRank score rank: 21/2000", "career categories": "<br/><b>data scientist</b> TextRank score rank: 1777/2000<br/><b>data engineer</b> TextRank score rank: 1/2000", "realtime streaming compute components Experience data modeling data architecture": "<br/><b>data scientist</b> TextRank score rank: 1778/2000<br/><b>data engineer</b> TextRank score rank: 268/2000", "big data patterns": "<br/><b>data scientist</b> TextRank score rank: 1779/2000<br/><b>data engineer</b> TextRank score rank: 335/2000", "Knowledgable distributed storage network resources level hosts": "<br/><b>data scientist</b> TextRank score rank: 1780/2000<br/><b>data engineer</b> TextRank score rank: 349/2000", "DCs troubleshoot prevent performance issues": "<br/><b>data scientist</b> TextRank score rank: 1781/2000<br/><b>data engineer</b> TextRank score rank: 357/2000", "particular MapReduce Spark Spark SQL": "<br/><b>data scientist</b> TextRank score rank: 1782/2000<br/><b>data engineer</b> TextRank score rank: 776/2000", "large scale data pipelines": "<br/><b>data scientist</b> TextRank score rank: 1783/2000<br/><b>data engineer</b> TextRank score rank: 405/2000", "Spark Streaming Hive YARN MR2 Experience building": "<br/><b>data scientist</b> TextRank score rank: 1784/2000<br/><b>data engineer</b> TextRank score rank: 869/2000", "MapReduce Spark": "<br/><b>data scientist</b> TextRank score rank: 1785/2000<br/><b>data engineer</b> TextRank score rank: 259/2000", "ie warehousing concepts efficient storage query HDFS data security privacy": "<br/><b>data scientist</b> TextRank score rank: 1786/2000<br/><b>data engineer</b> TextRank score rank: 477/2000", "highly scalable data systems services": "<br/><b>data scientist</b> TextRank score rank: 1787/2000<br/><b>data engineer</b> TextRank score rank: 704/2000", "batch": "<br/><b>data scientist</b> TextRank score rank: 1764/2000<br/><b>data engineer</b> TextRank score rank: 714/2000", "commitment data governance Demonstrated ability": "<br/><b>data scientist</b> TextRank score rank: 1763/2000<br/><b>data engineer</b> TextRank score rank: 810/2000", "analytics data engineering role": "<br/><b>data scientist</b> TextRank score rank: 1762/2000<br/><b>data engineer</b> TextRank score rank: 836/2000", "verbal visual communication capabilities Ability": "<br/><b>data scientist</b> TextRank score rank: 1749/2000<br/><b>data engineer</b> TextRank score rank: 842/2000", "relevant business people analytics": "<br/><b>data scientist</b> TextRank score rank: 1739/2000<br/><b>data engineer</b> TextRank score rank: 861/2000", "BS MS degree quantitative field equivalent practical experience": "<br/><b>data scientist</b> TextRank score rank: 1740/2000<br/><b>data engineer</b> TextRank score rank: 898/2000", "data analytics solutions": "<br/><b>data scientist</b> TextRank score rank: 1741/2000<br/><b>data engineer</b> TextRank score rank: 907/2000", "continuous refinement improvement": "<br/><b>data scientist</b> TextRank score rank: 1742/2000<br/><b>data engineer</b> TextRank score rank: 915/2000", "least years": "<br/><b>data scientist</b> TextRank score rank: 1743/2000<br/><b>data engineer</b> TextRank score rank: 429/2000", "e g Linux Mac OS Experience": "<br/><b>data scientist</b> TextRank score rank: 1744/2000<br/><b>data engineer</b> TextRank score rank: 667/2000", "nice required Data modeling Experience working search engines": "<br/><b>data scientist</b> TextRank score rank: 1745/2000<br/><b>data engineer</b> TextRank score rank: 804/2000", "analytic skills Solid computer science systems foundations ability": "<br/><b>data scientist</b> TextRank score rank: 1746/2000<br/><b>data engineer</b> TextRank score rank: 829/2000", "new domains Proven system development": "<br/><b>data scientist</b> TextRank score rank: 1747/2000<br/><b>data engineer</b> TextRank score rank: 854/2000", "Machine learning Natural": "<br/><b>data scientist</b> TextRank score rank: 1748/2000<br/><b>data engineer</b> TextRank score rank: 867/2000", "Good communication skills teamwork Passion": "<br/><b>data scientist</b> TextRank score rank: 1750/2000<br/><b>data engineer</b> TextRank score rank: 889/2000", "Natural language processing": "<br/><b>data scientist</b> TextRank score rank: 1761/2000<br/><b>data engineer</b> TextRank score rank: 912/2000", "Apache": "<br/><b>data scientist</b> TextRank score rank: 1751/2000<br/><b>data engineer</b> TextRank score rank: 499/2000", "Work clients model data landscape": "<br/><b>data scientist</b> TextRank score rank: 1752/2000<br/><b>data engineer</b> TextRank score rank: 895/2000", "data extracts": "<br/><b>data scientist</b> TextRank score rank: 1753/2000<br/><b>data engineer</b> TextRank score rank: 926/2000", "operational ETL data pipelines": "<br/><b>data scientist</b> TextRank score rank: 1754/2000<br/><b>data engineer</b> TextRank score rank: 931/2000", "data fields hypotheses": "<br/><b>data scientist</b> TextRank score rank: 1755/2000<br/><b>data engineer</b> TextRank score rank: 943/2000", "Collaborate data scientists": "<br/><b>data scientist</b> TextRank score rank: 1756/2000<br/><b>data engineer</b> TextRank score rank: 950/2000", "Strong development background experience": "<br/><b>data scientist</b> TextRank score rank: 1757/2000<br/><b>data engineer</b> TextRank score rank: 513/2000", "Processing Spark Hadoop EMR": "<br/><b>data scientist</b> TextRank score rank: 1758/2000<br/><b>data engineer</b> TextRank score rank: 636/2000", "MPP AWS Redshift Oracle Exadata Teradata IBM Netezza": "<br/><b>data scientist</b> TextRank score rank: 1759/2000<br/><b>data engineer</b> TextRank score rank: 671/2000", "Traditional RDBMS MS SQL Server Oracle": "<br/><b>data scientist</b> TextRank score rank: 1760/2000<br/><b>data engineer</b> TextRank score rank: 805/2000", "Redshift Oracle": "<br/><b>data scientist</b> TextRank score rank: 1686/2000<br/><b>data engineer</b> TextRank score rank: 831/2000", "Distributed Systems": "<br/><b>data scientist</b> TextRank score rank: 1788/2000<br/><b>data engineer</b> TextRank score rank: 961/2000", "clear timely professional manner": "<br/><b>data scientist</b> TextRank score rank: 1685/2000<br/><b>data engineer</b> TextRank score rank: 749/2000", "context data processing Experience proficiency Python Experience design implementation data": "<br/><b>data scientist</b> TextRank score rank: 1683/2000<br/><b>data engineer</b> TextRank score rank: 312/2000", "Google Cloud Platform DevOps Stack development experience Apache Airflow data pipeline tools": "<br/><b>data scientist</b> TextRank score rank: 1608/2000<br/><b>data engineer</b> TextRank score rank: 368/2000", "various sources data Manage": "<br/><b>data scientist</b> TextRank score rank: 1609/2000<br/><b>data engineer</b> TextRank score rank: 373/2000", "Data Engineering Hadoop Spark Data Processing products": "<br/><b>data scientist</b> TextRank score rank: 1610/2000<br/><b>data engineer</b> TextRank score rank: 382/2000", "data science production environments": "<br/><b>data scientist</b> TextRank score rank: 1611/2000<br/><b>data engineer</b> TextRank score rank: 383/2000", "working engineering team best track record data": "<br/><b>data scientist</b> TextRank score rank: 1612/2000<br/><b>data engineer</b> TextRank score rank: 384/2000", "third party elements data pipeline": "<br/><b>data scientist</b> TextRank score rank: 1613/2000<br/><b>data engineer</b> TextRank score rank: 390/2000", "key data functions": "<br/><b>data scientist</b> TextRank score rank: 1614/2000<br/><b>data engineer</b> TextRank score rank: 391/2000", "Support sophisticated predictive data products": "<br/><b>data scientist</b> TextRank score rank: 1615/2000<br/><b>data engineer</b> TextRank score rank: 395/2000", "Data Engineering Hadoop Spark Data": "<br/><b>data scientist</b> TextRank score rank: 1616/2000<br/><b>data engineer</b> TextRank score rank: 397/2000", "data inconsistencies": "<br/><b>data scientist</b> TextRank score rank: 1617/2000<br/><b>data engineer</b> TextRank score rank: 401/2000", "Cloud experience": "<br/><b>data scientist</b> TextRank score rank: 1619/2000<br/><b>data engineer</b> TextRank score rank: 434/2000", "outputs Data Science models": "<br/><b>data scientist</b> TextRank score rank: 1630/2000<br/><b>data engineer</b> TextRank score rank: 441/2000", "open source tools": "<br/><b>data scientist</b> TextRank score rank: 1620/2000<br/><b>data engineer</b> TextRank score rank: 288/2000", "similar Software Engineering Data Science etc experience software": "<br/><b>data scientist</b> TextRank score rank: 1621/2000<br/><b>data engineer</b> TextRank score rank: 558/2000", "infrastructure layout": "<br/><b>data scientist</b> TextRank score rank: 1622/2000<br/><b>data engineer</b> TextRank score rank: 595/2000", "cloud service integrations": "<br/><b>data scientist</b> TextRank score rank: 1623/2000<br/><b>data engineer</b> TextRank score rank: 634/2000", "Big Query Redshift Spectrum S3 Athena Kafka Spark Storm Flink Beam Presto Hive ETL": "<br/><b>data scientist</b> TextRank score rank: 1624/2000<br/><b>data engineer</b> TextRank score rank: 645/2000", "Apache Airflow": "<br/><b>data scientist</b> TextRank score rank: 1625/2000<br/><b>data engineer</b> TextRank score rank: 744/2000", "python": "<br/><b>data scientist</b> TextRank score rank: 1626/2000<br/><b>data engineer</b> TextRank score rank: 868/2000", "transformations": "<br/><b>data scientist</b> TextRank score rank: 1627/2000<br/><b>data engineer</b> TextRank score rank: 936/2000", "Manage": "<br/><b>data scientist</b> TextRank score rank: 1628/2000<br/><b>data engineer</b> TextRank score rank: 67/2000", "Scala Java": "<br/><b>data scientist</b> TextRank score rank: 1629/2000<br/><b>data engineer</b> TextRank score rank: 485/2000", "401K": "<br/><b>data scientist</b> TextRank score rank: 1607/2000<br/><b>data engineer</b> TextRank score rank: 356/2000", "Agile projects Data Warehousing experience": "<br/><b>data scientist</b> TextRank score rank: 1618/2000<br/><b>data engineer</b> TextRank score rank: 852/2000", "Experience multiple Database technologies": "<br/><b>data scientist</b> TextRank score rank: 1606/2000<br/><b>data engineer</b> TextRank score rank: 921/2000", "technical aspects Data Technology industry personal professional development work life": "<br/><b>data scientist</b> TextRank score rank: 1592/2000<br/><b>data engineer</b> TextRank score rank: 929/2000", "different multiple projects": "<br/><b>data scientist</b> TextRank score rank: 1582/2000<br/><b>data engineer</b> TextRank score rank: 973/2000", "Titan Experience developing solutions": "<br/><b>data scientist</b> TextRank score rank: 1583/2000<br/><b>data engineer</b> TextRank score rank: 982/2000", "Cloud": "<br/><b>data scientist</b> TextRank score rank: 1584/2000<br/><b>data engineer</b> TextRank score rank: 933/2000", "data streaming Design": "<br/><b>data scientist</b> TextRank score rank: 1585/2000<br/><b>data engineer</b> TextRank score rank: 39/2000", "data warehouse data models": "<br/><b>data scientist</b> TextRank score rank: 1586/2000<br/><b>data engineer</b> TextRank score rank: 42/2000", "source data e g data profiling definition mapping Design": "<br/><b>data scientist</b> TextRank score rank: 1587/2000<br/><b>data engineer</b> TextRank score rank: 45/2000", "data Manage data growth usage": "<br/><b>data scientist</b> TextRank score rank: 1588/2000<br/><b>data engineer</b> TextRank score rank: 218/2000", "data monitoring solutions procedures": "<br/><b>data scientist</b> TextRank score rank: 1589/2000<br/><b>data engineer</b> TextRank score rank: 219/2000", "efficient data loads": "<br/><b>data scientist</b> TextRank score rank: 1590/2000<br/><b>data engineer</b> TextRank score rank: 47/2000", "good data governance Work": "<br/><b>data scientist</b> TextRank score rank: 1591/2000<br/><b>data engineer</b> TextRank score rank: 224/2000", "unstructured data loads": "<br/><b>data scientist</b> TextRank score rank: 1593/2000<br/><b>data engineer</b> TextRank score rank: 48/2000", "functional data team knowledge gathering": "<br/><b>data scientist</b> TextRank score rank: 1604/2000<br/><b>data engineer</b> TextRank score rank: 225/2000", "managing data": "<br/><b>data scientist</b> TextRank score rank: 1594/2000<br/><b>data engineer</b> TextRank score rank: 51/2000", "traditional structured data ETL techniques Design": "<br/><b>data scientist</b> TextRank score rank: 1595/2000<br/><b>data engineer</b> TextRank score rank: 53/2000", "technical data related support source system teams": "<br/><b>data scientist</b> TextRank score rank: 1596/2000<br/><b>data engineer</b> TextRank score rank: 56/2000", "usability data": "<br/><b>data scientist</b> TextRank score rank: 1597/2000<br/><b>data engineer</b> TextRank score rank: 54/2000", "real time data load solutions": "<br/><b>data scientist</b> TextRank score rank: 1598/2000<br/><b>data engineer</b> TextRank score rank: 55/2000", "appropriate aggregation data structures": "<br/><b>data scientist</b> TextRank score rank: 1599/2000<br/><b>data engineer</b> TextRank score rank: 57/2000", "changes data organisation": "<br/><b>data scientist</b> TextRank score rank: 1600/2000<br/><b>data engineer</b> TextRank score rank: 249/2000", "troubleshoot technical data issues": "<br/><b>data scientist</b> TextRank score rank: 1601/2000<br/><b>data engineer</b> TextRank score rank: 58/2000", "working data business intelligence analytics environment": "<br/><b>data scientist</b> TextRank score rank: 1602/2000<br/><b>data engineer</b> TextRank score rank: 257/2000", "SQL Data analysis Data visualisation Data": "<br/><b>data scientist</b> TextRank score rank: 1603/2000<br/><b>data engineer</b> TextRank score rank: 59/2000", "data management analytics": "<br/><b>data scientist</b> TextRank score rank: 1605/2000<br/><b>data engineer</b> TextRank score rank: 63/2000", "meta data solutions": "<br/><b>data scientist</b> TextRank score rank: 1631/2000<br/><b>data engineer</b> TextRank score rank: 266/2000", "team dynamics performance Complex solution service design implementation": "<br/><b>data scientist</b> TextRank score rank: 1632/2000<br/><b>data engineer</b> TextRank score rank: 274/2000", "effective efficient data models": "<br/><b>data scientist</b> TextRank score rank: 1633/2000<br/><b>data engineer</b> TextRank score rank: 64/2000", "Microsoft business intelligence data technologies": "<br/><b>data scientist</b> TextRank score rank: 1660/2000<br/><b>data engineer</b> TextRank score rank: 60/2000", "speed access Design": "<br/><b>data scientist</b> TextRank score rank: 1661/2000<br/><b>data engineer</b> TextRank score rank: 73/2000", "data processes": "<br/><b>data scientist</b> TextRank score rank: 1662/2000<br/><b>data engineer</b> TextRank score rank: 65/2000", "data elements": "<br/><b>data scientist</b> TextRank score rank: 1663/2000<br/><b>data engineer</b> TextRank score rank: 68/2000", "Work source system owners analysts": "<br/><b>data scientist</b> TextRank score rank: 1664/2000<br/><b>data engineer</b> TextRank score rank: 77/2000", "availability accuracy Design": "<br/><b>data scientist</b> TextRank score rank: 1665/2000<br/><b>data engineer</b> TextRank score rank: 316/2000", "Responsible team activities team dynamics performance Manage project task delivery team": "<br/><b>data scientist</b> TextRank score rank: 1666/2000<br/><b>data engineer</b> TextRank score rank: 325/2000", "supplement enhance context Design": "<br/><b>data scientist</b> TextRank score rank: 1667/2000<br/><b>data engineer</b> TextRank score rank: 80/2000", "interface monitoring management solutions": "<br/><b>data scientist</b> TextRank score rank: 1668/2000<br/><b>data engineer</b> TextRank score rank: 81/2000", "solutions Positive engagement team activities": "<br/><b>data scientist</b> TextRank score rank: 1669/2000<br/><b>data engineer</b> TextRank score rank: 92/2000", "data access e g batch exports": "<br/><b>data scientist</b> TextRank score rank: 1670/2000<br/><b>data engineer</b> TextRank score rank: 75/2000", "Work analysts": "<br/><b>data scientist</b> TextRank score rank: 1671/2000<br/><b>data engineer</b> TextRank score rank: 86/2000", "e g text speech images video Design": "<br/><b>data scientist</b> TextRank score rank: 1672/2000<br/><b>data engineer</b> TextRank score rank: 79/2000", "knowledge share Quality control work Degree information technology engineering mathematics statistics actuarial related discipline": "<br/><b>data scientist</b> TextRank score rank: 1673/2000<br/><b>data engineer</b> TextRank score rank: 412/2000", "ownership work": "<br/><b>data scientist</b> TextRank score rank: 1674/2000<br/><b>data engineer</b> TextRank score rank: 93/2000", "business owners analysts": "<br/><b>data scientist</b> TextRank score rank: 1675/2000<br/><b>data engineer</b> TextRank score rank: 61/2000", "load monitoring tools procedures": "<br/><b>data scientist</b> TextRank score rank: 1676/2000<br/><b>data engineer</b> TextRank score rank: 91/2000", "high quality work time Show initiative": "<br/><b>data scientist</b> TextRank score rank: 1677/2000<br/><b>data engineer</b> TextRank score rank: 94/2000", "system infrastructure management": "<br/><b>data scientist</b> TextRank score rank: 1678/2000<br/><b>data engineer</b> TextRank score rank: 442/2000", "real time decision": "<br/><b>data scientist</b> TextRank score rank: 1679/2000<br/><b>data engineer</b> TextRank score rank: 97/2000", "Manage systems technology tools": "<br/><b>data scientist</b> TextRank score rank: 1680/2000<br/><b>data engineer</b> TextRank score rank: 105/2000", "Information gathering problem analysis": "<br/><b>data scientist</b> TextRank score rank: 1681/2000<br/><b>data engineer</b> TextRank score rank: 126/2000", "appropriate indexing tables": "<br/><b>data scientist</b> TextRank score rank: 1682/2000<br/><b>data engineer</b> TextRank score rank: 109/2000", "SSAS SQL Server Data warehouse": "<br/><b>data scientist</b> TextRank score rank: 1659/2000<br/><b>data engineer</b> TextRank score rank: 120/2000", "Presenting Communicating information": "<br/><b>data scientist</b> TextRank score rank: 1658/2000<br/><b>data engineer</b> TextRank score rank: 516/2000", "appropriate modelling techniques": "<br/><b>data scientist</b> TextRank score rank: 1657/2000<br/><b>data engineer</b> TextRank score rank: 124/2000", "appropriate changes": "<br/><b>data scientist</b> TextRank score rank: 1644/2000<br/><b>data engineer</b> TextRank score rank: 133/2000", "internal external Assist development others": "<br/><b>data scientist</b> TextRank score rank: 1634/2000<br/><b>data engineer</b> TextRank score rank: 530/2000", "professional specialist technical expertise": "<br/><b>data scientist</b> TextRank score rank: 1635/2000<br/><b>data engineer</b> TextRank score rank: 128/2000", "Multiple stakeholder management": "<br/><b>data scientist</b> TextRank score rank: 1636/2000<br/><b>data engineer</b> TextRank score rank: 534/2000", "SQL Data": "<br/><b>data scientist</b> TextRank score rank: 1637/2000<br/><b>data engineer</b> TextRank score rank: 66/2000", "skills knowledge application": "<br/><b>data scientist</b> TextRank score rank: 1638/2000<br/><b>data engineer</b> TextRank score rank: 155/2000", "loads": "<br/><b>data scientist</b> TextRank score rank: 1639/2000<br/><b>data engineer</b> TextRank score rank: 134/2000", "ownership career development": "<br/><b>data scientist</b> TextRank score rank: 1640/2000<br/><b>data engineer</b> TextRank score rank: 140/2000", "Quality Detail orientation Planning": "<br/><b>data scientist</b> TextRank score rank: 1641/2000<br/><b>data engineer</b> TextRank score rank: 570/2000", "continuous monitoring": "<br/><b>data scientist</b> TextRank score rank: 1642/2000<br/><b>data engineer</b> TextRank score rank: 137/2000", "sources": "<br/><b>data scientist</b> TextRank score rank: 1643/2000<br/><b>data engineer</b> TextRank score rank: 143/2000", "integrity existing environment": "<br/><b>data scientist</b> TextRank score rank: 1645/2000<br/><b>data engineer</b> TextRank score rank: 142/2000", "IT infrastructure IT Operations": "<br/><b>data scientist</b> TextRank score rank: 1656/2000<br/><b>data engineer</b> TextRank score rank: 606/2000", "Analysing Leadership": "<br/><b>data scientist</b> TextRank score rank: 1646/2000<br/><b>data engineer</b> TextRank score rank: 614/2000", "automated decision": "<br/><b>data scientist</b> TextRank score rank: 1647/2000<br/><b>data engineer</b> TextRank score rank: 163/2000", "value decision": "<br/><b>data scientist</b> TextRank score rank: 1648/2000<br/><b>data engineer</b> TextRank score rank: 169/2000", "active finding opportunities": "<br/><b>data scientist</b> TextRank score rank: 1649/2000<br/><b>data engineer</b> TextRank score rank: 187/2000", "effective strategies": "<br/><b>data scientist</b> TextRank score rank: 1650/2000<br/><b>data engineer</b> TextRank score rank: 193/2000", "Presenting Communicating": "<br/><b>data scientist</b> TextRank score rank: 1651/2000<br/><b>data engineer</b> TextRank score rank: 695/2000", "external parties": "<br/><b>data scientist</b> TextRank score rank: 1652/2000<br/><b>data engineer</b> TextRank score rank: 200/2000", "Quality": "<br/><b>data scientist</b> TextRank score rank: 1653/2000<br/><b>data engineer</b> TextRank score rank: 242/2000", "g multi dimensional OLAP structures summary tables": "<br/><b>data scientist</b> TextRank score rank: 1654/2000<br/><b>data engineer</b> TextRank score rank: 217/2000", "Take": "<br/><b>data scientist</b> TextRank score rank: 1655/2000<br/><b>data engineer</b> TextRank score rank: 250/2000", "interfaces": "<br/><b>data scientist</b> TextRank score rank: 1684/2000<br/><b>data engineer</b> TextRank score rank: 244/2000", "Cross": "<br/><b>data scientist</b> TextRank score rank: 1789/2000<br/><b>data engineer</b> TextRank score rank: 519/2000", "Positive": "<br/><b>data scientist</b> TextRank score rank: 1790/2000<br/><b>data engineer</b> TextRank score rank: 366/2000", "SSIS": "<br/><b>data scientist</b> TextRank score rank: 1791/2000<br/><b>data engineer</b> TextRank score rank: 209/2000", "OLAP": "<br/><b>data scientist</b> TextRank score rank: 1923/2000<br/><b>data engineer</b> TextRank score rank: 323/2000", "etc Design implement": "<br/><b>data scientist</b> TextRank score rank: 1924/2000<br/><b>data engineer</b> TextRank score rank: 386/2000", "ad hoc unstructured data models": "<br/><b>data scientist</b> TextRank score rank: 1925/2000<br/><b>data engineer</b> TextRank score rank: 459/2000", "API etc Design": "<br/><b>data scientist</b> TextRank score rank: 1926/2000<br/><b>data engineer</b> TextRank score rank: 478/2000", "code Scala Experience working Agile environment Experience building data processing pipelines": "<br/><b>data scientist</b> TextRank score rank: 1927/2000<br/><b>data engineer</b> TextRank score rank: 633/2000", "Amazing working environment Employee referral scheme ETL Scala": "<br/><b>data scientist</b> TextRank score rank: 1928/2000<br/><b>data engineer</b> TextRank score rank: 652/2000", "Competitive Salary Company Bonus Private Healthcare Life Insurance Income protection Pension Scheme company contribution": "<br/><b>data scientist</b> TextRank score rank: 1929/2000<br/><b>data engineer</b> TextRank score rank: 752/2000", "analytics pipelines": "<br/><b>data scientist</b> TextRank score rank: 1930/2000<br/><b>data engineer</b> TextRank score rank: 755/2000", "Competitive Salary Company Bonus Private Healthcare Life Insurance Income": "<br/><b>data scientist</b> TextRank score rank: 1931/2000<br/><b>data engineer</b> TextRank score rank: 784/2000", "big data experience": "<br/><b>data scientist</b> TextRank score rank: 1932/2000<br/><b>data engineer</b> TextRank score rank: 841/2000", "Scala Experience": "<br/><b>data scientist</b> TextRank score rank: 1933/2000<br/><b>data engineer</b> TextRank score rank: 875/2000", "sell days": "<br/><b>data scientist</b> TextRank score rank: 1934/2000<br/><b>data engineer</b> TextRank score rank: 879/2000", "production handsoff batch systems": "<br/><b>data scientist</b> TextRank score rank: 1935/2000<br/><b>data engineer</b> TextRank score rank: 896/2000", "Scala": "<br/><b>data scientist</b> TextRank score rank: 1936/2000<br/><b>data engineer</b> TextRank score rank: 561/2000", "social events": "<br/><b>data scientist</b> TextRank score rank: 1937/2000<br/><b>data engineer</b> TextRank score rank: 177/2000", "Virtual company": "<br/><b>data scientist</b> TextRank score rank: 1938/2000<br/><b>data engineer</b> TextRank score rank: 380/2000", "Virtual": "<br/><b>data scientist</b> TextRank score rank: 1939/2000<br/><b>data engineer</b> TextRank score rank: 568/2000", "Team player excellent communication skills": "<br/><b>data scientist</b> TextRank score rank: 1940/2000<br/><b>data engineer</b> TextRank score rank: 172/2000", "Exposure Business Intelligence tools Business Objects": "<br/><b>data scientist</b> TextRank score rank: 1941/2000<br/><b>data engineer</b> TextRank score rank: 737/2000", "Business Objects Informatica": "<br/><b>data scientist</b> TextRank score rank: 1942/2000<br/><b>data engineer</b> TextRank score rank: 843/2000", "developing testing ETL interfaces": "<br/><b>data scientist</b> TextRank score rank: 1943/2000<br/><b>data engineer</b> TextRank score rank: 846/2000", "Exposure Business Intelligence": "<br/><b>data scientist</b> TextRank score rank: 1944/2000<br/><b>data engineer</b> TextRank score rank: 849/2000", "Teradata Oracle MS SQL": "<br/><b>data scientist</b> TextRank score rank: 1945/2000<br/><b>data engineer</b> TextRank score rank: 440/2000", "MDM": "<br/><b>data scientist</b> TextRank score rank: 1922/2000<br/><b>data engineer</b> TextRank score rank: 740/2000", "Kinesis Riak": "<br/><b>data scientist</b> TextRank score rank: 1921/2000<br/><b>data engineer</b> TextRank score rank: 275/2000", "Aurora Dynamo": "<br/><b>data scientist</b> TextRank score rank: 1920/2000<br/><b>data engineer</b> TextRank score rank: 146/2000", "Python SQL Spark Scala Extensive Experience SQL": "<br/><b>data scientist</b> TextRank score rank: 1907/2000<br/><b>data engineer</b> TextRank score rank: 769/2000", "big data years": "<br/><b>data scientist</b> TextRank score rank: 1897/2000<br/><b>data engineer</b> TextRank score rank: 859/2000", "NoSQL solutions": "<br/><b>data scientist</b> TextRank score rank: 1898/2000<br/><b>data engineer</b> TextRank score rank: 496/2000", "display excellent judgment": "<br/><b>data scientist</b> TextRank score rank: 1899/2000<br/><b>data engineer</b> TextRank score rank: 84/2000", "difficult tradeoffs": "<br/><b>data scientist</b> TextRank score rank: 1900/2000<br/><b>data engineer</b> TextRank score rank: 98/2000", "new information": "<br/><b>data scientist</b> TextRank score rank: 1901/2000<br/><b>data engineer</b> TextRank score rank: 99/2000", "BA BS Degree Computer Science Engineering discipline Statistics Information Systems": "<br/><b>data scientist</b> TextRank score rank: 1902/2000<br/><b>data engineer</b> TextRank score rank: 347/2000", "Statistics Information Systems": "<br/><b>data scientist</b> TextRank score rank: 1580/2000<br/><b>data engineer</b> TextRank score rank: 164/2000", "BA BS Degree Computer Science Engineering": "<br/><b>data scientist</b> TextRank score rank: 1903/2000<br/><b>data engineer</b> TextRank score rank: 188/2000", "another quantitative field": "<br/><b>data scientist</b> TextRank score rank: 1904/2000<br/><b>data engineer</b> TextRank score rank: 402/2000", "statistical modeling discriminative methods": "<br/><b>data scientist</b> TextRank score rank: 1905/2000<br/><b>data engineer</b> TextRank score rank: 139/2000", "extraction analysis": "<br/><b>data scientist</b> TextRank score rank: 1906/2000<br/><b>data engineer</b> TextRank score rank: 144/2000", "Experience areas data": "<br/><b>data scientist</b> TextRank score rank: 1908/2000<br/><b>data engineer</b> TextRank score rank: 282/2000", "Mathematics Engineering technology": "<br/><b>data scientist</b> TextRank score rank: 1919/2000<br/><b>data engineer</b> TextRank score rank: 116/2000", "Possess bachelor degree": "<br/><b>data scientist</b> TextRank score rank: 1909/2000<br/><b>data engineer</b> TextRank score rank: 241/2000", "data stores data": "<br/><b>data scientist</b> TextRank score rank: 1910/2000<br/><b>data engineer</b> TextRank score rank: 639/2000", "model evaluation validation Enthusiasm big data translating data": "<br/><b>data scientist</b> TextRank score rank: 1911/2000<br/><b>data engineer</b> TextRank score rank: 722/2000", "unstructured data Proficient building robust data pipelines": "<br/><b>data scientist</b> TextRank score rank: 1912/2000<br/><b>data engineer</b> TextRank score rank: 748/2000", "data processing tools": "<br/><b>data scientist</b> TextRank score rank: 1913/2000<br/><b>data engineer</b> TextRank score rank: 801/2000", "leading successful data engineering projects": "<br/><b>data scientist</b> TextRank score rank: 1914/2000<br/><b>data engineer</b> TextRank score rank: 813/2000", "reliable data services stakeholders": "<br/><b>data scientist</b> TextRank score rank: 1915/2000<br/><b>data engineer</b> TextRank score rank: 835/2000", "Agile project development experience": "<br/><b>data scientist</b> TextRank score rank: 1916/2000<br/><b>data engineer</b> TextRank score rank: 906/2000", "Data Engineer Machine Learning Engineer": "<br/><b>data scientist</b> TextRank score rank: 1917/2000<br/><b>data engineer</b> TextRank score rank: 537/2000", "Kafka Apache Spark": "<br/><b>data scientist</b> TextRank score rank: 1918/2000<br/><b>data engineer</b> TextRank score rank: 559/2000", "analyze present data answer business questions Experience data visualization tools": "<br/><b>data scientist</b> TextRank score rank: 1946/2000<br/><b>data engineer</b> TextRank score rank: 669/2000", "Experience data induction validation source systems Experience working Capital Projects": "<br/><b>data scientist</b> TextRank score rank: 1948/2000<br/><b>data engineer</b> TextRank score rank: 746/2000", "Advanced SQL knowledge years data extraction experience": "<br/><b>data scientist</b> TextRank score rank: 1999/2000<br/><b>data engineer</b> TextRank score rank: 782/2000", "UAT Expert normalizing data": "<br/><b>data scientist</b> TextRank score rank: 1949/2000<br/><b>data engineer</b> TextRank score rank: 807/2000", "Familiarity Finance Operations Retail Contact Center data": "<br/><b>data scientist</b> TextRank score rank: 1976/2000<br/><b>data engineer</b> TextRank score rank: 816/2000", "Desire end end ownership work Flexibility balance directional changes ability": "<br/><b>data scientist</b> TextRank score rank: 1977/2000<br/><b>data engineer</b> TextRank score rank: 830/2000", "Strong analytical skills ability": "<br/><b>data scientist</b> TextRank score rank: 1978/2000<br/><b>data engineer</b> TextRank score rank: 892/2000", "day day": "<br/><b>data scientist</b> TextRank score rank: 1979/2000<br/><b>data engineer</b> TextRank score rank: 909/2000", "business support Ability deal ambiguity Proactive driven individual comfortable working global matrixed fast paced environment": "<br/><b>data scientist</b> TextRank score rank: 1980/2000<br/><b>data engineer</b> TextRank score rank: 927/2000", "multiple deadline specific projects": "<br/><b>data scientist</b> TextRank score rank: 1981/2000<br/><b>data engineer</b> TextRank score rank: 531/2000", "Oracle Teradata Vertica Hadoop": "<br/><b>data scientist</b> TextRank score rank: 1982/2000<br/><b>data engineer</b> TextRank score rank: 548/2000", "k Savings Plan Company Match Paid Vacations": "<br/><b>data scientist</b> TextRank score rank: 1983/2000<br/><b>data engineer</b> TextRank score rank: 374/2000", "Safety Quality First Valuing Ethics Integrity Diversity Passion": "<br/><b>data scientist</b> TextRank score rank: 1984/2000<br/><b>data engineer</b> TextRank score rank: 389/2000", "Competitive Salary Comprehensive Health Wellness Income Protection Benefits": "<br/><b>data scientist</b> TextRank score rank: 1985/2000<br/><b>data engineer</b> TextRank score rank: 413/2000", "Safety Quality First Valuing Ethics Integrity Diversity Passion Serving Our Customers Globally Dedication": "<br/><b>data scientist</b> TextRank score rank: 1986/2000<br/><b>data engineer</b> TextRank score rank: 541/2000", "Bachelor Master degree Computer Science": "<br/><b>data scientist</b> TextRank score rank: 1987/2000<br/><b>data engineer</b> TextRank score rank: 765/2000", "Servant Leadership": "<br/><b>data scientist</b> TextRank score rank: 1988/2000<br/><b>data engineer</b> TextRank score rank: 893/2000", "Pig Hive Impala Experience integration data multiple data sources": "<br/><b>data scientist</b> TextRank score rank: 1989/2000<br/><b>data engineer</b> TextRank score rank: 820/2000", "TDD Continuous Integration Experience refactoring code scale production mind": "<br/><b>data scientist</b> TextRank score rank: 1990/2000<br/><b>data engineer</b> TextRank score rank: 899/2000", "Solid knowledge data structures": "<br/><b>data scientist</b> TextRank score rank: 1991/2000<br/><b>data engineer</b> TextRank score rank: 901/2000", "Experience Big Data ML": "<br/><b>data scientist</b> TextRank score rank: 1992/2000<br/><b>data engineer</b> TextRank score rank: 414/2000", "services Experience building stream processing systems": "<br/><b>data scientist</b> TextRank score rank: 1993/2000<br/><b>data engineer</b> TextRank score rank: 928/2000", "Good knowledge Big Data querying tools": "<br/><b>data scientist</b> TextRank score rank: 1994/2000<br/><b>data engineer</b> TextRank score rank: 436/2000", "Big Data ML": "<br/><b>data scientist</b> TextRank score rank: 1995/2000<br/><b>data engineer</b> TextRank score rank: 451/2000", "Lambda Architecture": "<br/><b>data scientist</b> TextRank score rank: 1996/2000<br/><b>data engineer</b> TextRank score rank: 340/2000", "advantages": "<br/><b>data scientist</b> TextRank score rank: 1997/2000<br/><b>data engineer</b> TextRank score rank: 757/2000", "technical data role": "<br/><b>data scientist</b> TextRank score rank: 1998/2000<br/><b>data engineer</b> TextRank score rank: 110/2000", "good data governance": "<br/><b>data scientist</b> TextRank score rank: 1975/2000<br/><b>data engineer</b> TextRank score rank: 114/2000", "Unstructured data experience": "<br/><b>data scientist</b> TextRank score rank: 1974/2000<br/><b>data engineer</b> TextRank score rank: 118/2000", "Implement meta data solutions": "<br/><b>data scientist</b> TextRank score rank: 1973/2000<br/><b>data engineer</b> TextRank score rank: 129/2000", "Microsoft business intelligence visualisation technologies": "<br/><b>data scientist</b> TextRank score rank: 1960/2000<br/><b>data engineer</b> TextRank score rank: 166/2000", "knowledge share Quality control work Degree information technology": "<br/><b>data scientist</b> TextRank score rank: 1950/2000<br/><b>data engineer</b> TextRank score rank: 191/2000", "Stakeholder management internal external Assist development others": "<br/><b>data scientist</b> TextRank score rank: 1951/2000<br/><b>data engineer</b> TextRank score rank: 233/2000", "SSRS Power BI IT infrastructure e g storage networking servers": "<br/><b>data scientist</b> TextRank score rank: 1952/2000<br/><b>data engineer</b> TextRank score rank: 261/2000", "team dynamics performance": "<br/><b>data scientist</b> TextRank score rank: 1953/2000<br/><b>data engineer</b> TextRank score rank: 276/2000", "mathematics engineering actuarial science related discipline": "<br/><b>data scientist</b> TextRank score rank: 1954/2000<br/><b>data engineer</b> TextRank score rank: 277/2000", "specifically personal unsecured loans Business process monitoring": "<br/><b>data scientist</b> TextRank score rank: 1955/2000<br/><b>data engineer</b> TextRank score rank: 308/2000", "Quality Detail orientation": "<br/><b>data scientist</b> TextRank score rank: 1956/2000<br/><b>data engineer</b> TextRank score rank: 314/2000", "availability accuracy Monitor": "<br/><b>data scientist</b> TextRank score rank: 1957/2000<br/><b>data engineer</b> TextRank score rank: 396/2000", "SSRS Power BI": "<br/><b>data scientist</b> TextRank score rank: 1958/2000<br/><b>data engineer</b> TextRank score rank: 428/2000", "Stakeholder": "<br/><b>data scientist</b> TextRank score rank: 1959/2000<br/><b>data engineer</b> TextRank score rank: 599/2000", "Unstructured": "<br/><b>data scientist</b> TextRank score rank: 1961/2000<br/><b>data engineer</b> TextRank score rank: 600/2000", "data processing systems Experience": "<br/><b>data scientist</b> TextRank score rank: 1972/2000<br/><b>data engineer</b> TextRank score rank: 585/2000", "years experience schema": "<br/><b>data scientist</b> TextRank score rank: 1962/2000<br/><b>data engineer</b> TextRank score rank: 587/2000", "internal clients Experience designing building": "<br/><b>data scientist</b> TextRank score rank: 1963/2000<br/><b>data engineer</b> TextRank score rank: 673/2000", "communicating data warehouse": "<br/><b>data scientist</b> TextRank score rank: 1964/2000<br/><b>data engineer</b> TextRank score rank: 780/2000", "troubleshooting skills Process oriented great documentation skills": "<br/><b>data scientist</b> TextRank score rank: 1965/2000<br/><b>data engineer</b> TextRank score rank: 791/2000", "dimensional data": "<br/><b>data scientist</b> TextRank score rank: 1966/2000<br/><b>data engineer</b> TextRank score rank: 808/2000", "keen sense customer service BS MS degree": "<br/><b>data scientist</b> TextRank score rank: 1967/2000<br/><b>data engineer</b> TextRank score rank: 826/2000", "data Optimize tune data warehouse query performance analytical workloads": "<br/><b>data scientist</b> TextRank score rank: 1968/2000<br/><b>data engineer</b> TextRank score rank: 198/2000", "SQL Server Experience developing software code": "<br/><b>data scientist</b> TextRank score rank: 1969/2000<br/><b>data engineer</b> TextRank score rank: 204/2000", "integrations BI tools third party productivity applications years engineering experience Expert SQL": "<br/><b>data scientist</b> TextRank score rank: 1970/2000<br/><b>data engineer</b> TextRank score rank: 205/2000", "data warehouse structure table": "<br/><b>data scientist</b> TextRank score rank: 1971/2000<br/><b>data engineer</b> TextRank score rank: 212/2000", "Python Java Scala Ruby Experience managing database data warehouse technologies bonus Redshift Snowflake Experience": "<br/><b>data scientist</b> TextRank score rank: 1896/2000<br/><b>data engineer</b> TextRank score rank: 220/2000", "robust data": "<br/><b>data scientist</b> TextRank score rank: 1895/2000<br/><b>data engineer</b> TextRank score rank: 227/2000", "resolve data quality issues": "<br/><b>data scientist</b> TextRank score rank: 1894/2000<br/><b>data engineer</b> TextRank score rank: 228/2000", "Bonus Stitch Fivetran Matillion Understanding data analytics ecosystem": "<br/><b>data scientist</b> TextRank score rank: 1893/2000<br/><b>data engineer</b> TextRank score rank: 229/2000", "data analysis Design": "<br/><b>data scientist</b> TextRank score rank: 1818/2000<br/><b>data engineer</b> TextRank score rank: 231/2000", "visualization tools based requirements": "<br/><b>data scientist</b> TextRank score rank: 1819/2000<br/><b>data engineer</b> TextRank score rank: 234/2000", "Business Intelligence tools": "<br/><b>data scientist</b> TextRank score rank: 1820/2000<br/><b>data engineer</b> TextRank score rank: 239/2000", "ETL tools": "<br/><b>data scientist</b> TextRank score rank: 1821/2000<br/><b>data engineer</b> TextRank score rank: 186/2000", "Spark Kafka AWS Glue Amazon Kinesis Sqoop Flume Flink Experience": "<br/><b>data scientist</b> TextRank score rank: 1822/2000<br/><b>data engineer</b> TextRank score rank: 253/2000", "Bonus Looker Experience": "<br/><b>data scientist</b> TextRank score rank: 1823/2000<br/><b>data engineer</b> TextRank score rank: 262/2000", "Snowflake Redshift PostgreSQL": "<br/><b>data scientist</b> TextRank score rank: 1824/2000<br/><b>data engineer</b> TextRank score rank: 296/2000", "Bonus Stitch Fivetran Matillion Understanding": "<br/><b>data scientist</b> TextRank score rank: 1825/2000<br/><b>data engineer</b> TextRank score rank: 309/2000", "Redshift Snowflake": "<br/><b>data scientist</b> TextRank score rank: 1826/2000<br/><b>data engineer</b> TextRank score rank: 311/2000", "Snowflake Redshift": "<br/><b>data scientist</b> TextRank score rank: 1827/2000<br/><b>data engineer</b> TextRank score rank: 310/2000", "Bonus Looker": "<br/><b>data scientist</b> TextRank score rank: 1829/2000<br/><b>data engineer</b> TextRank score rank: 385/2000", "Kinesis Sqoop": "<br/><b>data scientist</b> TextRank score rank: 1840/2000<br/><b>data engineer</b> TextRank score rank: 445/2000", "Business Intelligence": "<br/><b>data scientist</b> TextRank score rank: 1830/2000<br/><b>data engineer</b> TextRank score rank: 471/2000", "Spark Kafka": "<br/><b>data scientist</b> TextRank score rank: 1831/2000<br/><b>data engineer</b> TextRank score rank: 473/2000", "one relevant tools": "<br/><b>data scientist</b> TextRank score rank: 1832/2000<br/><b>data engineer</b> TextRank score rank: 542/2000", "troubleshoot": "<br/><b>data scientist</b> TextRank score rank: 1833/2000<br/><b>data engineer</b> TextRank score rank: 609/2000", "users": "<br/><b>data scientist</b> TextRank score rank: 1834/2000<br/><b>data engineer</b> TextRank score rank: 615/2000", "Architect": "<br/><b>data scientist</b> TextRank score rank: 1835/2000<br/><b>data engineer</b> TextRank score rank: 315/2000", "JSON ProtocolBuffers XML": "<br/><b>data scientist</b> TextRank score rank: 1836/2000<br/><b>data engineer</b> TextRank score rank: 520/2000", "Numpy Scipy Experience query APIs": "<br/><b>data scientist</b> TextRank score rank: 1837/2000<br/><b>data engineer</b> TextRank score rank: 545/2000", "JSON ProtocolBuffers": "<br/><b>data scientist</b> TextRank score rank: 1838/2000<br/><b>data engineer</b> TextRank score rank: 650/2000", "Numpy Scipy": "<br/><b>data scientist</b> TextRank score rank: 1839/2000<br/><b>data engineer</b> TextRank score rank: 690/2000", "algebra ML": "<br/><b>data scientist</b> TextRank score rank: 1817/2000<br/><b>data engineer</b> TextRank score rank: 702/2000", "RDB MPP DB": "<br/><b>data scientist</b> TextRank score rank: 1828/2000<br/><b>data engineer</b> TextRank score rank: 795/2000", "Oozie Big data warehousing RDB": "<br/><b>data scientist</b> TextRank score rank: 1816/2000<br/><b>data engineer</b> TextRank score rank: 815/2000", "Apple benefits programmes": "<br/><b>data scientist</b> TextRank score rank: 1802/2000<br/><b>data engineer</b> TextRank score rank: 271/2000", "Apple benefits": "<br/><b>data scientist</b> TextRank score rank: 1792/2000<br/><b>data engineer</b> TextRank score rank: 286/2000", "Apple programmes": "<br/><b>data scientist</b> TextRank score rank: 1793/2000<br/><b>data engineer</b> TextRank score rank: 300/2000", "Apple important resource soul people": "<br/><b>data scientist</b> TextRank score rank: 1794/2000<br/><b>data engineer</b> TextRank score rank: 866/2000", "Apple chance share company success": "<br/><b>data scientist</b> TextRank score rank: 1795/2000<br/><b>data engineer</b> TextRank score rank: 367/2000", "Supporting data collection curation data provenance": "<br/><b>data scientist</b> TextRank score rank: 1796/2000<br/><b>data engineer</b> TextRank score rank: 935/2000", "stock grants employees levels company": "<br/><b>data scientist</b> TextRank score rank: 1797/2000<br/><b>data engineer</b> TextRank score rank: 430/2000", "special employee pricing": "<br/><b>data scientist</b> TextRank score rank: 1798/2000<br/><b>data engineer</b> TextRank score rank: 486/2000", "benefits privileges": "<br/><b>data scientist</b> TextRank score rank: 1799/2000<br/><b>data engineer</b> TextRank score rank: 1017/2000", "many benefits": "<br/><b>data scientist</b> TextRank score rank: 1800/2000<br/><b>data engineer</b> TextRank score rank: 512/2000", "distributed systems blob storage elastic compute virtual instances Familiarity Software Development Life Cycles tools methodologies": "<br/><b>data scientist</b> TextRank score rank: 1801/2000<br/><b>data engineer</b> TextRank score rank: 1023/2000", "reasonable accommodation applicants": "<br/><b>data scientist</b> TextRank score rank: 1803/2000<br/><b>data engineer</b> TextRank score rank: 1046/2000", "Familiarity Software Development Life Cycles": "<br/><b>data scientist</b> TextRank score rank: 1814/2000<br/><b>data engineer</b> TextRank score rank: 1047/2000", "reasonable accommodation": "<br/><b>data scientist</b> TextRank score rank: 1804/2000<br/><b>data engineer</b> TextRank score rank: 1048/2000", "employees": "<br/><b>data scientist</b> TextRank score rank: 1805/2000<br/><b>data engineer</b> TextRank score rank: 160/2000", "charitable contributions reimburse continuing education": "<br/><b>data scientist</b> TextRank score rank: 1806/2000<br/><b>data engineer</b> TextRank score rank: 594/2000", "programmes": "<br/><b>data scientist</b> TextRank score rank: 1807/2000<br/><b>data engineer</b> TextRank score rank: 612/2000", "country subject eligibility requirements": "<br/><b>data scientist</b> TextRank score rank: 1808/2000<br/><b>data engineer</b> TextRank score rank: 575/2000", "Apple products": "<br/><b>data scientist</b> TextRank score rank: 1809/2000<br/><b>data engineer</b> TextRank score rank: 732/2000", "meaningful ways": "<br/><b>data scientist</b> TextRank score rank: 1810/2000<br/><b>data engineer</b> TextRank score rank: 739/2000", "Experience Scala": "<br/><b>data scientist</b> TextRank score rank: 1811/2000<br/><b>data engineer</b> TextRank score rank: 878/2000", "option": "<br/><b>data scientist</b> TextRank score rank: 1812/2000<br/><b>data engineer</b> TextRank score rank: 958/2000", "source systems data": "<br/><b>data scientist</b> TextRank score rank: 1813/2000<br/><b>data engineer</b> TextRank score rank: 825/2000", "published data sources": "<br/><b>data scientist</b> TextRank score rank: 1815/2000<br/><b>data engineer</b> TextRank score rank: 877/2000", "Create manage data sources": "<br/><b>data scientist</b> TextRank score rank: 1841/2000<br/><b>data engineer</b> TextRank score rank: 945/2000", "ETL programs data pipelines": "<br/><b>data scientist</b> TextRank score rank: 1842/2000<br/><b>data engineer</b> TextRank score rank: 951/2000", "AWS Redshift Python R Hadoop Spark technologies Work": "<br/><b>data scientist</b> TextRank score rank: 1843/2000<br/><b>data engineer</b> TextRank score rank: 964/2000", "unstructured data Competitive wages": "<br/><b>data scientist</b> TextRank score rank: 1870/2000<br/><b>data engineer</b> TextRank score rank: 969/2000", "practical demonstrable hands work experience SQL": "<br/><b>data scientist</b> TextRank score rank: 1871/2000<br/><b>data engineer</b> TextRank score rank: 970/2000", "relational NoSQL columnar data stores": "<br/><b>data scientist</b> TextRank score rank: 1872/2000<br/><b>data engineer</b> TextRank score rank: 971/2000", "open source cloud based environment": "<br/><b>data scientist</b> TextRank score rank: 1873/2000<br/><b>data engineer</b> TextRank score rank: 988/2000", "Python Java Scala R Sharp attention detail ability": "<br/><b>data scientist</b> TextRank score rank: 1874/2000<br/><b>data engineer</b> TextRank score rank: 1003/2000", "Health Savings Account Medical Dependent Care Flexible Spending Accounts Wellness Program Membership TPC": "<br/><b>data scientist</b> TextRank score rank: 1875/2000<br/><b>data engineer</b> TextRank score rank: 1012/2000", "database design execution Work": "<br/><b>data scientist</b> TextRank score rank: 1876/2000<br/><b>data engineer</b> TextRank score rank: 1024/2000", "Health Savings Account Medical Dependent Care Flexible Spending Accounts": "<br/><b>data scientist</b> TextRank score rank: 1877/2000<br/><b>data engineer</b> TextRank score rank: 1025/2000", "Redshift Python R Hadoop": "<br/><b>data scientist</b> TextRank score rank: 1878/2000<br/><b>data engineer</b> TextRank score rank: 1027/2000", "data release testing processes": "<br/><b>data scientist</b> TextRank score rank: 1879/2000<br/><b>data engineer</b> TextRank score rank: 1040/2000", "multiple tasks": "<br/><b>data scientist</b> TextRank score rank: 1880/2000<br/><b>data engineer</b> TextRank score rank: 848/2000", "Data Engineering": "<br/><b>data scientist</b> TextRank score rank: 1881/2000<br/><b>data engineer</b> TextRank score rank: 806/2000", "Spark development years": "<br/><b>data scientist</b> TextRank score rank: 1882/2000<br/><b>data engineer</b> TextRank score rank: 387/2000", "data engineering ETL pipeline development years": "<br/><b>data scientist</b> TextRank score rank: 1883/2000<br/><b>data engineer</b> TextRank score rank: 427/2000", "preferred years": "<br/><b>data scientist</b> TextRank score rank: 1884/2000<br/><b>data engineer</b> TextRank score rank: 487/2000", "Python preferred Experience": "<br/><b>data scientist</b> TextRank score rank: 1885/2000<br/><b>data engineer</b> TextRank score rank: 503/2000", "Big Data Technologies Hadoop MapReduce Hive": "<br/><b>data scientist</b> TextRank score rank: 1886/2000<br/><b>data engineer</b> TextRank score rank: 514/2000", "Big Data Technologies Hadoop MapReduce Hive etc Spark experience": "<br/><b>data scientist</b> TextRank score rank: 1887/2000<br/><b>data engineer</b> TextRank score rank: 590/2000", "SSAS SSRS Degree Information Technology": "<br/><b>data scientist</b> TextRank score rank: 1888/2000<br/><b>data engineer</b> TextRank score rank: 620/2000", "Full SQL Stack": "<br/><b>data scientist</b> TextRank score rank: 1889/2000<br/><b>data engineer</b> TextRank score rank: 625/2000", "SQL knowledge experience": "<br/><b>data scientist</b> TextRank score rank: 1890/2000<br/><b>data engineer</b> TextRank score rank: 666/2000", "Five seven years": "<br/><b>data scientist</b> TextRank score rank: 1891/2000<br/><b>data engineer</b> TextRank score rank: 649/2000", "SQL NoSQL database experience": "<br/><b>data scientist</b> TextRank score rank: 1892/2000<br/><b>data engineer</b> TextRank score rank: 303/2000", "challenge": "<br/><b>data scientist</b> TextRank score rank: 1869/2000<br/><b>data engineer</b> TextRank score rank: 1036/2000", "data analytic pipelines": "<br/><b>data scientist</b> TextRank score rank: 1868/2000<br/><b>data engineer</b> TextRank score rank: 694/2000", "Experience data movement management Pharmaceutical industry": "<br/><b>data scientist</b> TextRank score rank: 1867/2000<br/><b>data engineer</b> TextRank score rank: 726/2000", "Computer Science Bioinformatics related degree years experience data movement data wrangling delivery data analytics pipelines": "<br/><b>data scientist</b> TextRank score rank: 1854/2000<br/><b>data engineer</b> TextRank score rank: 766/2000", "diverse omic data types": "<br/><b>data scientist</b> TextRank score rank: 1844/2000<br/><b>data engineer</b> TextRank score rank: 785/2000", "RNA Seq DNA Seq Chip Seq WES WGS ATAC seq microbiome proteomic metabolomic data": "<br/><b>data scientist</b> TextRank score rank: 1845/2000<br/><b>data engineer</b> TextRank score rank: 793/2000", "Familiarity data mining machine": "<br/><b>data scientist</b> TextRank score rank: 1846/2000<br/><b>data engineer</b> TextRank score rank: 802/2000", "RNA Seq DNA Seq Chip Seq WES WGS ATAC": "<br/><b>data scientist</b> TextRank score rank: 1847/2000<br/><b>data engineer</b> TextRank score rank: 871/2000", "scientific fields Experience core components Hadoop stack": "<br/><b>data scientist</b> TextRank score rank: 1848/2000<br/><b>data engineer</b> TextRank score rank: 905/2000", "judgement balance pace": "<br/><b>data scientist</b> TextRank score rank: 1849/2000<br/><b>data engineer</b> TextRank score rank: 993/2000", "honest open conversations": "<br/><b>data scientist</b> TextRank score rank: 1850/2000<br/><b>data engineer</b> TextRank score rank: 1030/2000", "Operating pace": "<br/><b>data scientist</b> TextRank score rank: 1851/2000<br/><b>data engineer</b> TextRank score rank: 1033/2000", "rigour risk": "<br/><b>data scientist</b> TextRank score rank: 1852/2000<br/><b>data engineer</b> TextRank score rank: 1037/2000", "agile decision making": "<br/><b>data scientist</b> TextRank score rank: 1853/2000<br/><b>data engineer</b> TextRank score rank: 1045/2000", "Cloud computing HPC systems": "<br/><b>data scientist</b> TextRank score rank: 1855/2000<br/><b>data engineer</b> TextRank score rank: 1054/2000", "artificial intelligence techniques": "<br/><b>data scientist</b> TextRank score rank: 1866/2000<br/><b>data engineer</b> TextRank score rank: 1056/2000", "HDFS Apache Spark": "<br/><b>data scientist</b> TextRank score rank: 1856/2000<br/><b>data engineer</b> TextRank score rank: 653/2000", "Agile Engineering Kanban Lean Hybrid agile experience": "<br/><b>data scientist</b> TextRank score rank: 1857/2000<br/><b>data engineer</b> TextRank score rank: 88/2000", "Python SQL Elastic visualise data surfacing tool Experience developing machine learning systems Experience Amazon Quicksite advantage": "<br/><b>data scientist</b> TextRank score rank: 1858/2000<br/><b>data engineer</b> TextRank score rank: 213/2000", "exploration visualisation Experience statistical models times": "<br/><b>data scientist</b> TextRank score rank: 1859/2000<br/><b>data engineer</b> TextRank score rank: 251/2000", "Degree educated Data Science similar Strong experience data preparation techniques": "<br/><b>data scientist</b> TextRank score rank: 1860/2000<br/><b>data engineer</b> TextRank score rank: 284/2000", "regression classification Strong skills": "<br/><b>data scientist</b> TextRank score rank: 1861/2000<br/><b>data engineer</b> TextRank score rank: 289/2000", "Python SQL Elastic": "<br/><b>data scientist</b> TextRank score rank: 1862/2000<br/><b>data engineer</b> TextRank score rank: 350/2000", "series analysis": "<br/><b>data scientist</b> TextRank score rank: 1863/2000<br/><b>data engineer</b> TextRank score rank: 411/2000", "Splunk Hadoop": "<br/><b>data scientist</b> TextRank score rank: 1864/2000<br/><b>data engineer</b> TextRank score rank: 214/2000", "insightful data performance visualizations": "<br/><b>data scientist</b> TextRank score rank: 1865/2000<br/><b>data engineer</b> TextRank score rank: 449/2000", "optimized pipelines data acquisition": "<br/><b>data scientist</b> TextRank score rank: 1581/2000<br/><b>data engineer</b> TextRank score rank: 469/2000", "algorithm variants": "<br/><b>data scientist</b> TextRank score rank: 1947/2000<br/><b>data engineer</b> TextRank score rank: 476/2000", "Expertise Python programming functional object": "<br/><b>data scientist</b> TextRank score rank: 1579/2000<br/><b>data engineer</b> TextRank score rank: 828/2000", "limited personnel policies policies": "<br/><b>data scientist</b> TextRank score rank: 1464/2000<br/><b>data engineer</b> TextRank score rank: 334/2000", "University Administrative Guide http": "<br/><b>data scientist</b> TextRank score rank: 1293/2000<br/><b>data engineer</b> TextRank score rank: 455/2000", "comply applicable University policies procedures": "<br/><b>data scientist</b> TextRank score rank: 1292/2000<br/><b>data engineer</b> TextRank score rank: 465/2000", "University Administrative Guide": "<br/><b>data scientist</b> TextRank score rank: 1294/2000<br/><b>data engineer</b> TextRank score rank: 493/2000", "unsolicited services": "<br/><b>data scientist</b> TextRank score rank: 1295/2000<br/><b>data engineer</b> TextRank score rank: 236/2000", "Linux system administration command line tools": "<br/><b>data scientist</b> TextRank score rank: 1296/2000<br/><b>data engineer</b> TextRank score rank: 522/2000", "Strong analytical thinking": "<br/><b>data scientist</b> TextRank score rank: 1297/2000<br/><b>data engineer</b> TextRank score rank: 535/2000", "Excellent programming skills C C Python Java": "<br/><b>data scientist</b> TextRank score rank: 1298/2000<br/><b>data engineer</b> TextRank score rank: 635/2000", "minimum experience": "<br/><b>data scientist</b> TextRank score rank: 1299/2000<br/><b>data engineer</b> TextRank score rank: 685/2000", "production software": "<br/><b>data scientist</b> TextRank score rank: 1300/2000<br/><b>data engineer</b> TextRank score rank: 817/2000", "Experience data tools": "<br/><b>data scientist</b> TextRank score rank: 1301/2000<br/><b>data engineer</b> TextRank score rank: 526/2000", "streaming data processing Ability": "<br/><b>data scientist</b> TextRank score rank: 1302/2000<br/><b>data engineer</b> TextRank score rank: 603/2000", "Scala preferred Proficient schema design data": "<br/><b>data scientist</b> TextRank score rank: 1303/2000<br/><b>data engineer</b> TextRank score rank: 648/2000", "analytic skills Ability program several scripting languages Python Perl Bash Experience workflow management tools": "<br/><b>data scientist</b> TextRank score rank: 1304/2000<br/><b>data engineer</b> TextRank score rank: 661/2000", "high volume data Apache Hadoop ecosystem": "<br/><b>data scientist</b> TextRank score rank: 1305/2000<br/><b>data engineer</b> TextRank score rank: 680/2000", "Oozie Airflow Azkaban": "<br/><b>data scientist</b> TextRank score rank: 1306/2000<br/><b>data engineer</b> TextRank score rank: 761/2000", "Python Perl Bash": "<br/><b>data scientist</b> TextRank score rank: 1307/2000<br/><b>data engineer</b> TextRank score rank: 932/2000", "Oozie Airflow Azkaban etc Experience": "<br/><b>data scientist</b> TextRank score rank: 1308/2000<br/><b>data engineer</b> TextRank score rank: 941/2000", "working cross functional projects": "<br/><b>data scientist</b> TextRank score rank: 1309/2000<br/><b>data engineer</b> TextRank score rank: 963/2000", "one object oriented programming languages": "<br/><b>data scientist</b> TextRank score rank: 1310/2000<br/><b>data engineer</b> TextRank score rank: 1044/2000", "Passion customer privacy Strong interpersonal skills": "<br/><b>data scientist</b> TextRank score rank: 1311/2000<br/><b>data engineer</b> TextRank score rank: 1052/2000", "Cassandra Neo4J": "<br/><b>data scientist</b> TextRank score rank: 1312/2000<br/><b>data engineer</b> TextRank score rank: 159/2000", "MongoDB Cassandra": "<br/><b>data scientist</b> TextRank score rank: 1313/2000<br/><b>data engineer</b> TextRank score rank: 783/2000", "SSIS standard ETL": "<br/><b>data scientist</b> TextRank score rank: 1290/2000<br/><b>data engineer</b> TextRank score rank: 482/2000", "strong Stored Procs": "<br/><b>data scientist</b> TextRank score rank: 1289/2000<br/><b>data engineer</b> TextRank score rank: 564/2000", "Stored Procs": "<br/><b>data scientist</b> TextRank score rank: 1288/2000<br/><b>data engineer</b> TextRank score rank: 622/2000", "serious interest": "<br/><b>data scientist</b> TextRank score rank: 1275/2000<br/><b>data engineer</b> TextRank score rank: 686/2000", "SQL Dev": "<br/><b>data scientist</b> TextRank score rank: 1265/2000<br/><b>data engineer</b> TextRank score rank: 711/2000", "MapReduce Spark Spark SQL": "<br/><b>data scientist</b> TextRank score rank: 1266/2000<br/><b>data engineer</b> TextRank score rank: 777/2000", "Java Scala Extensive experience Hadoop ecosystem technologies": "<br/><b>data scientist</b> TextRank score rank: 1267/2000<br/><b>data engineer</b> TextRank score rank: 844/2000", "Spark Streaming Hive YARN MR2 Expertise building": "<br/><b>data scientist</b> TextRank score rank: 1268/2000<br/><b>data engineer</b> TextRank score rank: 903/2000", "Java Scala Extensive": "<br/><b>data scientist</b> TextRank score rank: 1269/2000<br/><b>data engineer</b> TextRank score rank: 1009/2000", "Scala Python Apple": "<br/><b>data scientist</b> TextRank score rank: 1270/2000<br/><b>data engineer</b> TextRank score rank: 708/2000", "Scala Python Apple important resource soul people": "<br/><b>data scientist</b> TextRank score rank: 1271/2000<br/><b>data engineer</b> TextRank score rank: 734/2000", "self sufficient Experience": "<br/><b>data scientist</b> TextRank score rank: 1272/2000<br/><b>data engineer</b> TextRank score rank: 855/2000", "distributed systems services scale Experience": "<br/><b>data scientist</b> TextRank score rank: 1273/2000<br/><b>data engineer</b> TextRank score rank: 890/2000", "Preference experience": "<br/><b>data scientist</b> TextRank score rank: 1274/2000<br/><b>data engineer</b> TextRank score rank: 904/2000", "health wellness resources time": "<br/><b>data scientist</b> TextRank score rank: 1276/2000<br/><b>data engineer</b> TextRank score rank: 938/2000", "similar technologies production contexts": "<br/><b>data scientist</b> TextRank score rank: 1287/2000<br/><b>data engineer</b> TextRank score rank: 984/2000", "SOLR Spark Hadoop Kafka": "<br/><b>data scientist</b> TextRank score rank: 1277/2000<br/><b>data engineer</b> TextRank score rank: 1010/2000", "years software engineering experience": "<br/><b>data scientist</b> TextRank score rank: 1278/2000<br/><b>data engineer</b> TextRank score rank: 1021/2000", "responsible self": "<br/><b>data scientist</b> TextRank score rank: 1279/2000<br/><b>data engineer</b> TextRank score rank: 1026/2000", "Redis Apache Spark similar tools Experience regression testing data pipelines": "<br/><b>data scientist</b> TextRank score rank: 1280/2000<br/><b>data engineer</b> TextRank score rank: 610/2000", "instance Docker Kubernetes Terraform CloudFormation Ansible Chef Puppet Salt Splunk Elastic ELK Stack Sentry Datadog similar tools Knowledge Machine Learning Computer Vision": "<br/><b>data scientist</b> TextRank score rank: 1281/2000<br/><b>data engineer</b> TextRank score rank: 632/2000", "Experience DevOps application monitoring tools": "<br/><b>data scientist</b> TextRank score rank: 1282/2000<br/><b>data engineer</b> TextRank score rank: 687/2000", "AWS RDS Apache Kafka AWS Kinesis": "<br/><b>data scientist</b> TextRank score rank: 1283/2000<br/><b>data engineer</b> TextRank score rank: 697/2000", "Knowledge Machine Learning Computer Vision": "<br/><b>data scientist</b> TextRank score rank: 1284/2000<br/><b>data engineer</b> TextRank score rank: 718/2000", "Proficient scripting functional programming languages": "<br/><b>data scientist</b> TextRank score rank: 1285/2000<br/><b>data engineer</b> TextRank score rank: 819/2000", "Docker Kubernetes Terraform CloudFormation Ansible": "<br/><b>data scientist</b> TextRank score rank: 1286/2000<br/><b>data engineer</b> TextRank score rank: 827/2000", "RDS Apache Kafka": "<br/><b>data scientist</b> TextRank score rank: 1314/2000<br/><b>data engineer</b> TextRank score rank: 838/2000", "Redis Apache": "<br/><b>data scientist</b> TextRank score rank: 1316/2000<br/><b>data engineer</b> TextRank score rank: 882/2000", "streaming solutions instance": "<br/><b>data scientist</b> TextRank score rank: 1367/2000<br/><b>data engineer</b> TextRank score rank: 883/2000", "Kinesis RabbitMQ": "<br/><b>data scientist</b> TextRank score rank: 1317/2000<br/><b>data engineer</b> TextRank score rank: 980/2000", "Python Scala Bash Groovy Ruby Experience database message": "<br/><b>data scientist</b> TextRank score rank: 1344/2000<br/><b>data engineer</b> TextRank score rank: 1031/2000", "working Batch Real Time data processing systems Ability work": "<br/><b>data scientist</b> TextRank score rank: 1345/2000<br/><b>data engineer</b> TextRank score rank: 322/2000", "large scale data processing": "<br/><b>data scientist</b> TextRank score rank: 1346/2000<br/><b>data engineer</b> TextRank score rank: 329/2000", "machine learning solutions scale Experience": "<br/><b>data scientist</b> TextRank score rank: 1347/2000<br/><b>data engineer</b> TextRank score rank: 339/2000", "based systems Experience custom ETL design implementation maintenance Experience": "<br/><b>data scientist</b> TextRank score rank: 1348/2000<br/><b>data engineer</b> TextRank score rank: 348/2000", "data storage principles": "<br/><b>data scientist</b> TextRank score rank: 1349/2000<br/><b>data engineer</b> TextRank score rank: 359/2000", "Knowledge distributed systems": "<br/><b>data scientist</b> TextRank score rank: 1350/2000<br/><b>data engineer</b> TextRank score rank: 365/2000", "data management": "<br/><b>data scientist</b> TextRank score rank: 1351/2000<br/><b>data engineer</b> TextRank score rank: 100/2000", "data storage cloud computing Understanding administration AWS Docker Linux": "<br/><b>data scientist</b> TextRank score rank: 1352/2000<br/><b>data engineer</b> TextRank score rank: 394/2000", "Hadoop Spark Dataflow Airflow Knowledge practical experience machine": "<br/><b>data scientist</b> TextRank score rank: 1353/2000<br/><b>data engineer</b> TextRank score rank: 381/2000", "traditional distributed systems": "<br/><b>data scientist</b> TextRank score rank: 1354/2000<br/><b>data engineer</b> TextRank score rank: 403/2000", "Competitive Salary Equity 401k Company Match Gym Public Transportation Subsidy Student Loan Assistance Relocation Assistance Unlimited PTO": "<br/><b>data scientist</b> TextRank score rank: 1355/2000<br/><b>data engineer</b> TextRank score rank: 858/2000", "Competitive Salary Equity 401k Company Match Gym Public Transportation Subsidy Student Loan Assistance Relocation Assistance": "<br/><b>data scientist</b> TextRank score rank: 1356/2000<br/><b>data engineer</b> TextRank score rank: 886/2000", "Unlimited PTO": "<br/><b>data scientist</b> TextRank score rank: 1357/2000<br/><b>data engineer</b> TextRank score rank: 948/2000", "Opportunity work": "<br/><b>data scientist</b> TextRank score rank: 1358/2000<br/><b>data engineer</b> TextRank score rank: 523/2000", "AI fundamentals": "<br/><b>data scientist</b> TextRank score rank: 1359/2000<br/><b>data engineer</b> TextRank score rank: 592/2000", "Batch Real Time": "<br/><b>data scientist</b> TextRank score rank: 1360/2000<br/><b>data engineer</b> TextRank score rank: 579/2000", "Computer Science Statistics Engineering": "<br/><b>data scientist</b> TextRank score rank: 1361/2000<br/><b>data engineer</b> TextRank score rank: 408/2000", "higher quantitative technical field": "<br/><b>data scientist</b> TextRank score rank: 1362/2000<br/><b>data engineer</b> TextRank score rank: 733/2000", "Working knowledge data design architecture": "<br/><b>data scientist</b> TextRank score rank: 1363/2000<br/><b>data engineer</b> TextRank score rank: 786/2000", "401K Gym public transportation subsidy Relocation assistance": "<br/><b>data scientist</b> TextRank score rank: 1364/2000<br/><b>data engineer</b> TextRank score rank: 1004/2000", "fastest growing financial startups Competitive salary equity Health dental vision insurance": "<br/><b>data scientist</b> TextRank score rank: 1365/2000<br/><b>data engineer</b> TextRank score rank: 1013/2000", "K Gym": "<br/><b>data scientist</b> TextRank score rank: 1366/2000<br/><b>data engineer</b> TextRank score rank: 1022/2000", "data ingest enrichment analysis visualization dissemination": "<br/><b>data scientist</b> TextRank score rank: 1343/2000<br/><b>data engineer</b> TextRank score rank: 529/2000", "Spark Knime Exposure AWS Data Services Experience Architect design implement": "<br/><b>data scientist</b> TextRank score rank: 1342/2000<br/><b>data engineer</b> TextRank score rank: 608/2000", "Spark Knime Exposure AWS Data Services": "<br/><b>data scientist</b> TextRank score rank: 1341/2000<br/><b>data engineer</b> TextRank score rank: 654/2000", "Data transformation experience": "<br/><b>data scientist</b> TextRank score rank: 1328/2000<br/><b>data engineer</b> TextRank score rank: 659/2000", "data repositories": "<br/><b>data scientist</b> TextRank score rank: 1318/2000<br/><b>data engineer</b> TextRank score rank: 764/2000", "largest growth": "<br/><b>data scientist</b> TextRank score rank: 1319/2000<br/><b>data engineer</b> TextRank score rank: 920/2000", "indices": "<br/><b>data scientist</b> TextRank score rank: 1320/2000<br/><b>data engineer</b> TextRank score rank: 954/2000", "Graph Databases": "<br/><b>data scientist</b> TextRank score rank: 1321/2000<br/><b>data engineer</b> TextRank score rank: 960/2000", "enhancements": "<br/><b>data scientist</b> TextRank score rank: 1322/2000<br/><b>data engineer</b> TextRank score rank: 965/2000", "working day year": "<br/><b>data scientist</b> TextRank score rank: 1323/2000<br/><b>data engineer</b> TextRank score rank: 745/2000", "data enterprise systems SAP Security management Data modelling ETL development": "<br/><b>data scientist</b> TextRank score rank: 1324/2000<br/><b>data engineer</b> TextRank score rank: 851/2000", "Annual Bonus Plan Discretionary Cash Award Group Personal Pension Plan": "<br/><b>data scientist</b> TextRank score rank: 1325/2000<br/><b>data engineer</b> TextRank score rank: 439/2000", "additional days": "<br/><b>data scientist</b> TextRank score rank: 1326/2000<br/><b>data engineer</b> TextRank score rank: 887/2000", "tools Data Integrator Services Experience experience": "<br/><b>data scientist</b> TextRank score rank: 1327/2000<br/><b>data engineer</b> TextRank score rank: 937/2000", "agile project management": "<br/><b>data scientist</b> TextRank score rank: 1329/2000<br/><b>data engineer</b> TextRank score rank: 967/2000", "Medical Travel Health Life Insurances": "<br/><b>data scientist</b> TextRank score rank: 1340/2000<br/><b>data engineer</b> TextRank score rank: 968/2000", "data engineering domain": "<br/><b>data scientist</b> TextRank score rank: 1330/2000<br/><b>data engineer</b> TextRank score rank: 975/2000", "Data Integrator Services": "<br/><b>data scientist</b> TextRank score rank: 1263/2000<br/><b>data engineer</b> TextRank score rank: 976/2000", "free car parking gym site team": "<br/><b>data scientist</b> TextRank score rank: 1331/2000<br/><b>data engineer</b> TextRank score rank: 983/2000", "schemas dimensional modelling normalisation": "<br/><b>data scientist</b> TextRank score rank: 1332/2000<br/><b>data engineer</b> TextRank score rank: 985/2000", "Strong knowledge concepts": "<br/><b>data scientist</b> TextRank score rank: 1333/2000<br/><b>data engineer</b> TextRank score rank: 999/2000", "yearly basis taxable benefit Employee Stock Purchase Program Free snacks": "<br/><b>data scientist</b> TextRank score rank: 1334/2000<br/><b>data engineer</b> TextRank score rank: 753/2000", "spark Experience Scala Python Experience building batch pipelines data event data": "<br/><b>data scientist</b> TextRank score rank: 1335/2000<br/><b>data engineer</b> TextRank score rank: 798/2000", "Employee Stock Purchase Program Free": "<br/><b>data scientist</b> TextRank score rank: 1336/2000<br/><b>data engineer</b> TextRank score rank: 811/2000", "Experience building data pipelines": "<br/><b>data scientist</b> TextRank score rank: 1337/2000<br/><b>data engineer</b> TextRank score rank: 847/2000", "data systems AWS": "<br/><b>data scientist</b> TextRank score rank: 1338/2000<br/><b>data engineer</b> TextRank score rank: 942/2000", "NoSQL APIs Competitive health insurance benefits Competitive salary Annual target bonus commission": "<br/><b>data scientist</b> TextRank score rank: 1339/2000<br/><b>data engineer</b> TextRank score rank: 949/2000", "Vacation": "<br/><b>data scientist</b> TextRank score rank: 1264/2000<br/><b>data engineer</b> TextRank score rank: 981/2000", "scalable data pipelines data processing frameworks": "<br/><b>data scientist</b> TextRank score rank: 1315/2000<br/><b>data engineer</b> TextRank score rank: 668/2000", "Depth knowledge Data Operations Data Quality management space Experience layered geospatial data structures data representations": "<br/><b>data scientist</b> TextRank score rank: 1262/2000<br/><b>data engineer</b> TextRank score rank: 845/2000", "modern cloud native processing frameworks": "<br/><b>data scientist</b> TextRank score rank: 1247/2000<br/><b>data engineer</b> TextRank score rank: 863/2000", "high volume data processing organization business division": "<br/><b>data scientist</b> TextRank score rank: 1186/2000<br/><b>data engineer</b> TextRank score rank: 872/2000", "computing frameworks geospatial processing indexing": "<br/><b>data scientist</b> TextRank score rank: 1187/2000<br/><b>data engineer</b> TextRank score rank: 884/2000", "data quality management": "<br/><b>data scientist</b> TextRank score rank: 1188/2000<br/><b>data engineer</b> TextRank score rank: 891/2000", "Expertise processing": "<br/><b>data scientist</b> TextRank score rank: 1189/2000<br/><b>data engineer</b> TextRank score rank: 918/2000", "scalable cloud native backend compute capabilities REST APIs microservices": "<br/><b>data scientist</b> TextRank score rank: 1190/2000<br/><b>data engineer</b> TextRank score rank: 989/2000", "distributed computing environment years": "<br/><b>data scientist</b> TextRank score rank: 1191/2000<br/><b>data engineer</b> TextRank score rank: 994/2000", "Inspire": "<br/><b>data scientist</b> TextRank score rank: 1192/2000<br/><b>data engineer</b> TextRank score rank: 647/2000", "intellectual curiosity Show passion innovation continuous improvement initiate efforts": "<br/><b>data scientist</b> TextRank score rank: 1193/2000<br/><b>data engineer</b> TextRank score rank: 894/2000", "Extensive experience relational database development": "<br/><b>data scientist</b> TextRank score rank: 1194/2000<br/><b>data engineer</b> TextRank score rank: 919/2000", "Experience scripting automation language": "<br/><b>data scientist</b> TextRank score rank: 1195/2000<br/><b>data engineer</b> TextRank score rank: 924/2000", "technical direction problem": "<br/><b>data scientist</b> TextRank score rank: 1197/2000<br/><b>data engineer</b> TextRank score rank: 940/2000", "organisation best practice quality standards": "<br/><b>data scientist</b> TextRank score rank: 1208/2000<br/><b>data engineer</b> TextRank score rank: 957/2000", "Ensure third party development": "<br/><b>data scientist</b> TextRank score rank: 1198/2000<br/><b>data engineer</b> TextRank score rank: 966/2000", "exceptional problem": "<br/><b>data scientist</b> TextRank score rank: 1184/2000<br/><b>data engineer</b> TextRank score rank: 992/2000", "Knowledge investment management": "<br/><b>data scientist</b> TextRank score rank: 1200/2000<br/><b>data engineer</b> TextRank score rank: 998/2000", "support team": "<br/><b>data scientist</b> TextRank score rank: 1201/2000<br/><b>data engineer</b> TextRank score rank: 1005/2000", "Interest NoSQL database": "<br/><b>data scientist</b> TextRank score rank: 1202/2000<br/><b>data engineer</b> TextRank score rank: 1014/2000", "Embrace": "<br/><b>data scientist</b> TextRank score rank: 1203/2000<br/><b>data engineer</b> TextRank score rank: 550/2000", "functional team environment Apple Equal Opportunity Employer": "<br/><b>data scientist</b> TextRank score rank: 1204/2000<br/><b>data engineer</b> TextRank score rank: 916/2000", "relationships Ability": "<br/><b>data scientist</b> TextRank score rank: 1205/2000<br/><b>data engineer</b> TextRank score rank: 925/2000", "HTML CSS Javascript Strong interpersonal skills verbal written Ability": "<br/><b>data scientist</b> TextRank score rank: 1206/2000<br/><b>data engineer</b> TextRank score rank: 939/2000", "day day business support": "<br/><b>data scientist</b> TextRank score rank: 1207/2000<br/><b>data engineer</b> TextRank score rank: 952/2000", "directional changes ability": "<br/><b>data scientist</b> TextRank score rank: 1185/2000<br/><b>data engineer</b> TextRank score rank: 955/2000", "Apple Equal Opportunity Employer": "<br/><b>data scientist</b> TextRank score rank: 1196/2000<br/><b>data engineer</b> TextRank score rank: 959/2000", "similar Proficient data access preparation methods": "<br/><b>data scientist</b> TextRank score rank: 1183/2000<br/><b>data engineer</b> TextRank score rank: 1000/2000", "Proficient scripting glue languages": "<br/><b>data scientist</b> TextRank score rank: 1179/2000<br/><b>data engineer</b> TextRank score rank: 1028/2000", "data elements sources": "<br/><b>data scientist</b> TextRank score rank: 1167/2000<br/><b>data engineer</b> TextRank score rank: 1032/2000", "PHP Python web technologies": "<br/><b>data scientist</b> TextRank score rank: 1162/2000<br/><b>data engineer</b> TextRank score rank: 1039/2000", "PHP": "<br/><b>data scientist</b> TextRank score rank: 1161/2000<br/><b>data engineer</b> TextRank score rank: 536/2000", "Minimum five years data analytics programming database administration data management experience": "<br/><b>data scientist</b> TextRank score rank: 1163/2000<br/><b>data engineer</b> TextRank score rank: 327/2000", "requisite skills": "<br/><b>data scientist</b> TextRank score rank: 1164/2000<br/><b>data engineer</b> TextRank score rank: 424/2000", "less experience": "<br/><b>data scientist</b> TextRank score rank: 1165/2000<br/><b>data engineer</b> TextRank score rank: 425/2000", "applications candidates": "<br/><b>data scientist</b> TextRank score rank: 1166/2000<br/><b>data engineer</b> TextRank score rank: 472/2000", "The stated experience level guide": "<br/><b>data scientist</b> TextRank score rank: 1168/2000<br/><b>data engineer</b> TextRank score rank: 713/2000", "Medical Health Insurance Onsite Wellness Clinic Long Term Disability Life Insurance Dental Vision Coverage": "<br/><b>data scientist</b> TextRank score rank: 1169/2000<br/><b>data engineer</b> TextRank score rank: 747/2000", "cruises anniversary Medical Health Insurance Onsite Wellness Clinic Long Term Disability Life Insurance Dental Vision Coverage": "<br/><b>data scientist</b> TextRank score rank: 1170/2000<br/><b>data engineer</b> TextRank score rank: 771/2000", "Legal Insurance": "<br/><b>data scientist</b> TextRank score rank: 1182/2000<br/><b>data engineer</b> TextRank score rank: 775/2000", "K Plan Pet Care Insurance": "<br/><b>data scientist</b> TextRank score rank: 1172/2000<br/><b>data engineer</b> TextRank score rank: 778/2000", "Data design experience Experience data cleansing optimization data consumption Experience source control tools Git TFS": "<br/><b>data scientist</b> TextRank score rank: 1173/2000<br/><b>data engineer</b> TextRank score rank: 788/2000", "Consumer Websites Experience consumer facing": "<br/><b>data scientist</b> TextRank score rank: 1174/2000<br/><b>data engineer</b> TextRank score rank: 857/2000", "data management systems": "<br/><b>data scientist</b> TextRank score rank: 1175/2000<br/><b>data engineer</b> TextRank score rank: 977/2000", "Experience Azure Service Fabric": "<br/><b>data scientist</b> TextRank score rank: 1176/2000<br/><b>data engineer</b> TextRank score rank: 979/2000", "Working familiarity front end web framework": "<br/><b>data scientist</b> TextRank score rank: 1177/2000<br/><b>data engineer</b> TextRank score rank: 995/2000", "CSV JSON XML data formats": "<br/><b>data scientist</b> TextRank score rank: 1178/2000<br/><b>data engineer</b> TextRank score rank: 1016/2000", "Dedicated Employee Enrichment Recognition Programs": "<br/><b>data scientist</b> TextRank score rank: 1171/2000<br/><b>data engineer</b> TextRank score rank: 1020/2000", "mobile systems": "<br/><b>data scientist</b> TextRank score rank: 1180/2000<br/><b>data engineer</b> TextRank score rank: 1035/2000", "data engineering tasks": "<br/><b>data scientist</b> TextRank score rank: 1181/2000<br/><b>data engineer</b> TextRank score rank: 630/2000", "Expertise Hadoop related technologies": "<br/><b>data scientist</b> TextRank score rank: 1199/2000<br/><b>data engineer</b> TextRank score rank: 640/2000", "large scale data warehousing mining analytic systems Ability work analysts": "<br/><b>data scientist</b> TextRank score rank: 1209/2000<br/><b>data engineer</b> TextRank score rank: 664/2000", "Spark Streaming Spark SQL Map": "<br/><b>data scientist</b> TextRank score rank: 1261/2000<br/><b>data engineer</b> TextRank score rank: 674/2000", "big data pipelines": "<br/><b>data scientist</b> TextRank score rank: 1211/2000<br/><b>data engineer</b> TextRank score rank: 681/2000", "Azkaban Oozie Impala Hive Pig Expertise": "<br/><b>data scientist</b> TextRank score rank: 1238/2000<br/><b>data engineer</b> TextRank score rank: 698/2000", "Proficiency data processing": "<br/><b>data scientist</b> TextRank score rank: 1239/2000<br/><b>data engineer</b> TextRank score rank: 731/2000", "Map Reduce Expertise Hadoop": "<br/><b>data scientist</b> TextRank score rank: 1240/2000<br/><b>data engineer</b> TextRank score rank: 770/2000", "Kafka Flume Storm Experience": "<br/><b>data scientist</b> TextRank score rank: 1241/2000<br/><b>data engineer</b> TextRank score rank: 809/2000", "Spark Streaming": "<br/><b>data scientist</b> TextRank score rank: 1242/2000<br/><b>data engineer</b> TextRank score rank: 853/2000", "Kafka Flume Storm": "<br/><b>data scientist</b> TextRank score rank: 1243/2000<br/><b>data engineer</b> TextRank score rank: 870/2000", "HDFS Azkaban Oozie": "<br/><b>data scientist</b> TextRank score rank: 1244/2000<br/><b>data engineer</b> TextRank score rank: 873/2000", "broad variety audiences": "<br/><b>data scientist</b> TextRank score rank: 1245/2000<br/><b>data engineer</b> TextRank score rank: 642/2000", "complex technical concepts": "<br/><b>data scientist</b> TextRank score rank: 1246/2000<br/><b>data engineer</b> TextRank score rank: 683/2000", "object oriented programming languages": "<br/><b>data scientist</b> TextRank score rank: 1210/2000<br/><b>data engineer</b> TextRank score rank: 709/2000", "BS BA Technical Field Computer Science Mathematics Knowledge Python Java Experience": "<br/><b>data scientist</b> TextRank score rank: 1248/2000<br/><b>data engineer</b> TextRank score rank: 823/2000", "BA Technical Field Computer Science Mathematics Knowledge Python": "<br/><b>data scientist</b> TextRank score rank: 1249/2000<br/><b>data engineer</b> TextRank score rank: 902/2000", "SQL ETL": "<br/><b>data scientist</b> TextRank score rank: 1250/2000<br/><b>data engineer</b> TextRank score rank: 934/2000", "MapReduce MPP": "<br/><b>data scientist</b> TextRank score rank: 1251/2000<br/><b>data engineer</b> TextRank score rank: 978/2000", "Large scale ETL Apache beam Apache spark High scale Restful Services Cloud experience": "<br/><b>data scientist</b> TextRank score rank: 1252/2000<br/><b>data engineer</b> TextRank score rank: 463/2000", "B Tech Computer Science IT": "<br/><b>data scientist</b> TextRank score rank: 1253/2000<br/><b>data engineer</b> TextRank score rank: 554/2000", "Google Cloud Platform Azure AWS": "<br/><b>data scientist</b> TextRank score rank: 1254/2000<br/><b>data engineer</b> TextRank score rank: 569/2000", "ETL Apache": "<br/><b>data scientist</b> TextRank score rank: 1255/2000<br/><b>data engineer</b> TextRank score rank: 631/2000", "SQL document stores": "<br/><b>data scientist</b> TextRank score rank: 1256/2000<br/><b>data engineer</b> TextRank score rank: 725/2000", "BSc B": "<br/><b>data scientist</b> TextRank score rank: 1257/2000<br/><b>data engineer</b> TextRank score rank: 735/2000", "Python Data": "<br/><b>data scientist</b> TextRank score rank: 1258/2000<br/><b>data engineer</b> TextRank score rank: 910/2000", "Experience Azure Data Factory Data Bricks Data Lake": "<br/><b>data scientist</b> TextRank score rank: 1259/2000<br/><b>data engineer</b> TextRank score rank: 145/2000", "Bricks Data Lake": "<br/><b>data scientist</b> TextRank score rank: 1260/2000<br/><b>data engineer</b> TextRank score rank: 176/2000", "solid understanding relational NoSQL database technologies Experience visualization data mining statistical tools": "<br/><b>data scientist</b> TextRank score rank: 1237/2000<br/><b>data engineer</b> TextRank score rank: 626/2000", "massive complex datasets": "<br/><b>data scientist</b> TextRank score rank: 1236/2000<br/><b>data engineer</b> TextRank score rank: 628/2000", "metrics statistical information": "<br/><b>data scientist</b> TextRank score rank: 1235/2000<br/><b>data engineer</b> TextRank score rank: 677/2000", "familiar ETL tools": "<br/><b>data scientist</b> TextRank score rank: 1222/2000<br/><b>data engineer</b> TextRank score rank: 699/2000", "robust data analytic pipelines": "<br/><b>data scientist</b> TextRank score rank: 1212/2000<br/><b>data engineer</b> TextRank score rank: 706/2000", "Expertise various ETL technologies": "<br/><b>data scientist</b> TextRank score rank: 1213/2000<br/><b>data engineer</b> TextRank score rank: 738/2000", "e g Python Scala comfortable developing code": "<br/><b>data scientist</b> TextRank score rank: 1214/2000<br/><b>data engineer</b> TextRank score rank: 799/2000", "Solr Kafka": "<br/><b>data scientist</b> TextRank score rank: 1215/2000<br/><b>data engineer</b> TextRank score rank: 917/2000", "e g Oozie Airflow": "<br/><b>data scientist</b> TextRank score rank: 1216/2000<br/><b>data engineer</b> TextRank score rank: 972/2000", "Oozie Airflow Have": "<br/><b>data scientist</b> TextRank score rank: 1217/2000<br/><b>data engineer</b> TextRank score rank: 1006/2000", "relational data Postgres programming experience": "<br/><b>data scientist</b> TextRank score rank: 1218/2000<br/><b>data engineer</b> TextRank score rank: 728/2000", "unstructured data APIs Experience ETL integration": "<br/><b>data scientist</b> TextRank score rank: 1219/2000<br/><b>data engineer</b> TextRank score rank: 742/2000", "DMS Stitch Experience data analysis visualization tools Mode Working knowledge message": "<br/><b>data scientist</b> TextRank score rank: 1220/2000<br/><b>data engineer</b> TextRank score rank: 760/2000", "tech debt Experience business operations tools": "<br/><b>data scientist</b> TextRank score rank: 1221/2000<br/><b>data engineer</b> TextRank score rank: 789/2000", "technology landscape Experience AWS services": "<br/><b>data scientist</b> TextRank score rank: 1223/2000<br/><b>data engineer</b> TextRank score rank: 822/2000", "data science machine": "<br/><b>data scientist</b> TextRank score rank: 1234/2000<br/><b>data engineer</b> TextRank score rank: 865/2000", "positive attitude empathy Self awareness desire": "<br/><b>data scientist</b> TextRank score rank: 1224/2000<br/><b>data engineer</b> TextRank score rank: 900/2000", "Dog Friendly Office": "<br/><b>data scientist</b> TextRank score rank: 1225/2000<br/><b>data engineer</b> TextRank score rank: 922/2000", "deep understanding data engineering concepts database": "<br/><b>data scientist</b> TextRank score rank: 1226/2000<br/><b>data engineer</b> TextRank score rank: 953/2000", "Lambda DynamoDB etc Competitive salary Employee Stock Option Plan Generous health commuter benefits": "<br/><b>data scientist</b> TextRank score rank: 1227/2000<br/><b>data engineer</b> TextRank score rank: 1018/2000", "Advanced SQL knowledge": "<br/><b>data scientist</b> TextRank score rank: 1228/2000<br/><b>data engineer</b> TextRank score rank: 1019/2000", "Informatica Talend Pentaho DataStage Experience interest Big Data technologies": "<br/><b>data scientist</b> TextRank score rank: 1229/2000<br/><b>data engineer</b> TextRank score rank: 582/2000", "Azure Strong SQL experience": "<br/><b>data scientist</b> TextRank score rank: 1230/2000<br/><b>data engineer</b> TextRank score rank: 588/2000", "Data security governance expertise": "<br/><b>data scientist</b> TextRank score rank: 1231/2000<br/><b>data engineer</b> TextRank score rank: 589/2000", "structured unstructured data Extensive AWS Experience": "<br/><b>data scientist</b> TextRank score rank: 1232/2000<br/><b>data engineer</b> TextRank score rank: 458/2000", "Python preferred Experience designing data architecture ground Experience": "<br/><b>data scientist</b> TextRank score rank: 1233/2000<br/><b>data engineer</b> TextRank score rank: 488/2000", "working data systems years": "<br/><b>data scientist</b> TextRank score rank: 1291/2000<br/><b>data engineer</b> TextRank score rank: 566/2000", "Spark Hadoop years": "<br/><b>data scientist</b> TextRank score rank: 1368/2000<br/><b>data engineer</b> TextRank score rank: 578/2000", "Bachelor Degree computer science engineering mathematics related fields equivalent experience Expert SQL knowledge experience": "<br/><b>data scientist</b> TextRank score rank: 1526/2000<br/><b>data engineer</b> TextRank score rank: 502/2000", "large datasets Masters Degree computer science engineering mathematics related fields equivalent experience": "<br/><b>data scientist</b> TextRank score rank: 1370/2000<br/><b>data engineer</b> TextRank score rank: 511/2000", "large scale data warehouse platform Hands experience": "<br/><b>data scientist</b> TextRank score rank: 1502/2000<br/><b>data engineer</b> TextRank score rank: 571/2000", "engineering experience years": "<br/><b>data scientist</b> TextRank score rank: 1503/2000<br/><b>data engineer</b> TextRank score rank: 580/2000", "Python C C Experience data visualization presentation": "<br/><b>data scientist</b> TextRank score rank: 1504/2000<br/><b>data engineer</b> TextRank score rank: 435/2000", "familiar data analysis tools": "<br/><b>data scientist</b> TextRank score rank: 1505/2000<br/><b>data engineer</b> TextRank score rank: 505/2000", "large scale data": "<br/><b>data scientist</b> TextRank score rank: 1506/2000<br/><b>data engineer</b> TextRank score rank: 527/2000", "online caches real time systems BA BS Degree Computer Science Engineering discipline Statistics Information Systems": "<br/><b>data scientist</b> TextRank score rank: 1507/2000<br/><b>data engineer</b> TextRank score rank: 498/2000", "Data Warehouse": "<br/><b>data scientist</b> TextRank score rank: 1508/2000<br/><b>data engineer</b> TextRank score rank: 119/2000", "Travel": "<br/><b>data scientist</b> TextRank score rank: 1509/2000<br/><b>data engineer</b> TextRank score rank: 112/2000", "sit shoulder shoulder": "<br/><b>data scientist</b> TextRank score rank: 1510/2000<br/><b>data engineer</b> TextRank score rank: 307/2000", "challenging encouraging": "<br/><b>data scientist</b> TextRank score rank: 1511/2000<br/><b>data engineer</b> TextRank score rank: 370/2000", "New Hire Orientation": "<br/><b>data scientist</b> TextRank score rank: 1512/2000<br/><b>data engineer</b> TextRank score rank: 591/2000", "Robust Perks generous PTO 401k contributions tuition assistance entertainment discounts": "<br/><b>data scientist</b> TextRank score rank: 1513/2000<br/><b>data engineer</b> TextRank score rank: 258/2000", "massage volunteer opportunities": "<br/><b>data scientist</b> TextRank score rank: 1514/2000<br/><b>data engineer</b> TextRank score rank: 467/2000", "Vibrancy Wellness Program Yoga fitness classes": "<br/><b>data scientist</b> TextRank score rank: 1515/2000<br/><b>data engineer</b> TextRank score rank: 565/2000", "employee coverage": "<br/><b>data scientist</b> TextRank score rank: 1516/2000<br/><b>data engineer</b> TextRank score rank: 602/2000", "monthly": "<br/><b>data scientist</b> TextRank score rank: 1517/2000<br/><b>data engineer</b> TextRank score rank: 544/2000", "healthy food utmost convenience": "<br/><b>data scientist</b> TextRank score rank: 1518/2000<br/><b>data engineer</b> TextRank score rank: 254/2000", "market boundaries": "<br/><b>data scientist</b> TextRank score rank: 1519/2000<br/><b>data engineer</b> TextRank score rank: 474/2000", "phenomenal team individuals": "<br/><b>data scientist</b> TextRank score rank: 1520/2000<br/><b>data engineer</b> TextRank score rank: 549/2000", "Previously healthcare experience": "<br/><b>data scientist</b> TextRank score rank: 1521/2000<br/><b>data engineer</b> TextRank score rank: 507/2000", "g Storm Spark Streaming ETL tools": "<br/><b>data scientist</b> TextRank score rank: 1522/2000<br/><b>data engineer</b> TextRank score rank: 278/2000", "sensitive available time resource constraints": "<br/><b>data scientist</b> TextRank score rank: 1523/2000<br/><b>data engineer</b> TextRank score rank: 305/2000", "g Cassandra MongoDB Stream processing systems": "<br/><b>data scientist</b> TextRank score rank: 1524/2000<br/><b>data engineer</b> TextRank score rank: 291/2000", "g MapReduce Hive Pig SQL": "<br/><b>data scientist</b> TextRank score rank: 1501/2000<br/><b>data engineer</b> TextRank score rank: 294/2000", "Hadoop based technologies": "<br/><b>data scientist</b> TextRank score rank: 1500/2000<br/><b>data engineer</b> TextRank score rank: 358/2000", "data storage retrieval specific use cases": "<br/><b>data scientist</b> TextRank score rank: 1499/2000<br/><b>data engineer</b> TextRank score rank: 456/2000", "Cloud computing architectures": "<br/><b>data scientist</b> TextRank score rank: 1486/2000<br/><b>data engineer</b> TextRank score rank: 492/2000", "NoSQL technologies": "<br/><b>data scientist</b> TextRank score rank: 1476/2000<br/><b>data engineer</b> TextRank score rank: 509/2000", "Legacy modern database": "<br/><b>data scientist</b> TextRank score rank: 1477/2000<br/><b>data engineer</b> TextRank score rank: 604/2000", "user defined functions table functions": "<br/><b>data scientist</b> TextRank score rank: 1478/2000<br/><b>data engineer</b> TextRank score rank: 432/2000", "career growth": "<br/><b>data scientist</b> TextRank score rank: 1479/2000<br/><b>data engineer</b> TextRank score rank: 415/2000", "smart people": "<br/><b>data scientist</b> TextRank score rank: 1480/2000<br/><b>data engineer</b> TextRank score rank: 313/2000", "Data Platform Administration Engineering": "<br/><b>data scientist</b> TextRank score rank: 1481/2000<br/><b>data engineer</b> TextRank score rank: 85/2000", "Bachelor Degree Computer Science related field years": "<br/><b>data scientist</b> TextRank score rank: 1482/2000<br/><b>data engineer</b> TextRank score rank: 426/2000", "Bachelor Degree Computer Science": "<br/><b>data scientist</b> TextRank score rank: 1483/2000<br/><b>data engineer</b> TextRank score rank: 539/2000", "Excellent understanding manipulation analysis": "<br/><b>data scientist</b> TextRank score rank: 1484/2000<br/><b>data engineer</b> TextRank score rank: 392/2000", "modern tech tools hi tech equipment": "<br/><b>data scientist</b> TextRank score rank: 1485/2000<br/><b>data engineer</b> TextRank score rank: 154/2000", "extra cash pocket": "<br/><b>data scientist</b> TextRank score rank: 1487/2000<br/><b>data engineer</b> TextRank score rank: 255/2000", "opportunity work friends": "<br/><b>data scientist</b> TextRank score rank: 1498/2000<br/><b>data engineer</b> TextRank score rank: 362/2000", "A commitment open inclusive diverse work culture": "<br/><b>data scientist</b> TextRank score rank: 1488/2000<br/><b>data engineer</b> TextRank score rank: 320/2000", "Data Warehouse Big Data": "<br/><b>data scientist</b> TextRank score rank: 1489/2000<br/><b>data engineer</b> TextRank score rank: 230/2000", "SQL Data Warehouse Data Catalog Azure Analysis Services Data Bricks Storage Account": "<br/><b>data scientist</b> TextRank score rank: 1490/2000<br/><b>data engineer</b> TextRank score rank: 243/2000", "SQL Server preferable multi dimensional Data Warehousing environment": "<br/><b>data scientist</b> TextRank score rank: 1491/2000<br/><b>data engineer</b> TextRank score rank: 328/2000", "Data Warehousing": "<br/><b>data scientist</b> TextRank score rank: 1492/2000<br/><b>data engineer</b> TextRank score rank: 330/2000", "Enterprise Data Analytics solution architecture years": "<br/><b>data scientist</b> TextRank score rank: 1493/2000<br/><b>data engineer</b> TextRank score rank: 332/2000", "SQL Programming PL SQL": "<br/><b>data scientist</b> TextRank score rank: 1494/2000<br/><b>data engineer</b> TextRank score rank: 352/2000", "Python SQL Strong": "<br/><b>data scientist</b> TextRank score rank: 1495/2000<br/><b>data engineer</b> TextRank score rank: 372/2000", "SQL Programming PL SQL T": "<br/><b>data scientist</b> TextRank score rank: 1496/2000<br/><b>data engineer</b> TextRank score rank: 375/2000", "Spark Pyspark Python Scala Pig Experience Big Data Management BDM relational non relational data formats": "<br/><b>data scientist</b> TextRank score rank: 1497/2000<br/><b>data engineer</b> TextRank score rank: 406/2000", "Python SQL Strong analytical abilities": "<br/><b>data scientist</b> TextRank score rank: 1525/2000<br/><b>data engineer</b> TextRank score rank: 407/2000", "Microsoft SQL Server preferable expert MDX DAX": "<br/><b>data scientist</b> TextRank score rank: 1527/2000<br/><b>data engineer</b> TextRank score rank: 422/2000", "Azure": "<br/><b>data scientist</b> TextRank score rank: 1578/2000<br/><b>data engineer</b> TextRank score rank: 437/2000", "SQL U": "<br/><b>data scientist</b> TextRank score rank: 1528/2000<br/><b>data engineer</b> TextRank score rank: 438/2000", "mobile solutions years": "<br/><b>data scientist</b> TextRank score rank: 1555/2000<br/><b>data engineer</b> TextRank score rank: 460/2000", "Power BI": "<br/><b>data scientist</b> TextRank score rank: 1556/2000<br/><b>data engineer</b> TextRank score rank: 131/2000", "Hive Hadoop": "<br/><b>data scientist</b> TextRank score rank: 1557/2000<br/><b>data engineer</b> TextRank score rank: 393/2000", "Hackathons": "<br/><b>data scientist</b> TextRank score rank: 1558/2000<br/><b>data engineer</b> TextRank score rank: 111/2000", "metrics consumers": "<br/><b>data scientist</b> TextRank score rank: 1559/2000<br/><b>data engineer</b> TextRank score rank: 207/2000", "Work data science teams": "<br/><b>data scientist</b> TextRank score rank: 1560/2000<br/><b>data engineer</b> TextRank score rank: 336/2000", "data curation management strategies": "<br/><b>data scientist</b> TextRank score rank: 1561/2000<br/><b>data engineer</b> TextRank score rank: 162/2000", "laboratory research data management processes procedures": "<br/><b>data scientist</b> TextRank score rank: 1562/2000<br/><b>data engineer</b> TextRank score rank: 165/2000", "biomedical data management data engineering quality assurance": "<br/><b>data scientist</b> TextRank score rank: 1563/2000<br/><b>data engineer</b> TextRank score rank: 256/2000", "Excellent skills R programming experience": "<br/><b>data scientist</b> TextRank score rank: 1564/2000<br/><b>data engineer</b> TextRank score rank: 183/2000", "development specimen data management related discipline Demonstrated proficiency molecular biology concepts ability support": "<br/><b>data scientist</b> TextRank score rank: 1565/2000<br/><b>data engineer</b> TextRank score rank: 295/2000", "systematic relational approaches data integration data processing": "<br/><b>data scientist</b> TextRank score rank: 1566/2000<br/><b>data engineer</b> TextRank score rank: 297/2000", "Detailed knowledge experience case report form design central laboratories": "<br/><b>data scientist</b> TextRank score rank: 1567/2000<br/><b>data engineer</b> TextRank score rank: 301/2000", "Working knowledge Windows Linux operating systems": "<br/><b>data scientist</b> TextRank score rank: 1568/2000<br/><b>data engineer</b> TextRank score rank: 341/2000", "query resolution data validation Computer": "<br/><b>data scientist</b> TextRank score rank: 1569/2000<br/><b>data engineer</b> TextRank score rank: 342/2000", "SAS data": "<br/><b>data scientist</b> TextRank score rank: 1570/2000<br/><b>data engineer</b> TextRank score rank: 343/2000", "detailed knowledge": "<br/><b>data scientist</b> TextRank score rank: 1571/2000<br/><b>data engineer</b> TextRank score rank: 345/2000", "action patient response Proven ability work team environment clinical personnel study monitors": "<br/><b>data scientist</b> TextRank score rank: 1572/2000<br/><b>data engineer</b> TextRank score rank: 371/2000", "strong capacity independent thinking ability": "<br/><b>data scientist</b> TextRank score rank: 1573/2000<br/><b>data engineer</b> TextRank score rank: 238/2000", "Oracle Clinical Clintrial preferred experience": "<br/><b>data scientist</b> TextRank score rank: 1574/2000<br/><b>data engineer</b> TextRank score rank: 409/2000", "Strong understanding LIMS systems": "<br/><b>data scientist</b> TextRank score rank: 1575/2000<br/><b>data engineer</b> TextRank score rank: 416/2000", "Java C C Extensive practical experience": "<br/><b>data scientist</b> TextRank score rank: 1576/2000<br/><b>data engineer</b> TextRank score rank: 431/2000", "database design implementation": "<br/><b>data scientist</b> TextRank score rank: 1577/2000<br/><b>data engineer</b> TextRank score rank: 287/2000", "complex dynamic environment": "<br/><b>data scientist</b> TextRank score rank: 1554/2000<br/><b>data engineer</b> TextRank score rank: 279/2000", "Along programming proficiency": "<br/><b>data scientist</b> TextRank score rank: 1553/2000<br/><b>data engineer</b> TextRank score rank: 269/2000", "least one data management system": "<br/><b>data scientist</b> TextRank score rank: 1552/2000<br/><b>data engineer</b> TextRank score rank: 450/2000", "additional computer languages": "<br/><b>data scientist</b> TextRank score rank: 1539/2000<br/><b>data engineer</b> TextRank score rank: 298/2000", "high level scientific datasets": "<br/><b>data scientist</b> TextRank score rank: 1529/2000<br/><b>data engineer</b> TextRank score rank: 290/2000", "medical writers": "<br/><b>data scientist</b> TextRank score rank: 1530/2000<br/><b>data engineer</b> TextRank score rank: 344/2000", "organizational skills": "<br/><b>data scientist</b> TextRank score rank: 1531/2000<br/><b>data engineer</b> TextRank score rank: 484/2000", "direct assess implementation": "<br/><b>data scientist</b> TextRank score rank: 1532/2000<br/><b>data engineer</b> TextRank score rank: 338/2000", "computational biologists biostatisticians": "<br/><b>data scientist</b> TextRank score rank: 1533/2000<br/><b>data engineer</b> TextRank score rank: 521/2000", "Familiarity Amazon Web Services": "<br/><b>data scientist</b> TextRank score rank: 1534/2000<br/><b>data engineer</b> TextRank score rank: 525/2000", "research hypotheses": "<br/><b>data scientist</b> TextRank score rank: 1535/2000<br/><b>data engineer</b> TextRank score rank: 378/2000", "underlying biological questions": "<br/><b>data scientist</b> TextRank score rank: 1536/2000<br/><b>data engineer</b> TextRank score rank: 400/2000", "query interfaces": "<br/><b>data scientist</b> TextRank score rank: 1537/2000<br/><b>data engineer</b> TextRank score rank: 421/2000", "diverse highly connected scientific knowledge collections": "<br/><b>data scientist</b> TextRank score rank: 1538/2000<br/><b>data engineer</b> TextRank score rank: 418/2000", "Perl Python PHP S": "<br/><b>data scientist</b> TextRank score rank: 1540/2000<br/><b>data engineer</b> TextRank score rank: 317/2000", "Experience integration data": "<br/><b>data scientist</b> TextRank score rank: 1551/2000<br/><b>data engineer</b> TextRank score rank: 232/2000", "Enriched Tuition reimbursement training learning programs": "<br/><b>data scientist</b> TextRank score rank: 1541/2000<br/><b>data engineer</b> TextRank score rank: 470/2000", "multiple partners": "<br/><b>data scientist</b> TextRank score rank: 1542/2000<br/><b>data engineer</b> TextRank score rank: 196/2000", "Track record": "<br/><b>data scientist</b> TextRank score rank: 1543/2000<br/><b>data engineer</b> TextRank score rank: 452/2000", "Knowledge sharing activities": "<br/><b>data scientist</b> TextRank score rank: 1544/2000<br/><b>data engineer</b> TextRank score rank: 136/2000", "preferred Data modeling experience": "<br/><b>data scientist</b> TextRank score rank: 1545/2000<br/><b>data engineer</b> TextRank score rank: 721/2000", "advantageous Pair programming experience Scrum agile experience Kanban agile experience JIRA experience Release search applications cloud environment": "<br/><b>data scientist</b> TextRank score rank: 1546/2000<br/><b>data engineer</b> TextRank score rank: 515/2000", "Experience graph database": "<br/><b>data scientist</b> TextRank score rank: 1547/2000<br/><b>data engineer</b> TextRank score rank: 593/2000", "Kafka Apache Spark Experience big data technologies Hadoop Kafka Akka Mesos": "<br/><b>data scientist</b> TextRank score rank: 1548/2000<br/><b>data engineer</b> TextRank score rank: 672/2000", "highly desirable Experience Semantic Web RDF OWL SPARQL": "<br/><b>data scientist</b> TextRank score rank: 1549/2000<br/><b>data engineer</b> TextRank score rank: 794/2000", "dev ops": "<br/><b>data scientist</b> TextRank score rank: 1550/2000<br/><b>data engineer</b> TextRank score rank: 860/2000", "specific Big Data DevOps roles": "<br/><b>data scientist</b> TextRank score rank: 1475/2000<br/><b>data engineer</b> TextRank score rank: 730/2000", "Most Big Data Engineers": "<br/><b>data scientist</b> TextRank score rank: 1474/2000<br/><b>data engineer</b> TextRank score rank: 790/2000", "Machine Learning Big Data": "<br/><b>data scientist</b> TextRank score rank: 1473/2000<br/><b>data engineer</b> TextRank score rank: 797/2000", "Machine Learning Big Data infrastructure": "<br/><b>data scientist</b> TextRank score rank: 1472/2000<br/><b>data engineer</b> TextRank score rank: 814/2000", "Flume Experience various messaging systems": "<br/><b>data scientist</b> TextRank score rank: 1397/2000<br/><b>data engineer</b> TextRank score rank: 833/2000", "GCP AWS Azure year experience": "<br/><b>data scientist</b> TextRank score rank: 1398/2000<br/><b>data engineer</b> TextRank score rank: 641/2000", "Python Scala Golang R year experience provisioned demand cloud computing platforms": "<br/><b>data scientist</b> TextRank score rank: 1399/2000<br/><b>data engineer</b> TextRank score rank: 700/2000", "computing fundamentals ability design scalability": "<br/><b>data scientist</b> TextRank score rank: 1400/2000<br/><b>data engineer</b> TextRank score rank: 862/2000", "g Git Jira": "<br/><b>data scientist</b> TextRank score rank: 1401/2000<br/><b>data engineer</b> TextRank score rank: 555/2000", "etc Knowledge": "<br/><b>data scientist</b> TextRank score rank: 1402/2000<br/><b>data engineer</b> TextRank score rank: 567/2000", "Git Jira": "<br/><b>data scientist</b> TextRank score rank: 1403/2000<br/><b>data engineer</b> TextRank score rank: 616/2000", "year experience working data lake environment Experience collecting transforming": "<br/><b>data scientist</b> TextRank score rank: 1404/2000<br/><b>data engineer</b> TextRank score rank: 663/2000", "working data engineering": "<br/><b>data scientist</b> TextRank score rank: 1405/2000<br/><b>data engineer</b> TextRank score rank: 707/2000", "data pipelines machine": "<br/><b>data scientist</b> TextRank score rank: 1406/2000<br/><b>data engineer</b> TextRank score rank: 717/2000", "large amounts data": "<br/><b>data scientist</b> TextRank score rank: 1408/2000<br/><b>data engineer</b> TextRank score rank: 751/2000", "Bachelor degree experience": "<br/><b>data scientist</b> TextRank score rank: 1419/2000<br/><b>data engineer</b> TextRank score rank: 772/2000", "year experience": "<br/><b>data scientist</b> TextRank score rank: 1409/2000<br/><b>data engineer</b> TextRank score rank: 787/2000", "Java Python Knowledge Hadoop Spark big data processing frameworks": "<br/><b>data scientist</b> TextRank score rank: 1410/2000<br/><b>data engineer</b> TextRank score rank: 821/2000", "Bachelor degree Master degree computer science field Computer Science Information Sciences Informatics Experience": "<br/><b>data scientist</b> TextRank score rank: 1411/2000<br/><b>data engineer</b> TextRank score rank: 824/2000", "Relevant degree work experience": "<br/><b>data scientist</b> TextRank score rank: 1412/2000<br/><b>data engineer</b> TextRank score rank: 152/2000", "This full time exempt position": "<br/><b>data scientist</b> TextRank score rank: 1413/2000<br/><b>data engineer</b> TextRank score rank: 304/2000", "real world experience AWS EMR E2 Kinesis S3": "<br/><b>data scientist</b> TextRank score rank: 1414/2000<br/><b>data engineer</b> TextRank score rank: 247/2000", "Bonus points": "<br/><b>data scientist</b> TextRank score rank: 1415/2000<br/><b>data engineer</b> TextRank score rank: 705/2000", "agile methodologies": "<br/><b>data scientist</b> TextRank score rank: 1416/2000<br/><b>data engineer</b> TextRank score rank: 208/2000", "Scala Java C": "<br/><b>data scientist</b> TextRank score rank: 1417/2000<br/><b>data engineer</b> TextRank score rank: 417/2000", "Data serialization JSON avro parquet": "<br/><b>data scientist</b> TextRank score rank: 1418/2000<br/><b>data engineer</b> TextRank score rank: 174/2000", "Building Cube Cube": "<br/><b>data scientist</b> TextRank score rank: 1396/2000<br/><b>data engineer</b> TextRank score rank: 141/2000", "products": "<br/><b>data scientist</b> TextRank score rank: 1407/2000<br/><b>data engineer</b> TextRank score rank: 206/2000", "Docker Apache Mesos Kubernetes": "<br/><b>data scientist</b> TextRank score rank: 1395/2000<br/><b>data engineer</b> TextRank score rank: 192/2000", "Cluster managers eg Docker Apache Mesos Kubernetes": "<br/><b>data scientist</b> TextRank score rank: 1381/2000<br/><b>data engineer</b> TextRank score rank: 210/2000", "401k retirement savings plan": "<br/><b>data scientist</b> TextRank score rank: 1371/2000<br/><b>data engineer</b> TextRank score rank: 148/2000", "LA best restaurants": "<br/><b>data scientist</b> TextRank score rank: 1372/2000<br/><b>data engineer</b> TextRank score rank: 299/2000", "Daily catered lunches": "<br/><b>data scientist</b> TextRank score rank: 1373/2000<br/><b>data engineer</b> TextRank score rank: 464/2000", "profile": "<br/><b>data scientist</b> TextRank score rank: 1374/2000<br/><b>data engineer</b> TextRank score rank: 184/2000", "Indemnity": "<br/><b>data scientist</b> TextRank score rank: 1375/2000<br/><b>data engineer</b> TextRank score rank: 377/2000", "meet business processes priorities": "<br/><b>data scientist</b> TextRank score rank: 1376/2000<br/><b>data engineer</b> TextRank score rank: 285/2000", "application enhancements": "<br/><b>data scientist</b> TextRank score rank: 1377/2000<br/><b>data engineer</b> TextRank score rank: 528/2000", "3rd party vendors": "<br/><b>data scientist</b> TextRank score rank: 1378/2000<br/><b>data engineer</b> TextRank score rank: 597/2000", "3rd party": "<br/><b>data scientist</b> TextRank score rank: 1379/2000<br/><b>data engineer</b> TextRank score rank: 691/2000", "academic experience data engineering capacity Experience Docker Apache Spark ElasticSearch": "<br/><b>data scientist</b> TextRank score rank: 1380/2000<br/><b>data engineer</b> TextRank score rank: 182/2000", "similar Hands experience": "<br/><b>data scientist</b> TextRank score rank: 1382/2000<br/><b>data engineer</b> TextRank score rank: 211/2000", "queue technology Apache Kafka": "<br/><b>data scientist</b> TextRank score rank: 1393/2000<br/><b>data engineer</b> TextRank score rank: 245/2000", "real time systems production stage years": "<br/><b>data scientist</b> TextRank score rank: 1383/2000<br/><b>data engineer</b> TextRank score rank: 248/2000", "Excellent experience": "<br/><b>data scientist</b> TextRank score rank: 1384/2000<br/><b>data engineer</b> TextRank score rank: 263/2000", "Apache Kafka": "<br/><b>data scientist</b> TextRank score rank: 1385/2000<br/><b>data engineer</b> TextRank score rank: 272/2000", "Google Analytics": "<br/><b>data scientist</b> TextRank score rank: 1386/2000<br/><b>data engineer</b> TextRank score rank: 16/2000", "Agile Scrum working practices": "<br/><b>data scientist</b> TextRank score rank: 1387/2000<br/><b>data engineer</b> TextRank score rank: 151/2000", "Masters degree years experience Experience proficiency Scala Experience proficiency": "<br/><b>data scientist</b> TextRank score rank: 1388/2000<br/><b>data engineer</b> TextRank score rank: 497/2000", "interest applying scale Experience data cleaning preparation feature building selection techniques": "<br/><b>data scientist</b> TextRank score rank: 1389/2000<br/><b>data engineer</b> TextRank score rank: 605/2000", "random effect models": "<br/><b>data scientist</b> TextRank score rank: 1390/2000<br/><b>data engineer</b> TextRank score rank: 662/2000", "Effective communication interpersonal teamwork skills Ability": "<br/><b>data scientist</b> TextRank score rank: 1391/2000<br/><b>data engineer</b> TextRank score rank: 678/2000", "duties": "<br/><b>data scientist</b> TextRank score rank: 1392/2000<br/><b>data engineer</b> TextRank score rank: 283/2000", "Information Technology experience": "<br/><b>data scientist</b> TextRank score rank: 1394/2000<br/><b>data engineer</b> TextRank score rank: 581/2000", "years Information Technology experience Proficiency domain driven design domain modeling Experience NoSql solutions Gemfire Cassandra HBase": "<br/><b>data scientist</b> TextRank score rank: 1420/2000<br/><b>data engineer</b> TextRank score rank: 583/2000", "CI CD tools": "<br/><b>data scientist</b> TextRank score rank: 1421/2000<br/><b>data engineer</b> TextRank score rank: 611/2000", "Bachelor Degree years Information Technology experience": "<br/><b>data scientist</b> TextRank score rank: 1422/2000<br/><b>data engineer</b> TextRank score rank: 643/2000", "MySQL SQL Server Oracle": "<br/><b>data scientist</b> TextRank score rank: 1449/2000<br/><b>data engineer</b> TextRank score rank: 679/2000", "A good understanding adherence data security standards": "<br/><b>data scientist</b> TextRank score rank: 1450/2000<br/><b>data engineer</b> TextRank score rank: 318/2000", "Python Golang Clojure R year experience provisioned demand cloud computing platforms GCP AWS Azure year experience": "<br/><b>data scientist</b> TextRank score rank: 1451/2000<br/><b>data engineer</b> TextRank score rank: 501/2000", "data solutions AWS Experience building data vision strategy": "<br/><b>data scientist</b> TextRank score rank: 1452/2000<br/><b>data engineer</b> TextRank score rank: 461/2000", "FinTech related area": "<br/><b>data scientist</b> TextRank score rank: 1453/2000<br/><b>data engineer</b> TextRank score rank: 518/2000", "Chicago Top Company Culture Entrepreneur Top Workplace Chicago Tribune": "<br/><b>data scientist</b> TextRank score rank: 1454/2000<br/><b>data engineer</b> TextRank score rank: 281/2000", "Crain Chicago Business": "<br/><b>data scientist</b> TextRank score rank: 1455/2000<br/><b>data engineer</b> TextRank score rank: 351/2000", "Best Consumer Web Company": "<br/><b>data scientist</b> TextRank score rank: 1456/2000<br/><b>data engineer</b> TextRank score rank: 553/2000", "one Chicago Best Places Work Women": "<br/><b>data scientist</b> TextRank score rank: 1457/2000<br/><b>data engineer</b> TextRank score rank: 562/2000", "Best Consumer": "<br/><b>data scientist</b> TextRank score rank: 1458/2000<br/><b>data engineer</b> TextRank score rank: 627/2000", "Experience HTTP REST SSL identity authentication": "<br/><b>data scientist</b> TextRank score rank: 1459/2000<br/><b>data engineer</b> TextRank score rank: 194/2000", "data infrastructure cloud": "<br/><b>data scientist</b> TextRank score rank: 1460/2000<br/><b>data engineer</b> TextRank score rank: 181/2000", "Comfortable building": "<br/><b>data scientist</b> TextRank score rank: 1461/2000<br/><b>data engineer</b> TextRank score rank: 453/2000", "happy hours wind": "<br/><b>data scientist</b> TextRank score rank: 1462/2000<br/><b>data engineer</b> TextRank score rank: 222/2000", "Spontaneous nerf gun wars": "<br/><b>data scientist</b> TextRank score rank: 1463/2000<br/><b>data engineer</b> TextRank score rank: 444/2000", "Thursday": "<br/><b>data scientist</b> TextRank score rank: 1369/2000<br/><b>data engineer</b> TextRank score rank: 202/2000", "Excellent verbal written communication skills": "<br/><b>data scientist</b> TextRank score rank: 1465/2000<br/><b>data engineer</b> TextRank score rank: 175/2000", "Java PHP Years database work mysql Postgres RedShift Experience": "<br/><b>data scientist</b> TextRank score rank: 1466/2000<br/><b>data engineer</b> TextRank score rank: 618/2000", "Oriented Programming Python Java Database Technologies Redshift Postgres Spark Presto Amazon Web Services S3 SQS Kinesis ECS ECR EMR": "<br/><b>data scientist</b> TextRank score rank: 1467/2000<br/><b>data engineer</b> TextRank score rank: 624/2000", "B S Computer Science Object": "<br/><b>data scientist</b> TextRank score rank: 1468/2000<br/><b>data engineer</b> TextRank score rank: 273/2000", "System availability Data Availability Data Quality": "<br/><b>data scientist</b> TextRank score rank: 1469/2000<br/><b>data engineer</b> TextRank score rank: 524/2000", "SAP Data Services Talend": "<br/><b>data scientist</b> TextRank score rank: 1470/2000<br/><b>data engineer</b> TextRank score rank: 572/2000", "SAP Data Services": "<br/><b>data scientist</b> TextRank score rank: 1471/2000<br/><b>data engineer</b> TextRank score rank: 573/2000", "MS SQL Server Strong programming experience": "<br/><b>data scientist</b> TextRank score rank: 1448/2000<br/><b>data engineer</b> TextRank score rank: 715/2000", "hard promote change industry": "<br/><b>data scientist</b> TextRank score rank: 1447/2000<br/><b>data engineer</b> TextRank score rank: 280/2000", "Share success": "<br/><b>data scientist</b> TextRank score rank: 1446/2000<br/><b>data engineer</b> TextRank score rank: 419/2000", "success": "<br/><b>data scientist</b> TextRank score rank: 1433/2000<br/><b>data engineer</b> TextRank score rank: 433/2000", "way": "<br/><b>data scientist</b> TextRank score rank: 1423/2000<br/><b>data engineer</b> TextRank score rank: 447/2000", "RDS redshift S3 Experience consuming cleaning data third party APIs sources": "<br/><b>data scientist</b> TextRank score rank: 1424/2000<br/><b>data engineer</b> TextRank score rank: 551/2000", "Hive Hadoop Spark": "<br/><b>data scientist</b> TextRank score rank: 1425/2000<br/><b>data engineer</b> TextRank score rank: 586/2000", "data Strong communication skills": "<br/><b>data scientist</b> TextRank score rank: 1426/2000<br/><b>data engineer</b> TextRank score rank: 689/2000", "various AWS services": "<br/><b>data scientist</b> TextRank score rank: 1427/2000<br/><b>data engineer</b> TextRank score rank: 763/2000", "unlimited vacation k plan": "<br/><b>data scientist</b> TextRank score rank: 1428/2000<br/><b>data engineer</b> TextRank score rank: 423/2000", "benefits health vision life dental insurance": "<br/><b>data scientist</b> TextRank score rank: 1429/2000<br/><b>data engineer</b> TextRank score rank: 454/2000", "cupcakes": "<br/><b>data scientist</b> TextRank score rank: 1430/2000<br/><b>data engineer</b> TextRank score rank: 490/2000", "competitive compensation equity packages": "<br/><b>data scientist</b> TextRank score rank: 1431/2000<br/><b>data engineer</b> TextRank score rank: 629/2000", "A collaborative nature entrepreneurial spirit": "<br/><b>data scientist</b> TextRank score rank: 1432/2000<br/><b>data engineer</b> TextRank score rank: 576/2000", "SVN C unit test strategy": "<br/><b>data scientist</b> TextRank score rank: 1434/2000<br/><b>data engineer</b> TextRank score rank: 696/2000", "internal tools utilities Set unit test strategy": "<br/><b>data scientist</b> TextRank score rank: 1445/2000<br/><b>data engineer</b> TextRank score rank: 337/2000", "revision control": "<br/><b>data scientist</b> TextRank score rank: 1435/2000<br/><b>data engineer</b> TextRank score rank: 533/2000", "disk Experience Large Scale Big Data methods MapReduce Hadoop Spark Hive Impala Storm Strong": "<br/><b>data scientist</b> TextRank score rank: 1436/2000<br/><b>data engineer</b> TextRank score rank: 675/2000", "automated reports data visualisation solutions": "<br/><b>data scientist</b> TextRank score rank: 1437/2000<br/><b>data engineer</b> TextRank score rank: 584/2000", "modern data solutions": "<br/><b>data scientist</b> TextRank score rank: 1438/2000<br/><b>data engineer</b> TextRank score rank: 617/2000", "Python applications data": "<br/><b>data scientist</b> TextRank score rank: 1439/2000<br/><b>data engineer</b> TextRank score rank: 665/2000", "SQL Comfort": "<br/><b>data scientist</b> TextRank score rank: 1440/2000<br/><b>data engineer</b> TextRank score rank: 420/2000", "LI PA1": "<br/><b>data scientist</b> TextRank score rank: 1441/2000<br/><b>data engineer</b> TextRank score rank: 37/2000", "truly global company offices countries": "<br/><b>data scientist</b> TextRank score rank: 1442/2000<br/><b>data engineer</b> TextRank score rank: 331/2000", "Ball games": "<br/><b>data scientist</b> TextRank score rank: 1443/2000<br/><b>data engineer</b> TextRank score rank: 130/2000", "Monthly team": "<br/><b>data scientist</b> TextRank score rank: 1444/2000<br/><b>data engineer</b> TextRank score rank: 556/2000", "Teradata MS SQL": "<br/><b>data scientist</b> TextRank score rank: 1714/2000<br/><b>data engineer</b> TextRank score rank: 355/2000", "SSRS": "<br/><b>data scientist</b> TextRank score rank: 2000/2000<br/><b>data engineer</b> TextRank score rank: 1077/2000"}, "data": [{"x": 0.0, "y": 0.5056768558951966, "ox": 0.0, "oy": 0.5056768558951966, "term": "Healthcare", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7250876314471708, "os": 0.17714833045962328}, {"x": 0.0, "y": 0.6689956331877731, "ox": 0.0, "oy": 0.6689956331877731, "term": "data Ability", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8157235853780671, "os": 0.23769528822042832}, {"x": 0.0, "y": 0.595633187772926, "ox": 0.0, "oy": 0.595633187772926, "term": "Medical dental vision insurance Life disability coverage", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7741612418627942, "os": 0.20315856388519496}, {"x": 0.0, "y": 0.4969432314410481, "ox": 0.0, "oy": 0.4969432314410481, "term": "401K Flexible Spending Accounts Apple equipment Daily breakfast lunch dinner", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7200801201802705, "os": 0.17569681969647016}, {"x": 0.0, "y": 0.3414847161572053, "ox": 0.0, "oy": 0.3414847161572053, "term": "graduation date", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6339509263895843, "os": 0.14453112295642476}, {"x": 0.838709677419355, "y": 0.675109170305677, "ox": 0.838709677419355, "oy": 0.675109170305677, "term": "Competitive", "cat25k": 13, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08612919379068604, "os": -0.35567468012137776}, {"x": 0.9705069124423964, "y": 0.9737991266375546, "ox": 0.9705069124423964, "oy": 0.9737991266375546, "term": "Tableau", "cat25k": 126, "ncat25k": 78, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 2, "ncat": 1, "s": 0.9849774661992989, "os": 2.2641377452777474}, {"x": 0.02304147465437788, "y": 0.015720524017467253, "ox": 0.02304147465437788, "oy": 0.015720524017467253, "term": "backgrounds", "cat25k": 2, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4947421131697547, "os": -0.047459079300263406}, {"x": 0.0, "y": 0.6139737991266376, "ox": 0.0, "oy": 0.6139737991266376, "term": "novel biomarkers dissect gene disease relationships", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7846770155232848, "os": 0.21349473974228825}, {"x": 0.0, "y": 0.6096069868995634, "ox": 0.0, "oy": 0.6096069868995634, "term": "Strong interested biology immunological diseases", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7821732598898347, "os": 0.21019298647596785}, {"x": 0.0, "y": 0.6052401746724893, "ox": 0.0, "oy": 0.6052401746724893, "term": "Excellent interpersonal team skills", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7796695042563845, "os": 0.2078283811547227}, {"x": 0.0, "y": 0.5921397379912665, "ox": 0.0, "oy": 0.5921397379912665, "term": "Experience Bayesian analysis causal inference", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7721582373560341, "os": 0.2016825724270957}, {"x": 0.0, "y": 0.5868995633187775, "ox": 0.0, "oy": 0.5868995633187775, "term": "PhD MS computational biology computer science statistics", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7691537305958939, "os": 0.20037825763696301}, {"x": 0.0, "y": 0.5475982532751094, "ox": 0.0, "oy": 0.5475982532751094, "term": "benchmark apply predictive algorithms", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7476214321482223, "os": 0.18801564356563372}, {"x": 0.0, "y": 0.5327510917030569, "ox": 0.0, "oy": 0.5327510917030569, "term": "AI machine learning methods", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7401101652478719, "os": 0.18331178089209443}, {"x": 0.0, "y": 0.4855895196506551, "ox": 0.0, "oy": 0.4855895196506551, "term": "non linear regression models", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.71407110665999, "os": 0.17328380178645386}, {"x": 0.0, "y": 0.45502183406113544, "ox": 0.0, "oy": 0.45502183406113544, "term": "dimensionality reduction clustering", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6965448172258387, "os": 0.1680434689101194}, {"x": 0.0, "y": 0.3362445414847162, "ox": 0.0, "oy": 0.3362445414847162, "term": "data R", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6309464196294442, "os": 0.1439069798249464}, {"x": 0.0, "y": 0.3423580786026202, "ox": 0.0, "oy": 0.3423580786026202, "term": "Immunology Inflammation", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6344516775162744, "os": 0.14515943113544647}, {"x": 0.03778801843317973, "y": 0.8209606986899565, "ox": 0.03778801843317973, "oy": 0.8209606986899565, "term": "Proficiency", "cat25k": 22, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8988482724086129, "os": 0.3892433326152225}, {"x": 0.0, "y": 0.8558951965065503, "ox": 0.0, "oy": 0.8558951965065503, "term": "Bayesian", "cat25k": 28, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9203805708562843, "os": 0.5093521291348971}, {"x": 0.9723502304147466, "y": 0.9729257641921398, "ox": 0.9723502304147466, "oy": 0.9729257641921398, "term": "Ability", "cat25k": 122, "ncat25k": 94, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 2, "ncat": 1, "s": 0.9844767150726089, "os": 2.1924068155264025}, {"x": 0.0, "y": 0.37903930131004376, "ox": 0.0, "oy": 0.37903930131004376, "term": "hypotheses", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6549824737105657, "os": 0.15224636420322218}, {"x": 0.4645161290322582, "y": 0.8759825327510917, "ox": 0.4645161290322582, "oy": 0.8759825327510917, "term": "AI", "cat25k": 34, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.930395593390085, "os": 0.6061438398091342}, {"x": 0.011059907834101384, "y": 0.7449781659388647, "ox": 0.011059907834101384, "oy": 0.7449781659388647, "term": "Excellent", "cat25k": 16, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.85578367551327, "os": 0.29305907737548237}, {"x": 0.327188940092166, "y": 0.09956331877729259, "ox": 0.327188940092166, "oy": 0.09956331877729259, "term": "relevant work experience", "cat25k": 6, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3470205307961943, "os": -0.11857736602170926}, {"x": 0.0, "y": 0.5711790393013102, "ox": 0.0, "oy": 0.5711790393013102, "term": "depth knowledge", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7606409614421632, "os": 0.19416403533285015}, {"x": 0.0, "y": 0.5196506550218342, "ox": 0.0, "oy": 0.5196506550218342, "term": "neural networks", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7330996494742112, "os": 0.18033259090472675}, {"x": 0.5502304147465439, "y": 0.606113537117904, "ox": 0.5502304147465439, "oy": 0.606113537117904, "term": "Bachelor degree", "cat25k": 12, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7801702553830746, "os": 0.2088747627572963}, {"x": 0.9317972350230416, "y": 0.9222707423580787, "ox": 0.9317972350230416, "oy": 0.9222707423580787, "term": "Minimum years", "cat25k": 58, "ncat25k": 46, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.956434651977967, "os": 1.045899307765209}, {"x": 0.9640552995391706, "y": 0.8611353711790394, "ox": 0.9640552995391706, "oy": 0.8611353711790394, "term": "Hadoop Spark", "cat25k": 30, "ncat25k": 65, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.018027040560841263, "os": -0.9232468910941851}, {"x": 0.0, "y": 0.5729257641921398, "ox": 0.0, "oy": 0.5729257641921398, "term": "Proficiency R", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7616424636955433, "os": 0.1948031112699628}, {"x": 0.9797235023041475, "y": 0.9781659388646288, "ox": 0.9797235023041475, "oy": 0.9781659388646288, "term": "data", "cat25k": 169, "ncat25k": 161, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 2, "s": 0.9874812218327491, "os": 3.031064240835131}, {"x": 0.0, "y": 0.6244541484716158, "ox": 0.0, "oy": 0.6244541484716158, "term": "scikit", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7906860290435653, "os": 0.2178976271003361}, {"x": 0.9612903225806452, "y": 0.8148471615720526, "ox": 0.9612903225806452, "oy": 0.8148471615720526, "term": "Hadoop", "cat25k": 21, "ncat25k": 62, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.01952929394091137, "os": -0.8738341817059097}, {"x": 0.9806451612903228, "y": 1.0, "ox": 0.9806451612903228, "oy": 1.0, "term": "Experience", "cat25k": 514, "ncat25k": 170, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 9, "ncat": 2, "s": 1.0, "os": 9.226613281058674}, {"x": 0.6497695852534563, "y": 0.05938864628820961, "ox": 0.6497695852534563, "oy": 0.05938864628820961, "term": "Java Scala Python", "cat25k": 4, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.18577866800200302, "os": -0.21578683188486508}, {"x": 0.04976958525345623, "y": 0.05764192139737992, "ox": 0.04976958525345623, "oy": 0.05764192139737992, "term": "production environments", "cat25k": 4, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.500751126690035, "os": 0.07688911614495422}, {"x": 0.07188940092165899, "y": 0.056768558951965066, "ox": 0.07188940092165899, "oy": 0.056768558951965066, "term": "analytical techniques", "cat25k": 4, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.47771657486229346, "os": -0.07700748396895254}, {"x": 0.48940092165898624, "y": 0.09344978165938866, "ox": 0.48940092165898624, "oy": 0.09344978165938866, "term": "Software", "cat25k": 6, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2653980971457186, "os": -0.15329148887386607}, {"x": 0.28940092165898623, "y": 0.5423580786026202, "ox": 0.28940092165898623, "oy": 0.5423580786026202, "term": "Self", "cat25k": 10, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7451176765147721, "os": 0.18553235036226257}, {"x": 0.7170506912442397, "y": 0.9117903930131006, "ox": 0.7170506912442397, "oy": 0.9117903930131006, "term": "algorithms", "cat25k": 53, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9504256384576865, "os": 0.9561539321331114}, {"x": 0.0, "y": 0.5624454148471617, "ox": 0.0, "oy": 0.5624454148471617, "term": "Experiences", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7556334501752628, "os": 0.1926406050661784}, {"x": 0.021198156682027656, "y": 0.858515283842795, "ox": 0.021198156682027656, "oy": 0.858515283842795, "term": "computing frameworks", "cat25k": 29, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9218828242363545, "os": 0.5142720666708995}, {"x": 0.030414746543778806, "y": 0.6890829694323145, "ox": 0.030414746543778806, "oy": 0.6890829694323145, "term": "actionable insights", "cat25k": 14, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8257386079118678, "os": 0.2475106294177711}, {"x": 0.0, "y": 0.40174672489082974, "ox": 0.0, "oy": 0.40174672489082974, "term": "Python Java R", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6680020030045067, "os": 0.15659649942054257}, {"x": 0.0, "y": 0.35021834061135376, "ox": 0.0, "oy": 0.35021834061135376, "term": "Deep learning", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6389584376564846, "os": 0.14664325366376615}, {"x": 0.63963133640553, "y": 0.9327510917030568, "ox": 0.63963133640553, "oy": 0.9327510917030568, "term": "PhD", "cat25k": 65, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9619429143715573, "os": 1.1662765659757748}, {"x": 0.0, "y": 0.9213973799126638, "ox": 0.0, "oy": 0.9213973799126638, "term": "Master", "cat25k": 58, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9559339008512769, "os": 1.0442429949181533}, {"x": 0.0, "y": 0.583406113537118, "ox": 0.0, "oy": 0.583406113537118, "term": "Master Degree PhD Experience working AWS", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7671507260891337, "os": 0.19843166060319534}, {"x": 0.0, "y": 0.7790393013100437, "ox": 0.0, "oy": 0.7790393013100437, "term": "Master Degree PhD", "cat25k": 18, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8748122183274912, "os": 0.32724775404952666}, {"x": 0.0, "y": 0.7467248908296945, "ox": 0.0, "oy": 0.7467248908296945, "term": "Degree PhD", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.85678517776665, "os": 0.29398655325167067}, {"x": 0.0, "y": 0.7580786026200875, "ox": 0.0, "oy": 0.7580786026200875, "term": "large scale data analysis", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8627941912869304, "os": 0.3052422258718994}, {"x": 0.0, "y": 0.7484716157205241, "ox": 0.0, "oy": 0.7484716157205241, "term": "At least year experience open source programming languages", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.85778668002003, "os": 0.2991664627829952}, {"x": 0.0, "y": 0.7371179039301312, "ox": 0.0, "oy": 0.7371179039301312, "term": "Python Scala R", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8517776664997496, "os": 0.28212776445395216}, {"x": 0.0, "y": 0.7388646288209608, "ox": 0.0, "oy": 0.7388646288209608, "term": "At least year experience machine", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8527791687531296, "os": 0.28769761386336756}, {"x": 0.0, "y": 0.29956331877729264, "ox": 0.0, "oy": 0.29956331877729264, "term": "At least years experience machine", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6104156234351528, "os": 0.13839454682407448}, {"x": 0.35483870967741943, "y": 0.8646288209606988, "ox": 0.35483870967741943, "oy": 0.8646288209606988, "term": "data analytics", "cat25k": 31, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9243865798698047, "os": 0.5542366727394442}, {"x": 0.7364055299539172, "y": 0.6532751091703057, "ox": 0.7364055299539172, "oy": 0.6532751091703057, "term": "Bachelor Degree", "cat25k": 13, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14071106659989988, "os": -0.2565228372056242}, {"x": 0.5806451612903226, "y": 0.8689956331877731, "ox": 0.5806451612903226, "oy": 0.8689956331877731, "term": "At least year", "cat25k": 33, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9268903355032548, "os": 0.5876218116865444}, {"x": 0.8525345622119817, "y": 0.9231441048034934, "ox": 0.8525345622119817, "oy": 0.9231441048034934, "term": "At least years", "cat25k": 59, "ncat25k": 27, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.956935403104657, "os": 1.0538461724859014}, {"x": 0.0, "y": 0.6716157205240175, "ox": 0.0, "oy": 0.6716157205240175, "term": "Good English language skills", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8172258387581371, "os": 0.23831630413576207}, {"x": 0.0, "y": 0.6235807860262009, "ox": 0.0, "oy": 0.6235807860262009, "term": "Computer Science related degree years related work experience Experience working Open Source project", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7901852779168753, "os": 0.2177852120492239}, {"x": 0.9557603686635945, "y": 0.9170305676855895, "ox": 0.9557603686635945, "oy": 0.9170305676855895, "term": "English", "cat25k": 56, "ncat25k": 57, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9534301452178268, "os": 0.9979671840154117}, {"x": 0.9622119815668204, "y": 0.720524017467249, "ox": 0.9622119815668204, "oy": 0.720524017467249, "term": "Spark", "cat25k": 15, "ncat25k": 63, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.019028542814221335, "os": -0.8901659357740545}, {"x": 0.9382488479262673, "y": 0.9432314410480349, "ox": 0.9382488479262673, "oy": 0.9432314410480349, "term": "ability", "cat25k": 78, "ncat25k": 49, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9679519278918377, "os": 1.3943667225841336}, {"x": 0.9373271889400921, "y": 0.869868995633188, "ox": 0.9373271889400921, "oy": 0.869868995633188, "term": "Java Scala", "cat25k": 33, "ncat25k": 48, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.031547320981472206, "os": -0.6767262383323838}, {"x": 0.4866359447004609, "y": 0.011353711790393016, "ox": 0.4866359447004609, "oy": 0.011353711790393016, "term": "Python Java", "cat25k": 2, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2669003505257887, "os": -0.1528388258534757}, {"x": 0.0, "y": 0.7406113537117904, "ox": 0.0, "oy": 0.7406113537117904, "term": "strong baselines ability", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8537806710065097, "os": 0.2897191092087526}, {"x": 0.0, "y": 0.783406113537118, "ox": 0.0, "oy": 0.783406113537118, "term": "experimental analytic plans data modeling processes", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8773159739609414, "os": 0.3327076301560387}, {"x": 0.0, "y": 0.5109170305676857, "ox": 0.0, "oy": 0.5109170305676857, "term": "Demonstrable track record", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7280921382073109, "os": 0.17812207955288126}, {"x": 0.710599078341014, "y": 0.879475982532751, "ox": 0.710599078341014, "oy": 0.879475982532751, "term": "results", "cat25k": 35, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9323985978968453, "os": 0.6333081816336911}, {"x": 0.0, "y": 0.4192139737991267, "ox": 0.0, "oy": 0.4192139737991267, "term": "well ambiguity", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6770155232849274, "os": 0.1600913013835616}, {"x": 0.0, "y": 0.40087336244541494, "ox": 0.0, "oy": 0.40087336244541494, "term": "effect relations", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6675012518778166, "os": 0.1564171142882842}, {"x": 0.9907834101382489, "y": 0.7362445414847163, "ox": 0.9907834101382489, "oy": 0.7362445414847163, "term": "hands", "cat25k": 16, "ncat25k": 283, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 4, "s": 0.005007511266900351, "os": -4.003189756052376}, {"x": 0.0, "y": 0.8751091703056768, "ox": 0.0, "oy": 0.8751091703056768, "term": "Drilling Completion Production Operations", "cat25k": 33, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9298948422633951, "os": 0.6004398931859963}, {"x": 0.0, "y": 0.554585152838428, "ox": 0.0, "oy": 0.554585152838428, "term": "Upstream oil gas industry experience", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7511266900350526, "os": 0.18960624429787884}, {"x": 0.0, "y": 0.6270742358078604, "ox": 0.0, "oy": 0.6270742358078604, "term": "year experience data analytics", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7921882824236354, "os": 0.2188752727618717}, {"x": 0.31152073732718905, "y": 0.7222707423580788, "ox": 0.31152073732718905, "oy": 0.7222707423580788, "term": "At least year experience", "cat25k": 15, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8442663995993991, "os": 0.2660377131720378}, {"x": 0.6857142857142858, "y": 0.5336244541484717, "ox": 0.6857142857142858, "oy": 0.5336244541484717, "term": "Master Degree", "cat25k": 10, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1682523785678518, "os": -0.22851282415784008}, {"x": 0.71889400921659, "y": 0.6855895196506552, "ox": 0.71889400921659, "oy": 0.6855895196506552, "term": "Degree", "cat25k": 14, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15172759138708064, "os": -0.24477102766200623}, {"x": 0.0, "y": 0.8995633187772926, "ox": 0.0, "oy": 0.8995633187772926, "term": "machine", "cat25k": 45, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.943415122684026, "os": 0.8165826955083337}, {"x": 0.9843317972350231, "y": 0.966812227074236, "ox": 0.9843317972350231, "oy": 0.966812227074236, "term": "SQL", "cat25k": 111, "ncat25k": 255, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 3, "s": 0.008512769153730596, "os": -3.605116941771512}, {"x": 0.8764976958525347, "y": 0.05327510917030569, "ox": 0.8764976958525347, "oy": 0.05327510917030569, "term": "AWS", "cat25k": 4, "ncat25k": 30, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.061592388582874316, "os": -0.42157873707971866}, {"x": 0.0, "y": 0.7982532751091704, "ox": 0.0, "oy": 0.7982532751091704, "term": "tools Tableau", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.885828743114672, "os": 0.3498759579292246}, {"x": 0.0, "y": 0.6620087336244542, "ox": 0.0, "oy": 0.6620087336244542, "term": "Experience Data Visualizaiton", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8112168252378568, "os": 0.2340164370673894}, {"x": 0.0, "y": 0.7240174672489085, "ox": 0.0, "oy": 0.7240174672489085, "term": "Experience Data", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8452679018527791, "os": 0.2674109006380381}, {"x": 0.0, "y": 0.4917030567685591, "ox": 0.0, "oy": 0.4917030567685591, "term": "Visualizaiton", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7170756134201302, "os": 0.1749217208134885}, {"x": 0.0, "y": 0.5860262008733625, "ox": 0.0, "oy": 0.5860262008733625, "term": "BA Computer Science Engineering relevant field graduate degree Data Science quantitative field", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7686529794692037, "os": 0.19992961383919514}, {"x": 0.0, "y": 0.34672489082969443, "ox": 0.0, "oy": 0.34672489082969443, "term": "Strong math skills", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6369554331497246, "os": 0.14560880942882218}, {"x": 0.0, "y": 0.6445414847161574, "ox": 0.0, "oy": 0.6445414847161574, "term": "Excellent communication presentation", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8022033049574361, "os": 0.22515639285525188}, {"x": 0.0, "y": 0.44279475982532757, "ox": 0.0, "oy": 0.44279475982532757, "term": "Basic knowledge web development Experience data work\ufb02ow management tools advantage Experience big data cloud computing advantage", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6900350525788683, "os": 0.16482328316843017}, {"x": 0.0, "y": 0.3187772925764193, "ox": 0.0, "oy": 0.3187772925764193, "term": "R Python Linux Experience systems biology research data", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6214321482223335, "os": 0.14233496780874647}, {"x": 0.0, "y": 0.28471615720524024, "ox": 0.0, "oy": 0.28471615720524024, "term": "PhD bioinformatics computer science similar experience Experience relational database management systems", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6019028542814221, "os": 0.1363824907210576}, {"x": 0.0, "y": 0.7921397379912665, "ox": 0.0, "oy": 0.7921397379912665, "term": "Ability work team", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8823234852278418, "os": 0.341878820044702}, {"x": 0.026728110599078342, "y": 0.8506550218340613, "ox": 0.026728110599078342, "oy": 0.8506550218340613, "term": "goals", "cat25k": 26, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9178768152228343, "os": 0.4728307636573108}, {"x": 0.0, "y": 0.7956331877729259, "ox": 0.0, "oy": 0.7956331877729259, "term": "consistent research institutes", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8843264897346019, "os": 0.3466800150008662}, {"x": 0.0, "y": 0.6759825327510918, "ox": 0.0, "oy": 0.6759825327510918, "term": "Employment payment social benefits", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8192288432648973, "os": 0.2396672665936658}, {"x": 0.5870967741935486, "y": 0.8445414847161574, "ox": 0.5870967741935486, "oy": 0.8445414847161574, "term": "able work", "cat25k": 25, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.914371557336004, "os": 0.44924166346899186}, {"x": 0.0, "y": 0.7711790393013103, "ox": 0.0, "oy": 0.7711790393013103, "term": "Excellent understanding machine", "cat25k": 18, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8703054581872809, "os": 0.3176259305835252}, {"x": 0.8986175115207374, "y": 0.9135371179039302, "ox": 0.8986175115207374, "oy": 0.9135371179039302, "term": "techniques", "cat25k": 54, "ncat25k": 34, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9514271407110666, "os": 0.9770218355497484}, {"x": 0.0, "y": 0.320524017467249, "ox": 0.0, "oy": 0.320524017467249, "term": "data mining machine", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6224336504757135, "os": 0.1425647719822397}, {"x": 0.0, "y": 0.43231441048034946, "ox": 0.0, "oy": 0.43231441048034946, "term": "SQL Oracle", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6840260390585878, "os": 0.16238324044077962}, {"x": 0.3953917050691245, "y": 0.06288209606986901, "ox": 0.3953917050691245, "oy": 0.06288209606986901, "term": "large amounts", "cat25k": 4, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.31347020530796194, "os": -0.1294251298029777}, {"x": 0.0, "y": 0.44454148471615734, "ox": 0.0, "oy": 0.44454148471615734, "term": "Possess", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6910365548322484, "os": 0.16491148541434275}, {"x": 0.0, "y": 0.5842794759825328, "ox": 0.0, "oy": 0.5842794759825328, "term": "media mix", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7676514772158237, "os": 0.19879140223445313}, {"x": 0.0, "y": 0.7179039301310045, "ox": 0.0, "oy": 0.7179039301310045, "term": "visualization", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8422633950926389, "os": 0.26191847750852054}, {"x": 0.0, "y": 0.4681222707423582, "ox": 0.0, "oy": 0.4681222707423582, "term": "multi touch attribution", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7040560841261893, "os": 0.16997431481007577}, {"x": 0.0, "y": 0.6034934497816595, "ox": 0.0, "oy": 0.6034934497816595, "term": "data science", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7786680020030045, "os": 0.20606873250596686}, {"x": 0.17695852534562215, "y": 0.8419213973799128, "ox": 0.17695852534562215, "oy": 0.8419213973799128, "term": "data scientists", "cat25k": 25, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9128693039559339, "os": 0.4421211189780269}, {"x": 0.8912442396313366, "y": 0.8655021834061137, "ox": 0.8912442396313366, "oy": 0.8655021834061137, "term": "problems", "cat25k": 31, "ncat25k": 34, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9248873309964948, "os": 0.555718649461159}, {"x": 0.0, "y": 0.6454148471615722, "ox": 0.0, "oy": 0.6454148471615722, "term": "customers", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8027040560841262, "os": 0.22591602450697434}, {"x": 0.02027649769585254, "y": 0.8681222707423583, "ox": 0.02027649769585254, "oy": 0.8681222707423583, "term": "Masters", "cat25k": 32, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9263895843765648, "os": 0.5695996888138217}, {"x": 0.0, "y": 0.7877729257641922, "ox": 0.0, "oy": 0.7877729257641922, "term": "bars", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8798197295943916, "os": 0.33592266913231045}, {"x": 0.0, "y": 0.7126637554585155, "ox": 0.0, "oy": 0.7126637554585155, "term": "Social environment", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8392588883324987, "os": 0.2601864215065202}, {"x": 0.9069124423963135, "y": 0.017467248908296946, "ox": 0.9069124423963135, "oy": 0.017467248908296946, "term": "Fluency English", "cat25k": 2, "ncat25k": 37, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.04606910365548322, "os": -0.5203728430130404}, {"x": 0.0, "y": 0.8628820960698692, "ox": 0.0, "oy": 0.8628820960698692, "term": "hard questions data", "cat25k": 31, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9233850776164246, "os": 0.5517343925999226}, {"x": 0.0, "y": 0.40262008733624466, "ox": 0.0, "oy": 0.40262008733624466, "term": "complex ideas", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6685027541311969, "os": 0.1567041809745392}, {"x": 0.9852534562211983, "y": 0.8951965065502183, "ox": 0.9852534562211983, "oy": 0.8951965065502183, "term": "skills", "cat25k": 43, "ncat25k": 264, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 3, "s": 0.008012018027040562, "os": -3.7358105227821903}, {"x": 0.0009216589861751153, "y": 0.3895196506550219, "ox": 0.0009216589861751153, "oy": 0.3895196506550219, "term": "The ability", "cat25k": 9, "ncat25k": 1, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6609914872308463, "os": 0.15411502364025376}, {"x": 0.9972350230414746, "y": 0.5467248908296944, "ox": 0.9972350230414746, "oy": 0.5467248908296944, "term": "industry experience", "cat25k": 10, "ncat25k": 458, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 6, "s": 0.0015022533800701052, "os": -6.466306773939164}, {"x": 0.0, "y": 0.834934497816594, "ox": 0.0, "oy": 0.834934497816594, "term": "AI ML", "cat25k": 24, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9063595393089634, "os": 0.4226225518386767}, {"x": 0.0, "y": 0.7021834061135372, "ox": 0.0, "oy": 0.7021834061135372, "term": "NLP", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8332498748122183, "os": 0.254776907953392}, {"x": 0.0, "y": 0.629694323144105, "ox": 0.0, "oy": 0.629694323144105, "term": "Experience cleaning visualizing data", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7936905358037055, "os": 0.22007530695967087}, {"x": 0.0, "y": 0.7973799126637556, "ox": 0.0, "oy": 0.7973799126637556, "term": "Mathematics Statistics Physics Computer Science Engineering Background", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.885327991987982, "os": 0.349053710359966}, {"x": 0.0, "y": 0.48471615720524025, "ox": 0.0, "oy": 0.48471615720524025, "term": "algebra multivariable calculus", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7135703555333, "os": 0.1731698611979051}, {"x": 0.012903225806451615, "y": 0.7729257641921399, "ox": 0.012903225806451615, "oy": 0.7729257641921399, "term": "Experience Python", "cat25k": 18, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8713069604406609, "os": 0.31889173546064686}, {"x": 0.0, "y": 0.8200873362445417, "ox": 0.0, "oy": 0.8200873362445417, "term": "Python R", "cat25k": 22, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8983475212819229, "os": 0.38844963456566894}, {"x": 0.0, "y": 0.31965065502183415, "ox": 0.0, "oy": 0.31965065502183415, "term": "Oracle graph", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6219328993490235, "os": 0.14236067889104292}, {"x": 0.0, "y": 0.5764192139737992, "ox": 0.0, "oy": 0.5764192139737992, "term": "techniques ability", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7631447170756134, "os": 0.19608889898635024}, {"x": 0.04055299539170507, "y": 0.8960698689956332, "ox": 0.04055299539170507, "oy": 0.8960698689956332, "term": "Proven ability", "cat25k": 44, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9414121181772659, "os": 0.7818298624858697}, {"x": 0.0, "y": 0.35283842794759834, "ox": 0.0, "oy": 0.35283842794759834, "term": "Math", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6404606910365548, "os": 0.14697286125785267}, {"x": 0.0, "y": 0.42882096069869, "ox": 0.0, "oy": 0.42882096069869, "term": "Knowledge immunology tumor immunology tumor biology genetics Proficiency Python R", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6825237856785178, "os": 0.16167789142239433}, {"x": 0.0, "y": 0.41222707423580796, "ox": 0.0, "oy": 0.41222707423580796, "term": "D degree Bioinformatics Computer Science Biostatistics Applied", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6735102653980971, "os": 0.15923232223466136}, {"x": 0.0, "y": 0.297816593886463, "ox": 0.0, "oy": 0.297816593886463, "term": "Ph D degree Bioinformatics Computer Science Biostatistics", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6094141211817726, "os": 0.13824267337182264}, {"x": 0.06082949308755761, "y": 0.5938864628820961, "ox": 0.06082949308755761, "oy": 0.5938864628820961, "term": "environment", "cat25k": 11, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7731597396094141, "os": 0.20256592183278574}, {"x": 0.0, "y": 0.9371179039301311, "ox": 0.0, "oy": 0.9371179039301311, "term": "problem", "cat25k": 70, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9644466700050075, "os": 1.2514104858688404}, {"x": 0.6092165898617512, "y": 0.08995633187772926, "ox": 0.6092165898617512, "oy": 0.08995633187772926, "term": "Agile", "cat25k": 6, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.20731096644967453, "os": -0.19932978298214138}, {"x": 0.6682027649769586, "y": 0.8829694323144106, "ox": 0.6682027649769586, "oy": 0.8829694323144106, "term": "Expertise", "cat25k": 37, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9344016024036054, "os": 0.6664894063314687}, {"x": 0.9142857142857145, "y": 0.9275109170305676, "ox": 0.9142857142857145, "oy": 0.9275109170305676, "term": "Proven", "cat25k": 61, "ncat25k": 38, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9594391587381071, "os": 1.1021665748594192}, {"x": 0.9732718894009218, "y": 0.7283842794759827, "ox": 0.9732718894009218, "oy": 0.7283842794759827, "term": "Python", "cat25k": 15, "ncat25k": 95, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 1, "s": 0.013520280420630948, "os": -1.3391162684095985}, {"x": 0.1023041474654378, "y": 0.010480349344978167, "ox": 0.1023041474654378, "oy": 0.010480349344978167, "term": "time", "cat25k": 2, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4621932899349024, "os": -0.08230088044242848}, {"x": 0.0, "y": 0.39563318777292583, "ox": 0.0, "oy": 0.39563318777292583, "term": "predictive analytics multivariate testing optimization algorithms", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6644967451176765, "os": 0.15591583320027025}, {"x": 0.0, "y": 0.3729257641921398, "ox": 0.0, "oy": 0.3729257641921398, "term": "Working knowledge upstream data Experience analytical simulation tools field", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6519779669504256, "os": 0.15114778386321365}, {"x": 0.0, "y": 0.9982532751091704, "ox": 0.0, "oy": 0.9982532751091704, "term": "Google Cloud Platform NET Experience", "cat25k": 289, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 5, "ncat": 0, "s": 0.99899849774662, "os": 5.183951101056056}, {"x": 0.0, "y": 0.9965065502183407, "ox": 0.0, "oy": 0.9965065502183407, "term": "OCR Experience", "cat25k": 253, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 4, "ncat": 0, "s": 0.99799699549324, "os": 4.549774187321506}, {"x": 0.0, "y": 0.9956331877729258, "ox": 0.0, "oy": 0.9956331877729258, "term": "successful machine learning systems", "cat25k": 249, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 4, "ncat": 0, "s": 0.9974962443665498, "os": 4.474200395800409}, {"x": 0.0, "y": 0.9938864628820961, "ox": 0.0, "oy": 0.9938864628820961, "term": "Cloud ML resources", "cat25k": 241, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 4, "ncat": 0, "s": 0.9964947421131698, "os": 4.317277104156014}, {"x": 0.0, "y": 0.9921397379912664, "ox": 0.0, "oy": 0.9921397379912664, "term": "Cloud ML", "cat25k": 225, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 4, "ncat": 0, "s": 0.9954932398597898, "os": 4.041972599421924}, {"x": 0.0, "y": 0.9912663755458515, "ox": 0.0, "oy": 0.9912663755458515, "term": "regression clustering word embeddings", "cat25k": 222, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9949924887330996, "os": 3.9766595981886184}, {"x": 0.0, "y": 0.9903930131004368, "ox": 0.0, "oy": 0.9903930131004368, "term": "Tensorflow Keras Data Science algorithms decision trees", "cat25k": 220, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9944917376064095, "os": 3.9531909096024327}, {"x": 0.0, "y": 0.9860262008733626, "ox": 0.0, "oy": 0.9860262008733626, "term": "Tensorflow Keras Data Science", "cat25k": 195, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9919879819729593, "os": 3.503626103255569}, {"x": 0.0, "y": 0.9991266375545853, "ox": 0.0, "oy": 0.9991266375545853, "term": "Python R Javascript Machine", "cat25k": 309, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 5, "ncat": 0, "s": 0.9994992488733099, "os": 5.541127114061982}, {"x": 0.0, "y": 0.9493449781659389, "ox": 0.0, "oy": 0.9493449781659389, "term": "Development languages", "cat25k": 85, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.971457185778668, "os": 1.5326160248273089}, {"x": 0.0, "y": 0.7641921397379914, "ox": 0.0, "oy": 0.7641921397379914, "term": "Restaurant Retail industry experience", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8668002003004507, "os": 0.3117268033405843}, {"x": 0.0, "y": 0.6646288209606989, "ox": 0.0, "oy": 0.6646288209606989, "term": "The Best Jobs Retail Time Holiday Shopping Jobs Rated Report", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8132198297446169, "os": 0.2343905708617411}, {"x": 0.0, "y": 0.5039301310043669, "ox": 0.0, "oy": 0.5039301310043669, "term": "The Jobs Rated Report The Best Jobs The Toughest Jobs Fill", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7240861291937906, "os": 0.1769530140550504}, {"x": 0.0, "y": 0.4567685589519651, "ox": 0.0, "oy": 0.4567685589519651, "term": "The Jobs Rated Report", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6975463194792189, "os": 0.1683909264507124}, {"x": 0.0, "y": 0.4314410480349346, "ox": 0.0, "oy": 0.4314410480349346, "term": "The Best Jobs Advertising", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6835252879318978, "os": 0.16214011579751963}, {"x": 0.0, "y": 0.4218340611353713, "ox": 0.0, "oy": 0.4218340611353713, "term": "The Toughest Jobs Fill", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6785177766649975, "os": 0.16061517799306704}, {"x": 0.0, "y": 0.7458515283842796, "ox": 0.0, "oy": 0.7458515283842796, "term": "The Best Jobs", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8562844266399599, "os": 0.2935182493112787}, {"x": 0.0, "y": 0.40960698689956343, "ox": 0.0, "oy": 0.40960698689956343, "term": "analytic processes", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6720080120180271, "os": 0.15840739338338}, {"x": 0.9336405529953917, "y": 0.06026200873362446, "ox": 0.9336405529953917, "oy": 0.06026200873362446, "term": "best practices", "cat25k": 4, "ncat25k": 47, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.03355032548823234, "os": -0.661100205594983}, {"x": 0.855299539170507, "y": 0.7432314410480351, "ox": 0.855299539170507, "oy": 0.7432314410480351, "term": "BI", "cat25k": 16, "ncat25k": 27, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.0756134201301953, "os": -0.379551680070811}, {"x": 0.3161290322580646, "y": 0.041048034934497823, "ox": 0.3161290322580646, "oy": 0.041048034934497823, "term": "industry", "cat25k": 3, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3525287931897847, "os": -0.11691980216316064}, {"x": 0.7327188940092167, "y": 0.06986899563318778, "ox": 0.7327188940092167, "oy": 0.06986899563318778, "term": "Working", "cat25k": 5, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14271407110666, "os": -0.25402740388375106}, {"x": 0.0, "y": 0.48122270742358086, "ox": 0.0, "oy": 0.48122270742358086, "term": "recommendations", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7115673510265398, "os": 0.17217366926819783}, {"x": 0.10783410138248849, "y": 0.02532751091703057, "ox": 0.10783410138248849, "oy": 0.02532751091703057, "term": "Complex", "cat25k": 3, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.45918878317476214, "os": -0.08306128186241268}, {"x": 0.0, "y": 0.709170305676856, "ox": 0.0, "oy": 0.709170305676856, "term": "AI Machine Learning", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8372558838257386, "os": 0.2575289673915155}, {"x": 0.0, "y": 0.8925764192139738, "ox": 0.0, "oy": 0.8925764192139738, "term": "Machine Learning", "cat25k": 41, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9399098647971958, "os": 0.7294428537714255}, {"x": 0.0, "y": 0.954585152838428, "ox": 0.0, "oy": 0.954585152838428, "term": "Deep Learning", "cat25k": 94, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9744616925388082, "os": 1.6822608000052148}, {"x": 0.05161290322580646, "y": 0.9449781659388646, "ox": 0.05161290322580646, "oy": 0.9449781659388646, "term": "Deep", "cat25k": 78, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9689534301452178, "os": 1.4063415245594297}, {"x": 0.5769585253456222, "y": 0.06724890829694324, "ox": 0.5769585253456222, "oy": 0.06724890829694324, "term": "Git", "cat25k": 5, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2223335002503756, "os": -0.18535803982859175}, {"x": 0.0, "y": 0.38777292576419226, "ox": 0.0, "oy": 0.38777292576419226, "term": "GPU", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6599899849774661, "os": 0.15391750820862915}, {"x": 0.0, "y": 0.7336244541484718, "ox": 0.0, "oy": 0.7336244541484718, "term": "Experience Looker Tableau data visualization software", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8502754131196795, "os": 0.27853404319695196}, {"x": 0.0, "y": 0.6314410480349346, "ox": 0.0, "oy": 0.6314410480349346, "term": "statistical analysis techniques", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7946920380570855, "os": 0.2205415644182886}, {"x": 0.0, "y": 0.549344978165939, "ox": 0.0, "oy": 0.549344978165939, "term": "experimental design data", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7486229344016024, "os": 0.18865742492708354}, {"x": 0.0, "y": 0.9973799126637556, "ox": 0.0, "oy": 0.9973799126637556, "term": "related field Computational social science Computer science Data analytics", "cat25k": 264, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 4, "ncat": 0, "s": 0.9984977466199298, "os": 4.730571888653109}, {"x": 0.0, "y": 0.9930131004366813, "ox": 0.0, "oy": 0.9930131004366813, "term": "Ability work diverse team environment Interest experience science technology engineering mathematics", "cat25k": 235, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 4, "ncat": 0, "s": 0.9959939909864797, "os": 4.225174876637285}, {"x": 0.0, "y": 0.9947598253275111, "ox": 0.0, "oy": 0.9947598253275111, "term": "Computer science Data analytics Economics Engineering Geospatial", "cat25k": 249, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 4, "ncat": 0, "s": 0.9969954932398597, "os": 4.465020962563433}, {"x": 0.0, "y": 0.9877729257641922, "ox": 0.0, "oy": 0.9877729257641922, "term": "Quantitative finance", "cat25k": 201, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9929894842263396, "os": 3.612573450006814}, {"x": 0.0, "y": 0.9886462882096071, "ox": 0.0, "oy": 0.9886462882096071, "term": "Economics Engineering Geospatial analysis", "cat25k": 202, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9934902353530295, "os": 3.6192852572858403}, {"x": 0.0, "y": 0.9851528384279477, "ox": 0.0, "oy": 0.9851528384279477, "term": "prior graduation Attending school", "cat25k": 186, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9914872308462694, "os": 3.336533583226009}, {"x": 0.0, "y": 0.982532751091703, "ox": 0.0, "oy": 0.982532751091703, "term": "Availability work", "cat25k": 180, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9899849774661993, "os": 3.22457805973582}, {"x": 0.0, "y": 0.9868995633187773, "ox": 0.0, "oy": 0.9868995633187773, "term": "Mathematics Operations research", "cat25k": 201, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9924887330996495, "os": 3.608658053819537}, {"x": 0.0, "y": 0.9807860262008734, "ox": 0.0, "oy": 0.9807860262008734, "term": "Bachelor degree technical field", "cat25k": 178, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9889834752128193, "os": 3.1913496936838452}, {"x": 0.0, "y": 0.9834061135371179, "ox": 0.0, "oy": 0.9834061135371179, "term": "internship Creativity Initiative Integrity Leadership", "cat25k": 180, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9904857285928893, "os": 3.239749220967206}, {"x": 0.0, "y": 0.984279475982533, "ox": 0.0, "oy": 0.984279475982533, "term": "Creativity Initiative Integrity Leadership", "cat25k": 183, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9909864797195793, "os": 3.2919424490670837}, {"x": 0.0, "y": 0.9790393013100438, "ox": 0.0, "oy": 0.9790393013100438, "term": "full time basis", "cat25k": 170, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9879819729594391, "os": 3.0516707718298934}, {"x": 0.0, "y": 0.9816593886462883, "ox": 0.0, "oy": 0.9816593886462883, "term": "Problem solving skills", "cat25k": 179, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9894842263395093, "os": 3.215536906253572}, {"x": 0.0, "y": 0.9772925764192141, "ox": 0.0, "oy": 0.9772925764192141, "term": "Full time student", "cat25k": 161, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 2, "ncat": 0, "s": 0.9869804707060591, "os": 2.892567586051478}, {"x": 0.0, "y": 0.9799126637554587, "ox": 0.0, "oy": 0.9799126637554587, "term": "Mathematics Operations", "cat25k": 176, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9884827240861291, "os": 3.1522112519972425}, {"x": 0.0, "y": 0.9711790393013102, "ox": 0.0, "oy": 0.9711790393013102, "term": "Attending", "cat25k": 120, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 2, "ncat": 0, "s": 0.9834752128192288, "os": 2.1526184339585326}, {"x": 0.0, "y": 0.9746724890829696, "ox": 0.0, "oy": 0.9746724890829696, "term": "Computational", "cat25k": 128, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 2, "ncat": 0, "s": 0.985478217325989, "os": 2.2986729314396244}, {"x": 0.0, "y": 0.9676855895196507, "ox": 0.0, "oy": 0.9676855895196507, "term": "scale", "cat25k": 112, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 2, "ncat": 0, "s": 0.9814722083124687, "os": 2.0133032404258904}, {"x": 0.0, "y": 0.9685589519650656, "ox": 0.0, "oy": 0.9685589519650656, "term": "A thorough medical psychological exam", "cat25k": 114, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 2, "ncat": 0, "s": 0.9819729594391587, "os": 2.038646983193587}, {"x": 0.0, "y": 0.9895196506550219, "ox": 0.0, "oy": 0.9895196506550219, "term": "GPA", "cat25k": 216, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 3, "ncat": 0, "s": 0.9939909864797196, "os": 3.870393849713996}, {"x": 0.0, "y": 0.9589519650655022, "ox": 0.0, "oy": 0.9589519650655022, "term": "A comprehensive background investigation", "cat25k": 102, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9769654481722584, "os": 1.8227631219086782}, {"x": 0.6064516129032259, "y": 0.9615720524017468, "ox": 0.6064516129032259, "oy": 0.9615720524017468, "term": "Bachelor", "cat25k": 105, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9784677015523284, "os": 1.881944826570133}, {"x": 0.0, "y": 0.9467248908296945, "ox": 0.0, "oy": 0.9467248908296945, "term": "two day tours", "cat25k": 80, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9699549323985979, "os": 1.4398305310311843}, {"x": 0.0, "y": 0.9318777292576419, "ox": 0.0, "oy": 0.9318777292576419, "term": "A polygraph interview", "cat25k": 64, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9614421632448673, "os": 1.1508714652384946}, {"x": 0.0, "y": 0.9082969432314411, "ox": 0.0, "oy": 0.9082969432314411, "term": "two day", "cat25k": 52, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9484226339509264, "os": 0.9370493301538174}, {"x": 0.0, "y": 0.909170305676856, "ox": 0.0, "oy": 0.909170305676856, "term": "Statistics", "cat25k": 52, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9489233850776164, "os": 0.9381855786412275}, {"x": 0.0, "y": 0.8331877729257643, "ox": 0.0, "oy": 0.8331877729257643, "term": "complex analytical concepts", "cat25k": 23, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9053580370555834, "os": 0.41538540725781137}, {"x": 0.5419354838709679, "y": 0.8471615720524018, "ox": 0.5419354838709679, "oy": 0.8471615720524018, "term": "business problems", "cat25k": 26, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9158738107160741, "os": 0.4587761886667346}, {"x": 0.9741935483870967, "y": 0.5737991266375547, "ox": 0.9741935483870967, "oy": 0.5737991266375547, "term": "NoSQL", "cat25k": 11, "ncat25k": 99, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 1, "s": 0.013019529293940913, "os": -1.397657889083946}, {"x": 0.9078341013824885, "y": 0.823580786026201, "ox": 0.9078341013824885, "oy": 0.823580786026201, "term": "Knowledge", "cat25k": 22, "ncat25k": 37, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.04556835252879319, "os": -0.5229737223046979}, {"x": 0.44792626728110607, "y": 0.9179039301310045, "ox": 0.44792626728110607, "oy": 0.9179039301310045, "term": "people", "cat25k": 57, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9539308963445168, "os": 1.0178235313006478}, {"x": 0.8543778801843319, "y": 0.02270742358078603, "ox": 0.8543778801843319, "oy": 0.02270742358078603, "term": "year", "cat25k": 2, "ncat25k": 27, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07611417125688533, "os": -0.37827389971363606}, {"x": 0.0, "y": 0.4768558951965066, "ox": 0.0, "oy": 0.4768558951965066, "term": "R Python", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7090635953930896, "os": 0.1713645391020618}, {"x": 0.8635944700460831, "y": 0.9187772925764192, "ox": 0.8635944700460831, "oy": 0.9187772925764192, "term": "ML", "cat25k": 58, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9544316474712068, "os": 1.0331846851585622}, {"x": 0.0, "y": 0.5903930131004368, "ox": 0.0, "oy": 0.5903930131004368, "term": "analytics development industrial applications commercial industrial setting", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7711567351026539, "os": 0.20146086491950357}, {"x": 0.0, "y": 0.43318777292576427, "ox": 0.0, "oy": 0.43318777292576427, "term": "college university Ph D STEM field Science Technology Engineering Math", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.684526790185278, "os": 0.16276120963515064}, {"x": 0.0, "y": 0.42794759825327516, "ox": 0.0, "oy": 0.42794759825327516, "term": "Demonstrated skill feature extraction realtime analytics development deployment", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6820230345518278, "os": 0.16149134514669364}, {"x": 0.0, "y": 0.7554585152838429, "ox": 0.0, "oy": 0.7554585152838429, "term": "Science Technology Engineering Math", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8612919379068602, "os": 0.3024280574620259}, {"x": 0.0, "y": 0.37379912663755466, "ox": 0.0, "oy": 0.37379912663755466, "term": "Bachelor Degree STEM field Science Technology Engineering Math", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6524787180771155, "os": 0.15116784021612512}, {"x": 0.0, "y": 0.33449781659388655, "ox": 0.0, "oy": 0.33449781659388655, "term": "Desired Characteristics Master Degree STEM field Science Technology Engineering Math", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6299449173760641, "os": 0.14383318217334004}, {"x": 0.0, "y": 0.3048034934497817, "ox": 0.0, "oy": 0.3048034934497817, "term": "Demonstrated skill data management methods", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.613420130195293, "os": 0.13941544371985926}, {"x": 0.0, "y": 0.2681222707423581, "ox": 0.0, "oy": 0.2681222707423581, "term": "college university Minimum years", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5923885828743114, "os": 0.13334998736946443}, {"x": 0.0, "y": 0.24628820960698697, "ox": 0.0, "oy": 0.24628820960698697, "term": "college university", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5803705558337506, "os": 0.12959855494475503}, {"x": 0.0, "y": 0.2890829694323145, "ox": 0.0, "oy": 0.2890829694323145, "term": "move equipment pounds assistance Ability", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6044066099148723, "os": 0.13737960905536156}, {"x": 0.0, "y": 0.2524017467248909, "ox": 0.0, "oy": 0.2524017467248909, "term": "operations equipment", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5838758137205808, "os": 0.12997752747448055}, {"x": 0.9447004608294931, "y": 0.8069868995633189, "ox": 0.9447004608294931, "oy": 0.8069868995633189, "term": "hours", "cat25k": 20, "ncat25k": 53, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.028042063094641963, "os": -0.7472829318500097}, {"x": 0.0, "y": 0.8820960698689957, "ox": 0.0, "oy": 0.8820960698689957, "term": "business questions", "cat25k": 37, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9339008512769155, "os": 0.6650369178442256}, {"x": 0.0, "y": 0.8427947598253276, "ox": 0.0, "oy": 0.8427947598253276, "term": "deliverables Domain knowledge clinical data real world data life sciences related research data Expertise data science related tools", "cat25k": 25, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9133700550826239, "os": 0.4451473634396224}, {"x": 0.0, "y": 0.8113537117903932, "ox": 0.0, "oy": 0.8113537117903932, "term": "meaningful solutions life sciences business Task oriented ability", "cat25k": 21, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8938407611417125, "os": 0.3708991289837998}, {"x": 0.0, "y": 0.8104803493449784, "ox": 0.0, "oy": 0.8104803493449784, "term": "Deep understanding ML", "cat25k": 21, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8933400100150225, "os": 0.36902206394912784}, {"x": 0.0, "y": 0.8078602620087337, "ox": 0.0, "oy": 0.8078602620087337, "term": "Deep understanding tools trade", "cat25k": 20, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8918377566349525, "os": 0.36284699977456647}, {"x": 0.0, "y": 0.8026200873362447, "ox": 0.0, "oy": 0.8026200873362447, "term": "e g SQL Tableau D3", "cat25k": 20, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8893340010015023, "os": 0.35579586380785394}, {"x": 0.0, "y": 0.7755458515283845, "ox": 0.0, "oy": 0.7755458515283845, "term": "variety modern programming languages", "cat25k": 18, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8728092138207311, "os": 0.3216521150109313}, {"x": 0.0, "y": 0.7746724890829695, "ox": 0.0, "oy": 0.7746724890829695, "term": "PhD computational quantitative discipline e g statistics computer science", "cat25k": 18, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.872308462694041, "os": 0.3212190863466016}, {"x": 0.0, "y": 0.7703056768558953, "ox": 0.0, "oy": 0.7703056768558953, "term": "keen eye detail visual communication findings", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8698047070605909, "os": 0.3140723219897748}, {"x": 0.0, "y": 0.7545851528384281, "ox": 0.0, "oy": 0.7545851528384281, "term": "g regression techniques", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8607911867801703, "os": 0.30203691837133134}, {"x": 0.0, "y": 0.7519650655021836, "ox": 0.0, "oy": 0.7519650655021836, "term": "strong knowledge mathematical underpinnings", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8597896845267902, "os": 0.30030537823271747}, {"x": 0.0, "y": 0.7493449781659389, "ox": 0.0, "oy": 0.7493449781659389, "term": "informatics genetics physics epidemiology health economics", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8582874311467201, "os": 0.2993743433879056}, {"x": 0.0, "y": 0.7475982532751093, "ox": 0.0, "oy": 0.7475982532751093, "term": "non technical teams", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.85728592889334, "os": 0.29402608242482225}, {"x": 0.0, "y": 0.8227074235807862, "ox": 0.0, "oy": 0.8227074235807862, "term": "neural networks decision trees", "cat25k": 22, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.899849774661993, "os": 0.39447233761152445}, {"x": 0.0, "y": 0.6812227074235809, "ox": 0.0, "oy": 0.6812227074235809, "term": "Linux TensorFlow Hadoop Spark", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8217325988983475, "os": 0.24217536013912513}, {"x": 0.0, "y": 0.6558951965065504, "ox": 0.0, "oy": 0.6558951965065504, "term": "various methods", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8077115673510266, "os": 0.23088143736795358}, {"x": 0.0, "y": 0.6462882096069871, "ox": 0.0, "oy": 0.6462882096069871, "term": "D3", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8032048072108162, "os": 0.22699496455881868}, {"x": 0.0, "y": 0.7109170305676857, "ox": 0.0, "oy": 0.7109170305676857, "term": "Comfort", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8382573860791187, "os": 0.25857257696759695}, {"x": 0.0, "y": 0.49082969432314416, "ox": 0.0, "oy": 0.49082969432314416, "term": "source technologies", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7165748622934401, "os": 0.17469711583689185}, {"x": 0.0, "y": 0.30829694323144113, "ox": 0.0, "oy": 0.30829694323144113, "term": "R Python JavaScript", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6154231347020531, "os": 0.13973954631695434}, {"x": 0.0, "y": 0.4262008733624455, "ox": 0.0, "oy": 0.4262008733624455, "term": "PhD Data Science Analytics Statistics Mathematics Physics Economics Computer Science", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6810215322984476, "os": 0.1611087008261288}, {"x": 0.0, "y": 0.41746724890829706, "ox": 0.0, "oy": 0.41746724890829706, "term": "Bachelor Data Science Analytics Statistics Mathematics Physics Economics Computer Science", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6760140210315473, "os": 0.15990757719658702}, {"x": 0.0, "y": 0.4078602620087337, "ox": 0.0, "oy": 0.4078602620087337, "term": "Master degree PhD Data Science Analytics Statistics Mathematics Physics Economics Computer Science", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6710065097646469, "os": 0.15783163806216163}, {"x": 0.0, "y": 0.291703056768559, "ox": 0.0, "oy": 0.291703056768559, "term": "data Experience deep learning frameworks", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6059088632949423, "os": 0.1376035095340256}, {"x": 0.0, "y": 0.28122270742358085, "ox": 0.0, "oy": 0.28122270742358085, "term": "Professional experience machine", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5998998497746619, "os": 0.13596170330421933}, {"x": 0.0, "y": 0.7886462882096071, "ox": 0.0, "oy": 0.7886462882096071, "term": "machine learning models", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8803204807210816, "os": 0.3373495800815334}, {"x": 0.0, "y": 0.8567685589519651, "ox": 0.0, "oy": 0.8567685589519651, "term": "Professional experience", "cat25k": 29, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9208813219829745, "os": 0.5133732852280732}, {"x": 0.0, "y": 0.6323144104803494, "ox": 0.0, "oy": 0.6323144104803494, "term": "Data Scientist Machine Learning Engineer", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7951927891837757, "os": 0.22116371808315693}, {"x": 0.0, "y": 0.817467248908297, "ox": 0.0, "oy": 0.817467248908297, "term": "real world problems", "cat25k": 21, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8968452679018528, "os": 0.3845763303248447}, {"x": 0.0, "y": 0.2262008733624455, "ox": 0.0, "oy": 0.2262008733624455, "term": "keras", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5693540310465699, "os": 0.12751921868599428}, {"x": 0.0, "y": 0.5414847161572053, "ox": 0.0, "oy": 0.5414847161572053, "term": "statistical concepts", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7446169253880821, "os": 0.18522796763796884}, {"x": 0.5926267281105992, "y": 0.5877729257641923, "ox": 0.5926267281105992, "oy": 0.5877729257641923, "term": "libraries", "cat25k": 11, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7696544817225839, "os": 0.20081562943250164}, {"x": 0.0, "y": 0.841048034934498, "ox": 0.0, "oy": 0.841048034934498, "term": "Familiarity AWS ecosystem", "cat25k": 24, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9098647971957937, "os": 0.43301270189221913}, {"x": 0.0, "y": 0.3397379912663756, "ox": 0.0, "oy": 0.3397379912663756, "term": "technology customer operations analytics", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6329494241362043, "os": 0.1441810033360367}, {"x": 0.0, "y": 0.3301310043668123, "ox": 0.0, "oy": 0.3301310043668123, "term": "business performance Journey Analytics clients", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6279419128693039, "os": 0.14366005698030285}, {"x": 0.0, "y": 0.3213973799126638, "ox": 0.0, "oy": 0.3213973799126638, "term": "statistical advanced analytic methods", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6229344016024035, "os": 0.14268019367183554}, {"x": 0.0, "y": 0.24366812227074242, "ox": 0.0, "oy": 0.24366812227074242, "term": "senior clients colleagues", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5788683024536805, "os": 0.1294130744811594}, {"x": 0.05898617511520738, "y": 0.8663755458515285, "ox": 0.05898617511520738, "oy": 0.8663755458515285, "term": "Ability work", "cat25k": 31, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9253880821231847, "os": 0.5580530381399444}, {"x": 0.0, "y": 0.3903930131004368, "ox": 0.0, "oy": 0.3903930131004368, "term": "collaboratively team environment", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6614922383575362, "os": 0.15445314293641516}, {"x": 0.0, "y": 0.5301310043668124, "ox": 0.0, "oy": 0.5301310043668124, "term": "Masters PhD student statistics computer science economics physics quantitative field Internship work experience", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7386079118678017, "os": 0.18286227653297005}, {"x": 0.0, "y": 0.5161572052401747, "ox": 0.0, "oy": 0.5161572052401747, "term": "Bachelors degree statistics computer science economics physics quantitative field Experience", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7310966449674512, "os": 0.17961254937081264}, {"x": 0.0, "y": 0.497816593886463, "ox": 0.0, "oy": 0.497816593886463, "term": "applied statistics machine", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7205808713069604, "os": 0.1757591532040676}, {"x": 0.0, "y": 0.45414847161572064, "ox": 0.0, "oy": 0.45414847161572064, "term": "Proficiency Python R Experience working imperfect data Passion eagerness", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6960440660991487, "os": 0.16776705917366294}, {"x": 0.782488479262673, "y": 0.8541484716157207, "ox": 0.782488479262673, "oy": 0.8541484716157207, "term": "others", "cat25k": 28, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9193790686029043, "os": 0.4980651047549469}, {"x": 0.0, "y": 0.6655021834061137, "ox": 0.0, "oy": 0.6655021834061137, "term": "statistical techniques", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8137205808713069, "os": 0.23441394290622322}, {"x": 0.0, "y": 0.4698689956331878, "ox": 0.0, "oy": 0.4698689956331878, "term": "Experience MS Office Word Access Excel PowerPoint Outlook", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7050575863795694, "os": 0.17003967191319247}, {"x": 0.0, "y": 0.5895196506550219, "ox": 0.0, "oy": 0.5895196506550219, "term": "non technical audiences", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7706559839759639, "os": 0.20139422770468315}, {"x": 0.0, "y": 0.32663755458515287, "ox": 0.0, "oy": 0.32663755458515287, "term": "Experienced building large scale data analysis system Extensive knowledge experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6259389083625438, "os": 0.14311573605315706}, {"x": 0.0, "y": 0.2393013100436682, "ox": 0.0, "oy": 0.2393013100436682, "term": "Strong project management leadership skills", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5768652979469204, "os": 0.12896487673728788}, {"x": 0.0, "y": 0.22882096069869, "ox": 0.0, "oy": 0.22882096069869, "term": "Extensive knowledge details", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5708562844266399, "os": 0.1278740092363317}, {"x": 0.7705069124423964, "y": 0.5528384279475984, "ox": 0.7705069124423964, "oy": 0.5528384279475984, "term": "Machine", "cat25k": 11, "ncat25k": 20, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12218327491236855, "os": -0.27890618107528975}, {"x": 0.11152073732718895, "y": 0.0611353711790393, "ox": 0.11152073732718895, "oy": 0.0611353711790393, "term": "Apache Hadoop", "cat25k": 4, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4576865297946921, "os": -0.08375024472563937}, {"x": 0.0, "y": 0.27772925764192147, "ox": 0.0, "oy": 0.27772925764192147, "term": "similar Total Cost Ownership Net Present Value analysis Approaches systems biology proteomics analysis", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5978968452679019, "os": 0.1354183394853346}, {"x": 0.41290322580645167, "y": 0.04366812227074237, "ox": 0.41290322580645167, "oy": 0.04366812227074237, "term": "platforms", "cat25k": 3, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.30395593390085135, "os": -0.13352229971442847}, {"x": 0.9769585253456221, "y": 0.12838427947598255, "ox": 0.9769585253456221, "oy": 0.12838427947598255, "term": "Data", "cat25k": 6, "ncat25k": 145, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 2, "s": 0.011517275913870808, "os": -2.04575566733243}, {"x": 0.0, "y": 0.8812227074235809, "ox": 0.0, "oy": 0.8812227074235809, "term": "MS years", "cat25k": 36, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9334001001502253, "os": 0.6497913410209621}, {"x": 0.0, "y": 0.7528384279475984, "ox": 0.0, "oy": 0.7528384279475984, "term": "research results commercialization", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8602904356534802, "os": 0.30069402708873205}, {"x": 0.8811059907834102, "y": 0.07423580786026202, "ox": 0.8811059907834102, "oy": 0.07423580786026202, "term": "Strong knowledge", "cat25k": 5, "ncat25k": 31, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.058587881822734104, "os": -0.43781974770103566}, {"x": 0.0, "y": 0.7737991266375547, "ox": 0.0, "oy": 0.7737991266375547, "term": "complex analyses", "cat25k": 18, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.871807711567351, "os": 0.3193703231567981}, {"x": 0.0, "y": 0.383406113537118, "ox": 0.0, "oy": 0.383406113537118, "term": "simple terms", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6574862293440159, "os": 0.153235754421934}, {"x": 0.0, "y": 0.6148471615720525, "ox": 0.0, "oy": 0.6148471615720525, "term": "quantitative field", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.785177766649975, "os": 0.21479479691571152}, {"x": 0.02949308755760369, "y": 0.04017467248908298, "ox": 0.02949308755760369, "oy": 0.04017467248908298, "term": "equity", "cat25k": 3, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5002503755633451, "os": 0.057986279112909066}, {"x": 0.2995391705069125, "y": 0.9065502183406114, "ox": 0.2995391705069125, "oy": 0.9065502183406114, "term": "Deep knowledge", "cat25k": 51, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9474211316975464, "os": 0.9210011946818312}, {"x": 0.0, "y": 0.9764192139737992, "ox": 0.0, "oy": 0.9764192139737992, "term": "work level position", "cat25k": 135, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 2, "ncat": 0, "s": 0.9864797195793691, "os": 2.417896998242457}, {"x": 0.0, "y": 0.9720524017467249, "ox": 0.0, "oy": 0.9720524017467249, "term": "minimum acceptable considered position", "cat25k": 120, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 2, "ncat": 0, "s": 0.9839759639459189, "os": 2.160946333489832}, {"x": 0.0, "y": 0.9703056768558953, "ox": 0.0, "oy": 0.9703056768558953, "term": "relevant position", "cat25k": 119, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 2, "ncat": 0, "s": 0.9829744616925388, "os": 2.1373935903540735}, {"x": 0.0, "y": 0.9580786026200875, "ox": 0.0, "oy": 0.9580786026200875, "term": "hiring manager organization", "cat25k": 100, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9764646970455684, "os": 1.7957174152303907}, {"x": 0.0, "y": 0.9528384279475983, "ox": 0.0, "oy": 0.9528384279475983, "term": "account information", "cat25k": 88, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9734601902854281, "os": 1.5835271744196682}, {"x": 0.0, "y": 0.9510917030567687, "ox": 0.0, "oy": 0.9510917030567687, "term": "based candidates", "cat25k": 86, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.972458688032048, "os": 1.5478038780645655}, {"x": 0.0, "y": 0.9388646288209607, "ox": 0.0, "oy": 0.9388646288209607, "term": "Salary", "cat25k": 70, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9654481722583875, "os": 1.259590832234161}, {"x": 0.0, "y": 0.8532751091703059, "ox": 0.0, "oy": 0.8532751091703059, "term": "The qualifications", "cat25k": 28, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9188783174762143, "os": 0.4959468838475567}, {"x": 0.0, "y": 0.8873362445414849, "ox": 0.0, "oy": 0.8873362445414849, "term": "Degrees Physics Mathematics Computer Science Engineering", "cat25k": 39, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9369053580370555, "os": 0.6998542122237651}, {"x": 0.0, "y": 0.3930131004366813, "ox": 0.0, "oy": 0.3930131004366813, "term": "data visualization tools years experience packages", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6629944917376064, "os": 0.15521857197358127}, {"x": 0.0, "y": 0.31179039301310046, "ox": 0.0, "oy": 0.31179039301310046, "term": "project management experience years", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6174261392088132, "os": 0.14094467176588485}, {"x": 0.0, "y": 0.2855895196506551, "ox": 0.0, "oy": 0.2855895196506551, "term": "multiple data sources Experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6024036054081121, "os": 0.1369115095244175}, {"x": 0.0, "y": 0.27947598253275113, "ox": 0.0, "oy": 0.27947598253275113, "term": "role data analysis metrics development years", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5988983475212819, "os": 0.13580750983407938}, {"x": 0.9133640552995393, "y": 0.8777292576419214, "ox": 0.9133640552995393, "oy": 0.8777292576419214, "term": "experience", "cat25k": 34, "ncat25k": 38, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9313970956434653, "os": 0.6116793772222899}, {"x": 0.6921658986175117, "y": 0.8733624454148472, "ox": 0.6921658986175117, "oy": 0.8733624454148472, "term": "large datasets", "cat25k": 33, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.928893340010015, "os": 0.599371198543599}, {"x": 0.5050691244239632, "y": 0.034061135371179045, "ox": 0.5050691244239632, "oy": 0.034061135371179045, "term": "Hands", "cat25k": 3, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.25738607911867806, "os": -0.1569889198477695}, {"x": 0.0, "y": 0.6017467248908298, "ox": 0.0, "oy": 0.6017467248908298, "term": "organization Ability", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7776664997496244, "os": 0.20465172647539176}, {"x": 0.0, "y": 0.6820960698689957, "ox": 0.0, "oy": 0.6820960698689957, "term": "SAS R Python", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8222333500250375, "os": 0.24252787718250082}, {"x": 0.0, "y": 0.5275109170305678, "ox": 0.0, "oy": 0.5275109170305678, "term": "Significant experience", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7371056584877316, "os": 0.18233041807400224}, {"x": 0.9364055299539171, "y": 0.8593886462882098, "ox": 0.9364055299539171, "oy": 0.8593886462882098, "term": "relational databases", "cat25k": 29, "ncat25k": 47, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.03204807210816225, "os": -0.6695803933325449}, {"x": 0.0, "y": 0.560698689956332, "ox": 0.0, "oy": 0.560698689956332, "term": "depth experience", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7546319479218828, "os": 0.19218246967293934}, {"x": 0.0, "y": 0.4558951965065503, "ox": 0.0, "oy": 0.4558951965065503, "term": "mathematics computer science physical sciences", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6970455683525287, "os": 0.16820562105763823}, {"x": 0.0, "y": 0.40873362445414857, "ox": 0.0, "oy": 0.40873362445414857, "term": "deep learning solutions", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6715072608913369, "os": 0.15825973898162424}, {"x": 0.0, "y": 0.3965065502183407, "ox": 0.0, "oy": 0.3965065502183407, "term": "similar technical field Experience", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6649974962443664, "os": 0.15592772958694323}, {"x": 0.0, "y": 0.8550218340611355, "ox": 0.0, "oy": 0.8550218340611355, "term": "TensorFlow", "cat25k": 28, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9198798197295944, "os": 0.504057247963182}, {"x": 0.0, "y": 0.6192139737991267, "ox": 0.0, "oy": 0.6192139737991267, "term": "xgboost", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7876815222834251, "os": 0.2162046065394636}, {"x": 0.0, "y": 0.8087336244541485, "ox": 0.0, "oy": 0.8087336244541485, "term": "MongoDB Solr Indexes", "cat25k": 20, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8923385077616425, "os": 0.36432994274734615}, {"x": 0.0, "y": 0.7982532751091704, "ox": 0.0, "oy": 0.7982532751091704, "term": "Solr Indexes", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.885828743114672, "os": 0.3498759579292246}, {"x": 0.36221198156682033, "y": 0.572052401746725, "ox": 0.36221198156682033, "oy": 0.572052401746725, "term": "Experience SQL", "cat25k": 11, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7611417125688532, "os": 0.19418352986099446}, {"x": 0.0, "y": 0.49344978165938874, "ox": 0.0, "oy": 0.49344978165938874, "term": "Mechanical Engineering Materials Engineering Chemical Engineering Electrical Engineering Chemistry Physics Expertise", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7180771156735102, "os": 0.17520136236111694}, {"x": 0.0, "y": 0.4777292576419215, "ox": 0.0, "oy": 0.4777292576419215, "term": "Mechanical Engineering Materials Engineering Chemical Engineering Electrical Engineering Chemistry Physics Expertise engineering analysis tools data analysis scripting methods order automate train standard analytical tasks", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7095643465197796, "os": 0.17145309418212604}, {"x": 0.0, "y": 0.3222707423580787, "ox": 0.0, "oy": 0.3222707423580787, "term": "numerical computing", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6234351527290937, "os": 0.14275336933092814}, {"x": 0.0, "y": 0.691703056768559, "ox": 0.0, "oy": 0.691703056768559, "term": "Advanced degree data science equivalent field sub field Experience working data rich problems", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8272408612919379, "os": 0.24817363930183978}, {"x": 0.0, "y": 0.6847161572052403, "ox": 0.0, "oy": 0.6847161572052403, "term": "research programs Experience computer programming user experience user interface Ability", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8237356034051077, "os": 0.24369813066054286}, {"x": 0.0, "y": 0.6541484716157207, "ox": 0.0, "oy": 0.6541484716157207, "term": "Experience real world data thesis research internships", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8067100650976465, "os": 0.23055822153550826}, {"x": 0.0, "y": 0.612227074235808, "ox": 0.0, "oy": 0.612227074235808, "term": "work experience Creativity Initiative Integrity Leadership", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7836755132699048, "os": 0.2112339803593536}, {"x": 0.0, "y": 0.5240174672489084, "ox": 0.0, "oy": 0.5240174672489084, "term": "large incomplete data", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7351026539809715, "os": 0.18175052390353452}, {"x": 0.0, "y": 0.38864628820960706, "ox": 0.0, "oy": 0.38864628820960706, "term": "verbal communication", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6604907361041562, "os": 0.1539659004702838}, {"x": 0.6774193548387099, "y": 0.9755458515283845, "ox": 0.6774193548387099, "oy": 0.9755458515283845, "term": "solutions", "cat25k": 132, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 2, "ncat": 0, "s": 0.985978968452679, "os": 2.3756270130254764}, {"x": 0.043317972350230424, "y": 0.6724890829694324, "ox": 0.043317972350230424, "oy": 0.6724890829694324, "term": "Strong", "cat25k": 13, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8177265898848273, "os": 0.23856615094103353}, {"x": 0.8165898617511522, "y": 0.7807860262008736, "ox": 0.8165898617511522, "oy": 0.7807860262008736, "term": "projects", "cat25k": 18, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8758137205808714, "os": 0.32922317179400934}, {"x": 0.0, "y": 0.27161572052401756, "ox": 0.0, "oy": 0.27161572052401756, "term": "proficiency SQL Excellent communication organization analytical skills experience", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5943915873810717, "os": 0.13402004841142057}, {"x": 0.5539170506912443, "y": 0.5755458515283843, "ox": 0.5539170506912443, "oy": 0.5755458515283843, "term": "Background", "cat25k": 11, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7626439659489234, "os": 0.19555033889337306}, {"x": 0.0, "y": 0.3825327510917031, "ox": 0.0, "oy": 0.3825327510917031, "term": "SQL Python R SAS preferred Demonstrate familiarity work experience", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.656985478217326, "os": 0.15317266319550196}, {"x": 0.0, "y": 0.33799126637554594, "ox": 0.0, "oy": 0.33799126637554594, "term": "driving product impact", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6319479218828242, "os": 0.14403200898011995}, {"x": 0.3483870967741936, "y": 0.9484716157205241, "ox": 0.3483870967741936, "oy": 0.9484716157205241, "term": "SAS", "cat25k": 84, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.970956434651978, "os": 1.510658039286101}, {"x": 0.09677419354838711, "y": 0.051528384279475994, "ox": 0.09677419354838711, "oy": 0.051528384279475994, "term": "OOP", "cat25k": 4, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.46469704556835256, "os": -0.08160764157397105}, {"x": 0.0, "y": 0.5694323144104805, "ox": 0.0, "oy": 0.5694323144104805, "term": "Casual Work Environment", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7596394591887832, "os": 0.1938846627079447}, {"x": 0.4442396313364056, "y": 0.9021834061135372, "ox": 0.4442396313364056, "oy": 0.9021834061135372, "term": "US", "cat25k": 47, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9449173760640962, "os": 0.847542459598256}, {"x": 0.0, "y": 0.6419213973799128, "ox": 0.0, "oy": 0.6419213973799128, "term": "seriously huge datasets", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8007010515773659, "os": 0.22394480434190045}, {"x": 0.0, "y": 0.6969432314410481, "ox": 0.0, "oy": 0.6969432314410481, "term": "Expertise Python R Expertise", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8302453680520782, "os": 0.25217822920492694}, {"x": 0.575115207373272, "y": 0.11965065502183407, "ox": 0.575115207373272, "oy": 0.11965065502183407, "term": "Master degree", "cat25k": 6, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2228342513770656, "os": -0.18506487808046085}, {"x": 0.0, "y": 0.8096069868995635, "ox": 0.0, "oy": 0.8096069868995635, "term": "placement different job level", "cat25k": 20, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8928392588883325, "os": 0.3644870160185702}, {"x": 0.0, "y": 0.8899563318777294, "ox": 0.0, "oy": 0.8899563318777294, "term": "joy clients", "cat25k": 39, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9384076114171257, "os": 0.7059877192884996}, {"x": 0.0, "y": 0.8838427947598253, "ox": 0.0, "oy": 0.8838427947598253, "term": "work Stitch Fix", "cat25k": 38, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9349023535302955, "os": 0.6786230233162478}, {"x": 0.0, "y": 0.863755458515284, "ox": 0.0, "oy": 0.863755458515284, "term": "Stitch Fix", "cat25k": 31, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9238858287431146, "os": 0.5517434841913803}, {"x": 0.06359447004608296, "y": 0.8890829694323145, "ox": 0.06359447004608296, "oy": 0.8890829694323145, "term": "work", "cat25k": 39, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9379068602904356, "os": 0.7048665305201961}, {"x": 0.0, "y": 0.7860262008733626, "ox": 0.0, "oy": 0.7860262008733626, "term": "every day", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8788182273410114, "os": 0.33403268719356494}, {"x": 0.0, "y": 0.8375545851528385, "ox": 0.0, "oy": 0.8375545851528385, "term": "tensorflow R caret Experience curating datasets", "cat25k": 24, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9078617926890336, "os": 0.4231354638349409}, {"x": 0.0, "y": 0.8358078602620089, "ox": 0.0, "oy": 0.8358078602620089, "term": "Spark MLLib SQL OS Experience Windows Linux Windows Ability", "cat25k": 24, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9068602904356534, "os": 0.4226997172064513}, {"x": 0.0, "y": 0.8305676855895198, "ox": 0.0, "oy": 0.8305676855895198, "term": "Spark MLLib SQL OS Experience Windows Linux Windows Ability compile results", "cat25k": 23, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9038557836755132, "os": 0.41147761431744145}, {"x": 0.0, "y": 0.8253275109170307, "ox": 0.0, "oy": 0.8253275109170307, "term": "modeling Experience scikit", "cat25k": 22, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.900851276915373, "os": 0.3992741215125369}, {"x": 0.0, "y": 0.8244541484716159, "ox": 0.0, "oy": 0.8244541484716159, "term": "Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical", "cat25k": 22, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.900350525788683, "os": 0.39891058515696426}, {"x": 0.0, "y": 0.8218340611353713, "ox": 0.0, "oy": 0.8218340611353713, "term": "related Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical Modeling Geo spatial analytics Data Munging Cleaning Bachelor Degree Ability work datasets", "cat25k": 22, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.899349023535303, "os": 0.39411566632394524}, {"x": 0.0, "y": 0.8192139737991269, "ox": 0.0, "oy": 0.8192139737991269, "term": "unsupervised machine learning methods Experience C", "cat25k": 22, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8978467701552328, "os": 0.38675931998470137}, {"x": 0.0, "y": 0.7938864628820962, "ox": 0.0, "oy": 0.7938864628820962, "term": "spatial analysis Experience PCAP", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8833249874812219, "os": 0.34432494800798635}, {"x": 0.0, "y": 0.7912663755458517, "ox": 0.0, "oy": 0.7912663755458517, "term": "neural networks cluster analysis feature engineering extraction reduction web scraping decision trees", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8818227341011518, "os": 0.3389330073011326}, {"x": 0.0, "y": 0.7441048034934499, "ox": 0.0, "oy": 0.7441048034934499, "term": "working Intelligence Community teams", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8552829243865798, "os": 0.29255222560943206}, {"x": 0.0, "y": 0.737991266375546, "ox": 0.0, "oy": 0.737991266375546, "term": "Intelligence Community", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8522784176264396, "os": 0.28357643041094577}, {"x": 0.0, "y": 0.731877729257642, "ox": 0.0, "oy": 0.731877729257642, "term": "multi TB dataset manipulation cleaning", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8492739108662994, "os": 0.27611397546100297}, {"x": 0.0, "y": 0.7257641921397381, "ox": 0.0, "oy": 0.7257641921397381, "term": "Java R Javascript PhP MatLab Pig Hive Impala PySpark Scala Ruby Pytorch", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8462694041061593, "os": 0.2686113562510727}, {"x": 0.0, "y": 0.7170305676855897, "ox": 0.0, "oy": 0.7170305676855897, "term": "senior level leadership", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8417626439659489, "os": 0.2617422918002003}, {"x": 0.0, "y": 0.7135371179039303, "ox": 0.0, "oy": 0.7135371179039303, "term": "present material audiences", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8397596394591887, "os": 0.260711880294849}, {"x": 0.0, "y": 0.7013100436681223, "ox": 0.0, "oy": 0.7013100436681223, "term": "Elastic Search Hadoop", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8327491236855282, "os": 0.254115722607566}, {"x": 0.0, "y": 0.6960698689956333, "ox": 0.0, "oy": 0.6960698689956333, "term": "different sizes formats", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.829744616925388, "os": 0.25198921120463696}, {"x": 0.0, "y": 0.6611353711790394, "ox": 0.0, "oy": 0.6611353711790394, "term": "specific techniques", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8107160741111668, "os": 0.23234322245509634}, {"x": 0.23594470046082952, "y": 0.6506550218340613, "ox": 0.23594470046082952, "oy": 0.6506550218340613, "term": "multiple databases", "cat25k": 13, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8057085628442664, "os": 0.22879057014005547}, {"x": 0.0, "y": 0.5799126637554586, "ox": 0.0, "oy": 0.5799126637554586, "term": "working fields", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7651477215823735, "os": 0.19676589682406626}, {"x": 0.0, "y": 0.5676855895196508, "ox": 0.0, "oy": 0.5676855895196508, "term": "Impala PySpark", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7586379569354031, "os": 0.19350862283446163}, {"x": 0.0, "y": 0.566812227074236, "ox": 0.0, "oy": 0.566812227074236, "term": "Java R Javascript", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.758137205808713, "os": 0.19331473689229559}, {"x": 0.0, "y": 0.520524017467249, "ox": 0.0, "oy": 0.520524017467249, "term": "CART", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7336004006009014, "os": 0.18082425712089772}, {"x": 0.0, "y": 0.5982532751091704, "ox": 0.0, "oy": 0.5982532751091704, "term": "presentations", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7756634952428643, "os": 0.2036156408968923}, {"x": 0.0, "y": 0.46113537117903936, "ox": 0.0, "oy": 0.46113537117903936, "term": "PhP MatLab", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.700050075112669, "os": 0.16867098560363708}, {"x": 0.005529953917050692, "y": 0.4410480349344979, "ox": 0.005529953917050692, "oy": 0.4410480349344979, "term": "TB", "cat25k": 9, "ncat25k": 2, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6890335503254882, "os": 0.16397944385881782}, {"x": 0.0, "y": 0.697816593886463, "ox": 0.0, "oy": 0.697816593886463, "term": "advanced topics analytics artificial intelligence data engineering", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8307461191787682, "os": 0.2523989272565783}, {"x": 0.0, "y": 0.6838427947598255, "ox": 0.0, "oy": 0.6838427947598255, "term": "professional experience media company", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8232348522784176, "os": 0.24333674471489108}, {"x": 0.0, "y": 0.6113537117903931, "ox": 0.0, "oy": 0.6113537117903931, "term": "SQL Tableau Excel interest", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7831747621432148, "os": 0.21057097190613938}, {"x": 0.0, "y": 0.6104803493449783, "ox": 0.0, "oy": 0.6104803493449783, "term": "analytics tools", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7826740110165248, "os": 0.2102438023084497}, {"x": 0.0, "y": 0.565938864628821, "ox": 0.0, "oy": 0.565938864628821, "term": "work sweat details", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.757636454682023, "os": 0.19329807615500205}, {"x": 0.0, "y": 0.5563318777292577, "ox": 0.0, "oy": 0.5563318777292577, "term": "either R Python Experience building web applications agile development", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7521281922884326, "os": 0.18996195416842013}, {"x": 0.0, "y": 0.4794759825327512, "ox": 0.0, "oy": 0.4794759825327512, "term": "learning libraries", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7105658487731596, "os": 0.17169300844547822}, {"x": 0.0, "y": 0.4655021834061136, "ox": 0.0, "oy": 0.4655021834061136, "term": "visualization machine", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7025538307461192, "os": 0.16952471474830047}, {"x": 0.0036866359447004613, "y": 0.8366812227074237, "ox": 0.0036866359447004613, "oy": 0.8366812227074237, "term": "Excel", "cat25k": 24, "ncat25k": 2, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9073610415623435, "os": 0.42276393051271144}, {"x": 0.0, "y": 0.6279475982532752, "ox": 0.0, "oy": 0.6279475982532752, "term": "statistics", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7926890335503255, "os": 0.2195618611007335}, {"x": 0.0, "y": 0.9406113537117904, "ox": 0.0, "oy": 0.9406113537117904, "term": "date thread subject author", "cat25k": 73, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9664496745117677, "os": 1.3045965201285645}, {"x": 0.0, "y": 0.829694323144105, "ox": 0.0, "oy": 0.829694323144105, "term": "Messages", "cat25k": 23, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9033550325488232, "os": 0.40890746386634846}, {"x": 0.0, "y": 0.4366812227074237, "ox": 0.0, "oy": 0.4366812227074237, "term": "equal access benefits details training office", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.686529794692038, "os": 0.16312009476393696}, {"x": 0.0, "y": 0.732751091703057, "ox": 0.0, "oy": 0.732751091703057, "term": "accommodation", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8497746619929895, "os": 0.2774154326212118}, {"x": 0.0, "y": 0.47074235807860276, "ox": 0.0, "oy": 0.47074235807860276, "term": "Registered Selective Service", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7055583375062593, "os": 0.1700512931780461}, {"x": 0.0, "y": 0.6087336244541486, "ox": 0.0, "oy": 0.6087336244541486, "term": "job", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7816725087631448, "os": 0.20966904878196563}, {"x": 0.0, "y": 0.43056768558951974, "ox": 0.0, "oy": 0.43056768558951974, "term": "An employee disability", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6830245368052078, "os": 0.16192123140082107}, {"x": 0.05345622119815669, "y": 0.0043668122270742364, "ox": 0.05345622119815669, "oy": 0.0043668122270742364, "term": "one year", "cat25k": 2, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.485728592889334, "os": -0.07152996680549055}, {"x": 0.0, "y": 0.47423580786026204, "ox": 0.0, "oy": 0.47423580786026204, "term": "online application", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7075613420130196, "os": 0.1710917854079438}, {"x": 0.2654377880184332, "y": 0.04192139737991267, "ox": 0.2654377880184332, "oy": 0.04192139737991267, "term": "business requirements", "cat25k": 3, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3775663495242864, "os": -0.10813540237424876}, {"x": 0.2525345622119816, "y": 0.662882096069869, "ox": 0.2525345622119816, "oy": 0.662882096069869, "term": "applicants", "cat25k": 13, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8122183274912368, "os": 0.23407867860393458}, {"x": 0.5142857142857145, "y": 0.9074235807860264, "ox": 0.5142857142857145, "oy": 0.9074235807860264, "term": "requirements", "cat25k": 52, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9479218828242363, "os": 0.9357693890556702}, {"x": 0.02580645161290323, "y": 0.937991266375546, "ox": 0.02580645161290323, "oy": 0.937991266375546, "term": "position", "cat25k": 70, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9649474211316975, "os": 1.2540025385885782}, {"x": 0.9566820276497696, "y": 0.07074235807860263, "ox": 0.9566820276497696, "oy": 0.07074235807860263, "term": "Develop", "cat25k": 5, "ncat25k": 57, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.022033049574361543, "os": -0.8111604841689957}, {"x": 0.6599078341013827, "y": 0.11790393013100436, "ox": 0.6599078341013827, "oy": 0.11790393013100436, "term": "Provide", "cat25k": 6, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.18027040560841265, "os": -0.2181666660202904}, {"x": 0.0, "y": 0.7982532751091704, "ox": 0.0, "oy": 0.7982532751091704, "term": "LA location", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.885828743114672, "os": 0.3498759579292246}, {"x": 0.0, "y": 0.6620087336244542, "ox": 0.0, "oy": 0.6620087336244542, "term": "Gated dog run", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8112168252378568, "os": 0.2340164370673894}, {"x": 0.5179723502304148, "y": 0.6436681222707424, "ox": 0.5179723502304148, "oy": 0.6436681222707424, "term": "LA", "cat25k": 13, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8017025538307462, "os": 0.22514738896862999}, {"x": 0.8267281105990785, "y": 0.047161572052401755, "ox": 0.8267281105990785, "oy": 0.047161572052401755, "term": "large complex data sets", "cat25k": 4, "ncat25k": 24, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09313970956434652, "os": -0.33583601410541436}, {"x": 0.8857142857142858, "y": 0.9397379912663756, "ox": 0.8857142857142858, "oy": 0.9397379912663756, "term": "Demonstrated ability", "cat25k": 72, "ncat25k": 32, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9659489233850777, "os": 1.286171419652698}, {"x": 0.5760368663594471, "y": 0.6524017467248909, "ox": 0.5760368663594471, "oy": 0.6524017467248909, "term": "tools", "cat25k": 13, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8062093139709564, "os": 0.22981224206692855}, {"x": 0.8377880184331798, "y": 0.0812227074235808, "ox": 0.8377880184331798, "oy": 0.0812227074235808, "term": "self", "cat25k": 5, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08662994491737606, "os": -0.3531008534599946}, {"x": 0.27926267281106, "y": 0.08034934497816594, "ox": 0.27926267281106, "oy": 0.08034934497816594, "term": "decisions", "cat25k": 5, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.37005508262393594, "os": -0.110596203438321}, {"x": 0.4995391705069125, "y": 0.06200873362445415, "ox": 0.4995391705069125, "oy": 0.06200873362445415, "term": "Communicate", "cat25k": 4, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.25988983475212823, "os": -0.15623280664758366}, {"x": 0.0, "y": 0.9694323144104804, "ox": 0.0, "oy": 0.9694323144104804, "term": "statistical modeling techniques", "cat25k": 116, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 2, "ncat": 0, "s": 0.9824737105658488, "os": 2.078964717710996}, {"x": 0.0, "y": 0.9659388646288211, "ox": 0.0, "oy": 0.9659388646288211, "term": "Detail Oriented Process", "cat25k": 107, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9809714571857786, "os": 1.9268559570260084}, {"x": 0.0, "y": 0.9650655021834061, "ox": 0.0, "oy": 0.9650655021834061, "term": "Knowledge variety machine", "cat25k": 107, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9804707060590886, "os": 1.9250171055989287}, {"x": 0.0, "y": 0.9641921397379913, "ox": 0.0, "oy": 0.9641921397379913, "term": "new process efficiencies", "cat25k": 107, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9799699549323986, "os": 1.9200253520663728}, {"x": 0.0, "y": 0.9633187772925764, "ox": 0.0, "oy": 0.9633187772925764, "term": "Data Scientist A Data Geek", "cat25k": 106, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9794692038057086, "os": 1.9048705820881808}, {"x": 0.0, "y": 0.9624454148471617, "ox": 0.0, "oy": 0.9624454148471617, "term": "best technique", "cat25k": 106, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9789684526790186, "os": 1.9045144673961987}, {"x": 0.0, "y": 0.9606986899563319, "ox": 0.0, "oy": 0.9606986899563319, "term": "Mathematics Statistics Computer Science equivalent work experience", "cat25k": 103, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9779669504256384, "os": 1.8548340705027397}, {"x": 0.0, "y": 0.9598253275109172, "ox": 0.0, "oy": 0.9598253275109172, "term": "ML Proficiency Python R scripting languages", "cat25k": 102, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9774661992989484, "os": 1.8337978106122204}, {"x": 0.0, "y": 0.9572052401746726, "ox": 0.0, "oy": 0.9572052401746726, "term": "business setting Ability", "cat25k": 99, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9759639459188783, "os": 1.7854113666098363}, {"x": 0.0, "y": 0.955458515283843, "ox": 0.0, "oy": 0.955458515283843, "term": "comfortable working numbers patterns", "cat25k": 94, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9749624436654982, "os": 1.6838203767207505}, {"x": 0.0, "y": 0.9537117903930132, "ox": 0.0, "oy": 0.9537117903930132, "term": "looking people", "cat25k": 88, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9739609414121182, "os": 1.5850973546657696}, {"x": 0.0, "y": 0.9519650655021834, "ox": 0.0, "oy": 0.9519650655021834, "term": "work kinds", "cat25k": 88, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9729594391587381, "os": 1.5719633271324807}, {"x": 0.0, "y": 0.9502183406113538, "ox": 0.0, "oy": 0.9502183406113538, "term": "GCP cloud platforms", "cat25k": 86, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.971957936905358, "os": 1.5429094143191335}, {"x": 0.0, "y": 0.9458515283842795, "ox": 0.0, "oy": 0.9458515283842795, "term": "actionable results", "cat25k": 79, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9694541812719079, "os": 1.421000353457254}, {"x": 0.0, "y": 0.9441048034934498, "ox": 0.0, "oy": 0.9441048034934498, "term": "ready code", "cat25k": 78, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9684526790185278, "os": 1.3959972285134983}, {"x": 0.0, "y": 0.9475982532751092, "ox": 0.0, "oy": 0.9475982532751092, "term": "data patterns", "cat25k": 82, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9704556835252879, "os": 1.4678756682276082}, {"x": 0.0, "y": 0.9414847161572053, "ox": 0.0, "oy": 0.9414847161572053, "term": "Driven looking folks", "cat25k": 77, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9669504256384577, "os": 1.3796888183586968}, {"x": 0.0, "y": 0.9301310043668123, "ox": 0.0, "oy": 0.9301310043668123, "term": "Mathematics Statistics Computer Science", "cat25k": 63, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9604406609914872, "os": 1.133430616415128}, {"x": 0.0, "y": 0.926637554585153, "ox": 0.0, "oy": 0.926637554585153, "term": "Mass relocation", "cat25k": 61, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9589384076114171, "os": 1.1013512008012265}, {"x": 0.0, "y": 0.9248908296943232, "ox": 0.0, "oy": 0.9248908296943232, "term": "toolkits", "cat25k": 61, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.957936905358037, "os": 1.086228564082229}, {"x": 0.0, "y": 0.9344978165938864, "ox": 0.0, "oy": 0.9344978165938864, "term": "production", "cat25k": 67, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9629444166249373, "os": 1.199982232852876}, {"x": 0.0, "y": 0.920524017467249, "ox": 0.0, "oy": 0.920524017467249, "term": "A sense humor perspective", "cat25k": 58, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9554331497245868, "os": 1.0441676321499886}, {"x": 0.0, "y": 0.9152838427947598, "ox": 0.0, "oy": 0.9152838427947598, "term": "puzzles", "cat25k": 55, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9524286429644467, "os": 0.9800268756680842}, {"x": 0.0, "y": 0.9109170305676857, "ox": 0.0, "oy": 0.9109170305676857, "term": "local candidates", "cat25k": 53, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9499248873309966, "os": 0.9553069012394004}, {"x": 0.0, "y": 0.9013100436681223, "ox": 0.0, "oy": 0.9013100436681223, "term": "Mass", "cat25k": 46, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9444166249374061, "os": 0.8280606215111331}, {"x": 0.0, "y": 0.896943231441048, "ox": 0.0, "oy": 0.896943231441048, "term": "pandas NumPy etc Experience", "cat25k": 44, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9419128693039559, "os": 0.7877556769857498}, {"x": 0.0, "y": 0.8943231441048036, "ox": 0.0, "oy": 0.8943231441048036, "term": "Bachelor Degree concentration", "cat25k": 42, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9409113670505759, "os": 0.7556038060212432}, {"x": 0.0, "y": 0.8934497816593887, "ox": 0.0, "oy": 0.8934497816593887, "term": "A mindset research", "cat25k": 41, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9404106159238858, "os": 0.7406450982749564}, {"x": 0.0, "y": 0.880349344978166, "ox": 0.0, "oy": 0.880349344978166, "term": "intelligently passionately interesting challenges projects", "cat25k": 36, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9328993490235352, "os": 0.6430423564982458}, {"x": 0.0, "y": 0.8515283842794761, "ox": 0.0, "oy": 0.8515283842794761, "term": "even solution", "cat25k": 27, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9183775663495243, "os": 0.4861814789400325}, {"x": 0.3557603686635945, "y": 0.9048034934497817, "ox": 0.3557603686635945, "oy": 0.9048034934497817, "term": "Preference", "cat25k": 49, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9464196294441662, "os": 0.8802041492528514}, {"x": 0.0, "y": 0.7074235807860264, "ox": 0.0, "oy": 0.7074235807860264, "term": "knowledge system identification statistical inference", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8362543815723585, "os": 0.2572647482221939}, {"x": 0.0, "y": 0.6393013100436683, "ox": 0.0, "oy": 0.6393013100436683, "term": "knowledge MATLAB", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.799198798197296, "os": 0.22309882666731606}, {"x": 0.0, "y": 0.4724890829694324, "ox": 0.0, "oy": 0.4724890829694324, "term": "positive impact livelihood world", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7065598397596394, "os": 0.17032584544291615}, {"x": 0.9299539170506914, "y": 0.37729257641921404, "ox": 0.9299539170506914, "oy": 0.37729257641921404, "term": "401k", "cat25k": 8, "ncat25k": 44, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.03505257886830245, "os": -0.6273375322307604}, {"x": 0.8110599078341015, "y": 0.6515283842794761, "ox": 0.8110599078341015, "oy": 0.6515283842794761, "term": "C C", "cat25k": 13, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10115172759138709, "os": -0.31836113582639325}, {"x": 0.5207373271889402, "y": 0.03580786026200874, "ox": 0.5207373271889402, "oy": 0.03580786026200874, "term": "product", "cat25k": 3, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.25037556334501754, "os": -0.1612083404542337}, {"x": 0.5631336405529954, "y": 0.1109170305676856, "ox": 0.5631336405529954, "oy": 0.1109170305676856, "term": "information", "cat25k": 6, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.22934401602403606, "os": -0.17848911541773207}, {"x": 0.0, "y": 0.8489082969432317, "ox": 0.0, "oy": 0.8489082969432317, "term": "SQL data exploration tools SAS R Experience data analytics design Experience", "cat25k": 26, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9168753129694541, "os": 0.4684514742730092}, {"x": 0.0, "y": 0.8454148471615722, "ox": 0.0, "oy": 0.8454148471615722, "term": "data analysis Experience", "cat25k": 25, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9148723084626941, "os": 0.45472259681334815}, {"x": 0.0, "y": 0.8314410480349347, "ox": 0.0, "oy": 0.8314410480349347, "term": "Health care industry experience Demonstrated ability", "cat25k": 23, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9043565348022032, "os": 0.4126997533757823}, {"x": 0.0, "y": 0.8157205240174674, "ox": 0.0, "oy": 0.8157205240174674, "term": "Formulas Bilingual Spanish English Master Degree Experience", "cat25k": 21, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8958437656484727, "os": 0.3811937196337411}, {"x": 0.0, "y": 0.8043668122270744, "ox": 0.0, "oy": 0.8043668122270744, "term": "Proven organizational skills ability flexible work ambiguity", "cat25k": 20, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8903355032548823, "os": 0.35701426117203594}, {"x": 0.0, "y": 0.7930131004366814, "ox": 0.0, "oy": 0.7930131004366814, "term": "deep technical concepts", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8828242363545318, "os": 0.3435950617088569}, {"x": 0.0, "y": 0.7799126637554586, "ox": 0.0, "oy": 0.7799126637554586, "term": "SAS R Python Proficient MS Office applications Excel proficiency Pivots V Lookups", "cat25k": 18, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8753129694541812, "os": 0.3279062630435123}, {"x": 0.0, "y": 0.7624454148471618, "ox": 0.0, "oy": 0.7624454148471618, "term": "SAS R Python Proficient MS Office", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8652979469203805, "os": 0.3109103732643389}, {"x": 0.0, "y": 0.7572052401746726, "ox": 0.0, "oy": 0.7572052401746726, "term": "Bachelor degree Minimum year experience", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8622934401602403, "os": 0.3046681432656948}, {"x": 0.0, "y": 0.7275109170305678, "ox": 0.0, "oy": 0.7275109170305678, "term": "deeper understanding", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8472709063595393, "os": 0.2710501976235572}, {"x": 0.0, "y": 0.7196506550218342, "ox": 0.0, "oy": 0.7196506550218342, "term": "Pivots V Lookups", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8432648973460191, "os": 0.2648350479341905}, {"x": 0.0, "y": 0.6593886462882098, "ox": 0.0, "oy": 0.6593886462882098, "term": "technical well technical senior stakeholders", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8097145718577866, "os": 0.23182425809282667}, {"x": 0.0, "y": 0.7816593886462884, "ox": 0.0, "oy": 0.7816593886462884, "term": "large databases", "cat25k": 18, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8763144717075613, "os": 0.3292278571430509}, {"x": 0.0, "y": 0.6174672489082971, "ox": 0.0, "oy": 0.6174672489082971, "term": "predictive statistical modeling", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7866800200300451, "os": 0.2150173326161014}, {"x": 0.0, "y": 0.5248908296943232, "ox": 0.0, "oy": 0.5248908296943232, "term": "Spanish", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7356034051076614, "os": 0.18204321530414366}, {"x": 0.0, "y": 0.5213973799126638, "ox": 0.0, "oy": 0.5213973799126638, "term": "Bilingual", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7341011517275913, "os": 0.18085503858976576}, {"x": 0.059907834101382486, "y": 0.48733624454148483, "ox": 0.059907834101382486, "oy": 0.48733624454148483, "term": "deliverables", "cat25k": 10, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7150726089133701, "os": 0.1734361978079993}, {"x": 0.0, "y": 0.6375545851528385, "ox": 0.0, "oy": 0.6375545851528385, "term": "Excellent time management skills ability", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7981972959439158, "os": 0.2225194446940415}, {"x": 0.0, "y": 0.6253275109170308, "ox": 0.0, "oy": 0.6253275109170308, "term": "data elements sources relationships business technical terms", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7911867801702553, "os": 0.21863443790786735}, {"x": 0.0, "y": 0.6209606986899565, "ox": 0.0, "oy": 0.6209606986899565, "term": "big data technologies Hadoop Spark Familiarity Python R data visualization tools", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7886830245368052, "os": 0.21708410129581654}, {"x": 0.0, "y": 0.6165938864628823, "ox": 0.0, "oy": 0.6165938864628823, "term": "full stack data analysis insight synthesis presentation Ability", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.786179268903355, "os": 0.21489958920088695}, {"x": 0.0, "y": 0.577292576419214, "ox": 0.0, "oy": 0.577292576419214, "term": "complex analysis technical concepts", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7636454682023034, "os": 0.1966167318346962}, {"x": 0.0, "y": 0.5510917030567686, "ox": 0.0, "oy": 0.5510917030567686, "term": "years recent experience data science data analyst role", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7496244366549825, "os": 0.188782143727996}, {"x": 0.0, "y": 0.5310043668122272, "ox": 0.0, "oy": 0.5310043668122272, "term": "Hadoop Spark Familiarity Python", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7391086629944917, "os": 0.1831251078617335}, {"x": 0.0, "y": 0.5065502183406114, "ox": 0.0, "oy": 0.5065502183406114, "term": "Strong business mindset", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7255883825738607, "os": 0.177356669962397}, {"x": 0.0, "y": 0.5004366812227076, "ox": 0.0, "oy": 0.5004366812227076, "term": "Excellent presentation", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7220831246870305, "os": 0.17608313051159635}, {"x": 0.0, "y": 0.4436681222707424, "ox": 0.0, "oy": 0.4436681222707424, "term": "AB experiments", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6905358037055583, "os": 0.16488061017473005}, {"x": 0.5152073732718895, "y": 0.8061135371179041, "ox": 0.5152073732718895, "oy": 0.8061135371179041, "term": "Familiarity", "cat25k": 20, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8913370055082623, "os": 0.35943140753084835}, {"x": 0.5520737327188942, "y": 0.40436681222707427, "ox": 0.5520737327188942, "oy": 0.40436681222707427, "term": "Comfortable", "cat25k": 9, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23435152729093645, "os": -0.17308695128576462}, {"x": 0.0, "y": 0.9563318777292577, "ox": 0.0, "oy": 0.9563318777292577, "term": "United States Preferred", "cat25k": 96, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9754631947921882, "os": 1.7320508075688765}, {"x": 0.0, "y": 0.7825327510917032, "ox": 0.0, "oy": 0.7825327510917032, "term": "advanced optimization methodologies", "cat25k": 18, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8768152228342514, "os": 0.3303878224589271}, {"x": 0.0, "y": 0.8672489082969433, "ox": 0.0, "oy": 0.8672489082969433, "term": "advanced quantitative analyses", "cat25k": 31, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9258888332498748, "os": 0.5600846041785961}, {"x": 0.0, "y": 0.5886462882096071, "ox": 0.0, "oy": 0.5886462882096071, "term": "analysis Ability", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7701552328492739, "os": 0.20121468257981187}, {"x": 0.0, "y": 0.5807860262008735, "ox": 0.0, "oy": 0.5807860262008735, "term": "advanced statistical methodologies mixed model random fixed effects", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7656484727090636, "os": 0.1969608211532567}, {"x": 0.0, "y": 0.537991266375546, "ox": 0.0, "oy": 0.537991266375546, "term": "actual working experience", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7426139208813219, "os": 0.18444920650331187}, {"x": 0.0, "y": 0.7502183406113538, "ox": 0.0, "oy": 0.7502183406113538, "term": "mixed integer optimization Ability", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.85878818227341, "os": 0.2999447975767826}, {"x": 0.0, "y": 0.7659388646288211, "ox": 0.0, "oy": 0.7659388646288211, "term": "analysis variance correlation techniques", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8678017025538307, "os": 0.31228911894431177}, {"x": 0.0, "y": 0.531877729257642, "ox": 0.0, "oy": 0.531877729257642, "term": "ARIMA neural networks multinomial discrete choice Ability", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7396094141211818, "os": 0.1831322984929287}, {"x": 0.0, "y": 0.6794759825327512, "ox": 0.0, "oy": 0.6794759825327512, "term": "Demonstrated experience", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8212318477716575, "os": 0.24124406796286169}, {"x": 0.0, "y": 0.44541484716157215, "ox": 0.0, "oy": 0.44541484716157215, "term": "features software packages", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6915373059589384, "os": 0.165727696478513}, {"x": 0.0, "y": 0.45240174672489086, "ox": 0.0, "oy": 0.45240174672489086, "term": "Utilize complex computer operations", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6950425638457687, "os": 0.1676742594162039}, {"x": 0.0, "y": 0.7213973799126638, "ox": 0.0, "oy": 0.7213973799126638, "term": "mathematical operations tasks cluster analytics", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8437656484727091, "os": 0.2655947406382041}, {"x": 0.0, "y": 0.6637554585152841, "ox": 0.0, "oy": 0.6637554585152841, "term": "theory design experiments", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8127190786179269, "os": 0.23432854671860254}, {"x": 0.5281105990783411, "y": 0.41659388646288215, "ox": 0.5281105990783411, "oy": 0.41659388646288215, "term": "methodologies", "cat25k": 9, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.24636955433149726, "os": -0.1649876786131199}, {"x": 0.0, "y": 0.7048034934497818, "ox": 0.0, "oy": 0.7048034934497818, "term": "Working knowledge", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8347521281922884, "os": 0.25660790568175823}, {"x": 0.0, "y": 0.7694323144104804, "ox": 0.0, "oy": 0.7694323144104804, "term": "A strong passion empirical research", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8693039559339009, "os": 0.3138529369863909}, {"x": 0.0, "y": 0.4532751091703058, "ox": 0.0, "oy": 0.4532751091703058, "term": "3rd", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6955433149724587, "os": 0.1676839743045077}, {"x": 0.46912442396313375, "y": 0.5030567685589521, "ox": 0.46912442396313375, "oy": 0.5030567685589521, "term": "Map Reduce", "cat25k": 10, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7235853780671007, "os": 0.1763686486006602}, {"x": 0.0, "y": 0.6131004366812228, "ox": 0.0, "oy": 0.6131004366812228, "term": "Advanced data modeling experience", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7841762643965949, "os": 0.21330672221640948}, {"x": 0.0, "y": 0.5170305676855895, "ox": 0.0, "oy": 0.5170305676855895, "term": "working data", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7315973960941411, "os": 0.17990361275506978}, {"x": 0.0, "y": 0.45764192139738, "ox": 0.0, "oy": 0.45764192139738, "term": "trends", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6980470706059089, "os": 0.16847782215939472}, {"x": 0.9824884792626729, "y": 0.9292576419213975, "ox": 0.9824884792626729, "oy": 0.9292576419213975, "term": "ETL", "cat25k": 63, "ncat25k": 225, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 3, "s": 0.009514271407110668, "os": -3.1714668212535537}, {"x": 0.0, "y": 0.6908296943231442, "ox": 0.0, "oy": 0.6908296943231442, "term": "Artificial Neural Nets", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8267401101652478, "os": 0.24809917059436207}, {"x": 0.0, "y": 0.9004366812227075, "ox": 0.0, "oy": 0.9004366812227075, "term": "models", "cat25k": 46, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9439158738107161, "os": 0.8230117353504997}, {"x": 0.09769585253456223, "y": 0.049781659388646295, "ox": 0.09769585253456223, "oy": 0.049781659388646295, "term": "code", "cat25k": 4, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4641962944416625, "os": -0.08168975460823717}, {"x": 0.0, "y": 0.9423580786026202, "ox": 0.0, "oy": 0.9423580786026202, "term": "Breadth skills experience machine", "cat25k": 77, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9674511767651477, "os": 1.3846575364970706}, {"x": 0.0, "y": 0.9362445414847161, "ox": 0.0, "oy": 0.9362445414847161, "term": "business process outsourcing systems transportation systems healthcare systems financial services", "cat25k": 69, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9639459188783175, "os": 1.2385179899429064}, {"x": 0.0, "y": 0.9353711790393014, "ox": 0.0, "oy": 0.9353711790393014, "term": "novel solutions problems", "cat25k": 67, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9634451677516275, "os": 1.202364378351742}, {"x": 0.0, "y": 0.9336244541484717, "ox": 0.0, "oy": 0.9336244541484717, "term": "real world context Prior experience similar role", "cat25k": 67, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9624436654982473, "os": 1.198024415523773}, {"x": 0.0, "y": 0.9310043668122272, "ox": 0.0, "oy": 0.9310043668122272, "term": "practice Experience knowledge services", "cat25k": 64, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9609414121181773, "os": 1.1462928293789125}, {"x": 0.0, "y": 0.9283842794759826, "ox": 0.0, "oy": 0.9283842794759826, "term": "feasibility solutions", "cat25k": 62, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9599399098647972, "os": 1.1091805817683775}, {"x": 0.0, "y": 0.925764192139738, "ox": 0.0, "oy": 0.925764192139738, "term": "analytics models", "cat25k": 61, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9584376564847271, "os": 1.0912349680037976}, {"x": 0.0, "y": 0.9240174672489083, "ox": 0.0, "oy": 0.9240174672489083, "term": "Desired interdisciplinary skills", "cat25k": 59, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.957436154231347, "os": 1.0670328241963016}, {"x": 0.0, "y": 0.9196506550218341, "ox": 0.0, "oy": 0.9196506550218341, "term": "big data technologies ETL statistics causal inference", "cat25k": 58, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 1, "ncat": 0, "s": 0.9549323985978969, "os": 1.042968745861235}, {"x": 0.0, "y": 0.9161572052401749, "ox": 0.0, "oy": 0.9161572052401749, "term": "analytics packages", "cat25k": 55, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9529293940911366, "os": 0.9911531170335189}, {"x": 0.0, "y": 0.9144104803493449, "ox": 0.0, "oy": 0.9144104803493449, "term": "diverse learning settings", "cat25k": 55, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9519278918377566, "os": 0.9793245937767227}, {"x": 0.0, "y": 0.9126637554585153, "ox": 0.0, "oy": 0.9126637554585153, "term": "multi disciplinary environments", "cat25k": 54, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9509263895843766, "os": 0.9622654594904677}, {"x": 0.0, "y": 0.9100436681222707, "ox": 0.0, "oy": 0.9100436681222707, "term": "data mining statistical predictive", "cat25k": 52, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9494241362043064, "os": 0.9403192128738992}, {"x": 0.0, "y": 0.9056768558951965, "ox": 0.0, "oy": 0.9056768558951965, "term": "work US employer", "cat25k": 50, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9469203805708563, "os": 0.9036447973217027}, {"x": 0.0, "y": 0.9039301310043668, "ox": 0.0, "oy": 0.9039301310043668, "term": "Ability inclination", "cat25k": 48, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9459188783174762, "os": 0.8574888241403219}, {"x": 0.0, "y": 0.9030567685589521, "ox": 0.0, "oy": 0.9030567685589521, "term": "different types", "cat25k": 47, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9454181271907861, "os": 0.849321118534437}, {"x": 0.0, "y": 0.8986899563318779, "ox": 0.0, "oy": 0.8986899563318779, "term": "sponsorship", "cat25k": 45, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9429143715573359, "os": 0.80577168277073}, {"x": 0.0, "y": 0.8847161572052402, "ox": 0.0, "oy": 0.8847161572052402, "term": "history driving", "cat25k": 38, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9354031046569854, "os": 0.6839569945963613}, {"x": 0.9198156682027652, "y": 0.8882096069868995, "ox": 0.9198156682027652, "oy": 0.8882096069868995, "term": "related field", "cat25k": 39, "ncat25k": 40, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9374061091637457, "os": 0.7001232251027899}, {"x": 0.0, "y": 0.8716157205240176, "ox": 0.0, "oy": 0.8716157205240176, "term": "Breadth", "cat25k": 33, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9278918377566349, "os": 0.5907263157594091}, {"x": 0.0, "y": 0.8707423580786028, "ox": 0.0, "oy": 0.8707423580786028, "term": "simulation", "cat25k": 33, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.927391086629945, "os": 0.5901936447780719}, {"x": 0.0, "y": 0.8786026200873364, "ox": 0.0, "oy": 0.8786026200873364, "term": "methods", "cat25k": 35, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9318978467701552, "os": 0.6243015891981487}, {"x": 0.0, "y": 0.8864628820960699, "ox": 0.0, "oy": 0.8864628820960699, "term": "experiments", "cat25k": 39, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9364046069103656, "os": 0.6949129533143533}, {"x": 0.7981566820276499, "y": 0.8384279475982535, "ox": 0.7981566820276499, "oy": 0.8384279475982535, "term": "ideas", "cat25k": 24, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9083625438157236, "os": 0.4249759723106531}, {"x": 0.43041474654377887, "y": 0.6986899563318779, "ox": 0.43041474654377887, "oy": 0.6986899563318779, "term": "desire", "cat25k": 14, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8312468703054582, "os": 0.2532967383343124}, {"x": 0.0, "y": 0.49956331877729265, "ox": 0.0, "oy": 0.49956331877729265, "term": "programming languages", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7215823735603405, "os": 0.17603532417146095}, {"x": 0.8608294930875577, "y": 0.0777292576419214, "ox": 0.8608294930875577, "oy": 0.0777292576419214, "term": "multiple data sources", "cat25k": 5, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07260891337005508, "os": -0.39093127217386187}, {"x": 0.7658986175115209, "y": 0.05240174672489084, "ox": 0.7658986175115209, "oy": 0.05240174672489084, "term": "metadata", "cat25k": 4, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12468703054581874, "os": -0.2730281987780275}, {"x": 0.0, "y": 0.812227074235808, "ox": 0.0, "oy": 0.812227074235808, "term": "explain point", "cat25k": 21, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8943415122684026, "os": 0.3711047733623777}, {"x": 0.0, "y": 0.5851528384279476, "ox": 0.0, "oy": 0.5851528384279476, "term": "story", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7681522283425137, "os": 0.19959129852727492}, {"x": 0.0, "y": 0.5179039301310046, "ox": 0.0, "oy": 0.5179039301310046, "term": "Visualization", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7320981472208312, "os": 0.1802830599222913}, {"x": 0.0, "y": 0.42532751091703064, "ox": 0.0, "oy": 0.42532751091703064, "term": "minimal guidance Ability work business system owners", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6805207811717576, "os": 0.16101632029826296}, {"x": 0.0, "y": 0.8724890829694325, "ox": 0.0, "oy": 0.8724890829694325, "term": "SQL experience", "cat25k": 33, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.928392588883325, "os": 0.5984161245822278}, {"x": 0.0, "y": 0.6733624454148474, "ox": 0.0, "oy": 0.6733624454148474, "term": "Business Objects", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8182273410115173, "os": 0.23876415377618487}, {"x": 0.975115207373272, "y": 0.7676855895196508, "ox": 0.975115207373272, "oy": 0.7676855895196508, "term": "Big Data", "cat25k": 17, "ncat25k": 110, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 1, "s": 0.012518778167250876, "os": -1.5551507606523156}, {"x": 0.0, "y": 0.8401746724890832, "ox": 0.0, "oy": 0.8401746724890832, "term": "United States", "cat25k": 24, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9093640460691036, "os": 0.42617974632705374}, {"x": 0.028571428571428577, "y": 0.03231441048034935, "ox": 0.028571428571428577, "oy": 0.03231441048034935, "term": "Interested candidates", "cat25k": 3, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.49273910866299453, "os": -0.05314737498477737}, {"x": 0.0, "y": 0.8165938864628822, "ox": 0.0, "oy": 0.8165938864628822, "term": "small teams projects", "cat25k": 21, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8963445167751627, "os": 0.382201141444222}, {"x": 0.0, "y": 0.846288209606987, "ox": 0.0, "oy": 0.846288209606987, "term": "complex business problems", "cat25k": 25, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9153730595893841, "os": 0.4572874205383283}, {"x": 0.0, "y": 0.343231441048035, "ox": 0.0, "oy": 0.343231441048035, "term": "business results", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6349524286429644, "os": 0.14524135582711045}, {"x": 0.0, "y": 0.6550218340611356, "ox": 0.0, "oy": 0.6550218340611356, "term": "technology roadmaps realization", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8072108162243364, "os": 0.23058835484111678}, {"x": 0.0, "y": 0.7187772925764193, "ox": 0.0, "oy": 0.7187772925764193, "term": "existing problems", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8427641462193289, "os": 0.26411824035979387}, {"x": 0.0, "y": 0.6742358078602622, "ox": 0.0, "oy": 0.6742358078602622, "term": "new solution methods", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8187280921382073, "os": 0.23885444936823336}, {"x": 0.0, "y": 0.703930131004367, "ox": 0.0, "oy": 0.703930131004367, "term": "working knowledge", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8342513770655984, "os": 0.25571254843580093}, {"x": 0.0, "y": 0.6995633187772927, "ox": 0.0, "oy": 0.6995633187772927, "term": "External Technology Knowledge Keeps", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8317476214321482, "os": 0.2537088740950245}, {"x": 0.0, "y": 0.5746724890829695, "ox": 0.0, "oy": 0.5746724890829695, "term": "latest technological developments areas", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7621432148222334, "os": 0.19548268065251503}, {"x": 0.09216589861751152, "y": 0.013973799126637557, "ox": 0.09216589861751152, "oy": 0.013973799126637557, "term": "Analytics", "cat25k": 2, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.46720080120180274, "os": -0.08087672783151911}, {"x": 0.03870967741935485, "y": 0.012227074235807862, "ox": 0.03870967741935485, "oy": 0.012227074235807862, "term": "operations", "cat25k": 2, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.48973460190285434, "os": -0.06039266750453707}, {"x": 0.670967741935484, "y": 0.8393013100436683, "ox": 0.670967741935484, "oy": 0.8393013100436683, "term": "opportunities", "cat25k": 24, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9088632949424136, "os": 0.4254509991877842}, {"x": 0.37972350230414753, "y": 0.11877729257641922, "ox": 0.37972350230414753, "oy": 0.11877729257641922, "term": "things", "cat25k": 6, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.32148222333500254, "os": -0.1272402573183658}, {"x": 0.0, "y": 0.7353711790393014, "ox": 0.0, "oy": 0.7353711790393014, "term": "sports games", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8512769153730595, "os": 0.2801458834578816}, {"x": 0.0, "y": 0.6069868995633189, "ox": 0.0, "oy": 0.6069868995633189, "term": "analysis impact", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7806710065097646, "os": 0.20889090746574374}, {"x": 0.0, "y": 0.6331877729257642, "ox": 0.0, "oy": 0.6331877729257642, "term": "key business product decisions", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7956935403104656, "os": 0.2213647842712885}, {"x": 0.0, "y": 0.7344978165938866, "ox": 0.0, "oy": 0.7344978165938866, "term": "SQL Hive", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8507761642463696, "os": 0.27969761733699294}, {"x": 0.0, "y": 0.6698689956331879, "ox": 0.0, "oy": 0.6698689956331879, "term": "e g filtering morphology", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8162243365047571, "os": 0.23799157941279617}, {"x": 0.0, "y": 0.525764192139738, "ox": 0.0, "oy": 0.525764192139738, "term": "compression", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7361041562343515, "os": 0.1821150341259923}, {"x": 0.0, "y": 0.48034934497816606, "ox": 0.0, "oy": 0.48034934497816606, "term": "Background image processing concepts", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7110665998998498, "os": 0.1718771991253443}, {"x": 0.0, "y": 0.8270742358078604, "ox": 0.0, "oy": 0.8270742358078604, "term": "ping pong tournaments", "cat25k": 22, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9023535302954432, "os": 0.4030933718572922}, {"x": 0.0, "y": 0.7650655021834062, "ox": 0.0, "oy": 0.7650655021834062, "term": "statistical predictive modeling concepts machine learning approaches", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8673009514271407, "os": 0.31222461063070506}, {"x": 0.0, "y": 0.46375545851528394, "ox": 0.0, "oy": 0.46375545851528394, "term": "classification techniques recommendation optimization algorithms", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7015523284927391, "os": 0.1694884673129617}, {"x": 0.5576036866359448, "y": 0.6873362445414848, "ox": 0.5576036866359448, "oy": 0.6873362445414848, "term": "big data technologies", "cat25k": 14, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8247371056584877, "os": 0.24552609358553917}, {"x": 0.0, "y": 0.40349344978165946, "ox": 0.0, "oy": 0.40349344978165946, "term": "machine learning", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6690035052578868, "os": 0.15684298755835313}, {"x": 0.3705069124423964, "y": 0.031441048034934506, "ox": 0.3705069124423964, "oy": 0.031441048034934506, "term": "Continuous", "cat25k": 3, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3264897346019029, "os": -0.12496734253931306}, {"x": 0.2036866359447005, "y": 0.08733624454148473, "ox": 0.2036866359447005, "oy": 0.08733624454148473, "term": "functional teams", "cat25k": 5, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.40911367050575864, "os": -0.09994589589507448}, {"x": 0.05253456221198157, "y": 0.4052401746724892, "ox": 0.05253456221198157, "oy": 0.4052401746724892, "term": "Java C", "cat25k": 9, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6695042563845769, "os": 0.157550138123694}, {"x": 0.0, "y": 0.4672489082969433, "ox": 0.0, "oy": 0.4672489082969433, "term": "statistical models", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7035553329994992, "os": 0.1698047633480447}, {"x": 0.11059907834101385, "y": 0.47510917030567695, "ox": 0.11059907834101385, "oy": 0.47510917030567695, "term": "analysis", "cat25k": 10, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7080620931397095, "os": 0.1711676315795814}, {"x": 0.0, "y": 0.4113537117903931, "ox": 0.0, "oy": 0.4113537117903931, "term": "new business development proof concepts", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6730095142714071, "os": 0.15916193308254664}, {"x": 0.0, "y": 0.5685589519650656, "ox": 0.0, "oy": 0.5685589519650656, "term": "Computer Science Computer Science Engineering Engineering Computer Science Math Computer Science Mathematical", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7591387080620932, "os": 0.19371568470831754}, {"x": 0.0, "y": 0.5572052401746727, "ox": 0.0, "oy": 0.5572052401746727, "term": "Computer Science Computer Science Engineering Engineering Computer Science Math Computer Science Mathematical Engineering Mathematical Science Mathematics Statistics Strong data wrangling skills", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7526289434151227, "os": 0.18997352186447317}, {"x": 0.0, "y": 0.5266375545851529, "ox": 0.0, "oy": 0.5266375545851529, "term": "Ability manipulate JSON XML data Experience Splunk Experience data manipulation platforms", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7366049073610416, "os": 0.18224101440100224}, {"x": 0.0, "y": 0.4585152838427949, "ox": 0.0, "oy": 0.4585152838427949, "term": "Experience Ansible Puppet Jenkins Chef", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6985478217325989, "os": 0.16854997246525094}, {"x": 0.08847926267281107, "y": 0.47336244541484723, "ox": 0.08847926267281107, "oy": 0.47336244541484723, "term": "multiple projects", "cat25k": 10, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7070605908863294, "os": 0.17101476554965853}, {"x": 0.6506912442396315, "y": 0.5231441048034936, "ox": 0.6506912442396315, "oy": 0.5231441048034936, "term": "Excellent problem", "cat25k": 10, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.185277916875313, "os": -0.2158739428726292}, {"x": 0.894930875576037, "y": 0.8602620087336246, "ox": 0.894930875576037, "oy": 0.8602620087336246, "term": "Java", "cat25k": 30, "ncat25k": 34, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9223835753630446, "os": 0.5392980792269324}, {"x": 0.0, "y": 0.6227074235807861, "ox": 0.0, "oy": 0.6227074235807861, "term": "Cigna Healthcare MetLife Dental VSP Vision", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7896845267901852, "os": 0.21759717001701961}, {"x": 0.0, "y": 0.48296943231441064, "ox": 0.0, "oy": 0.48296943231441064, "term": "advanced data analysis", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7125688532799199, "os": 0.17242807835868135}, {"x": 0.8875576036866362, "y": 0.7004366812227075, "ox": 0.8875576036866362, "oy": 0.7004366812227075, "term": "world", "cat25k": 14, "ncat25k": 32, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.05558337506259389, "os": -0.4566965533919846}, {"x": 0.0, "y": 0.5973799126637556, "ox": 0.0, "oy": 0.5973799126637556, "term": "data things", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7751627441161743, "os": 0.20358404371393707}, {"x": 0.0, "y": 0.5082969432314411, "ox": 0.0, "oy": 0.5082969432314411, "term": "connections", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7265898848272407, "os": 0.17743725822400744}, {"x": 0.0, "y": 0.49432314410480355, "ox": 0.0, "oy": 0.49432314410480355, "term": "Reduce Experience working Hadoop Map", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7185778668002003, "os": 0.17527611366746398}, {"x": 0.0, "y": 0.3676855895196507, "ox": 0.0, "oy": 0.3676855895196507, "term": "Substantial data analysis experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6489734601902853, "os": 0.1498168405434012}, {"x": 0.0, "y": 0.5152838427947599, "ox": 0.0, "oy": 0.5152838427947599, "term": "complex problems", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7305958938407611, "os": 0.17954860911711118}, {"x": 0.9714285714285715, "y": 0.08209606986899563, "ox": 0.9714285714285715, "oy": 0.08209606986899563, "term": "new technologies", "cat25k": 5, "ncat25k": 82, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 1, "s": 0.014021031547320982, "os": -1.1551924753088647}, {"x": 0.0, "y": 0.7082969432314412, "ox": 0.0, "oy": 0.7082969432314412, "term": "major impact business", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8367551326990486, "os": 0.2573558505963801}, {"x": 0.0, "y": 0.5537117903930132, "ox": 0.0, "oy": 0.5537117903930132, "term": "prowess data scientist right", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7506259389083625, "os": 0.18958522098980135}, {"x": 0.0, "y": 0.5222707423580787, "ox": 0.0, "oy": 0.5222707423580787, "term": "Proficiency scripting language Python R MATLAB Proficiency", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7346019028542814, "os": 0.1811409788922317}, {"x": 0.0, "y": 0.7414847161572055, "ox": 0.0, "oy": 0.7414847161572055, "term": "written oral diagram form", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8542814221331998, "os": 0.29013041626376423}, {"x": 0.0, "y": 0.5441048034934499, "ox": 0.0, "oy": 0.5441048034934499, "term": "carry instructions", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7461191787681523, "os": 0.18646369080383335}, {"x": 0.0, "y": 0.6262008733624456, "ox": 0.0, "oy": 0.6262008733624456, "term": "Strong experience", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7916875312969455, "os": 0.21875943292320527}, {"x": 0.9041474654377881, "y": 0.8524017467248909, "ox": 0.9041474654377881, "oy": 0.8524017467248909, "term": "Computer Science", "cat25k": 27, "ncat25k": 36, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.047571357035553326, "os": -0.5072989580336735}, {"x": 0.0, "y": 0.8000000000000002, "ox": 0.0, "oy": 0.8000000000000002, "term": "software C C", "cat25k": 20, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8878317476214321, "os": 0.35168502515839295}, {"x": 0.0, "y": 0.8183406113537119, "ox": 0.0, "oy": 0.8183406113537119, "term": "large scale data management big data technologies Skilled aspects software project life cycle feasibility requirements", "cat25k": 21, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8973460190285428, "os": 0.38510344552601217}, {"x": 0.0, "y": 0.5650655021834062, "ox": 0.0, "oy": 0.5650655021834062, "term": "important project success Sufficient interpersonal skills necessary interact levels personnel", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.757135703555333, "os": 0.1932003800542198}, {"x": 0.0, "y": 0.8768558951965066, "ox": 0.0, "oy": 0.8768558951965066, "term": "scientific data analysis statistical analysis knowledge discovery computer security systems", "cat25k": 34, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9308963445167752, "os": 0.6063964723138271}, {"x": 0.0, "y": 0.8340611353711792, "ox": 0.0, "oy": 0.8340611353711792, "term": "Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules", "cat25k": 23, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9058587881822734, "os": 0.41619289489374733}, {"x": 0.0, "y": 0.8052401746724892, "ox": 0.0, "oy": 0.8052401746724892, "term": "algorithms data management", "cat25k": 20, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8908362543815723, "os": 0.358744629204269}, {"x": 0.0, "y": 0.5100436681222709, "ox": 0.0, "oy": 0.5100436681222709, "term": "design implementation integration test deployment Fundamental experience", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.727591387080621, "os": 0.17810054056696778}, {"x": 0.0, "y": 0.7685589519650656, "ox": 0.0, "oy": 0.7685589519650656, "term": "necessary work", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8688032048072107, "os": 0.3137532147391555}, {"x": 0.5889400921658987, "y": 0.7991266375545852, "ox": 0.5889400921658987, "oy": 0.7991266375545852, "term": "data analysis", "cat25k": 20, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8873309964947421, "os": 0.3514763706873279}, {"x": 0.0, "y": 0.38689956331877734, "ox": 0.0, "oy": 0.38689956331877734, "term": "Fundamental knowledge", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6594892338507762, "os": 0.15382050455574245}, {"x": 0.0, "y": 0.7895196506550219, "ox": 0.0, "oy": 0.7895196506550219, "term": "project", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8808212318477717, "os": 0.3378626810046601}, {"x": 0.0, "y": 0.760698689956332, "ox": 0.0, "oy": 0.760698689956332, "term": "Bachelor degree computer science computer engineering related field equivalent combination education related experience", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8642964446670005, "os": 0.3079360110900313}, {"x": 0.0, "y": 0.7301310043668123, "ox": 0.0, "oy": 0.7301310043668123, "term": "Linux UNIX Windows environments", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8482724086129194, "os": 0.27324522457132017}, {"x": 0.0, "y": 0.7065502183406115, "ox": 0.0, "oy": 0.7065502183406115, "term": "enthusiasm creativity change", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8357536304456685, "os": 0.2571102527945879}, {"x": 0.0, "y": 0.7851528384279478, "ox": 0.0, "oy": 0.7851528384279478, "term": "concurrent technical tasks", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8783174762143215, "os": 0.33387353452793156}, {"x": 0.0, "y": 0.6951965065502185, "ox": 0.0, "oy": 0.6951965065502185, "term": "research concepts", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.829243865798698, "os": 0.2513226957100437}, {"x": 0.0, "y": 0.6602620087336246, "ox": 0.0, "oy": 0.6602620087336246, "term": "conflicting priorities", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8102153229844767, "os": 0.23213918117544224}, {"x": 0.0, "y": 0.7720524017467251, "ox": 0.0, "oy": 0.7720524017467251, "term": "difficult problems", "cat25k": 18, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.870806209313971, "os": 0.3184457213275467}, {"x": 0.0, "y": 0.65764192139738, "ox": 0.0, "oy": 0.65764192139738, "term": "Java Python R Matlab software applications", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8087130696044066, "os": 0.23165683476732327}, {"x": 0.0, "y": 0.6358078602620089, "ox": 0.0, "oy": 0.6358078602620089, "term": "Linux UNIX Windows", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7971957936905357, "os": 0.22209238941750847}, {"x": 0.0, "y": 0.6899563318777294, "ox": 0.0, "oy": 0.6899563318777294, "term": "high performance", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8262393590385578, "os": 0.2480480085750269}, {"x": 0.0, "y": 0.3842794759825328, "ox": 0.0, "oy": 0.3842794759825328, "term": "Skilled", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.657986980470706, "os": 0.15326550160625557}, {"x": 0.0, "y": 0.36244541484716164, "ox": 0.0, "oy": 0.36244541484716164, "term": "Java Python R Matlab", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6459689534301453, "os": 0.14855859634005747}, {"x": 0.0, "y": 0.7292576419213975, "ox": 0.0, "oy": 0.7292576419213975, "term": "share knowledge others", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8477716574862293, "os": 0.2717541906348583}, {"x": 0.002764976958525346, "y": 0.7004366812227075, "ox": 0.002764976958525346, "oy": 0.7004366812227075, "term": "organization", "cat25k": 14, "ncat25k": 2, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8322483725588382, "os": 0.25409456980845746}, {"x": 0.0, "y": 0.3572052401746726, "ox": 0.0, "oy": 0.3572052401746726, "term": "skill", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.642964446670005, "os": 0.14729004418874336}, {"x": 0.0, "y": 0.34061135371179047, "ox": 0.0, "oy": 0.34061135371179047, "term": "Access opportunities", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6334501752628944, "os": 0.14433557441502345}, {"x": 0.0, "y": 0.6567685589519652, "ox": 0.0, "oy": 0.6567685589519652, "term": "volunteer time fuel efficient vehicle purchase assistance transit fare contribution", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8082123184777166, "os": 0.23126702768235938}, {"x": 0.011981566820276499, "y": 0.5117903930131005, "ox": 0.011981566820276499, "oy": 0.5117903930131005, "term": "first", "cat25k": 10, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.728592889334001, "os": 0.17838295569244716}, {"x": 0.8682027649769587, "y": 0.8279475982532752, "ox": 0.8682027649769587, "oy": 0.8279475982532752, "term": "video call", "cat25k": 23, "ncat25k": 29, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06609914872308463, "os": -0.4067069769086525}, {"x": 0.8322580645161292, "y": 0.7965065502183407, "ox": 0.8322580645161292, "oy": 0.7965065502183407, "term": "call", "cat25k": 19, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09013520280420631, "os": -0.348624126893826}, {"x": 0.004608294930875577, "y": 0.005240174672489084, "ox": 0.004608294930875577, "oy": 0.005240174672489084, "term": "As always interviews", "cat25k": 2, "ncat25k": 2, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4977466199298949, "os": -0.029047375096555625}, {"x": 0.0, "y": 0.85764192139738, "ox": 0.0, "oy": 0.85764192139738, "term": "Matplotlib", "cat25k": 29, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9213820731096645, "os": 0.5134080078003356}, {"x": 0.0, "y": 0.5449781659388647, "ox": 0.0, "oy": 0.5449781659388647, "term": "Plotly ggplot", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7466199298948423, "os": 0.1870828201468148}, {"x": 0.0, "y": 0.43580786026200885, "ox": 0.0, "oy": 0.43580786026200885, "term": "An eye great data visualization", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.686029043565348, "os": 0.16291858516929755}, {"x": 0.0, "y": 0.6497816593886464, "ox": 0.0, "oy": 0.6497816593886464, "term": "complex data analysis", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8052078117175764, "os": 0.22835912340152115}, {"x": 0.0, "y": 0.6218340611353713, "ox": 0.0, "oy": 0.6218340611353713, "term": "qualitative quantitative clear compelling manner", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7891837756634953, "os": 0.2171619018394695}, {"x": 0.0, "y": 0.6200873362445416, "ox": 0.0, "oy": 0.6200873362445416, "term": "action Strong understanding statistical analysis", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7881822734101152, "os": 0.21643790980133054}, {"x": 0.0, "y": 0.5633187772925765, "ox": 0.0, "oy": 0.5633187772925765, "term": "Quick learner ability", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.756134201301953, "os": 0.19277231898292496}, {"x": 0.0, "y": 0.8323144104803495, "ox": 0.0, "oy": 0.8323144104803495, "term": "large data", "cat25k": 23, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9048572859288934, "os": 0.4136454740210248}, {"x": 0.0, "y": 0.5484716157205242, "ox": 0.0, "oy": 0.5484716157205242, "term": "production level code Proficiency", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7481221832749123, "os": 0.18811209030968049}, {"x": 0.0, "y": 0.5021834061135372, "ox": 0.0, "oy": 0.5021834061135372, "term": "academic institution Expert Python SQL", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7230846269404105, "os": 0.17617247207752498}, {"x": 0.0, "y": 0.4882096069868997, "ox": 0.0, "oy": 0.4882096069868997, "term": "minimal guidance Ability", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.71557336004006, "os": 0.17389307846002208}, {"x": 0.0, "y": 0.71528384279476, "ox": 0.0, "oy": 0.71528384279476, "term": "varying levels", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8407611417125689, "os": 0.26096840162151014}, {"x": 0.0, "y": 0.68646288209607, "ox": 0.0, "oy": 0.68646288209607, "term": "quantitative discipline", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8242363545317977, "os": 0.24462654015966018}, {"x": 0.0, "y": 0.42707423580786036, "ox": 0.0, "oy": 0.42707423580786036, "term": "working Spark process", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6815222834251377, "os": 0.1611514579305829}, {"x": 0.0, "y": 0.4148471615720525, "ox": 0.0, "oy": 0.4148471615720525, "term": "Expert Python SQL", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6750125187781673, "os": 0.15950002968429922}, {"x": 0.0, "y": 0.6672489082969433, "ox": 0.0, "oy": 0.6672489082969433, "term": "Excellent communication skills", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.814722083124687, "os": 0.2345035424627199}, {"x": 0.0, "y": 0.3056768558951966, "ox": 0.0, "oy": 0.3056768558951966, "term": "dynamic fast paced environment Drive change", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.613920881321983, "os": 0.13942850569476645}, {"x": 0.0, "y": 0.2759825327510918, "ox": 0.0, "oy": 0.2759825327510918, "term": "initiate drive projects completion", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5968953430145219, "os": 0.13526004903496622}, {"x": 0.0, "y": 0.47161572052401757, "ox": 0.0, "oy": 0.47161572052401757, "term": "Drive", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7060590886329494, "os": 0.17018363958322136}, {"x": 0.0, "y": 0.20698689956331878, "ox": 0.0, "oy": 0.20698689956331878, "term": "comfort ambiguity", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.558337506259389, "os": 0.12422390341545678}, {"x": 0.0, "y": 0.3449781659388647, "ox": 0.0, "oy": 0.3449781659388647, "term": "A flexible analytic approach", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6359539308963446, "os": 0.1453486339658963}, {"x": 0.0, "y": 0.8262008733624455, "ox": 0.0, "oy": 0.8262008733624455, "term": "Interest politics educational policy", "cat25k": 22, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.901352028042063, "os": 0.4}, {"x": 0.0, "y": 0.2410480349344979, "ox": 0.0, "oy": 0.2410480349344979, "term": "industry experience Experience Python R Experience Tableau Ability model", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5773660490736103, "os": 0.12935208325229341}, {"x": 0.0, "y": 0.15982532751091708, "ox": 0.0, "oy": 0.15982532751091708, "term": "Ability ramp data science manager role", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5317976965448171, "os": 0.117906948009437}, {"x": 0.0, "y": 0.1441048034934498, "ox": 0.0, "oy": 0.1441048034934498, "term": "technical levels Ability", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5237856785177767, "os": 0.11587052112751704}, {"x": 0.0, "y": 0.6585152838427949, "ox": 0.0, "oy": 0.6585152838427949, "term": "Airflow Ability", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8092138207310967, "os": 0.2317018705387099}, {"x": 0.0, "y": 0.11441048034934498, "ox": 0.0, "oy": 0.11441048034934498, "term": "sound analytical modeling solutions Ability", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5097646469704556, "os": 0.11260797873986642}, {"x": 0.9760368663594471, "y": 0.48995633187772936, "ox": 0.9760368663594471, "oy": 0.48995633187772936, "term": "data pipelines", "cat25k": 10, "ncat25k": 131, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 1, "s": 0.012018027040560842, "os": -1.853670819832867}, {"x": 0.0, "y": 0.39388646288209617, "ox": 0.0, "oy": 0.39388646288209617, "term": "functional partners", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6634952428642965, "os": 0.15535124472148162}, {"x": 0.0, "y": 0.48209606986899567, "ox": 0.0, "oy": 0.48209606986899567, "term": "Proficiency SQL", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7120681021532298, "os": 0.17241160720630733}, {"x": 0.0, "y": 0.29344978165938873, "ox": 0.0, "oy": 0.29344978165938873, "term": "Java C C SQL relational database experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6069103655483225, "os": 0.13776441915106521}, {"x": 0.0, "y": 0.2532751091703057, "ox": 0.0, "oy": 0.2532751091703057, "term": "business plan Experience shelf", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.584376564847271, "os": 0.1302514304325648}, {"x": 0.0, "y": 0.23144104803493454, "ox": 0.0, "oy": 0.23144104803493454, "term": "algorithms Experience visualization tools", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.57235853780671, "os": 0.12799598577500484}, {"x": 0.16313364055299542, "y": 0.8620087336244543, "ox": 0.16313364055299542, "oy": 0.8620087336244543, "term": "relevant experience", "cat25k": 30, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9228843264897345, "os": 0.546289390441441}, {"x": 0.0, "y": 0.13362445414847163, "ox": 0.0, "oy": 0.13362445414847163, "term": "Java C C SQL", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5182774161241862, "os": 0.11504881704544911}, {"x": 0.01935483870967742, "y": 0.32576419213973806, "ox": 0.01935483870967742, "oy": 0.32576419213973806, "term": "complex concepts", "cat25k": 8, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6254381572358537, "os": 0.14311551219753627}, {"x": 0.0, "y": 0.7956331877729259, "ox": 0.0, "oy": 0.7956331877729259, "term": "Retail eCommerce company", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8843264897346019, "os": 0.3466800150008662}, {"x": 0.0, "y": 0.25502183406113543, "ox": 0.0, "oy": 0.25502183406113543, "term": "NoSQL SQL database experience Experience Google products", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.585378067100651, "os": 0.1307825858733537}, {"x": 0.0, "y": 0.18340611353711792, "ox": 0.0, "oy": 0.18340611353711792, "term": "code populate HDFS Hadoop log Kafka data", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5448172258387581, "os": 0.12140655465400152}, {"x": 0.0, "y": 0.1703056768558952, "ox": 0.0, "oy": 0.1703056768558952, "term": "Java Scala Python Hadoop stack HIVE Pig Hadoop streaming MapReduce HBase", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5378067100650976, "os": 0.11926508391791746}, {"x": 0.0, "y": 0.6349344978165941, "ox": 0.0, "oy": 0.6349344978165941, "term": "Big Data Systems", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7966950425638458, "os": 0.2217305520215076}, {"x": 0.8156682027649771, "y": 0.7947598253275111, "ox": 0.8156682027649771, "oy": 0.7947598253275111, "term": "years experience", "cat25k": 19, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8838257386079118, "os": 0.34636224740375565}, {"x": 0.008294930875576038, "y": 0.5362445414847162, "ox": 0.008294930875576038, "oy": 0.5362445414847162, "term": "Build", "cat25k": 10, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7416124186279419, "os": 0.18388158800633378}, {"x": 0.967741935483871, "y": 0.11528384279475984, "ox": 0.967741935483871, "oy": 0.11528384279475984, "term": "Kafka", "cat25k": 6, "ncat25k": 68, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.015523284927391088, "os": -0.9656400242997364}, {"x": 0.0, "y": 0.8908296943231441, "ox": 0.0, "oy": 0.8908296943231441, "term": "LAN", "cat25k": 40, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9389083625438157, "os": 0.7217127527814065}, {"x": 0.0, "y": 0.6366812227074237, "ox": 0.0, "oy": 0.6366812227074237, "term": "Parties", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7976965448172258, "os": 0.2222496308952425}, {"x": 0.0, "y": 0.33537117903930136, "ox": 0.0, "oy": 0.33537117903930136, "term": "first year", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6304456685027541, "os": 0.14386905704559028}, {"x": 0.3520737327188941, "y": 0.018340611353711792, "ox": 0.3520737327188941, "oy": 0.018340611353711792, "term": "one programming languages", "cat25k": 2, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.33500250375563345, "os": -0.12187692518328005}, {"x": 0.0, "y": 0.8131004366812228, "ox": 0.0, "oy": 0.8131004366812228, "term": "Designing data architecture table dashboard", "cat25k": 21, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8948422633950927, "os": 0.37267799624996495}, {"x": 0.0, "y": 0.37030567685589527, "ox": 0.0, "oy": 0.37030567685589527, "term": "physics related quantitative discipline preferred Experience Hive SQL", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6504757135703555, "os": 0.1501771589075385}, {"x": 0.0, "y": 0.2742358078602621, "ox": 0.0, "oy": 0.2742358078602621, "term": "statistics data mining machine", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5958938407611416, "os": 0.1351764255398765}, {"x": 0.0, "y": 0.594759825327511, "ox": 0.0, "oy": 0.594759825327511, "term": "classification techniques recommendation optimization", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7736604907361041, "os": 0.20280021965023476}, {"x": 0.0, "y": 0.19301310043668124, "ox": 0.0, "oy": 0.19301310043668124, "term": "Ph D Master Degree operations research", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5503254882323485, "os": 0.12281648835586104}, {"x": 0.33364055299539175, "y": 0.18689956331877733, "ox": 0.33364055299539175, "oy": 0.18689956331877733, "term": "Strong analytical problem", "cat25k": 7, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5468202303455183, "os": 0.12160080910373339}, {"x": 0.0, "y": 0.7248908296943233, "ox": 0.0, "oy": 0.7248908296943233, "term": "Collaborative team player values", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8457686529794692, "os": 0.2680718301601967}, {"x": 0.0, "y": 0.6157205240174674, "ox": 0.0, "oy": 0.6157205240174674, "term": "passionate Data Science", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.785678517776665, "os": 0.21488243997507409}, {"x": 0.6046082949308756, "y": 0.5930131004366813, "ox": 0.6046082949308756, "oy": 0.5930131004366813, "term": "Data Science", "cat25k": 11, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7726589884827241, "os": 0.20199313028321797}, {"x": 0.0, "y": 0.841048034934498, "ox": 0.0, "oy": 0.841048034934498, "term": "Dog friendly office", "cat25k": 24, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9098647971957937, "os": 0.43301270189221913}, {"x": 0.0, "y": 0.165938864628821, "ox": 0.0, "oy": 0.165938864628821, "term": "field Electrical Engineering Computer Science Data Science Statistics relevant fields", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5353029544316474, "os": 0.11892777452139912}, {"x": 0.0, "y": 0.15283842794759828, "ox": 0.0, "oy": 0.15283842794759828, "term": "Java C scripting language Experience database systems systems", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5282924386579869, "os": 0.1175332534776074}, {"x": 0.0, "y": 0.6663755458515285, "ox": 0.0, "oy": 0.6663755458515285, "term": "MS BS years", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.814221331997997, "os": 0.23450341253166868}, {"x": 0.0, "y": 0.15021834061135375, "ox": 0.0, "oy": 0.15021834061135375, "term": "aforementioned fields", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5267901852779168, "os": 0.11710249959289268}, {"x": 0.0, "y": 0.13973799126637557, "ox": 0.0, "oy": 0.13973799126637557, "term": "PhD aforementioned fields", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5212819228843265, "os": 0.11554743962868291}, {"x": 0.0, "y": 0.1344978165938865, "ox": 0.0, "oy": 0.1344978165938865, "term": "similar Experience project product program management customer design Excellent storytelling team work", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5187781672508763, "os": 0.11518155727363691}, {"x": 0.502304147465438, "y": 0.7868995633187774, "ox": 0.502304147465438, "oy": 0.7868995633187774, "term": "BS MS", "cat25k": 19, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8793189784677016, "os": 0.3341473265155325}, {"x": 0.0, "y": 0.2751091703056769, "ox": 0.0, "oy": 0.2751091703056769, "term": "probabilistic graphical models", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5963945918878317, "os": 0.13525472630268537}, {"x": 0.024884792626728117, "y": 0.02008733624454149, "ox": 0.024884792626728117, "oy": 0.02008733624454149, "term": "degree", "cat25k": 2, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.49374061091637456, "os": -0.05029601773071508}, {"x": 0.0, "y": 0.7310043668122271, "ox": 0.0, "oy": 0.7310043668122271, "term": "Jobs Fwd inedinfo Fwd JOB Statistician fte", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8487731597396093, "os": 0.2733175342336984}, {"x": 0.0, "y": 0.726637554585153, "ox": 0.0, "oy": 0.726637554585153, "term": "Next message Jobs NPD Group", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8467701552328493, "os": 0.27067808860805487}, {"x": 0.0, "y": 0.7030567685589522, "ox": 0.0, "oy": 0.7030567685589522, "term": "Fwd JOB Statistician fte Next", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8337506259389084, "os": 0.25515905454811094}, {"x": 0.0, "y": 0.6882096069868997, "ox": 0.0, "oy": 0.6882096069868997, "term": "Jobs NPD Group", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8252378567851778, "os": 0.24741357280085424}, {"x": 0.0, "y": 0.6480349344978167, "ox": 0.0, "oy": 0.6480349344978167, "term": "Jobs Fwd", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8042063094641964, "os": 0.2281192363392978}, {"x": 0.0, "y": 0.4663755458515285, "ox": 0.0, "oy": 0.4663755458515285, "term": "Previous message", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7030545818728092, "os": 0.1697888549455238}, {"x": 0.0, "y": 0.3152838427947599, "ox": 0.0, "oy": 0.3152838427947599, "term": "Experience working data analytics Experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6194291437155733, "os": 0.14155876982262003}, {"x": 0.0, "y": 0.6410480349344979, "ox": 0.0, "oy": 0.6410480349344979, "term": "e g", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.800200300450676, "os": 0.22370118565157132}, {"x": 0.0, "y": 0.19039301310043671, "ox": 0.0, "oy": 0.19039301310043671, "term": "moderate large scale data", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5488232348522784, "os": 0.12253655036676595}, {"x": 0.0, "y": 0.16331877729257643, "ox": 0.0, "oy": 0.16331877729257643, "term": "innovate state art machine", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5338007010515774, "os": 0.11849646058039223}, {"x": 0.0, "y": 0.1091703056768559, "ox": 0.0, "oy": 0.1091703056768559, "term": "predictive explanatory models experimentation processes", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5077616424636956, "os": 0.11122560592355904}, {"x": 0.0, "y": 0.4384279475982533, "ox": 0.0, "oy": 0.4384279475982533, "term": "R Python programming proficiency Proficiency data integration data quality development Programming experience", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6875312969454181, "os": 0.1638509287784808}, {"x": 0.0, "y": 0.3580786026200874, "ox": 0.0, "oy": 0.3580786026200874, "term": "non technical audience Interest educational applications", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6434651977966951, "os": 0.14764143484421846}, {"x": 0.0, "y": 0.3126637554585154, "ox": 0.0, "oy": 0.3126637554585154, "term": "track record Experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6179268903355032, "os": 0.14125014185419774}, {"x": 0.0, "y": 0.26637554585152845, "ox": 0.0, "oy": 0.26637554585152845, "term": "Experience technologies", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5913870806209314, "os": 0.13311873160456028}, {"x": 0.0, "y": 0.2620087336244542, "ox": 0.0, "oy": 0.2620087336244542, "term": "technical projects database components", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5888833249874812, "os": 0.1319086071381395}, {"x": 0.0, "y": 0.23318777292576426, "ox": 0.0, "oy": 0.23318777292576426, "term": "technical topics", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5733600400600901, "os": 0.12808873174721513}, {"x": 0.0, "y": 0.2087336244541485, "ox": 0.0, "oy": 0.2087336244541485, "term": "R Shiny Python", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5593390085127692, "os": 0.12443649948193183}, {"x": 0.0, "y": 0.1310043668122271, "ox": 0.0, "oy": 0.1310043668122271, "term": "Django", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5167751627441161, "os": 0.11474559781680628}, {"x": 0.0, "y": 0.3851528384279477, "ox": 0.0, "oy": 0.3851528384279477, "term": "Experience data visualization tools", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6584877315973962, "os": 0.15350584432131975}, {"x": 0.0, "y": 0.36506550218340617, "ox": 0.0, "oy": 0.36506550218340617, "term": "Experience relational databases", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6474712068102153, "os": 0.1491460979493673}, {"x": 0.0, "y": 0.31790393013100443, "ox": 0.0, "oy": 0.31790393013100443, "term": "R Python Experience working AWS environments", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6209313970956435, "os": 0.14188305625576}, {"x": 0.0, "y": 0.11353711790393013, "ox": 0.0, "oy": 0.11353711790393013, "term": "common data science toolkits", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5092638958437655, "os": 0.11240662614888929}, {"x": 0.31152073732718905, "y": 0.20524017467248912, "ox": 0.31152073732718905, "oy": 0.20524017467248912, "term": "At least years experience", "cat25k": 7, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.557336004006009, "os": 0.12414279484775022}, {"x": 0.006451612903225807, "y": 0.006113537117903931, "ox": 0.006451612903225807, "oy": 0.006113537117903931, "term": "Applied", "cat25k": 2, "ncat25k": 2, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.49874812218327497, "os": 0.030959882064885407}, {"x": 0.0, "y": 0.897816593886463, "ox": 0.0, "oy": 0.897816593886463, "term": "Nordstrom Stock Purchase Plan", "cat25k": 45, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.942413620430646, "os": 0.8}, {"x": 0.0, "y": 0.39475982532751097, "ox": 0.0, "oy": 0.39475982532751097, "term": "data science math physics computer science equivalent degree", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6639959939909864, "os": 0.1555613730637134}, {"x": 0.0, "y": 0.3336244541484717, "ox": 0.0, "oy": 0.3336244541484717, "term": "Exceptional understanding machine learning concepts data science programming", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.629444166249374, "os": 0.14380924738397527}, {"x": 0.0, "y": 0.3135371179039302, "ox": 0.0, "oy": 0.3135371179039302, "term": "mobile video games", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6184276414621933, "os": 0.1413168569126142}, {"x": 0.5225806451612903, "y": 0.24017467248908303, "ox": 0.5225806451612903, "oy": 0.24017467248908303, "term": "product managers", "cat25k": 7, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.24937406109163748, "os": -0.16128379896487982}, {"x": 0.0, "y": 0.6829694323144107, "ox": 0.0, "oy": 0.6829694323144107, "term": "Proficiency Python R SQL Authorization work United States", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8227341011517276, "os": 0.2432146192129675}, {"x": 0.0, "y": 0.5965065502183408, "ox": 0.0, "oy": 0.5965065502183408, "term": "Python R SQL Authorization", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7746619929894842, "os": 0.20321170558259705}, {"x": 0.0, "y": 0.48384279475982545, "ox": 0.0, "oy": 0.48384279475982545, "term": "Ph D M S quantitative discipline graduating Passion machine", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7130696044066098, "os": 0.17272539880945004}, {"x": 0.0, "y": 0.6340611353711791, "ox": 0.0, "oy": 0.6340611353711791, "term": "Experience Spark", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7961942914371557, "os": 0.22156958603625435}, {"x": 0.0, "y": 0.3694323144104804, "ox": 0.0, "oy": 0.3694323144104804, "term": "even new folks", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6499749624436655, "os": 0.14996520887367523}, {"x": 0.0, "y": 0.2969432314410481, "ox": 0.0, "oy": 0.2969432314410481, "term": "An open work environment", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6089133700550826, "os": 0.13810922110488308}, {"x": 0.0, "y": 0.2838427947598254, "ox": 0.0, "oy": 0.2838427947598254, "term": "large knowledge stores Experience information extraction creation application layer Experience developing REST JSON applications", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6014021031547321, "os": 0.13626287405577114}, {"x": 0.0, "y": 0.2253275109170306, "ox": 0.0, "oy": 0.2253275109170306, "term": "recommendation engines Experience", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5688532799198798, "os": 0.12677257636804476}, {"x": 0.0, "y": 0.18602620087336247, "ox": 0.0, "oy": 0.18602620087336247, "term": "Python Ruby Strong experience", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5463194792188282, "os": 0.12147847877561704}, {"x": 0.0, "y": 0.18165938864628825, "ox": 0.0, "oy": 0.18165938864628825, "term": "Knowledge statistics experience", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5438157235853781, "os": 0.12132417418259273}, {"x": 0.21198156682027652, "y": 0.08558951965065503, "ox": 0.21198156682027652, "oy": 0.08558951965065503, "term": "Fluency", "cat25k": 5, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.40460691036554836, "os": -0.10146802524233026}, {"x": 0.41474654377880193, "y": 0.14847161572052403, "ox": 0.41474654377880193, "oy": 0.14847161572052403, "term": "Microsoft Azure", "cat25k": 6, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3029544316474712, "os": -0.13378762281962625}, {"x": 0.0, "y": 0.5554585152838428, "ox": 0.0, "oy": 0.5554585152838428, "term": "Self starter results", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7516274411617426, "os": 0.18968443873813}, {"x": 0.0, "y": 0.16157205240174674, "ox": 0.0, "oy": 0.16157205240174674, "term": "Data Science Analytics Engineering Mathematics Industrial Engineering Computer Science Information Technology Economics Finance", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5327991987981973, "os": 0.11813518369761436}, {"x": 0.0, "y": 0.13187772925764196, "ox": 0.0, "oy": 0.13187772925764196, "term": "Bachelor degree Data Science Analytics Engineering Mathematics Industrial Engineering Computer Science Information Technology Economics Finance", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5172759138708062, "os": 0.11493570809876046}, {"x": 0.0, "y": 0.3991266375545852, "ox": 0.0, "oy": 0.3991266375545852, "term": "Big data experience", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6664997496244366, "os": 0.1563593105047975}, {"x": 0.0, "y": 0.3283842794759826, "ox": 0.0, "oy": 0.3283842794759826, "term": "US Citizenship Advanced degree computer science data science business analytics", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6269404106159239, "os": 0.1434164504091514}, {"x": 0.0, "y": 0.26899563318777303, "ox": 0.0, "oy": 0.26899563318777303, "term": "tools Experience", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5928893340010015, "os": 0.13386048612369905}, {"x": 0.0, "y": 0.2672489082969433, "ox": 0.0, "oy": 0.2672489082969433, "term": "Hive Spark Pig MapReduce Knowledge industry leading analytics", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5918878317476215, "os": 0.1331509933276854}, {"x": 0.0, "y": 0.18951965065502185, "ox": 0.0, "oy": 0.18951965065502185, "term": "oral presentation skills", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5483224837255883, "os": 0.122492920661959}, {"x": 0.04239631336405531, "y": 0.5432314410480351, "ox": 0.04239631336405531, "oy": 0.5432314410480351, "term": "Hive Spark", "cat25k": 10, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7456184276414621, "os": 0.18600563729169095}, {"x": 0.5622119815668204, "y": 0.027947598253275113, "ox": 0.5622119815668204, "oy": 0.027947598253275113, "term": "days", "cat25k": 3, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2298447671507261, "os": -0.1783145748400567}, {"x": 0.0, "y": 0.22008733624454155, "ox": 0.0, "oy": 0.22008733624454155, "term": "experience familiarity multivariate predictive modeling analytics software", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5658487731597396, "os": 0.1260967313969095}, {"x": 0.0, "y": 0.2104803493449782, "ox": 0.0, "oy": 0.2104803493449782, "term": "Deep familiarity analytics actuarial market landscape corresponding information", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5603405107661492, "os": 0.12450568414000734}, {"x": 0.0, "y": 0.17467248908296945, "ox": 0.0, "oy": 0.17467248908296945, "term": "Bachelor degree Master degree years work experience completing undergraduate degree years advanced analytics", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5398097145718578, "os": 0.11998600557683749}, {"x": 0.0, "y": 0.16943231441048037, "ox": 0.0, "oy": 0.16943231441048037, "term": "knowledge insurance industry", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5373059589384076, "os": 0.1192278865765991}, {"x": 0.0, "y": 0.23056768558951973, "ox": 0.0, "oy": 0.23056768558951973, "term": "Experience building deploying cloud based data pipelines", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5718577866800201, "os": 0.12797694360486409}, {"x": 0.0, "y": 0.13275109170305677, "ox": 0.0, "oy": 0.13275109170305677, "term": "Demonstrated programming experience", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5177766649974963, "os": 0.1150184446275592}, {"x": 0.03502304147465438, "y": 0.5816593886462883, "ox": 0.03502304147465438, "oy": 0.5816593886462883, "term": "team", "cat25k": 11, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7661492238357536, "os": 0.19756536423673113}, {"x": 0.0, "y": 0.28646288209606996, "ox": 0.0, "oy": 0.28646288209606996, "term": "business processes related client business questions years", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6029043565348022, "os": 0.13724319705183172}, {"x": 0.0, "y": 0.692576419213974, "ox": 0.0, "oy": 0.692576419213974, "term": "BI Tool e OBIEE Cognos Business Objects", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.827741612418628, "os": 0.24872767275714097}, {"x": 0.0, "y": 0.15895196506550222, "ox": 0.0, "oy": 0.15895196506550222, "term": "role Experience", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5312969454181272, "os": 0.11788132959829851}, {"x": 0.0, "y": 0.14061135371179043, "ox": 0.0, "oy": 0.14061135371179043, "term": "g Excel Word PowerPoint Experience", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5217826740110164, "os": 0.1156125055032833}, {"x": 0.9649769585253456, "y": 0.4296943231441049, "ox": 0.9649769585253456, "oy": 0.4296943231441049, "term": "Microsoft", "cat25k": 9, "ncat25k": 65, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.01752628943415123, "os": -0.9237975093926378}, {"x": 0.0, "y": 0.7231441048034936, "ox": 0.0, "oy": 0.7231441048034936, "term": "implementation integration test deployment Experience developing software C C", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8447671507260891, "os": 0.26637236513092527}, {"x": 0.0, "y": 0.5580786026200875, "ox": 0.0, "oy": 0.5580786026200875, "term": "large scale data management big data technologies", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7531296945418127, "os": 0.19086170404704053}, {"x": 0.0, "y": 0.5135371179039303, "ox": 0.0, "oy": 0.5135371179039303, "term": "important project success Effective interpersonal skills necessary interact levels personnel", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.729594391587381, "os": 0.17932073489164058}, {"x": 0.0, "y": 0.39213973799126645, "ox": 0.0, "oy": 0.39213973799126645, "term": "Significant experience demonstrated expertise", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6624937406109163, "os": 0.15473191310950896}, {"x": 0.0, "y": 0.3755458515283844, "ox": 0.0, "oy": 0.3755458515283844, "term": "technical languages concepts", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6534802203304958, "os": 0.15131571297163787}, {"x": 0.0, "y": 0.3685589519650656, "ox": 0.0, "oy": 0.3685589519650656, "term": "creative solutions complex problems", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6494742113169755, "os": 0.14986283212581933}, {"x": 0.0, "y": 0.3633187772925765, "ox": 0.0, "oy": 0.3633187772925765, "term": "Effective advanced analytical problem", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6464697045568352, "os": 0.14874076172852127}, {"x": 0.0, "y": 0.354585152838428, "ox": 0.0, "oy": 0.354585152838428, "term": "advanced areas high performance", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6414621932899348, "os": 0.14708676740441742}, {"x": 0.0, "y": 0.26288209606986906, "ox": 0.0, "oy": 0.26288209606986906, "term": "Comprehensive knowledge", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5893840761141713, "os": 0.13232373155197572}, {"x": 0.0, "y": 0.2384279475982533, "ox": 0.0, "oy": 0.2384279475982533, "term": "decision making skills", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5763645468202303, "os": 0.1288080416845621}, {"x": 0.4119815668202766, "y": 0.07598253275109171, "ox": 0.4119815668202766, "oy": 0.07598253275109171, "term": "Effective", "cat25k": 5, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.30445668502754136, "os": -0.13300298037027072}, {"x": 0.0, "y": 0.14148471615720526, "ox": 0.0, "oy": 0.14148471615720526, "term": "program entrepreneurial environment Top notch health dental vision insurance Stock options fast growing tech company 401k plan matching contribution", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5222834251377065, "os": 0.11576044083437186}, {"x": 0.14838709677419357, "y": 0.5074235807860262, "ox": 0.14838709677419357, "oy": 0.5074235807860262, "term": "Frequent company", "cat25k": 10, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7260891337005508, "os": 0.17736217473805715}, {"x": 0.0, "y": 0.7781659388646289, "ox": 0.0, "oy": 0.7781659388646289, "term": "Preferred Master Required United States", "cat25k": 18, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8743114672008012, "os": 0.32712714606416576}, {"x": 0.0, "y": 0.5406113537117905, "ox": 0.0, "oy": 0.5406113537117905, "term": "Data Science years", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7441161742613921, "os": 0.18521643372082883}, {"x": 0.0, "y": 0.3598253275109171, "ox": 0.0, "oy": 0.3598253275109171, "term": "Strong data mining data visualization Ability", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6444667000500751, "os": 0.14776716739293516}, {"x": 0.0, "y": 0.32925764192139745, "ox": 0.0, "oy": 0.32925764192139745, "term": "Strong least code bases", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6274411617426139, "os": 0.14363919514943918}, {"x": 0.0, "y": 0.2951965065502184, "ox": 0.0, "oy": 0.2951965065502184, "term": "machine learning models production environment", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6079118678017026, "os": 0.137968505451815}, {"x": 0.0, "y": 0.28733624454148476, "ox": 0.0, "oy": 0.28733624454148476, "term": "Python Healthcare Population Health knowledge preferred Experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6034051076614921, "os": 0.13729294264270395}, {"x": 0.0, "y": 0.22794759825327515, "ox": 0.0, "oy": 0.22794759825327515, "term": "Strong working stakeholders", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5703555332999499, "os": 0.1278145608536644}, {"x": 0.0, "y": 0.2017467248908297, "ox": 0.0, "oy": 0.2017467248908297, "term": "Python Healthcare Population Health", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5553329994992489, "os": 0.12352911888749565}, {"x": 0.0, "y": 0.15458515283842797, "ox": 0.0, "oy": 0.15458515283842797, "term": "fast paced environment Experience various math statistics methodologies", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.529293940911367, "os": 0.11761785772784615}, {"x": 0.047926267281105994, "y": 0.4890829694323145, "ox": 0.047926267281105994, "oy": 0.4890829694323145, "term": "multiple competing priorities", "cat25k": 10, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7160741111667501, "os": 0.17394887422361166}, {"x": 0.0, "y": 0.7842794759825329, "ox": 0.0, "oy": 0.7842794759825329, "term": "insights", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8778167250876314, "os": 0.33312200074217413}, {"x": 0.0, "y": 0.5353711790393014, "ox": 0.0, "oy": 0.5353711790393014, "term": "basic knowledge statistical concepts regression time series mixed model", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7411116675012519, "os": 0.18362555913642048}, {"x": 0.0, "y": 0.6786026200873364, "ox": 0.0, "oy": 0.6786026200873364, "term": "Bayesian methods", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8207310966449675, "os": 0.2411562302529009}, {"x": 0.0, "y": 0.3004366812227075, "ox": 0.0, "oy": 0.3004366812227075, "term": "BA Computer Science Engineering relevant field graduate degree Data Science quantitative field preferred Experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6109163745618428, "os": 0.13871707922508514}, {"x": 0.0, "y": 0.2882096069868996, "ox": 0.0, "oy": 0.2882096069868996, "term": "anomaly detection Experience bioinformatics NLP", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6039058587881823, "os": 0.13730116627117445}, {"x": 0.8285714285714287, "y": 0.2602620087336245, "ox": 0.8285714285714287, "oy": 0.2602620087336245, "term": "Experience building", "cat25k": 7, "ncat25k": 24, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09213820731096645, "os": -0.3383052868480525}, {"x": 0.0, "y": 0.15196506550218342, "ox": 0.0, "oy": 0.15196506550218342, "term": "Proficient Jupyter Python Spark", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5277916875312969, "os": 0.11741497678573179}, {"x": 0.24608294930875582, "y": 0.0480349344978166, "ox": 0.24608294930875582, "oy": 0.0480349344978166, "term": "cases", "cat25k": 4, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3870806209313971, "os": -0.105603150125403}, {"x": 0.0, "y": 0.2646288209606988, "ox": 0.0, "oy": 0.2646288209606988, "term": "internal non AI expert business partners", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5903855783675513, "os": 0.1324689106958545}, {"x": 0.0, "y": 0.20786026200873364, "ox": 0.0, "oy": 0.20786026200873364, "term": "asset drive diffusion AI", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5588382573860791, "os": 0.12430573276273234}, {"x": 0.0, "y": 0.14585152838427948, "ox": 0.0, "oy": 0.14585152838427948, "term": "execute coordinate innovative data analytics initiatives", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5247871807711567, "os": 0.11611823255295908}, {"x": 0.0, "y": 0.23580786026200878, "ox": 0.0, "oy": 0.23580786026200878, "term": "BASF", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5748622934401602, "os": 0.128305615047387}, {"x": 0.0, "y": 0.2820960698689957, "ox": 0.0, "oy": 0.2820960698689957, "term": "HDFS Hadoop Hive HBase Spark Modern versioning systems git subversion", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.600400600901352, "os": 0.13600141158860796}, {"x": 0.0, "y": 0.20262008733624456, "ox": 0.0, "oy": 0.20262008733624456, "term": "Windows OS Linux OS command line tools", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5558337506259389, "os": 0.12382583515367843}, {"x": 0.0, "y": 0.17205240174672493, "ox": 0.0, "oy": 0.17205240174672493, "term": "neural networks recommendation systems", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5383074611917876, "os": 0.11937712513791426}, {"x": 0.0, "y": 0.14672489082969434, "ox": 0.0, "oy": 0.14672489082969434, "term": "addition time series analysis Modern ML techniques", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5252879318978468, "os": 0.11625022995742881}, {"x": 0.0, "y": 0.49257641921397394, "ox": 0.0, "oy": 0.49257641921397394, "term": "SQL SQL", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7175763645468203, "os": 0.17516859355455539}, {"x": 0.0, "y": 0.19737991266375549, "ox": 0.0, "oy": 0.19737991266375549, "term": "time series regression cluster analysis decision trees", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5528292438657987, "os": 0.12330521816301772}, {"x": 0.0, "y": 0.1755458515283843, "ox": 0.0, "oy": 0.1755458515283843, "term": "advanced analytic techniques", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5403104656985478, "os": 0.12027895072353914}, {"x": 0.0, "y": 0.16855895196506554, "ox": 0.0, "oy": 0.16855895196506554, "term": "oral Hands experience manipulating deriving", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5368052078117175, "os": 0.11915865987800467}, {"x": 0.0, "y": 0.16506550218340613, "ox": 0.0, "oy": 0.16506550218340613, "term": "unstructured datasets", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5348022033049574, "os": 0.11871192832625344}, {"x": 0.0, "y": 0.12576419213973802, "ox": 0.0, "oy": 0.12576419213973802, "term": "practical casework agency corporate side Strong knowledge experience wide variety tools", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5142714071106659, "os": 0.11391674375230662}, {"x": 0.0, "y": 0.1240174672489083, "ox": 0.0, "oy": 0.1240174672489083, "term": "SQL SAS R Alteryx Tableau Proficient Excel PowerPoint presentation communication skills", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5132699048572859, "os": 0.113841832829939}, {"x": 0.0, "y": 0.12925764192139738, "ox": 0.0, "oy": 0.12925764192139738, "term": "Degree Statistics Information Systems Mathematics Finance", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.515773660490736, "os": 0.1144217233191134}, {"x": 0.0, "y": 0.841048034934498, "ox": 0.0, "oy": 0.841048034934498, "term": "Data Visualization skills", "cat25k": 24, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9098647971957937, "os": 0.43301270189221913}, {"x": 0.0, "y": 0.8288209606986902, "ox": 0.0, "oy": 0.8288209606986902, "term": "Data Visualization", "cat25k": 23, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9028542814221332, "os": 0.40718349144304594}, {"x": 0.0, "y": 0.8855895196506551, "ox": 0.0, "oy": 0.8855895196506551, "term": "SF Financial District", "cat25k": 39, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9359038557836755, "os": 0.6933600300017324}, {"x": 0.0, "y": 0.6759825327510918, "ox": 0.0, "oy": 0.6759825327510918, "term": "Fun puzzle loving office", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8192288432648973, "os": 0.2396672665936658}, {"x": 0.0, "y": 0.2506550218340612, "ox": 0.0, "oy": 0.2506550218340612, "term": "Required Statistical Algorithms years Required expert usage R Python years", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5828743114672008, "os": 0.12988528117803322}, {"x": 0.0, "y": 0.188646288209607, "ox": 0.0, "oy": 0.188646288209607, "term": "analytic requirement Modern machine learning models expert level years", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5478217325988983, "os": 0.12244892062427326}, {"x": 0.6829493087557605, "y": 0.0829694323144105, "ox": 0.6829493087557605, "oy": 0.0829694323144105, "term": "Strong coding skills", "cat25k": 5, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16925388082123188, "os": -0.22716603666132928}, {"x": 0.24792626728110606, "y": 0.10742358078602622, "ox": 0.24792626728110606, "oy": 0.10742358078602622, "term": "technical non technical stakeholders", "cat25k": 6, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5067601402103155, "os": 0.11086937184573918}, {"x": 0.28571428571428575, "y": 0.07161572052401748, "ox": 0.28571428571428575, "oy": 0.07161572052401748, "term": "verbal communication skills ability", "cat25k": 5, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3665498247371057, "os": -0.11155402506430179}, {"x": 0.3059907834101383, "y": 0.8480349344978168, "ox": 0.3059907834101383, "oy": 0.8480349344978168, "term": "large data sets", "cat25k": 26, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9163745618427641, "os": 0.467826653458967}, {"x": 0.0, "y": 0.5397379912663757, "ox": 0.0, "oy": 0.5397379912663757, "term": "clustering decision trees neural networks", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7436154231347021, "os": 0.184722848466995}, {"x": 0.7447004608294931, "y": 0.06812227074235808, "ox": 0.7447004608294931, "oy": 0.06812227074235808, "term": "databases", "cat25k": 5, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.13620430645968956, "os": -0.2609605407680562}, {"x": 0.0, "y": 0.7633187772925766, "ox": 0.0, "oy": 0.7633187772925766, "term": "computing tools Hive Redshift", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8657986980470707, "os": 0.31120756477299005}, {"x": 0.0, "y": 0.5144104803493451, "ox": 0.0, "oy": 0.5144104803493451, "term": "ETL validations Experience Druid columnar data stores Experience BI tools", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7300951427140712, "os": 0.17942897202938926}, {"x": 0.0, "y": 0.4235807860262009, "ox": 0.0, "oy": 0.4235807860262009, "term": "PREFERRED QUALIFICATIONS Experience designing data quality metrics", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6795192789183776, "os": 0.1608867779057185}, {"x": 0.0, "y": 0.32489082969432326, "ox": 0.0, "oy": 0.32489082969432326, "term": "quantitative data analysis years", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6249374061091637, "os": 0.14299031455375175}, {"x": 0.0, "y": 0.32401746724890834, "ox": 0.0, "oy": 0.32401746724890834, "term": "SQL Hive experience years", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6244366549824737, "os": 0.1428307401112809}, {"x": 0.0, "y": 0.2986899563318778, "ox": 0.0, "oy": 0.2986899563318778, "term": "Python R scripting languages", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6099148723084626, "os": 0.13832075777851455}, {"x": 0.0, "y": 0.2925764192139738, "ox": 0.0, "oy": 0.2925764192139738, "term": "Experience BI", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6064096144216324, "os": 0.13764522525935874}, {"x": 0.0, "y": 0.2655021834061136, "ox": 0.0, "oy": 0.2655021834061136, "term": "statistical data analysis linear models", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5908863294942412, "os": 0.13272093948677877}, {"x": 0.0, "y": 0.2585152838427948, "ox": 0.0, "oy": 0.2585152838427948, "term": "Machine Learning PhD Data Science Statistics similar technical quantitative field Ability initiate", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.587381071607411, "os": 0.13176654737199822}, {"x": 0.0, "y": 0.2489082969432315, "ox": 0.0, "oy": 0.2489082969432315, "term": "Research Economics Computer Science Mathematics Physics Electrical Engineering Industrial Engineering", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5818728092138208, "os": 0.1296952430628345}, {"x": 0.0, "y": 0.24803493449781666, "ox": 0.0, "oy": 0.24803493449781666, "term": "g Statistics Operations Research Economics Computer Science Mathematics Physics Electrical Engineering Industrial Engineering", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5813720580871307, "os": 0.1296574952603314}, {"x": 0.0, "y": 0.23493449781659395, "ox": 0.0, "oy": 0.23493449781659395, "term": "analysis stochastic models", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5743615423134703, "os": 0.12823573807891464}, {"x": 0.0, "y": 0.18253275109170308, "ox": 0.0, "oy": 0.18253275109170308, "term": "commitment drive success teams peers", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.544316474712068, "os": 0.12136557564896198}, {"x": 0.0, "y": 0.33275109170305683, "ox": 0.0, "oy": 0.33275109170305683, "term": "Previous work experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.628943415122684, "os": 0.14376569007795975}, {"x": 0.0, "y": 0.31004366812227085, "ox": 0.0, "oy": 0.31004366812227085, "term": "Experience large scale data analysis", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6164246369554331, "os": 0.14090043874067756}, {"x": 0.0, "y": 0.15807860262008736, "ox": 0.0, "oy": 0.15807860262008736, "term": "data mining statistical analysis", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5307961942914371, "os": 0.11785308897487479}, {"x": 0.0, "y": 0.14497816593886464, "ox": 0.0, "oy": 0.14497816593886464, "term": "aggressive deadlines", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5242864296444666, "os": 0.11591969234359778}, {"x": 0.0, "y": 0.12139737991266378, "ox": 0.0, "oy": 0.12139737991266378, "term": "key Strong communication data presentation", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5117676514772157, "os": 0.11361835630111644}, {"x": 0.0, "y": 0.12052401746724892, "ox": 0.0, "oy": 0.12052401746724892, "term": "new technologies tools techniques", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5112669003505258, "os": 0.11337764828742586}, {"x": 0.0, "y": 0.0978165938864629, "ox": 0.0, "oy": 0.0978165938864629, "term": "structured unstructured data Strong communication interpersonal skills ability work team environment", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5022533800701051, "os": 0.10904218142763066}, {"x": 0.0, "y": 0.2593886462882097, "ox": 0.0, "oy": 0.2593886462882097, "term": "statistical analysis software development Solid background machine", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5878818227341012, "os": 0.1318066090170279}, {"x": 0.0, "y": 0.19126637554585155, "ox": 0.0, "oy": 0.19126637554585155, "term": "Multivariate Regression Logistic Regression Combinatorial Optimization Stochastic Processes Complex Analysis Principal Component Analysis Time Series Analysis Experience Matlab R Weka Experience", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5493239859789685, "os": 0.1226128792271726}, {"x": 0.0, "y": 0.1807860262008734, "ox": 0.0, "oy": 0.1807860262008734, "term": "Multivariate Regression Logistic Regression Combinatorial Optimization Stochastic Processes Complex Analysis Principal Component Analysis Time Series Analysis", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.543314972458688, "os": 0.12123635458644146}, {"x": 0.0, "y": 0.1737991266375546, "ox": 0.0, "oy": 0.1737991266375546, "term": "Strong software development", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5393089634451677, "os": 0.11976057335785531}, {"x": 0.0, "y": 0.12663755458515286, "ox": 0.0, "oy": 0.12663755458515286, "term": "Agile software development methodology", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.514772158237356, "os": 0.11395392757274113}, {"x": 0.0, "y": 0.10567685589519651, "ox": 0.0, "oy": 0.10567685589519651, "term": "software support continuous integration continuous deployment process", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5057586379569353, "os": 0.11076595795963642}, {"x": 0.8626728110599079, "y": 0.6768558951965067, "ox": 0.8626728110599079, "oy": 0.6768558951965067, "term": "statistical analysis", "cat25k": 13, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07060590886329493, "os": -0.39309699602751175}, {"x": 0.0, "y": 0.7397379912663756, "ox": 0.0, "oy": 0.7397379912663756, "term": "high throughput data ingestion analysis", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8532799198798198, "os": 0.28937676183816274}, {"x": 0.0, "y": 0.7117903930131005, "ox": 0.0, "oy": 0.7117903930131005, "term": "new things test solutions technologies", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8387581372058087, "os": 0.2593613203955827}, {"x": 0.0, "y": 0.6078602620087338, "ox": 0.0, "oy": 0.6078602620087338, "term": "enterprise products", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7811717576364546, "os": 0.2089341435693275}, {"x": 0.0, "y": 0.4986899563318778, "ox": 0.0, "oy": 0.4986899563318778, "term": "deep learning", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7210816224336505, "os": 0.1760159739199051}, {"x": 0.0, "y": 0.7598253275109171, "ox": 0.0, "oy": 0.7598253275109171, "term": "TensorFlow PyTorch", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8637956935403104, "os": 0.30706692146550474}, {"x": 0.0, "y": 0.6183406113537119, "ox": 0.0, "oy": 0.6183406113537119, "term": "unique solutions", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.787180771156735, "os": 0.21577042843290412}, {"x": 0.0, "y": 0.6043668122270743, "ox": 0.0, "oy": 0.6043668122270743, "term": "micro managed freedom", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7791687531296946, "os": 0.20716343230910375}, {"x": 0.0, "y": 0.5991266375545853, "ox": 0.0, "oy": 0.5991266375545853, "term": "cloud console", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7761642463695543, "os": 0.20381722067525337}, {"x": 0.0, "y": 0.578165938864629, "ox": 0.0, "oy": 0.578165938864629, "term": "better path", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7641462193289935, "os": 0.19665917742623024}, {"x": 0.42304147465437797, "y": 0.5502183406113538, "ox": 0.42304147465437797, "oy": 0.5502183406113538, "term": "frameworks", "cat25k": 11, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7491236855282924, "os": 0.1887516347158112}, {"x": 0.0, "y": 0.45152838427947606, "ox": 0.0, "oy": 0.45152838427947606, "term": "Data science dynamic evolving profession", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6945418127190786, "os": 0.16715580117247045}, {"x": 0.0, "y": 0.23231441048034937, "ox": 0.0, "oy": 0.23231441048034937, "term": "current area expertise interest related interest positions", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5728592889334001, "os": 0.128070894576311}, {"x": 0.0, "y": 0.11004366812227075, "ox": 0.0, "oy": 0.11004366812227075, "term": "Bachelor degree Computational social science Computer science Data analytics Economics Engineering Geospatial analysis", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5082623935903855, "os": 0.11137925312730639}, {"x": 0.0, "y": 0.10043668122270742, "ox": 0.0, "oy": 0.10043668122270742, "term": "Bachelor degree Computational social science Computer science Data analytics", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5032548823234851, "os": 0.10940611826543917}, {"x": 0.0, "y": 0.5048034934497818, "ox": 0.0, "oy": 0.5048034934497818, "term": "Quantitative finance Statistics GPA", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7245868803204807, "os": 0.17708373343747816}, {"x": 0.0, "y": 0.15371179039301314, "ox": 0.0, "oy": 0.15371179039301314, "term": "CIA", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.528793189784677, "os": 0.11755371327120726}, {"x": 0.0, "y": 0.34847161572052404, "ox": 0.0, "oy": 0.34847161572052404, "term": "continuous improvement data science analytics Presents data insights", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6379569354031046, "os": 0.14619721679578077}, {"x": 0.0, "y": 0.2899563318777293, "ox": 0.0, "oy": 0.2899563318777293, "term": "analytics related field Certificate business analytics data mining statistical analysis", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6049073610415623, "os": 0.1373848231096337}, {"x": 0.0, "y": 0.25589519650655024, "ox": 0.0, "oy": 0.25589519650655024, "term": "Doctoral degree Statistics Economics Analytics Mathematics year experience analytics related field", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5858788182273409, "os": 0.13157382999555792}, {"x": 0.0, "y": 0.24192139737991272, "ox": 0.0, "oy": 0.24192139737991272, "term": "large data analytics project teams Models compliance company", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5778668002003005, "os": 0.12940483425972377}, {"x": 0.0, "y": 0.22096069868995638, "ox": 0.0, "oy": 0.22096069868995638, "term": "analytics insights", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5663495242864296, "os": 0.12614136022063963}, {"x": 0.0, "y": 0.17903930131004367, "ox": 0.0, "oy": 0.17903930131004367, "term": "data science experience years", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.542313470205308, "os": 0.12098718382843293}, {"x": 0.0, "y": 0.10393013100436682, "ox": 0.0, "oy": 0.10393013100436682, "term": "DB2 Oracle SQL Server years", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5047571357035553, "os": 0.11063716833550258}, {"x": 0.0, "y": 0.8262008733624455, "ox": 0.0, "oy": 0.8262008733624455, "term": "Commuter Benefits Flexible Spendi", "cat25k": 22, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.901352028042063, "os": 0.4}, {"x": 0.0, "y": 0.177292576419214, "ox": 0.0, "oy": 0.177292576419214, "term": "Demonstrable knowledge healthcare data", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5413119679519279, "os": 0.12048487229199854}, {"x": 0.0, "y": 0.10305676855895197, "ox": 0.0, "oy": 0.10305676855895197, "term": "little supervision Strong oral written presentation skills levels organization Ability", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5042563845768653, "os": 0.11039692384327648}, {"x": 0.0, "y": 0.10218340611353713, "ox": 0.0, "oy": 0.10218340611353713, "term": "working data science team", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5037556334501753, "os": 0.11036534603357413}, {"x": 0.0, "y": 0.09606986899563319, "ox": 0.0, "oy": 0.09606986899563319, "term": "R Python preferred ability interest", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5012518778167251, "os": 0.10747116311678481}, {"x": 0.8488479262672812, "y": 0.3310043668122271, "ox": 0.8488479262672812, "oy": 0.3310043668122271, "term": "g", "cat25k": 8, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08062093139709565, "os": -0.36669986631599616}, {"x": 0.023963133640553, "y": 0.003493449781659389, "ox": 0.023963133640553, "oy": 0.003493449781659389, "term": "least one scripting language", "cat25k": 1, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4942413620430646, "os": -0.049027268559011114}, {"x": 0.0, "y": 0.24454148471615725, "ox": 0.0, "oy": 0.24454148471615725, "term": "data mining Strong knowledge experiences machine", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5793690535803706, "os": 0.1294406612905801}, {"x": 0.0, "y": 0.217467248908297, "ox": 0.0, "oy": 0.217467248908297, "term": "Expertise data warehouse SQL programming", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5643465197796695, "os": 0.12572756915865457}, {"x": 0.0, "y": 0.16069868995633188, "ox": 0.0, "oy": 0.16069868995633188, "term": "Math quantitative field strong background machine", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5322984476715072, "os": 0.11795571890586588}, {"x": 0.0, "y": 0.1554585152838428, "ox": 0.0, "oy": 0.1554585152838428, "term": "Python based ML libraries", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5297946920380571, "os": 0.11766549013242977}, {"x": 0.0, "y": 0.137117903930131, "ox": 0.0, "oy": 0.137117903930131, "term": "Experience payment fraud detection prevention", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5202804206309465, "os": 0.11534082795441172}, {"x": 0.0, "y": 0.12489082969432316, "ox": 0.0, "oy": 0.12489082969432316, "term": "Python R SAS Base SAS Stats SAS Enterprise", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.513770655983976, "os": 0.11386916352402167}, {"x": 0.0, "y": 0.12227074235807862, "ox": 0.0, "oy": 0.12227074235807862, "term": "Python R SAS Base SAS Stats SAS Enterprise Miner", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5122684026039058, "os": 0.11372185722163108}, {"x": 0.0, "y": 0.41572052401746734, "ox": 0.0, "oy": 0.41572052401746734, "term": "mathematics statistics physics", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6755132699048573, "os": 0.15956383639901173}, {"x": 0.0, "y": 0.3371179039301311, "ox": 0.0, "oy": 0.3371179039301311, "term": "computer science artificial intelligence", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6314471707561342, "os": 0.14402945444990406}, {"x": 0.0, "y": 0.21135371179039303, "ox": 0.0, "oy": 0.21135371179039303, "term": "relevant work experience Experience building", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5608412618928392, "os": 0.12471996307819778}, {"x": 0.0, "y": 0.1641921397379913, "ox": 0.0, "oy": 0.1641921397379913, "term": "MS Computer Science emphasis Data Science Analytics Machine Learning PhD", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5343014521782673, "os": 0.11854839458578811}, {"x": 0.0, "y": 0.13537117903930132, "ox": 0.0, "oy": 0.13537117903930132, "term": "ideas efficient elegant code Development experience", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5192789183775662, "os": 0.1152667508673706}, {"x": 0.0, "y": 0.10655021834061136, "ox": 0.0, "oy": 0.10655021834061136, "term": "RDF S OWL SPARQL Strong command linear algebra statistics ability", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5062593890836254, "os": 0.1108023187734821}, {"x": 0.0, "y": 0.09694323144104805, "ox": 0.0, "oy": 0.09694323144104805, "term": "Python Java Scala good command respective data pipelining matrix algebra statistics", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5017526289434151, "os": 0.10884829634791231}, {"x": 0.91889400921659, "y": 0.7537117903930133, "ox": 0.91889400921659, "oy": 0.7537117903930133, "term": "Java Python", "cat25k": 17, "ncat25k": 39, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.040560841261892834, "os": -0.5560862226038853}, {"x": 0.0, "y": 0.4139737991266376, "ox": 0.0, "oy": 0.4139737991266376, "term": "common methods data transformation", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6745117676514772, "os": 0.1593119795498423}, {"x": 0.0, "y": 0.4131004366812228, "ox": 0.0, "oy": 0.4131004366812228, "term": "various data structures", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6740110165247871, "os": 0.15927487011182334}, {"x": 0.0, "y": 0.40698689956331885, "ox": 0.0, "oy": 0.40698689956331885, "term": "years practical experience SAS ETL data processing database programming data analytics Experience predictive", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6705057586379569, "os": 0.15773482073750061}, {"x": 0.0, "y": 0.3039301310043669, "ox": 0.0, "oy": 0.3039301310043669, "term": "Qlik SAP BO Experience mining Claims EMR data preferably Oncology related data", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6129193790686029, "os": 0.13917984155682261}, {"x": 0.0, "y": 0.30218340611353717, "ox": 0.0, "oy": 0.30218340611353717, "term": "statistical analysis Experience analytics", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6119178768152228, "os": 0.13885824766117846}, {"x": 0.0, "y": 0.27860262008733633, "ox": 0.0, "oy": 0.27860262008733633, "term": "Python SAS Alteryx Angos R Experience programming languages", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5983975963945918, "os": 0.13560666076285766}, {"x": 0.0, "y": 0.15109170305676856, "ox": 0.0, "oy": 0.15109170305676856, "term": "Tableau MS Power BI Tibco", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5272909364046069, "os": 0.11715710661413538}, {"x": 0.0359447004608295, "y": 0.4786026200873364, "ox": 0.0359447004608295, "oy": 0.4786026200873364, "term": "Extensive", "cat25k": 10, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7100650976464697, "os": 0.17150254937045772}, {"x": 0.0, "y": 0.5703056768558953, "ox": 0.0, "oy": 0.5703056768558953, "term": "data warehouse data cubes", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7601402103154732, "os": 0.19399184409138878}, {"x": 0.0, "y": 0.5126637554585154, "ox": 0.0, "oy": 0.5126637554585154, "term": "Pentaho data integration experience", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7290936404606909, "os": 0.17850053853700223}, {"x": 0.0, "y": 0.34934497816593896, "ox": 0.0, "oy": 0.34934497816593896, "term": "ETL ELT processes", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6384576865297947, "os": 0.14622448708060906}, {"x": 0.0, "y": 0.2637554585152839, "ox": 0.0, "oy": 0.2637554585152839, "term": "ETL ELT", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5898848272408612, "os": 0.13235553529617888}, {"x": 0.0, "y": 0.1956331877729258, "ox": 0.0, "oy": 0.1956331877729258, "term": "operational data PLAN TRACK VIEW", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5518277416124187, "os": 0.12303485802177781}, {"x": 0.0, "y": 0.09868995633187774, "ox": 0.0, "oy": 0.09868995633187774, "term": "applying structure schema", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5027541311967952, "os": 0.10910988690426339}, {"x": 0.01382488479262673, "y": 0.5519650655021836, "ox": 0.01382488479262673, "oy": 0.5519650655021836, "term": "Create", "cat25k": 11, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7501251877816725, "os": 0.18919929871544167}, {"x": 0.0, "y": 0.7589519650655023, "ox": 0.0, "oy": 0.7589519650655023, "term": "Mathematics related field", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8632949424136205, "os": 0.3054129409993863}, {"x": 0.0, "y": 0.5371179039301311, "ox": 0.0, "oy": 0.5371179039301311, "term": "Ph D MS degree", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7421131697546319, "os": 0.18438141779870657}, {"x": 0.0, "y": 0.5283842794759827, "ox": 0.0, "oy": 0.5283842794759827, "term": "D MS degree", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7376064096144217, "os": 0.1823400424586527}, {"x": 0.3235023041474655, "y": 0.07947598253275111, "ox": 0.3235023041474655, "oy": 0.07947598253275111, "term": "HomeAway com Electronic adjustable stand desk", "cat25k": 5, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3490235353029545, "os": -0.11802647659641453}, {"x": 0.21382488479262673, "y": 0.07685589519650657, "ox": 0.21382488479262673, "oy": 0.07685589519650657, "term": "talks leadership team", "cat25k": 5, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4036054081121683, "os": -0.10196362391992062}, {"x": 0.6451612903225807, "y": 0.4480349344978166, "ox": 0.6451612903225807, "oy": 0.4480349344978166, "term": "Discounted Metro Rail", "cat25k": 9, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1882824236354532, "os": -0.21258376697820808}, {"x": 0.3465437788018434, "y": 0.06462882096069869, "ox": 0.3465437788018434, "oy": 0.06462882096069869, "term": "unstructured data", "cat25k": 4, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.33750625938908363, "os": -0.12116925340191248}, {"x": 0.8967741935483873, "y": 0.05851528384279476, "ox": 0.8967741935483873, "oy": 0.05851528384279476, "term": "real time", "cat25k": 4, "ncat25k": 34, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.05157736604907361, "os": -0.483632817475904}, {"x": 0.5732718894009218, "y": 0.0925764192139738, "ox": 0.5732718894009218, "oy": 0.0925764192139738, "term": "weeks", "cat25k": 6, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2238357536304457, "os": -0.18458094169481773}, {"x": 0.03410138248847927, "y": 0.027074235807860267, "ox": 0.03410138248847927, "oy": 0.027074235807860267, "term": "Annual", "cat25k": 3, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.49073610415623437, "os": -0.05815452243924841}, {"x": 0.8894009216589863, "y": 0.06550218340611355, "ox": 0.8894009216589863, "oy": 0.06550218340611355, "term": "e", "cat25k": 4, "ncat25k": 33, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.054581872809213824, "os": -0.4644284655861173}, {"x": 0.0, "y": 0.2157205240174673, "ox": 0.0, "oy": 0.2157205240174673, "term": "Strong statistical knowledge intuition ability", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5633450175262894, "os": 0.12555966593515014}, {"x": 0.0, "y": 0.1624454148471616, "ox": 0.0, "oy": 0.1624454148471616, "term": "Hive Pig Presto Spark Data visualization skills", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5332999499248873, "os": 0.11817946211347764}, {"x": 0.0, "y": 0.1572052401746725, "ox": 0.0, "oy": 0.1572052401746725, "term": "Strong skills", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5302954431647471, "os": 0.11783094737739581}, {"x": 0.0, "y": 0.1475982532751092, "ox": 0.0, "oy": 0.1475982532751092, "term": "massive amounts data drive product innovation", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5257886830245367, "os": 0.1163040662730726}, {"x": 0.0, "y": 0.11703056768558955, "ox": 0.0, "oy": 0.11703056768558955, "term": "Deep product sense", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5107661492238357, "os": 0.11278403252659644}, {"x": 0.0, "y": 0.10829694323144107, "ox": 0.0, "oy": 0.10829694323144107, "term": "predictive modeling time series probabilistic graphical models", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5072608913370055, "os": 0.11096294537844048}, {"x": 0.0, "y": 0.5912663755458517, "ox": 0.0, "oy": 0.5912663755458517, "term": "track record", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.771657486229344, "os": 0.20155617980926374}, {"x": 0.7686635944700463, "y": 0.08820960698689957, "ox": 0.7686635944700463, "oy": 0.08820960698689957, "term": "structured semi structured unstructured data", "cat25k": 5, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12318477716574863, "os": -0.2745864931516153}, {"x": 0.06728110599078341, "y": 0.030567685589519656, "ox": 0.06728110599078341, "oy": 0.030567685589519656, "term": "millions", "cat25k": 3, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.48022033049574364, "os": -0.0754076077704973}, {"x": 0.5658986175115208, "y": 0.002620087336244542, "ox": 0.5658986175115208, "oy": 0.002620087336244542, "term": "Years", "cat25k": 1, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.22784176264396597, "os": -0.1796487613949784}, {"x": 0.0018433179723502306, "y": 0.0, "ox": 0.0018433179723502306, "oy": 0.0, "term": "daily", "cat25k": 0, "ncat25k": 2, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4982473710565849, "os": -0.025821139531563196}, {"x": 0.0, "y": 0.8742358078602621, "ox": 0.0, "oy": 0.8742358078602621, "term": "Education Computer science Statistics Physics Mathematics Economics Specialization Certification", "cat25k": 33, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.929394091136705, "os": 0.6}, {"x": 0.0, "y": 0.3982532751091704, "ox": 0.0, "oy": 0.3982532751091704, "term": "quantitative trading research role Experience top tier quantitative investment firms", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6659989984977467, "os": 0.15617872845682806}, {"x": 0.0, "y": 0.3065502183406114, "ox": 0.0, "oy": 0.3065502183406114, "term": "working experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.614421632448673, "os": 0.13951617405663153}, {"x": 0.0, "y": 0.22969432314410484, "ox": 0.0, "oy": 0.22969432314410484, "term": "AQR Capital QMS Capital", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.57135703555333, "os": 0.12790357364587326}, {"x": 0.0, "y": 0.19475982532751093, "ox": 0.0, "oy": 0.19475982532751093, "term": "Publications top tier journals", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5513269904857285, "os": 0.12299871535671775}, {"x": 0.0, "y": 0.17292576419213976, "ox": 0.0, "oy": 0.17292576419213976, "term": "Professional experience software development practices", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5388082123184778, "os": 0.11943885910358529}, {"x": 0.0, "y": 0.16768558951965068, "ox": 0.0, "oy": 0.16768558951965068, "term": "advanced statistical methodologies multiple regression model mixed models time series models", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5363044566850276, "os": 0.11905231054784486}, {"x": 0.0, "y": 0.1275109170305677, "ox": 0.0, "oy": 0.1275109170305677, "term": "prior experience optimization simulation marketing mix multivariate testing ensemble modeling graph", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5152729093640461, "os": 0.11423218440048041}, {"x": 0.0, "y": 0.41834061135371187, "ox": 0.0, "oy": 0.41834061135371187, "term": "Python R SQL", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6765147721582373, "os": 0.15996755722860168}, {"x": 0.0, "y": 0.7633187772925766, "ox": 0.0, "oy": 0.7633187772925766, "term": "Postgres Druid Aerospike Elasticsearch", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8657986980470707, "os": 0.31120756477299005}, {"x": 0.0, "y": 0.62882096069869, "ox": 0.0, "oy": 0.62882096069869, "term": "Nice Experience working Database storage systems", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7931897846770155, "os": 0.21983850454982395}, {"x": 0.0, "y": 0.25676855895196515, "ox": 0.0, "oy": 0.25676855895196515, "term": "g artificial intelligence operations research", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.586379569354031, "os": 0.1316524005187437}, {"x": 0.0, "y": 0.1921397379912664, "ox": 0.0, "oy": 0.1921397379912664, "term": "Familiarity operations research CPLEX", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5498247371056585, "os": 0.12280458934079744}, {"x": 0.0, "y": 0.14323144104803495, "ox": 0.0, "oy": 0.14323144104803495, "term": "complicated problems", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5232849273910866, "os": 0.11581226724917949}, {"x": 0.0, "y": 0.13013100436681224, "ox": 0.0, "oy": 0.13013100436681224, "term": "integer problems", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5162744116174262, "os": 0.11443465535040033}, {"x": 0.0, "y": 0.11615720524017469, "ox": 0.0, "oy": 0.11615720524017469, "term": "actionable manner Ability", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5102653980971458, "os": 0.11273035311190911}, {"x": 0.0, "y": 0.11179039301310045, "ox": 0.0, "oy": 0.11179039301310045, "term": "quantitative research e", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5087631447170756, "os": 0.11168328262300231}, {"x": 0.30138248847926274, "y": 0.446288209606987, "ox": 0.30138248847926274, "oy": 0.446288209606987, "term": "languages", "cat25k": 9, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6920380570856284, "os": 0.16596609556091296}, {"x": 0.0, "y": 0.4209606986899564, "ox": 0.0, "oy": 0.4209606986899564, "term": "key decisions", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6780170255383074, "os": 0.16039486587519075}, {"x": 0.08479262672811061, "y": 0.04628820960698691, "ox": 0.08479262672811061, "oy": 0.04628820960698691, "term": "colleagues", "cat25k": 4, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.47070605908863294, "os": -0.07925297614234077}, {"x": 0.0, "y": 0.5292576419213975, "ox": 0.0, "oy": 0.5292576419213975, "term": "IT systems", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7381071607411116, "os": 0.18243217794431832}, {"x": 0.0, "y": 0.5187772925764194, "ox": 0.0, "oy": 0.5187772925764194, "term": "preferably Big similar firm Demonstrated expertise business analysis data analysis Experience writing requirements", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7325988983475213, "os": 0.1803174068458849}, {"x": 0.0, "y": 0.4506550218340612, "ox": 0.0, "oy": 0.4506550218340612, "term": "accessing data years", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6940410615923885, "os": 0.1671335572223526}, {"x": 0.0, "y": 0.4593886462882097, "ox": 0.0, "oy": 0.4593886462882097, "term": "working SQL", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6990485728592889, "os": 0.16865150623689612}, {"x": 0.0, "y": 0.10480349344978168, "ox": 0.0, "oy": 0.10480349344978168, "term": "Master degree computer science computer engineering related field equivalent combination education related experience Experience developing software", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5052578868302454, "os": 0.11066628331421603}, {"x": 0.018433179723502308, "y": 0.019213973799126642, "ox": 0.018433179723502308, "oy": 0.019213973799126642, "term": "Broad", "cat25k": 2, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4952428642964447, "os": -0.04117478760904082}, {"x": 0.0, "y": 0.6471615720524019, "ox": 0.0, "oy": 0.6471615720524019, "term": "PhD Masters approved field minimum years", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8037055583375062, "os": 0.22774698911916366}, {"x": 0.009216589861751154, "y": 0.5641921397379913, "ox": 0.009216589861751154, "oy": 0.5641921397379913, "term": "minimum years", "cat25k": 11, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.756634952428643, "os": 0.19281187842373576}, {"x": 0.0, "y": 0.4602620087336245, "ox": 0.0, "oy": 0.4602620087336245, "term": "PhD Masters", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6995493239859789, "os": 0.16866051710250332}, {"x": 0.0, "y": 0.4200873362445416, "ox": 0.0, "oy": 0.4200873362445416, "term": "Preferred Bachelors Science Computer Science Math Scientific Computing Data Analytics Machine Learning Business Analyst nanodegree equivalent experience", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6775162744116174, "os": 0.16022626756200278}, {"x": 0.0, "y": 0.4489082969432316, "ox": 0.0, "oy": 0.4489082969432316, "term": "data data sources", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6930395593390085, "os": 0.16661286337863845}, {"x": 0.0, "y": 0.3807860262008735, "ox": 0.0, "oy": 0.3807860262008735, "term": "Advanced knowledge R Experience SAS SPSS Experience", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.655983975963946, "os": 0.15277652597936886}, {"x": 0.0, "y": 0.2908296943231442, "ox": 0.0, "oy": 0.2908296943231442, "term": "Exposure Big Data technologies Hadoop Hive Advanced knowledge Excel Experience handling", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6054081121682524, "os": 0.1374710961051051}, {"x": 0.0, "y": 0.280349344978166, "ox": 0.0, "oy": 0.280349344978166, "term": "solid experience marketing analytics", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5993990986479719, "os": 0.13595143120438533}, {"x": 0.0, "y": 0.2768558951965066, "ox": 0.0, "oy": 0.2768558951965066, "term": "digital behavioural data", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5973960941412118, "os": 0.13529435537730194}, {"x": 0.0, "y": 0.13624454148471618, "ox": 0.0, "oy": 0.13624454148471618, "term": "segmentation predictive analytics", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5197796695042564, "os": 0.11530749641365354}, {"x": 0.0, "y": 0.12314410480349346, "ox": 0.0, "oy": 0.12314410480349346, "term": "information webpages product characteristics reviews", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.512769153730596, "os": 0.11372684058242695}, {"x": 0.0, "y": 0.6681222707423582, "ox": 0.0, "oy": 0.6681222707423582, "term": "track record application ML NLP", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8152228342513771, "os": 0.23689363126861704}, {"x": 0.0, "y": 0.46462882096069874, "ox": 0.0, "oy": 0.46462882096069874, "term": "global business rely diversity culture", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7020530796194291, "os": 0.16949374856596988}, {"x": 0.0, "y": 0.6384279475982534, "ox": 0.0, "oy": 0.6384279475982534, "term": "Multiple years", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7986980470706059, "os": 0.22259255080863039}, {"x": 0.0, "y": 0.46200873362445427, "ox": 0.0, "oy": 0.46200873362445427, "term": "statistical analysis Experience Python development", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.700550826239359, "os": 0.1688034387566401}, {"x": 0.0, "y": 0.41048034934497823, "ox": 0.0, "oy": 0.41048034934497823, "term": "Python SAS R statistical packages", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.672508763144717, "os": 0.15856295529220857}, {"x": 0.0, "y": 0.36419213973799136, "ox": 0.0, "oy": 0.36419213973799136, "term": "Master Degree Economics Math Statistics Finance Engineering similar discipline year experience business application machine", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6469704556835253, "os": 0.14874505680252395}, {"x": 0.0, "y": 0.32314410480349354, "ox": 0.0, "oy": 0.32314410480349354, "term": "Comfortable developing statistical models", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6239359038557837, "os": 0.1428199327248952}, {"x": 0.0, "y": 0.7056768558951966, "ox": 0.0, "oy": 0.7056768558951966, "term": "Bachelor Degree Economics Math Science Finance", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8352528793189784, "os": 0.25698001003330734}, {"x": 0.0, "y": 0.1851528384279476, "ox": 0.0, "oy": 0.1851528384279476, "term": "similar discipline", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5458187280921382, "os": 0.12147494813024291}, {"x": 0.0, "y": 0.3074235807860263, "ox": 0.0, "oy": 0.3074235807860263, "term": "Experience working scientists R D systems", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.614922383575363, "os": 0.13971748068380155}, {"x": 0.0, "y": 0.26986899563318784, "ox": 0.0, "oy": 0.26986899563318784, "term": "good organizational communication analytical technical writing skills", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5933900851276914, "os": 0.13388539596793603}, {"x": 0.0, "y": 0.22183406113537124, "ox": 0.0, "oy": 0.22183406113537124, "term": "data science statistics", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5668502754131197, "os": 0.12622399023503914}, {"x": 0.0, "y": 0.19912663755458518, "ox": 0.0, "oy": 0.19912663755458518, "term": "Experience scripting languages", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5538307461191787, "os": 0.12340376022907072}, {"x": 0.0, "y": 0.6427947598253276, "ox": 0.0, "oy": 0.6427947598253276, "term": "healthcare domain Masters PhD Application data science solutions industrial projects", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.801201802704056, "os": 0.225125426420805}, {"x": 0.0, "y": 0.800873362445415, "ox": 0.0, "oy": 0.800873362445415, "term": "data science problems", "cat25k": 20, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8883324987481221, "os": 0.35181404174277986}, {"x": 0.0, "y": 0.7903930131004369, "ox": 0.0, "oy": 0.7903930131004369, "term": "Masters PhD Application", "cat25k": 19, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8813219829744616, "os": 0.33846556454088483}, {"x": 0.0, "y": 0.4227074235807861, "ox": 0.0, "oy": 0.4227074235807861, "term": "BS MS PhD healthcare related field Minimum years", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6790185277916875, "os": 0.16086609672934665}, {"x": 0.0, "y": 0.23755458515283848, "ox": 0.0, "oy": 0.23755458515283848, "term": "BS MS PhD", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5758637956935403, "os": 0.12837741145967574}, {"x": 0.0, "y": 0.6934497816593888, "ox": 0.0, "oy": 0.6934497816593888, "term": "A love games", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.828242363545318, "os": 0.24999999999999997}, {"x": 0.0, "y": 0.1423580786026201, "ox": 0.0, "oy": 0.1423580786026201, "term": "related field minimum years general management experience business marketing analytics field equivalent combination experience training", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5227841762643967, "os": 0.11580046286893748}, {"x": 0.02211981566820277, "y": 0.02882096069868996, "ox": 0.02211981566820277, "oy": 0.02882096069868996, "term": "Alteryx", "cat25k": 3, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.499749624436655, "os": 0.05028077728147317}, {"x": 0.0, "y": 0.1388646288209607, "ox": 0.0, "oy": 0.1388646288209607, "term": "CRM", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5207811717576364, "os": 0.11548916279196844}, {"x": 0.0, "y": 0.4960698689956333, "ox": 0.0, "oy": 0.4960698689956333, "term": "internship school project", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7195793690535803, "os": 0.1755784839564672}, {"x": 0.0, "y": 0.35895196506550225, "ox": 0.0, "oy": 0.35895196506550225, "term": "Machine Learning Algorithms Statistics", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.643965948923385, "os": 0.14765009840771978}, {"x": 0.0, "y": 0.29606986899563326, "ox": 0.0, "oy": 0.29606986899563326, "term": "Python R Programming", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6084126189283926, "os": 0.13810740073899636}, {"x": 0.0, "y": 0.27074235807860264, "ox": 0.0, "oy": 0.27074235807860264, "term": "engine implementation", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5938908362543815, "os": 0.13401324156539504}, {"x": 0.0, "y": 0.20000000000000004, "ox": 0.0, "oy": 0.20000000000000004, "term": "Theoretical knowledge Machine Learning Algorithms Statistics etc Basic coding ability", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5543314972458688, "os": 0.12340523058138786}, {"x": 0.0, "y": 0.7144104803493451, "ox": 0.0, "oy": 0.7144104803493451, "term": "young growing company", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8402603905858788, "os": 0.2608068623959588}, {"x": 0.0, "y": 0.303056768558952, "ox": 0.0, "oy": 0.303056768558952, "term": "today", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6124186279419128, "os": 0.1389732147177363}, {"x": 0.0, "y": 0.24279475982532756, "ox": 0.0, "oy": 0.24279475982532756, "term": "Fetch", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5783675513269905, "os": 0.1294096178853818}, {"x": 0.0, "y": 0.7615720524017469, "ox": 0.0, "oy": 0.7615720524017469, "term": "web mobile applications business intelligence tools", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8647971957936906, "os": 0.31053380567540323}, {"x": 0.0, "y": 0.6777292576419215, "ox": 0.0, "oy": 0.6777292576419215, "term": "Building", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8202303455182774, "os": 0.24062426851434826}, {"x": 0.1797235023041475, "y": 0.06899563318777294, "ox": 0.1797235023041475, "oy": 0.06899563318777294, "term": "data systems", "cat25k": 5, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.42213319979969954, "os": -0.09499981803763514}, {"x": 0.0, "y": 0.6401746724890831, "ox": 0.0, "oy": 0.6401746724890831, "term": "Crown Center", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7996995493239859, "os": 0.22369220085444674}, {"x": 0.0, "y": 0.3746724890829695, "ox": 0.0, "oy": 0.3746724890829695, "term": "site cafeteria", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6529794692038057, "os": 0.15130319566206213}, {"x": 0.0, "y": 0.33187772925764203, "ox": 0.0, "oy": 0.33187772925764203, "term": "Machine Learning algorithms models", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.628442663995994, "os": 0.143743815355129}, {"x": 0.0, "y": 0.25152838427947605, "ox": 0.0, "oy": 0.25152838427947605, "term": "Background Machine Learning Statistics Information Retrieval Design", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5833750625938907, "os": 0.12993325491554136}, {"x": 0.0, "y": 0.2244541484716158, "ox": 0.0, "oy": 0.2244541484716158, "term": "Scala Golang Haskell Clojure", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5683525287931898, "os": 0.12659847390188672}, {"x": 0.12258064516129034, "y": 0.023580786026200878, "ox": 0.12258064516129034, "oy": 0.023580786026200878, "term": "collaborative environment", "cat25k": 3, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4516775162744116, "os": -0.08485406950575508}, {"x": 0.5972350230414748, "y": 0.10131004366812228, "ox": 0.5972350230414748, "oy": 0.10131004366812228, "term": "Write", "cat25k": 6, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21331997996995494, "os": -0.19209862564623825}, {"x": 0.4138248847926268, "y": 0.008733624454148473, "ox": 0.4138248847926268, "oy": 0.008733624454148473, "term": "company", "cat25k": 2, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3034551827741612, "os": -0.1336846966943919}, {"x": 0.04423963133640554, "y": 0.007860262008733626, "ox": 0.04423963133640554, "oy": 0.007860262008733626, "term": "features", "cat25k": 2, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4882323485227842, "os": -0.06316594665977965}, {"x": 0.014746543778801845, "y": 0.006986899563318778, "ox": 0.014746543778801845, "oy": 0.006986899563318778, "term": "Superb", "cat25k": 2, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4967451176765148, "os": -0.03847941195247442}, {"x": 0.0, "y": 0.30917030567685594, "ox": 0.0, "oy": 0.30917030567685594, "term": "new trends data science", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6159238858287431, "os": 0.1407478680229112}, {"x": 0.0, "y": 0.2340611353711791, "ox": 0.0, "oy": 0.2340611353711791, "term": "implementation data science project", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5738607911867801, "os": 0.12809931275693612}, {"x": 0.0, "y": 0.20087336244541487, "ox": 0.0, "oy": 0.20087336244541487, "term": "digital marketing data", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5548322483725588, "os": 0.1235232213260736}, {"x": 0.0, "y": 0.1938864628820961, "ox": 0.0, "oy": 0.1938864628820961, "term": "connecting data", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5508262393590385, "os": 0.12288472793440103}, {"x": 0.28202764976958533, "y": 0.09082969432314413, "ox": 0.28202764976958533, "oy": 0.09082969432314413, "term": "new challenges", "cat25k": 6, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.36855282924386584, "os": -0.11118441318450857}, {"x": 0.4672811059907835, "y": 0.05502183406113537, "ox": 0.4672811059907835, "oy": 0.05502183406113537, "term": "business", "cat25k": 4, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2769153730595894, "os": -0.14995032991418739}, {"x": 0.03963133640552996, "y": 0.038427947598253284, "ox": 0.03963133640552996, "oy": 0.038427947598253284, "term": "Education", "cat25k": 3, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.48923385077616427, "os": -0.06068734361882514}, {"x": 0.04516129032258065, "y": 0.841048034934498, "ox": 0.04516129032258065, "oy": 0.841048034934498, "term": "New York NY", "cat25k": 24, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9098647971957937, "os": 0.43301270189221913}, {"x": 0.10138248847926268, "y": 0.7772925764192141, "ox": 0.10138248847926268, "oy": 0.7772925764192141, "term": "New York", "cat25k": 18, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8738107160741111, "os": 0.3263027573257299}, {"x": 0.5096774193548389, "y": 0.1126637554585153, "ox": 0.5096774193548389, "oy": 0.1126637554585153, "term": "clients", "cat25k": 6, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2548823234852279, "os": -0.1577672102560009}, {"x": 0.0, "y": 0.3275109170305678, "ox": 0.0, "oy": 0.3275109170305678, "term": "real world Experience Python", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6264396594892339, "os": 0.1431535853180977}, {"x": 0.0, "y": 0.23668122270742362, "ox": 0.0, "oy": 0.23668122270742362, "term": "natural language processing Development deployment software", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5753630445668503, "os": 0.1283760839909503}, {"x": 0.0, "y": 0.20960698689956336, "ox": 0.0, "oy": 0.20960698689956336, "term": "related degree equivalent experience years", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5598397596394592, "os": 0.12444779534987158}, {"x": 0.0, "y": 0.20349344978165942, "ox": 0.0, "oy": 0.20349344978165942, "term": "work ethic passion problem", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5563345017526289, "os": 0.12385091188419345}, {"x": 0.0, "y": 0.25764192139737996, "ox": 0.0, "oy": 0.25764192139737996, "term": "Familiar data pipelines", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5868803204807211, "os": 0.13169648910183587}, {"x": 0.6847926267281107, "y": 0.6489082969432316, "ox": 0.6847926267281107, "oy": 0.6489082969432316, "term": "knowledge", "cat25k": 13, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8047070605908863, "os": 0.22834073395733462}, {"x": 0.0, "y": 0.7423580786026203, "ox": 0.0, "oy": 0.7423580786026203, "term": "smartest people", "cat25k": 16, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8547821732598898, "os": 0.29064737094615933}, {"x": 0.0, "y": 0.44192139737991276, "ox": 0.0, "oy": 0.44192139737991276, "term": "boundaries", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6895343014521782, "os": 0.164191770372194}, {"x": 0.0, "y": 0.42445414847161583, "ox": 0.0, "oy": 0.42445414847161583, "term": "Huge technical problems", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6800200300450676, "os": 0.16095789879425387}, {"x": 0.0, "y": 0.4951965065502184, "ox": 0.0, "oy": 0.4951965065502184, "term": "extensive operational data analysis experience data analysis regression analysis", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7190786179268903, "os": 0.17550883717574783}, {"x": 0.0, "y": 0.43406113537117913, "ox": 0.0, "oy": 0.43406113537117913, "term": "industry experience predictive modeling data science analysis Programming experience", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.685027541311968, "os": 0.16278948872828128}, {"x": 0.0, "y": 0.3458515283842795, "ox": 0.0, "oy": 0.3458515283842795, "term": "Python R equivalent Demonstrated experience data science data analysis Desire", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6364546820230345, "os": 0.14552444295668482}, {"x": 0.0, "y": 0.22270742358078607, "ox": 0.0, "oy": 0.22270742358078607, "term": "Comfortable Linux environment Experience Amazon Web Services AWS", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5673510265398096, "os": 0.12629889294625252}, {"x": 0.0, "y": 0.21834061135371186, "ox": 0.0, "oy": 0.21834061135371186, "term": "e g Computer Science Operations Research Systems Engineering Physics equivalent experience years", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5648472709063594, "os": 0.12581539125539362}, {"x": 0.7935483870967743, "y": 0.03493449781659389, "ox": 0.7935483870967743, "oy": 0.03493449781659389, "term": "Desire", "cat25k": 3, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11016524787180772, "os": -0.3027682821642871}, {"x": 0.0, "y": 0.4864628820960699, "ox": 0.0, "oy": 0.4864628820960699, "term": "healthcare data", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.71457185778668, "os": 0.17337031186764817}, {"x": 0.036866359447004615, "y": 0.02620087336244542, "ox": 0.036866359447004615, "oy": 0.02620087336244542, "term": "Advanced", "cat25k": 3, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.49023535302954435, "os": -0.05867363384092288}, {"x": 0.5677419354838711, "y": 0.05414847161572053, "ox": 0.5677419354838711, "oy": 0.05414847161572053, "term": "areas", "cat25k": 4, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.22684026039058588, "os": -0.1813970902228858}, {"x": 0.15023041474654378, "y": 0.0008733624454148473, "ox": 0.15023041474654378, "oy": 0.0008733624454148473, "term": "five years", "cat25k": 1, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.43715573360040066, "os": -0.08989497251965435}, {"x": 0.0, "y": 0.5825327510917032, "ox": 0.0, "oy": 0.5825327510917032, "term": "Chief Statistician Next message Jobs Tenure track position University Hawaii Messages", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7666499749624437, "os": 0.19800344324350086}, {"x": 0.0, "y": 0.4375545851528385, "ox": 0.0, "oy": 0.4375545851528385, "term": "University Hawaii Messages", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6870305458187281, "os": 0.1635256074853059}, {"x": 0.0, "y": 0.7563318777292578, "ox": 0.0, "oy": 0.7563318777292578, "term": "Jobs Fwd OMB", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8617926890335503, "os": 0.3033344712384062}, {"x": 0.0, "y": 0.35633187772925773, "ox": 0.0, "oy": 0.35633187772925773, "term": "Jobs Tenure", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.642463695543315, "os": 0.14722945253665914}, {"x": 0.0, "y": 0.4497816593886464, "ox": 0.0, "oy": 0.4497816593886464, "term": "Statistician", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6935403104656985, "os": 0.1671093034870521}, {"x": 0.0, "y": 0.37205240174672494, "ox": 0.0, "oy": 0.37205240174672494, "term": "Python R similar data science language Advanced proficiency data visualization Prefer financial services industry experience Prefer experience CRM financial analysis financial advisory Bachelors Master degree Computer Science Math Data Science Statistics", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6514772158237355, "os": 0.15113754228419643}, {"x": 0.0, "y": 0.5790393013100438, "ox": 0.0, "oy": 0.5790393013100438, "term": "Best Corporate Citizens InformationWeek", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7646469704556835, "os": 0.19669410693284783}, {"x": 0.0, "y": 0.5589519650655023, "ox": 0.0, "oy": 0.5589519650655023, "term": "FORTUNE World Most Admired Companies Corporate Responsibility Magazine Best Corporate Citizens", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7536304456685028, "os": 0.19147452894563152}, {"x": 0.0, "y": 0.5458515283842795, "ox": 0.0, "oy": 0.5458515283842795, "term": "Elite Women Business Enterprise National Council America Top Corporations Women Business Enterprises Reputation Institute World Most Reputable Companies", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7471206810215323, "os": 0.1870974639108549}, {"x": 0.0, "y": 0.468995633187773, "ox": 0.0, "oy": 0.468995633187773, "term": "Corporate Responsibility Magazine", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7045568352528793, "os": 0.17002558665561687}, {"x": 0.0, "y": 0.3659388646288211, "ox": 0.0, "oy": 0.3659388646288211, "term": "FORTUNE World Most Admired Companies", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6479719579369053, "os": 0.14920133671800753}, {"x": 0.0, "y": 0.3668122270742359, "ox": 0.0, "oy": 0.3668122270742359, "term": "diverse technical non technical audiences", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6484727090635954, "os": 0.14947894491386318}, {"x": 0.2451612903225807, "y": 0.6943231441048037, "ox": 0.2451612903225807, "oy": 0.6943231441048037, "term": "technical concepts", "cat25k": 14, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.828743114672008, "os": 0.25024331696095614}, {"x": 0.0, "y": 0.8497816593886465, "ox": 0.0, "oy": 0.8497816593886465, "term": "Doctorate Preferred", "cat25k": 26, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9173760640961443, "os": 0.4714045207910316}, {"x": 0.0, "y": 0.29432314410480354, "ox": 0.0, "oy": 0.29432314410480354, "term": "Python development language emphasis data science Experience Python data analysis packages", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6074111166750125, "os": 0.13795590141171823}, {"x": 0.0, "y": 0.24978165938864635, "ox": 0.0, "oy": 0.24978165938864635, "term": "Postgres Knowledge Bayesian data analysis methods model comparison", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5823735603405107, "os": 0.1297947805979622}, {"x": 0.0, "y": 0.8436681222707425, "ox": 0.0, "oy": 0.8436681222707425, "term": "Technologies Linux Python", "cat25k": 25, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9138708062093139, "os": 0.4485244621691702}, {"x": 0.0, "y": 0.4471615720524018, "ox": 0.0, "oy": 0.4471615720524018, "term": "Numerical topic", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6925388082123185, "os": 0.16600229555606477}, {"x": 0.0, "y": 0.4000000000000001, "ox": 0.0, "oy": 0.4000000000000001, "term": "MS PhD degree Computer Science Artificial Intelligence Machine Learning", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6670005007511267, "os": 0.1564076256059939}, {"x": 0.38801843317972357, "y": 0.38602620087336253, "ox": 0.38801843317972357, "oy": 0.38602620087336253, "term": "technical field", "cat25k": 9, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.658988482724086, "os": 0.15370915147213973}, {"x": 0.8423963133640554, "y": 0.680349344978166, "ox": 0.8423963133640554, "oy": 0.680349344978166, "term": "Spark Hadoop", "cat25k": 13, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08412618928392589, "os": -0.3600871479971183}, {"x": 0.0, "y": 0.3816593886462883, "ox": 0.0, "oy": 0.3816593886462883, "term": "analysis Experience machine", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6564847270906359, "os": 0.1529892394663261}, {"x": 0.0, "y": 0.3519650655021835, "ox": 0.0, "oy": 0.3519650655021835, "term": "Python scikit computer language experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6399599399098648, "os": 0.14691725027816638}, {"x": 0.0, "y": 0.34759825327510924, "ox": 0.0, "oy": 0.34759825327510924, "term": "statistical software Insurance industry experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6374561842764146, "os": 0.1456610811160259}, {"x": 0.0, "y": 0.31441048034934505, "ox": 0.0, "oy": 0.31441048034934505, "term": "progressive experience data science statistical analysis data modeling years", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6189283925888833, "os": 0.1415058021561058}, {"x": 0.0, "y": 0.2122270742358079, "ox": 0.0, "oy": 0.2122270742358079, "term": "regression segmentation decision tree time series design experiments", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5613420130195292, "os": 0.12474392451579702}, {"x": 0.0, "y": 0.7161572052401748, "ox": 0.0, "oy": 0.7161572052401748, "term": "Advanced Degree", "cat25k": 15, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8412618928392589, "os": 0.26099183937612236}, {"x": 0.0, "y": 0.5091703056768561, "ox": 0.0, "oy": 0.5091703056768561, "term": "MBA", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7270906359539309, "os": 0.17776537474909693}, {"x": 0.0, "y": 0.2165938864628821, "ox": 0.0, "oy": 0.2165938864628821, "term": "internal data processing visualization tools years", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5638457686529794, "os": 0.12562782038546624}, {"x": 0.959447004608295, "y": 0.044541484716157216, "ox": 0.959447004608295, "oy": 0.044541484716157216, "term": "data sources", "cat25k": 3, "ncat25k": 62, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.020530796194291438, "os": -0.8692261697959914}, {"x": 0.319815668202765, "y": 0.03755458515283844, "ox": 0.319815668202765, "oy": 0.03755458515283844, "term": "data warehouses", "cat25k": 3, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3510265398097146, "os": -0.11762956727545718}, {"x": 0.0, "y": 0.31091703056768566, "ox": 0.0, "oy": 0.31091703056768566, "term": "Regularization Boosting Random Forests Decision Trees Bayesian", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6169253880821232, "os": 0.14092235736341635}, {"x": 0.0, "y": 0.2235807860262009, "ox": 0.0, "oy": 0.2235807860262009, "term": "Washington DC", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5678517776664997, "os": 0.12659489774166538}, {"x": 0.7714285714285716, "y": 0.03668122270742359, "ox": 0.7714285714285716, "oy": 0.03668122270742359, "term": "hour", "cat25k": 3, "ncat25k": 20, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12168252378567851, "os": -0.2795984421205809}, {"x": 0.0, "y": 0.766812227074236, "ox": 0.0, "oy": 0.766812227074236, "term": "U S", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8683024536805208, "os": 0.3123501887480784}, {"x": 0.01751152073732719, "y": 0.020960698689956335, "ox": 0.01751152073732719, "oy": 0.020960698689956335, "term": "Willingness", "cat25k": 2, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.499248873309965, "os": 0.04123332412515369}, {"x": 0.3898617511520738, "y": 0.01310043668122271, "ox": 0.3898617511520738, "oy": 0.01310043668122271, "term": "Designing", "cat25k": 2, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3164747120681022, "os": -0.12866755149466869}, {"x": 0.6820276497695854, "y": 0.009606986899563321, "ox": 0.6820276497695854, "oy": 0.009606986899563321, "term": "Health", "cat25k": 2, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1697546319479219, "os": -0.22711383936453763}, {"x": 0.0, "y": 0.7764192139737993, "ox": 0.0, "oy": 0.7764192139737993, "term": "Google Analytics Adobe Analytics Experience", "cat25k": 18, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8733099649474212, "os": 0.3220676082083148}, {"x": 0.0, "y": 0.3510917030567686, "ox": 0.0, "oy": 0.3510917030567686, "term": "analyzing data 3rd party providers", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6394591887831748, "os": 0.14671083832954734}, {"x": 0.0, "y": 0.31703056768558957, "ox": 0.0, "oy": 0.31703056768558957, "term": "Hadoop Hive Spark Experience visualizing", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6204306459689534, "os": 0.14179970256456093}, {"x": 0.0, "y": 0.21397379912663758, "ox": 0.0, "oy": 0.21397379912663758, "term": "Map Reduce Hadoop Hive", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5623435152729094, "os": 0.12482261050455051}, {"x": 0.0, "y": 0.16681222707423582, "ox": 0.0, "oy": 0.16681222707423582, "term": "data computing tools", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5358037055583375, "os": 0.11897425461615699}, {"x": 0.03225806451612904, "y": 0.0331877729257642, "ox": 0.03225806451612904, "oy": 0.0331877729257642, "term": "etc Experience", "cat25k": 3, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.49173760640961445, "os": -0.056508681192195646}, {"x": 0.0, "y": 0.4393013100436682, "ox": 0.0, "oy": 0.4393013100436682, "term": "data science analysis", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6880320480721082, "os": 0.16386713727077862}, {"x": 0.0, "y": 0.34410480349344985, "ox": 0.0, "oy": 0.34410480349344985, "term": "preferred Excellent communication collaborative skills years", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6354531797696544, "os": 0.14527721857605022}, {"x": 0.0, "y": 0.3161572052401747, "ox": 0.0, "oy": 0.3161572052401747, "term": "Python R C", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6199298948422634, "os": 0.1417035182742587}, {"x": 0.0, "y": 0.17991266375545853, "ox": 0.0, "oy": 0.17991266375545853, "term": "Mathematics Physics Engineering MS PhD", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.542814221331998, "os": 0.12119601446419997}, {"x": 0.0, "y": 0.6707423580786027, "ox": 0.0, "oy": 0.6707423580786027, "term": "Scikit Learn Keras TensorFlow", "cat25k": 13, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8167250876314471, "os": 0.23813626211909344}, {"x": 0.0, "y": 0.6000000000000001, "ox": 0.0, "oy": 0.6000000000000001, "term": "ongoing operational needs", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7766649974962444, "os": 0.2042350531286779}, {"x": 0.0, "y": 0.5615720524017469, "ox": 0.0, "oy": 0.5615720524017469, "term": "satisfactory job performance continuing availability funds", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7551326990485728, "os": 0.1924985903997622}, {"x": 0.0, "y": 0.37117903930131013, "ox": 0.0, "oy": 0.37117903930131013, "term": "This full time year term appointment possibility extension conversion Career appointment", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6509764646970456, "os": 0.15054795238716925}, {"x": 0.5483870967741936, "y": 0.09519650655021836, "ox": 0.5483870967741936, "oy": 0.09519650655021836, "term": "Career", "cat25k": 6, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23585378067100654, "os": -0.17157056831827186}, {"x": 0.0, "y": 0.6305676855895198, "ox": 0.0, "oy": 0.6305676855895198, "term": "quantitative methods principles statistics", "cat25k": 12, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7941912869303956, "os": 0.22032765453150516}, {"x": 0.0, "y": 0.5598253275109171, "ox": 0.0, "oy": 0.5598253275109171, "term": "masters level degree statistics biostatistics related fields", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7541311967951928, "os": 0.19159423942944268}, {"x": 0.0, "y": 0.434934497816594, "ox": 0.0, "oy": 0.434934497816594, "term": "research setting", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.685528292438658, "os": 0.16281976182205798}, {"x": 0.0, "y": 0.4628820960698691, "ox": 0.0, "oy": 0.4628820960698691, "term": "data sets", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7010515773660491, "os": 0.16910547256812392}, {"x": 0.0, "y": 0.4401746724890831, "ox": 0.0, "oy": 0.4401746724890831, "term": "USAID", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6885327991987982, "os": 0.16388557698607464}, {"x": 0.9788018433179723, "y": 0.02183406113537118, "ox": 0.9788018433179723, "oy": 0.02183406113537118, "term": "Design", "cat25k": 2, "ncat25k": 161, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 2, "s": 0.010515773660490736, "os": -2.27708656674403}, {"x": 0.0, "y": 0.1493449781659389, "ox": 0.0, "oy": 0.1493449781659389, "term": "modeling data mining years", "cat25k": 6, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5262894341512269, "os": 0.11666731093620618}, {"x": 0.0, "y": 0.21310043668122272, "ox": 0.0, "oy": 0.21310043668122272, "term": "Millions Billions", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5618427641462194, "os": 0.12481023870999737}, {"x": 0.0, "y": 0.841048034934498, "ox": 0.0, "oy": 0.841048034934498, "term": "Interest causal inference", "cat25k": 24, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9098647971957937, "os": 0.43301270189221913}, {"x": 0.0, "y": 0.30131004366812236, "ox": 0.0, "oy": 0.30131004366812236, "term": "SAS Enterprise Guide manipulate data", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6114171256885328, "os": 0.13876970017551532}, {"x": 0.0, "y": 0.17816593886462886, "ox": 0.0, "oy": 0.17816593886462886, "term": "SAS Enterprise Guide", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5418127190786178, "os": 0.12078561687984325}, {"x": 0.0, "y": 0.17641921397379914, "ox": 0.0, "oy": 0.17641921397379914, "term": "broader goal", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5408112168252378, "os": 0.12034252362359937}, {"x": 0.0, "y": 0.600873362445415, "ox": 0.0, "oy": 0.600873362445415, "term": "Strong interest gaming industry", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7771657486229343, "os": 0.2044696962685844}, {"x": 0.0, "y": 0.4759825327510918, "ox": 0.0, "oy": 0.4759825327510918, "term": "HiveQL Knowledge data visualization Experience advanced analytics", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7085628442663996, "os": 0.17127274365941952}, {"x": 0.0, "y": 0.37641921397379924, "ox": 0.0, "oy": 0.37641921397379924, "term": "software engineer data engineer data scientist Proficiency R", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6539809714571857, "os": 0.15134139170327898}, {"x": 0.0, "y": 0.7510917030567688, "ox": 0.0, "oy": 0.7510917030567688, "term": "Advanced Degree Mathematics Statistics Economics Computer Science related fields", "cat25k": 17, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8592889334001002, "os": 0.3}, {"x": 0.0, "y": 0.7100436681222708, "ox": 0.0, "oy": 0.7100436681222708, "term": "Degree Mathematics Statistics Economics Computer Science", "cat25k": 14, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8377566349524286, "os": 0.2585235193068112}, {"x": 0.0, "y": 0.8917030567685591, "ox": 0.0, "oy": 0.8917030567685591, "term": "Amazon Web Services AWS", "cat25k": 41, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9394091136705057, "os": 0.7289740320371404}, {"x": 0.0, "y": 0.5344978165938866, "ox": 0.0, "oy": 0.5344978165938866, "term": "Proficient R Python", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7406109163745618, "os": 0.1833830302925752}, {"x": 0.0, "y": 0.5013100436681224, "ox": 0.0, "oy": 0.5013100436681224, "term": "tasks text mining sentiment analysis language", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7225838758137206, "os": 0.17609372451296748}, {"x": 0.0, "y": 0.406113537117904, "ox": 0.0, "oy": 0.406113537117904, "term": "professional experience Data Scientist NLP experience", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6700050075112668, "os": 0.15759302844026382}, {"x": 0.0, "y": 0.39737991266375555, "ox": 0.0, "oy": 0.39737991266375555, "term": "unstructured text data", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6654982473710566, "os": 0.1561116848314744}, {"x": 0.0, "y": 0.3912663755458516, "ox": 0.0, "oy": 0.3912663755458516, "term": "classification information retrieval", "cat25k": 9, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6619929894842264, "os": 0.15452394316768556}, {"x": 0.35115207373271895, "y": 0.08384279475982534, "ox": 0.35115207373271895, "oy": 0.08384279475982534, "term": "process", "cat25k": 5, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.33550325488232347, "os": -0.12180931193304835}, {"x": 0.031336405529953926, "y": 0.024454148471615724, "ox": 0.031336405529953926, "oy": 0.024454148471615724, "term": "initiative", "cat25k": 3, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4922383575363045, "os": -0.055499197546217696}, {"x": 0.0, "y": 0.1877729257641922, "ox": 0.0, "oy": 0.1877729257641922, "term": "U S government U S citizenship", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5473209814722083, "os": 0.12181177096067126}, {"x": 0.2230414746543779, "y": 0.08471615720524019, "ox": 0.2230414746543779, "oy": 0.08471615720524019, "term": "Minimum years experience", "cat25k": 5, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3985978968452679, "os": -0.10317433143925775}, {"x": 0.0, "y": 0.5388646288209609, "ox": 0.0, "oy": 0.5388646288209609, "term": "Familiarity Agile", "cat25k": 10, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.743114672008012, "os": 0.184661161935961}, {"x": 0.0, "y": 0.8034934497816595, "ox": 0.0, "oy": 0.8034934497816595, "term": "k NN Naive Bayes SVM Decision Forests", "cat25k": 20, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8898347521281923, "os": 0.3562040792919148}, {"x": 0.0, "y": 0.2829694323144105, "ox": 0.0, "oy": 0.2829694323144105, "term": "Intermediate advanced experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.600901352028042, "os": 0.1362194924341469}, {"x": 0.0, "y": 0.24541484716157214, "ox": 0.0, "oy": 0.24541484716157214, "term": "original innovative techniques style Ability", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5798698047070605, "os": 0.12952921205131943}, {"x": 0.0, "y": 0.37991266375545857, "ox": 0.0, "oy": 0.37991266375545857, "term": "Python Java B S Computer Science Software Engineering Information Science Mathematics Statistics Electrical Engineering Physics related fields", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6554832248372559, "os": 0.15241212238059992}, {"x": 0.0073732718894009225, "y": 0.22707423580786032, "ox": 0.0073732718894009225, "oy": 0.22707423580786032, "term": "Communication", "cat25k": 7, "ncat25k": 2, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5698547821732598, "os": 0.12768404174012382}, {"x": 0.01658986175115208, "y": 0.0017467248908296946, "ox": 0.01658986175115208, "oy": 0.0017467248908296946, "term": "seven years", "cat25k": 1, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4957436154231347, "os": -0.04005941170948063}, {"x": 0.0, "y": 0.36157205240174684, "ox": 0.0, "oy": 0.36157205240174684, "term": "large volume data Experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6454682023034551, "os": 0.14835719283212673}, {"x": 0.0, "y": 0.3537117903930132, "ox": 0.0, "oy": 0.3537117903930132, "term": "healthcare industry Proven ability experience design development solutions increasing yield Proven analytical skills experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6409614421632449, "os": 0.1470478174805039}, {"x": 0.0, "y": 0.21484716157205244, "ox": 0.0, "oy": 0.21484716157205244, "term": "statistical analysis data mining algorithms mathematical segmentation", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5628442663995994, "os": 0.1253066451698202}, {"x": 0.0, "y": 0.20611353711790398, "ox": 0.0, "oy": 0.20611353711790398, "term": "Working knowledge statistical programming languages", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.557836755132699, "os": 0.12421685889155652}, {"x": 0.0, "y": 0.18427947598253278, "ox": 0.0, "oy": 0.18427947598253278, "term": "Strong SQL experience ability", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5453179769654481, "os": 0.12143263600904404}, {"x": 0.0, "y": 0.26113537117903934, "ox": 0.0, "oy": 0.26113537117903934, "term": "clear precise actionable manner", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5883825738607911, "os": 0.1318883477983936}, {"x": 0.0, "y": 0.21921397379912666, "ox": 0.0, "oy": 0.21921397379912666, "term": "Travel Master Degree statistics actuarial science related field study Experience data mining predictive modeling experience", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5653480220330496, "os": 0.12581984697353124}, {"x": 0.0, "y": 0.20436681222707426, "ox": 0.0, "oy": 0.20436681222707426, "term": "Extensive knowledge tools data mining statistics Experience HR Analytics Strong knowledge MS Office products", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.556835252879319, "os": 0.12385140974017848}, {"x": 0.0, "y": 0.19650655021834065, "ox": 0.0, "oy": 0.19650655021834065, "term": "statistical modeling programming Experience Tableau", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5523284927391087, "os": 0.12321378185697697}, {"x": 0.10691244239631337, "y": 0.05589519650655023, "ox": 0.10691244239631337, "oy": 0.05589519650655023, "term": "team environment", "cat25k": 4, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4596895343014522, "os": -0.08292055338522997}, {"x": 0.4101382488479263, "y": 0.05065502183406115, "ox": 0.4101382488479263, "oy": 0.05065502183406115, "term": "MS Office", "cat25k": 4, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3054581872809214, "os": -0.13247927490992084}, {"x": 0.0, "y": 0.8139737991266377, "ox": 0.0, "oy": 0.8139737991266377, "term": "measurement teams product teams members", "cat25k": 21, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8953430145217827, "os": 0.37273708420148155}, {"x": 0.0, "y": 0.8017467248908299, "ox": 0.0, "oy": 0.8017467248908299, "term": "wider analytical teams", "cat25k": 20, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.8888332498748122, "os": 0.3538548689805455}, {"x": 0.335483870967742, "y": 0.17117903930131007, "ox": 0.335483870967742, "oy": 0.17117903930131007, "term": "challenges years work experience technology industry", "cat25k": 7, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.343014521782674, "os": -0.11926686703315065}, {"x": 0.3216589861751153, "y": 0.15633187772925766, "ox": 0.3216589861751153, "oy": 0.15633187772925766, "term": "public speaking engagements Extensive software development experience", "cat25k": 7, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3500250375563345, "os": -0.11777152952829353}, {"x": 0.30691244239631343, "y": 0.13799126637554587, "ox": 0.30691244239631343, "oy": 0.13799126637554587, "term": "Extensive experience software development expertise", "cat25k": 6, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.35703555332999504, "os": -0.11545614258434352}, {"x": 0.2506912442396314, "y": 0.0943231441048035, "ox": 0.2506912442396314, "oy": 0.0943231441048035, "term": "Strong customer facing relationship building skills", "cat25k": 6, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.38507761642463695, "os": -0.10615870108739908}, {"x": 0.23041474654377886, "y": 0.09170305676855896, "ox": 0.23041474654377886, "oy": 0.09170305676855896, "term": "present big picture offer solutions", "cat25k": 6, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.39459188783174765, "os": -0.10397276175796123}, {"x": 0.20092165898617514, "y": 0.08908296943231442, "ox": 0.20092165898617514, "oy": 0.08908296943231442, "term": "custom solutions", "cat25k": 6, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4106159238858288, "os": -0.09919457243572793}, {"x": 0.1926267281105991, "y": 0.08646288209606987, "ox": 0.1926267281105991, "oy": 0.08646288209606987, "term": "Python Experience", "cat25k": 5, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.41512268402603913, "os": -0.09754513321960719}, {"x": 0.14746543778801846, "y": 0.07860262008733625, "ox": 0.14746543778801846, "oy": 0.07860262008733625, "term": "Prior technical paper publications", "cat25k": 5, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4381572358537807, "os": -0.08969024681712404}, {"x": 0.13917050691244243, "y": 0.07510917030567686, "ox": 0.13917050691244243, "oy": 0.07510917030567686, "term": "business challenges", "cat25k": 5, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.44266399599399103, "os": -0.0882328992805693}, {"x": 0.13364055299539174, "y": 0.07248908296943231, "ox": 0.13364055299539174, "oy": 0.07248908296943231, "term": "bright charismatic people", "cat25k": 5, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4456685027541312, "os": -0.08699486682740706}, {"x": 0.0912442396313364, "y": 0.06637554585152838, "ox": 0.0912442396313364, "oy": 0.06637554585152838, "term": "highly reliable cloud services Experience", "cat25k": 4, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.46770155232849275, "os": -0.08051086510822592}, {"x": 0.04608294930875577, "y": 0.04890829694323145, "ox": 0.04608294930875577, "oy": 0.04890829694323145, "term": "Strong algorithmic problem", "cat25k": 4, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4877315973960942, "os": -0.06769566163132952}, {"x": 0.04147465437788019, "y": 0.04541484716157206, "ox": 0.04147465437788019, "oy": 0.04541484716157206, "term": "highly reliable service offerings", "cat25k": 3, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4887330996494742, "os": -0.061462002814272054}, {"x": 0.45898617511520745, "y": 0.042794759825327516, "ox": 0.45898617511520745, "oy": 0.042794759825327516, "term": "C", "cat25k": 3, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2809213820731097, "os": -0.1469423290142034}, {"x": 0.03317972350230415, "y": 0.03930131004366813, "ox": 0.03317972350230415, "oy": 0.03930131004366813, "term": "uncover", "cat25k": 3, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4912368552829244, "os": -0.05705541095391192}, {"x": 0.35852534562211985, "y": 0.02969432314410481, "ox": 0.35852534562211985, "oy": 0.02969432314410481, "term": "Windows Linux", "cat25k": 3, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3324987481221833, "os": -0.12279798931564888}, {"x": 0.01566820276497696, "y": 0.0165938864628821, "ox": 0.01566820276497696, "oy": 0.0165938864628821, "term": "JAVA C", "cat25k": 2, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4962443665498248, "os": -0.03857102890653427}, {"x": 0.010138248847926268, "y": 0.014847161572052403, "ox": 0.010138248847926268, "oy": 0.014847161572052403, "term": "An extraordinarily intelligent rigorous thinker", "cat25k": 2, "ncat25k": 3, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4972458688032048, "os": -0.036737793791199014}, {"x": 0.34009216589861757, "y": 0.35545851528384287, "ox": 0.34009216589861757, "oy": 0.35545851528384287, "term": "Apple discriminate retaliate applicants inquire", "cat25k": 8, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6419629444166249, "os": 0.14718434842374045}, {"x": 0.31889400921658995, "y": 0.33886462882096074, "ox": 0.31889400921658995, "oy": 0.33886462882096074, "term": "compensation applicants", "cat25k": 8, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6324486730095142, "os": 0.14406856747898136}, {"x": 0.9778801843317974, "y": 0.07336244541484717, "ox": 0.9778801843317974, "oy": 0.07336244541484717, "term": "Apple", "cat25k": 5, "ncat25k": 159, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 2, "s": 0.011016524787180773, "os": -2.244719585969689}, {"x": 0.0, "y": 0.3606986899563319, "ox": 0.0, "oy": 0.3606986899563319, "term": "SQL Proven", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6449674511767651, "os": 0.1482902757948052}, {"x": 0.0, "y": 0.841048034934498, "ox": 0.0, "oy": 0.841048034934498, "term": "Prior experience finance", "cat25k": 24, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.9098647971957937, "os": 0.43301270189221913}, {"x": 0.0, "y": 0.6026200873362446, "ox": 0.0, "oy": 0.6026200873362446, "term": "A solid understanding ad networks media campaigns", "cat25k": 11, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.7781672508763144, "os": 0.20517566677147003}, {"x": 0.0, "y": 0.2733624454148472, "ox": 0.0, "oy": 0.2733624454148472, "term": "Spark Streaming Experience Data", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5953930896344517, "os": 0.13463486355952828}, {"x": 0.0, "y": 0.24716157205240177, "ox": 0.0, "oy": 0.24716157205240177, "term": "e g Hive Spark Experience", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5808713069604405, "os": 0.12960715147753027}, {"x": 0.0, "y": 0.19825327510917032, "ox": 0.0, "oy": 0.19825327510917032, "term": "RNN LSTM GANs Streaming Analytics e", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5533299949924887, "os": 0.1233535156487411}, {"x": 0.0, "y": 0.3781659388646289, "ox": 0.0, "oy": 0.3781659388646289, "term": "dynamic innovative years applicable experience Experience Digital Media Experience", "cat25k": 8, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.6544817225838758, "os": 0.15204539517525723}, {"x": 0.0, "y": 0.27248908296943236, "ox": 0.0, "oy": 0.27248908296943236, "term": "user event data analysis Experience", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5948923385077616, "os": 0.1343297768303895}, {"x": 0.0, "y": 0.25414847161572063, "ox": 0.0, "oy": 0.25414847161572063, "term": "SQL Excel", "cat25k": 7, "ncat25k": 0, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.5848773159739609, "os": 0.13073854479677427}, {"x": 0.9695852534562212, "y": 0.06375545851528384, "ox": 0.9695852534562212, "oy": 0.06375545851528384, "term": "technologies", "cat25k": 4, "ncat25k": 77, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 1, "s": 0.014521782674011016, "os": -1.0946480348959022}, {"x": 0.6986175115207375, "y": 0.0, "ox": 0.6986175115207375, "oy": 0.0, "term": "schemas", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16174261392088135, "os": -0.23626949282689355}, {"x": 0.9889400921658986, "y": 0.0, "ox": 0.9889400921658986, "oy": 0.0, "term": "Gym membership compensation", "cat25k": 0, "ncat25k": 276, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 3, "s": 0.006009013520280421, "os": -3.8971143170299722}, {"x": 0.7963133640552997, "y": 0.0, "ox": 0.7963133640552997, "oy": 0.0, "term": "Git SDLC", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10866299449173761, "os": -0.30370960170729866}, {"x": 0.7880184331797236, "y": 0.0, "ox": 0.7880184331797236, "oy": 0.0, "term": "advanced courses data science machine", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11316975463194792, "os": -0.29531036809083494}, {"x": 0.806451612903226, "y": 0.0, "ox": 0.806451612903226, "oy": 0.0, "term": "communicate data driven insight", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10365548322483725, "os": -0.31120756477299005}, {"x": 0.8672811059907836, "y": 0.0, "ox": 0.8672811059907836, "oy": 0.0, "term": "Knowledge digital AdTech landscape", "cat25k": 0, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06659989984977466, "os": -0.4}, {"x": 0.7216589861751153, "y": 0.0, "ox": 0.7216589861751153, "oy": 0.0, "term": "AdTech", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15022533800701052, "os": -0.24697543336253017}, {"x": 0.7225806451612904, "y": 0.0, "ox": 0.7225806451612904, "oy": 0.0, "term": "Creative analytic problem solver diligent attention detail", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14872308462694042, "os": -0.24748737341529156}, {"x": 0.8903225806451613, "y": 0.0, "ox": 0.8903225806451613, "oy": 0.0, "term": "Experience Cloudera", "cat25k": 0, "ncat25k": 33, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.05408112168252378, "os": -0.4714045207910316}, {"x": 0.9216589861751152, "y": 0.0, "ox": 0.9216589861751152, "oy": 0.0, "term": "MPP", "cat25k": 0, "ncat25k": 40, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.039559339008512766, "os": -0.5631546966288232}, {"x": 0.8092165898617514, "y": 0.0, "ox": 0.8092165898617514, "oy": 0.0, "term": "various data sources", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10215322984476716, "os": -0.3149102696856959}, {"x": 0.966820276497696, "y": 0.0, "ox": 0.966820276497696, "oy": 0.0, "term": "Willingness travel", "cat25k": 0, "ncat25k": 67, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.016024036054081123, "os": -0.9428090415820632}, {"x": 0.8783410138248849, "y": 0.0, "ox": 0.8783410138248849, "oy": 0.0, "term": "Python Django Flask", "cat25k": 0, "ncat25k": 31, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06009013520280421, "os": -0.43301270189221913}, {"x": 0.7456221198156684, "y": 0.0, "ox": 0.7456221198156684, "oy": 0.0, "term": "Responsible staying current enterprise standards industry standards technologies", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1357035553329995, "os": -0.2612836697927243}, {"x": 0.6912442396313365, "y": 0.0, "ox": 0.6912442396313365, "oy": 0.0, "term": "data access data storage techniques", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16524787180771158, "os": -0.23164814904420078}, {"x": 0.8304147465437789, "y": 0.0, "ox": 0.8304147465437789, "oy": 0.0, "term": "video person hour", "cat25k": 0, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09113670505758638, "os": -0.3466800150008662}, {"x": 0.8626728110599079, "y": 0.0, "ox": 0.8626728110599079, "oy": 0.0, "term": "employee benefits", "cat25k": 0, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07060590886329493, "os": -0.39309699602751175}, {"x": 0.8663594470046084, "y": 0.0, "ox": 0.8663594470046084, "oy": 0.0, "term": "kitchen", "cat25k": 0, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06910365548322484, "os": -0.399788275554427}, {"x": 0.903225806451613, "y": 0.0, "ox": 0.903225806451613, "oy": 0.0, "term": "data visualization tools", "cat25k": 0, "ncat25k": 36, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.04807210816224337, "os": -0.5028046393894022}, {"x": 0.935483870967742, "y": 0.0, "ox": 0.935483870967742, "oy": 0.0, "term": "big data data pipelines", "cat25k": 0, "ncat25k": 47, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.032548823234852274, "os": -0.6693537841915613}, {"x": 0.8470046082949311, "y": 0.0, "ox": 0.8470046082949311, "oy": 0.0, "term": "data transformation data structures metadata dependency workload management", "cat25k": 0, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08162243365047571, "os": -0.36451985124577363}, {"x": 0.902304147465438, "y": 0.0, "ox": 0.902304147465438, "oy": 0.0, "term": "working familiarity variety", "cat25k": 0, "ncat25k": 36, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.048572859288933394, "os": -0.5021375989625001}, {"x": 0.9059907834101384, "y": 0.0, "ox": 0.9059907834101384, "oy": 0.0, "term": "NoSQL databases", "cat25k": 0, "ncat25k": 36, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.04656985478217326, "os": -0.5145427159669852}, {"x": 0.9253456221198159, "y": 0.0, "ox": 0.9253456221198159, "oy": 0.0, "term": "third", "cat25k": 0, "ncat25k": 41, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.03755633450175263, "os": -0.5847926180749219}, {"x": 0.9087557603686637, "y": 0.0, "ox": 0.9087557603686637, "oy": 0.0, "term": "Mustache Get Mustache", "cat25k": 0, "ncat25k": 37, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.045067601402103155, "os": -0.5236717735104779}, {"x": 0.8331797235023043, "y": 0.0, "ox": 0.8331797235023043, "oy": 0.0, "term": "data flows", "cat25k": 0, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08913370055082623, "os": -0.3498759579292246}, {"x": 0.8672811059907836, "y": 0.0, "ox": 0.8672811059907836, "oy": 0.0, "term": "Pet friendly office environment", "cat25k": 0, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06659989984977466, "os": -0.4}, {"x": 0.8516129032258066, "y": 0.0, "ox": 0.8516129032258066, "oy": 0.0, "term": "Fixed term contract option perm", "cat25k": 0, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.0771156735102654, "os": -0.37267799624996495}, {"x": 0.8516129032258066, "y": 0.0, "ox": 0.8516129032258066, "oy": 0.0, "term": "Experience Agile Methodologies Scrum Kanban", "cat25k": 0, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.0771156735102654, "os": -0.37267799624996495}, {"x": 0.991705069124424, "y": 0.0, "ox": 0.991705069124424, "oy": 0.0, "term": "least one high level programming language", "cat25k": 0, "ncat25k": 305, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 4, "s": 0.004506760140210316, "os": -4.302348966995371}, {"x": 0.8479262672811061, "y": 0.0, "ox": 0.8479262672811061, "oy": 0.0, "term": "data engineering", "cat25k": 0, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08112168252378567, "os": -0.3649295982910231}, {"x": 0.9686635944700461, "y": 0.0, "ox": 0.9686635944700461, "oy": 0.0, "term": "millions daily players", "cat25k": 0, "ncat25k": 74, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 1, "s": 0.015022533800701053, "os": -1.0400400450025986}, {"x": 0.9539170506912442, "y": 0.0, "ox": 0.9539170506912442, "oy": 0.0, "term": "millions daily", "cat25k": 0, "ncat25k": 57, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.023034551827741615, "os": -0.8103040823382058}, {"x": 0.9262672811059908, "y": 0.0, "ox": 0.9262672811059908, "oy": 0.0, "term": "cool people", "cat25k": 0, "ncat25k": 42, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.037055583375062595, "os": -0.590012476439457}, {"x": 0.45345622119815676, "y": 0.0, "ox": 0.45345622119815676, "oy": 0.0, "term": "unstructured data acquisition Realtime Data Integration Patterns Engagement", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2839258888332499, "os": -0.14471950751889004}, {"x": 0.44608294930875586, "y": 0.0, "ox": 0.44608294930875586, "oy": 0.0, "term": "data services", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.28743114672008013, "os": -0.14214618787976052}, {"x": 0.431336405529954, "y": 0.0, "ox": 0.431336405529954, "oy": 0.0, "term": "Operational analytical data provisioning insights data landscape", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.29494241362043067, "os": -0.13811263343861713}, {"x": 0.4248847926267282, "y": 0.0, "ox": 0.4248847926267282, "oy": 0.0, "term": "Group Data", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.29794692038057086, "os": -0.13623724355609376}, {"x": 0.4184331797235024, "y": 0.0, "ox": 0.4184331797235024, "oy": 0.0, "term": "Assist driving data services strategy", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.30095142714071105, "os": -0.1347756733279453}, {"x": 0.4009216589861752, "y": 0.0, "ox": 0.4009216589861752, "oy": 0.0, "term": "Realtime Data Integration Patterns", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.31046569854782174, "os": -0.13023504743159375}, {"x": 0.38433179723502314, "y": 0.0, "ox": 0.38433179723502314, "oy": 0.0, "term": "Building Big Data Platform", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.31897846770155236, "os": -0.12781673177759406}, {"x": 0.38064516129032266, "y": 0.0, "ox": 0.38064516129032266, "oy": 0.0, "term": "next level excellence Building Big Data Platform", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.32098147220831247, "os": -0.12726482928804}, {"x": 0.37235023041474663, "y": 0.0, "ox": 0.37235023041474663, "oy": 0.0, "term": "Data Flow Patterns", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3254882323485228, "os": -0.12543103147268347}, {"x": 0.3640552995391706, "y": 0.0, "ox": 0.3640552995391706, "oy": 0.0, "term": "Data Initiatives", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3299949924887331, "os": -0.12372526166378472}, {"x": 0.27096774193548395, "y": 0.0, "ox": 0.27096774193548395, "oy": 0.0, "term": "Strategic Alignment Group Architecture", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3745618427641462, "os": -0.10924612254630749}, {"x": 0.20829493087557605, "y": 0.0, "ox": 0.20829493087557605, "oy": 0.0, "term": "Visualisation Storyboarding experience Stats", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.40660991487230846, "os": -0.10038274348361853}, {"x": 0.20737327188940097, "y": 0.0, "ox": 0.20737327188940097, "oy": 0.0, "term": "Building operation frameworks processes", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4071106659989985, "os": -0.10034448896777955}, {"x": 0.18248847926267284, "y": 0.0, "ox": 0.18248847926267284, "oy": 0.0, "term": "Net Language experience", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4206309464196295, "os": -0.09613915214306182}, {"x": 0.17788018433179725, "y": 0.0, "ox": 0.17788018433179725, "oy": 0.0, "term": "Banking financial sector experience", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4231347020530797, "os": -0.09473676409284926}, {"x": 0.775115207373272, "y": 0.0, "ox": 0.775115207373272, "oy": 0.0, "term": "Assist", "cat25k": 0, "ncat25k": 20, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11967951927891837, "os": -0.28498003688016466}, {"x": 0.999078341013825, "y": 0.0, "ox": 0.999078341013825, "oy": 0.0, "term": "Apache Flink Spark Streaming Apache Storm Kafka Streams others", "cat25k": 0, "ncat25k": 544, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 7, "s": 0.0005007511266900351, "os": -7.686107609471943}, {"x": 0.9981566820276498, "y": 0.0, "ox": 0.9981566820276498, "oy": 0.0, "term": "Experience building stream processing applications", "cat25k": 0, "ncat25k": 473, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 6, "s": 0.0010015022533800702, "os": -6.6857862971127595}, {"x": 0.9953917050691244, "y": 0.0, "ox": 0.9953917050691244, "oy": 0.0, "term": "Python Go Java Scala", "cat25k": 0, "ncat25k": 437, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 6, "s": 0.0025037556334501754, "os": -6.176262414584018}, {"x": 0.9944700460829494, "y": 0.0, "ox": 0.9944700460829494, "oy": 0.0, "term": "massive petabyte scale semi structured datasets", "cat25k": 0, "ncat25k": 411, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 5, "s": 0.0030045067601402104, "os": -5.8101118965377445}, {"x": 0.9935483870967743, "y": 0.0, "ox": 0.9935483870967743, "oy": 0.0, "term": "Apache Flink", "cat25k": 0, "ncat25k": 404, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 5, "s": 0.0035052578868302454, "os": -5.705615409942971}, {"x": 0.992626728110599, "y": 0.0, "ox": 0.992626728110599, "oy": 0.0, "term": "data technologies", "cat25k": 0, "ncat25k": 344, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 4, "s": 0.004006009013520281, "os": -4.856881994203813}, {"x": 0.9898617511520739, "y": 0.0, "ox": 0.9898617511520739, "oy": 0.0, "term": "growth mindset", "cat25k": 0, "ncat25k": 277, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 3, "s": 0.005508262393590386, "os": -3.913065563983876}, {"x": 0.9880184331797235, "y": 0.0, "ox": 0.9880184331797235, "oy": 0.0, "term": "self awareness", "cat25k": 0, "ncat25k": 274, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 3, "s": 0.006509764646970456, "os": -3.863342470893667}, {"x": 0.9870967741935485, "y": 0.0, "ox": 0.9870967741935485, "oy": 0.0, "term": "large complex highly dimensional data", "cat25k": 0, "ncat25k": 271, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 3, "s": 0.007010515773660491, "os": -3.8269008475972037}, {"x": 0.9963133640552996, "y": 0.0, "ox": 0.9963133640552996, "oy": 0.0, "term": "Extras", "cat25k": 0, "ncat25k": 449, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 6, "s": 0.0020030045067601404, "os": -6.335532205549589}, {"x": 0.9834101382488479, "y": 0.0, "ox": 0.9834101382488479, "oy": 0.0, "term": "perfect enemy", "cat25k": 0, "ncat25k": 249, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 3, "s": 0.009013520280420633, "os": -3.5161020844037663}, {"x": 0.9815668202764977, "y": 0.0, "ox": 0.9815668202764977, "oy": 0.0, "term": "You curious excellent analytical problem", "cat25k": 0, "ncat25k": 193, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 2, "s": 0.010015022533800702, "os": -2.7221497158691417}, {"x": 1.0, "y": 0.0, "ox": 1.0, "oy": 0.0, "term": "career categories", "cat25k": 0, "ncat25k": 634, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 8, "s": 0.0, "os": -8.956685895029599}, {"x": 0.767741935483871, "y": 0.0, "ox": 0.767741935483871, "oy": 0.0, "term": "realtime streaming compute components Experience data modeling data architecture", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12368552829243867, "os": -0.27381210020425945}, {"x": 0.7087557603686637, "y": 0.0, "ox": 0.7087557603686637, "oy": 0.0, "term": "big data patterns", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15623435152729095, "os": -0.23978251511424598}, {"x": 0.6958525345622122, "y": 0.0, "ox": 0.6958525345622122, "oy": 0.0, "term": "Knowledgable distributed storage network resources level hosts", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16324486730095145, "os": -0.23403899787202825}, {"x": 0.6884792626728112, "y": 0.0, "ox": 0.6884792626728112, "oy": 0.0, "term": "DCs troubleshoot prevent performance issues", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1667501251877817, "os": -0.23054884578546014}, {"x": 0.30414746543778803, "y": 0.0, "ox": 0.30414746543778803, "oy": 0.0, "term": "particular MapReduce Spark Spark SQL", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.35803705558337506, "os": -0.11506109923670571}, {"x": 0.6442396313364056, "y": 0.0, "ox": 0.6442396313364056, "oy": 0.0, "term": "large scale data pipelines", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.18878317476214324, "os": -0.21241733881737937}, {"x": 0.21843317972350232, "y": 0.0, "ox": 0.21843317972350232, "oy": 0.0, "term": "Spark Streaming Hive YARN MR2 Experience building", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4011016524787181, "os": -0.10229843783147842}, {"x": 0.7760368663594471, "y": 0.0, "ox": 0.7760368663594471, "oy": 0.0, "term": "MapReduce Spark", "cat25k": 0, "ncat25k": 20, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11917876815222835, "os": -0.28506710985082184}, {"x": 0.5788018433179725, "y": 0.0, "ox": 0.5788018433179725, "oy": 0.0, "term": "ie warehousing concepts efficient storage query HDFS data security privacy", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.22133199799699552, "os": -0.1855268592417751}, {"x": 0.36958525345622123, "y": 0.0, "ox": 0.36958525345622123, "oy": 0.0, "term": "highly scalable data systems services", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3269904857285929, "os": -0.12494153157265704}, {"x": 0.3603686635944701, "y": 0.0, "ox": 0.3603686635944701, "oy": 0.0, "term": "batch", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.33149724586880325, "os": -0.1228403025271059}, {"x": 0.27281105990783416, "y": 0.0, "ox": 0.27281105990783416, "oy": 0.0, "term": "commitment data governance Demonstrated ability", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3735603405107662, "os": -0.10937657988592787}, {"x": 0.24884792626728117, "y": 0.0, "ox": 0.24884792626728117, "oy": 0.0, "term": "analytics data engineering role", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3860791186780171, "os": -0.10583916973536252}, {"x": 0.24331797235023048, "y": 0.0, "ox": 0.24331797235023048, "oy": 0.0, "term": "verbal visual communication capabilities Ability", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3880821231847772, "os": -0.10527495942669714}, {"x": 0.22580645161290325, "y": 0.0, "ox": 0.22580645161290325, "oy": 0.0, "term": "relevant business people analytics", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3970956434651978, "os": -0.10339186186101441}, {"x": 0.19170506912442398, "y": 0.0, "ox": 0.19170506912442398, "oy": 0.0, "term": "BS MS degree quantitative field equivalent practical experience", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.41562343515272915, "os": -0.09740601669738559}, {"x": 0.18341013824884794, "y": 0.0, "ox": 0.18341013824884794, "oy": 0.0, "term": "data analytics solutions", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.42013019529293943, "os": -0.09615600587797413}, {"x": 0.17603686635944701, "y": 0.0, "ox": 0.17603686635944701, "oy": 0.0, "term": "continuous refinement improvement", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4236354531797697, "os": -0.09425680083244098}, {"x": 0.6221198156682028, "y": 0.0, "ox": 0.6221198156682028, "oy": 0.0, "term": "least years", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.20030045067601404, "os": -0.20436466155472321}, {"x": 0.4036866359447005, "y": 0.0, "ox": 0.4036866359447005, "oy": 0.0, "term": "e g Linux Mac OS Experience", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.30896344516775165, "os": -0.13073645703760842}, {"x": 0.27834101382488485, "y": 0.0, "ox": 0.27834101382488485, "oy": 0.0, "term": "nice required Data modeling Experience working search engines", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.370555833750626, "os": -0.11038708931409055}, {"x": 0.25529953917050696, "y": 0.0, "ox": 0.25529953917050696, "oy": 0.0, "term": "analytic skills Solid computer science systems foundations ability", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.38307461191787684, "os": -0.106597249403011}, {"x": 0.2322580645161291, "y": 0.0, "ox": 0.2322580645161291, "oy": 0.0, "term": "new domains Proven system development", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.39359038557836756, "os": -0.10410856242501619}, {"x": 0.22027649769585256, "y": 0.0, "ox": 0.22027649769585256, "oy": 0.0, "term": "Machine learning Natural", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.400100150225338, "os": -0.1027793578882717}, {"x": 0.2, "y": 0.0, "ox": 0.2, "oy": 0.0, "term": "Good communication skills teamwork Passion", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4111166750125188, "os": -0.09916579747088573}, {"x": 0.17880184331797236, "y": 0.0, "ox": 0.17880184331797236, "oy": 0.0, "term": "Natural language processing", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4226339509263896, "os": -0.09476603288699911}, {"x": 0.5585253456221199, "y": 0.0, "ox": 0.5585253456221199, "oy": 0.0, "term": "Apache", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23184777165748624, "os": -0.1755084371182086}, {"x": 0.19447004608294932, "y": 0.0, "ox": 0.19447004608294932, "oy": 0.0, "term": "Work clients model data landscape", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.414121181772659, "os": -0.09760694675905611}, {"x": 0.16682027649769587, "y": 0.0, "ox": 0.16682027649769587, "oy": 0.0, "term": "data extracts", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.42864296444667005, "os": -0.09271979088012472}, {"x": 0.1622119815668203, "y": 0.0, "ox": 0.1622119815668203, "oy": 0.0, "term": "operational ETL data pipelines", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.43064596895343016, "os": -0.09207460654705199}, {"x": 0.1511520737327189, "y": 0.0, "ox": 0.1511520737327189, "oy": 0.0, "term": "data fields hypotheses", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4366549824737106, "os": -0.08990924488286221}, {"x": 0.1447004608294931, "y": 0.0, "ox": 0.1447004608294931, "oy": 0.0, "term": "Collaborate data scientists", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.43965948923385084, "os": -0.08895362797915148}, {"x": 0.5456221198156682, "y": 0.0, "ox": 0.5456221198156682, "oy": 0.0, "term": "Strong development background experience", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23735603405107664, "os": -0.1706765530095053}, {"x": 0.43225806451612914, "y": 0.0, "ox": 0.43225806451612914, "oy": 0.0, "term": "Processing Spark Hadoop EMR", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.29444166249374065, "os": -0.13829513872725505}, {"x": 0.4000000000000001, "y": 0.0, "ox": 0.4000000000000001, "oy": 0.0, "term": "MPP AWS Redshift Oracle Exadata Teradata IBM Netezza", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.31096644967451176, "os": -0.1302260848432748}, {"x": 0.2774193548387098, "y": 0.0, "ox": 0.2774193548387098, "oy": 0.0, "term": "Traditional RDBMS MS SQL Server Oracle", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.371056584877316, "os": -0.1103834523024496}, {"x": 0.25345622119815675, "y": 0.0, "ox": 0.25345622119815675, "oy": 0.0, "term": "Redshift Oracle", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3840761141712569, "os": -0.10630164882458744}, {"x": 0.13456221198156681, "y": 0.0, "ox": 0.13456221198156681, "oy": 0.0, "term": "Distributed Systems", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4451677516274412, "os": -0.0870664747739859}, {"x": 0.32811059907834106, "y": 0.0, "ox": 0.32811059907834106, "oy": 0.0, "term": "clear timely professional manner", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3465197796695043, "os": -0.11863403835732078}, {"x": 0.7281105990783412, "y": 0.0, "ox": 0.7281105990783412, "oy": 0.0, "term": "context data processing Experience proficiency Python Experience design implementation data", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14571857786680023, "os": -0.2499201833442466}, {"x": 0.678341013824885, "y": 0.0, "ox": 0.678341013824885, "oy": 0.0, "term": "Google Cloud Platform DevOps Stack development experience Apache Airflow data pipeline tools", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17175763645468206, "os": -0.2258720064070704}, {"x": 0.6737327188940093, "y": 0.0, "ox": 0.6737327188940093, "oy": 0.0, "term": "various sources data Manage", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17376064096144217, "os": -0.22404513259825692}, {"x": 0.6654377880184333, "y": 0.0, "ox": 0.6654377880184333, "oy": 0.0, "term": "Data Engineering Hadoop Spark Data Processing products", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17726589884827243, "os": -0.2195622653698907}, {"x": 0.6645161290322582, "y": 0.0, "ox": 0.6645161290322582, "oy": 0.0, "term": "data science production environments", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17776664997496247, "os": -0.21928561141372255}, {"x": 0.663594470046083, "y": 0.0, "ox": 0.663594470046083, "oy": 0.0, "term": "working engineering team best track record data", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17826740110165248, "os": -0.21925039127548923}, {"x": 0.6580645161290324, "y": 0.0, "ox": 0.6580645161290324, "oy": 0.0, "term": "third party elements data pipeline", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1812719078617927, "os": -0.2174395663431254}, {"x": 0.6571428571428573, "y": 0.0, "ox": 0.6571428571428573, "oy": 0.0, "term": "key data functions", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.18177265898848274, "os": -0.2173988828101735}, {"x": 0.6534562211981568, "y": 0.0, "ox": 0.6534562211981568, "oy": 0.0, "term": "Support sophisticated predictive data products", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1837756634952429, "os": -0.2169965321244916}, {"x": 0.6516129032258066, "y": 0.0, "ox": 0.6516129032258066, "oy": 0.0, "term": "Data Engineering Hadoop Spark Data", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.18477716574862293, "os": -0.2164159728650495}, {"x": 0.6479262672811061, "y": 0.0, "ox": 0.6479262672811061, "oy": 0.0, "term": "data inconsistencies", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1867801702553831, "os": -0.2142333456032911}, {"x": 0.6175115207373273, "y": 0.0, "ox": 0.6175115207373273, "oy": 0.0, "term": "Cloud experience", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.20280420630946422, "os": -0.20112641016091773}, {"x": 0.6110599078341015, "y": 0.0, "ox": 0.6110599078341015, "oy": 0.0, "term": "outputs Data Science models", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.20630946419629448, "os": -0.19975201034578932}, {"x": 0.7493087557603687, "y": 0.0, "ox": 0.7493087557603687, "oy": 0.0, "term": "open source tools", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.13370055082623938, "os": -0.26269436572092203}, {"x": 0.5041474654377881, "y": 0.0, "ox": 0.5041474654377881, "oy": 0.0, "term": "similar Software Engineering Data Science etc experience software", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.25788683024536807, "os": -0.1568763000806926}, {"x": 0.4700460829493089, "y": 0.0, "ox": 0.4700460829493089, "oy": 0.0, "term": "infrastructure layout", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2759138708062093, "os": -0.1504817902338007}, {"x": 0.43410138248847935, "y": 0.0, "ox": 0.43410138248847935, "oy": 0.0, "term": "cloud service integrations", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.29344016024036057, "os": -0.13863462253857253}, {"x": 0.42396313364055305, "y": 0.0, "ox": 0.42396313364055305, "oy": 0.0, "term": "Big Query Redshift Spectrum S3 Athena Kafka Spark Storm Flink Beam Presto Hive ETL", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2984476715072609, "os": -0.13557771316160022}, {"x": 0.33271889400921667, "y": 0.0, "ox": 0.33271889400921667, "oy": 0.0, "term": "Apache Airflow", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.34401602403605414, "os": -0.11903161475816716}, {"x": 0.21935483870967745, "y": 0.0, "ox": 0.21935483870967745, "oy": 0.0, "term": "python", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4006009013520281, "os": -0.10247596890831805}, {"x": 0.15760368663594473, "y": 0.0, "ox": 0.15760368663594473, "oy": 0.0, "term": "transformations", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.43314972458688034, "os": -0.091168617399672}, {"x": 0.9400921658986175, "y": 0.0, "ox": 0.9400921658986175, "oy": 0.0, "term": "Manage", "cat25k": 0, "ncat25k": 50, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.03054581872809214, "os": -0.7021872586588511}, {"x": 0.5714285714285715, "y": 0.0, "ox": 0.5714285714285715, "oy": 0.0, "term": "Scala Java", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.22483725588382578, "os": -0.18252627124460963}, {"x": 0.6894009216589863, "y": 0.0, "ox": 0.6894009216589863, "oy": 0.0, "term": "401K", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16624937406109164, "os": -0.2309401076758503}, {"x": 0.23410138248847934, "y": 0.0, "ox": 0.23410138248847934, "oy": 0.0, "term": "Agile projects Data Warehousing experience", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3925888833249875, "os": -0.10444909582676278}, {"x": 0.17050691244239632, "y": 0.0, "ox": 0.17050691244239632, "oy": 0.0, "term": "Experience multiple Database technologies", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4266399599399099, "os": -0.09314968282846212}, {"x": 0.1640552995391705, "y": 0.0, "ox": 0.1640552995391705, "oy": 0.0, "term": "technical aspects Data Technology industry personal professional development work life", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.43014521782674014, "os": -0.09236679662887709}, {"x": 0.12350230414746546, "y": 0.0, "ox": 0.12350230414746546, "oy": 0.0, "term": "different multiple projects", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4511767651477216, "os": -0.0852148279161972}, {"x": 0.1152073732718894, "y": 0.0, "ox": 0.1152073732718894, "oy": 0.0, "term": "Titan Experience developing solutions", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.45568352528793193, "os": -0.08406091483673189}, {"x": 0.16036866359447005, "y": 0.0, "ox": 0.16036866359447005, "oy": 0.0, "term": "Cloud", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.43164747120681024, "os": -0.09136035666256503}, {"x": 0.9658986175115208, "y": 0.0, "ox": 0.9658986175115208, "oy": 0.0, "term": "data streaming Design", "cat25k": 0, "ncat25k": 66, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.017025538307461195, "os": -0.93065555264833}, {"x": 0.9631336405529954, "y": 0.0, "ox": 0.9631336405529954, "oy": 0.0, "term": "data warehouse data models", "cat25k": 0, "ncat25k": 64, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.0185277916875313, "os": -0.9001890559442032}, {"x": 0.96036866359447, "y": 0.0, "ox": 0.96036866359447, "oy": 0.0, "term": "source data e g data profiling definition mapping Design", "cat25k": 0, "ncat25k": 62, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.020030045067601403, "os": -0.8695145275772963}, {"x": 0.8138248847926269, "y": 0.0, "ox": 0.8138248847926269, "oy": 0.0, "term": "data Manage data growth usage", "cat25k": 0, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09964947421131697, "os": -0.32206004065865285}, {"x": 0.8129032258064517, "y": 0.0, "ox": 0.8129032258064517, "oy": 0.0, "term": "data monitoring solutions procedures", "cat25k": 0, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.100150225338007, "os": -0.32003090013307867}, {"x": 0.9585253456221198, "y": 0.0, "ox": 0.9585253456221198, "oy": 0.0, "term": "efficient data loads", "cat25k": 0, "ncat25k": 60, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.021031547320981475, "os": -0.846602181773435}, {"x": 0.8082949308755761, "y": 0.0, "ox": 0.8082949308755761, "oy": 0.0, "term": "good data governance Work", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10265398097145718, "os": -0.3121480780398317}, {"x": 0.9576036866359449, "y": 0.0, "ox": 0.9576036866359449, "oy": 0.0, "term": "unstructured data loads", "cat25k": 0, "ncat25k": 59, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.02153229844767151, "os": -0.8279506166462368}, {"x": 0.807373271889401, "y": 0.0, "ox": 0.807373271889401, "oy": 0.0, "term": "functional data team knowledge gathering", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10315473209814723, "os": -0.31138450629661496}, {"x": 0.9548387096774195, "y": 0.0, "ox": 0.9548387096774195, "oy": 0.0, "term": "managing data", "cat25k": 0, "ncat25k": 57, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.02253380070105158, "os": -0.8104706143458072}, {"x": 0.9529953917050693, "y": 0.0, "ox": 0.9529953917050693, "oy": 0.0, "term": "traditional structured data ETL techniques Design", "cat25k": 0, "ncat25k": 57, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.02353530295443165, "os": -0.8086909722493204}, {"x": 0.9502304147465439, "y": 0.0, "ox": 0.9502304147465439, "oy": 0.0, "term": "technical data related support source system teams", "cat25k": 0, "ncat25k": 56, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.025037556334501755, "os": -0.7948105955797862}, {"x": 0.9520737327188941, "y": 0.0, "ox": 0.9520737327188941, "oy": 0.0, "term": "usability data", "cat25k": 0, "ncat25k": 57, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.024036054081121683, "os": -0.8036761869246201}, {"x": 0.9511520737327188, "y": 0.0, "ox": 0.9511520737327188, "oy": 0.0, "term": "real time data load solutions", "cat25k": 0, "ncat25k": 56, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.024536805207811718, "os": -0.7960426267315345}, {"x": 0.9493087557603687, "y": 0.0, "ox": 0.9493087557603687, "oy": 0.0, "term": "appropriate aggregation data structures", "cat25k": 0, "ncat25k": 56, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.02553830746119179, "os": -0.7888248409501395}, {"x": 0.7852534562211982, "y": 0.0, "ox": 0.7852534562211982, "oy": 0.0, "term": "changes data organisation", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11467200801201803, "os": -0.2941540199431548}, {"x": 0.9483870967741936, "y": 0.0, "ox": 0.9483870967741936, "oy": 0.0, "term": "troubleshoot technical data issues", "cat25k": 0, "ncat25k": 54, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.026039058587881823, "os": -0.7686443039803451}, {"x": 0.7778801843317974, "y": 0.0, "ox": 0.7778801843317974, "oy": 0.0, "term": "working data business intelligence analytics environment", "cat25k": 0, "ncat25k": 20, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11817726589884828, "os": -0.2884794511910889}, {"x": 0.9474654377880185, "y": 0.0, "ox": 0.9474654377880185, "oy": 0.0, "term": "SQL Data analysis Data visualisation Data", "cat25k": 0, "ncat25k": 54, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.02653980971457186, "os": -0.7579572209010008}, {"x": 0.9437788018433181, "y": 0.0, "ox": 0.9437788018433181, "oy": 0.0, "term": "data management analytics", "cat25k": 0, "ncat25k": 53, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.028542814221331998, "os": -0.7433522789200595}, {"x": 0.7695852534562213, "y": 0.0, "ox": 0.7695852534562213, "oy": 0.0, "term": "meta data solutions", "cat25k": 0, "ncat25k": 20, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12268402603905859, "os": -0.2779575448685734}, {"x": 0.7622119815668204, "y": 0.0, "ox": 0.7622119815668204, "oy": 0.0, "term": "team dynamics performance Complex solution service design implementation", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1266900350525789, "os": -0.27019654208617966}, {"x": 0.942857142857143, "y": 0.0, "ox": 0.942857142857143, "oy": 0.0, "term": "effective efficient data models", "cat25k": 0, "ncat25k": 52, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.029043565348022035, "os": -0.7306065736797523}, {"x": 0.9465437788018433, "y": 0.0, "ox": 0.9465437788018433, "oy": 0.0, "term": "Microsoft business intelligence data technologies", "cat25k": 0, "ncat25k": 53, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.027040560841261895, "os": -0.7553446075924248}, {"x": 0.934562211981567, "y": 0.0, "ox": 0.934562211981567, "oy": 0.0, "term": "speed access Design", "cat25k": 0, "ncat25k": 47, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.033049574361542315, "os": -0.6637666274388943}, {"x": 0.9419354838709677, "y": 0.0, "ox": 0.9419354838709677, "oy": 0.0, "term": "data processes", "cat25k": 0, "ncat25k": 51, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.02954431647471207, "os": -0.7203301778540628}, {"x": 0.9391705069124425, "y": 0.0, "ox": 0.9391705069124425, "oy": 0.0, "term": "data elements", "cat25k": 0, "ncat25k": 49, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.03104656985478217, "os": -0.6985050674506457}, {"x": 0.9308755760368663, "y": 0.0, "ox": 0.9308755760368663, "oy": 0.0, "term": "Work source system owners analysts", "cat25k": 0, "ncat25k": 45, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.03455182774161242, "os": -0.6405413096379465}, {"x": 0.7244239631336407, "y": 0.0, "ox": 0.7244239631336407, "oy": 0.0, "term": "availability accuracy Design", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14772158237356034, "os": -0.24761286475314576}, {"x": 0.7179723502304148, "y": 0.0, "ox": 0.7179723502304148, "oy": 0.0, "term": "Responsible team activities team dynamics performance Manage project task delivery team", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15222834251377068, "os": -0.24445898110174585}, {"x": 0.928110599078341, "y": 0.0, "ox": 0.928110599078341, "oy": 0.0, "term": "supplement enhance context Design", "cat25k": 0, "ncat25k": 43, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.03605408112168253, "os": -0.6131615658100459}, {"x": 0.927188940092166, "y": 0.0, "ox": 0.927188940092166, "oy": 0.0, "term": "interface monitoring management solutions", "cat25k": 0, "ncat25k": 43, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.036554832248372554, "os": -0.6065177518463911}, {"x": 0.9170506912442398, "y": 0.0, "ox": 0.9170506912442398, "oy": 0.0, "term": "solutions Positive engagement team activities", "cat25k": 0, "ncat25k": 39, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.0415623435152729, "os": -0.5485458855254757}, {"x": 0.9327188940092166, "y": 0.0, "ox": 0.9327188940092166, "oy": 0.0, "term": "data access e g batch exports", "cat25k": 0, "ncat25k": 46, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.03405107661492238, "os": -0.6529602387434367}, {"x": 0.9225806451612905, "y": 0.0, "ox": 0.9225806451612905, "oy": 0.0, "term": "Work analysts", "cat25k": 0, "ncat25k": 40, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.03905858788182273, "os": -0.5710744537268516}, {"x": 0.9290322580645162, "y": 0.0, "ox": 0.9290322580645162, "oy": 0.0, "term": "e g text speech images video Design", "cat25k": 0, "ncat25k": 43, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.035553329994992486, "os": -0.6133877550135083}, {"x": 0.6377880184331799, "y": 0.0, "ox": 0.6377880184331799, "oy": 0.0, "term": "knowledge share Quality control work Degree information technology engineering mathematics statistics actuarial related discipline", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19178768152228345, "os": -0.2098860789746813}, {"x": 0.9161290322580646, "y": 0.0, "ox": 0.9161290322580646, "oy": 0.0, "term": "ownership work", "cat25k": 0, "ncat25k": 38, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.04206309464196294, "os": -0.5426969196584969}, {"x": 0.9456221198156683, "y": 0.0, "ox": 0.9456221198156683, "oy": 0.0, "term": "business owners analysts", "cat25k": 0, "ncat25k": 53, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.02754131196795193, "os": -0.7543730658580083}, {"x": 0.9179723502304149, "y": 0.0, "ox": 0.9179723502304149, "oy": 0.0, "term": "load monitoring tools procedures", "cat25k": 0, "ncat25k": 39, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.041061592388582875, "os": -0.5533039836110465}, {"x": 0.9152073732718896, "y": 0.0, "ox": 0.9152073732718896, "oy": 0.0, "term": "high quality work time Show initiative", "cat25k": 0, "ncat25k": 38, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.04256384576865298, "os": -0.5398639093318336}, {"x": 0.6101382488479264, "y": 0.0, "ox": 0.6101382488479264, "oy": 0.0, "term": "system infrastructure management", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2068102153229845, "os": -0.19957548729130606}, {"x": 0.9124423963133642, "y": 0.0, "ox": 0.9124423963133642, "oy": 0.0, "term": "real time decision", "cat25k": 0, "ncat25k": 38, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.04306459689534301, "os": -0.5339586057743255}, {"x": 0.9050691244239634, "y": 0.0, "ox": 0.9050691244239634, "oy": 0.0, "term": "Manage systems technology tools", "cat25k": 0, "ncat25k": 36, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.04707060590886329, "os": -0.5095936217566103}, {"x": 0.886635944700461, "y": 0.0, "ox": 0.886635944700461, "oy": 0.0, "term": "Information gathering problem analysis", "cat25k": 0, "ncat25k": 32, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.05608412618928393, "os": -0.45545918211612013}, {"x": 0.9013824884792628, "y": 0.0, "ox": 0.9013824884792628, "oy": 0.0, "term": "appropriate indexing tables", "cat25k": 0, "ncat25k": 36, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.049073610415623435, "os": -0.5020315897117257}, {"x": 0.8921658986175117, "y": 0.0, "ox": 0.8921658986175117, "oy": 0.0, "term": "SSAS SQL Server Data warehouse", "cat25k": 0, "ncat25k": 34, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.053580370555833756, "os": -0.4754353079015484}, {"x": 0.5428571428571429, "y": 0.0, "ox": 0.5428571428571429, "oy": 0.0, "term": "Presenting Communicating information", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23885828743114673, "os": -0.16980588413579828}, {"x": 0.8884792626728112, "y": 0.0, "ox": 0.8884792626728112, "oy": 0.0, "term": "appropriate modelling techniques", "cat25k": 0, "ncat25k": 33, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.05508262393590385, "os": -0.4607622983260296}, {"x": 0.8801843317972351, "y": 0.0, "ox": 0.8801843317972351, "oy": 0.0, "term": "appropriate changes", "cat25k": 0, "ncat25k": 31, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.05908863294942413, "os": -0.43592909764024423}, {"x": 0.5299539170506914, "y": 0.0, "ox": 0.5299539170506914, "oy": 0.0, "term": "internal external Assist development others", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.24536805207811718, "os": -0.16593713829608694}, {"x": 0.8847926267281108, "y": 0.0, "ox": 0.8847926267281108, "oy": 0.0, "term": "professional specialist technical expertise", "cat25k": 0, "ncat25k": 32, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.05658487731597396, "os": -0.4488990049122423}, {"x": 0.5262672811059909, "y": 0.0, "ox": 0.5262672811059909, "oy": 0.0, "term": "Multiple stakeholder management", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.24737105658487735, "os": -0.16471609794953124}, {"x": 0.9410138248847927, "y": 0.0, "ox": 0.9410138248847927, "oy": 0.0, "term": "SQL Data", "cat25k": 0, "ncat25k": 50, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.030045067601402103, "os": -0.7110882327863667}, {"x": 0.8645161290322583, "y": 0.0, "ox": 0.8645161290322583, "oy": 0.0, "term": "skills knowledge application", "cat25k": 0, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07010515773660492, "os": -0.39490763370482207}, {"x": 0.8792626728110601, "y": 0.0, "ox": 0.8792626728110601, "oy": 0.0, "term": "loads", "cat25k": 0, "ncat25k": 31, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.05958938407611417, "os": -0.43428112973069377}, {"x": 0.8746543778801845, "y": 0.0, "ox": 0.8746543778801845, "oy": 0.0, "term": "ownership career development", "cat25k": 0, "ncat25k": 30, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06259389083625437, "os": -0.4208784480639268}, {"x": 0.4930875576036867, "y": 0.0, "ox": 0.4930875576036867, "oy": 0.0, "term": "Quality Detail orientation Planning", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.26339509263895844, "os": -0.15518450919438403}, {"x": 0.8774193548387099, "y": 0.0, "ox": 0.8774193548387099, "oy": 0.0, "term": "continuous monitoring", "cat25k": 0, "ncat25k": 30, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.061091637456184275, "os": -0.43069055098875475}, {"x": 0.8718894009216591, "y": 0.0, "ox": 0.8718894009216591, "oy": 0.0, "term": "sources", "cat25k": 0, "ncat25k": 29, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.0640961442163245, "os": -0.41445253621214617}, {"x": 0.8728110599078343, "y": 0.0, "ox": 0.8728110599078343, "oy": 0.0, "term": "integrity existing environment", "cat25k": 0, "ncat25k": 29, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06359539308963445, "os": -0.41529543247876255}, {"x": 0.45990783410138264, "y": 0.0, "ox": 0.45990783410138264, "oy": 0.0, "term": "IT infrastructure IT Operations", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.28042063094641967, "os": -0.14724854097607282}, {"x": 0.4525345622119817, "y": 0.0, "ox": 0.4525345622119817, "oy": 0.0, "term": "Analysing Leadership", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.28442663995993994, "os": -0.14391215118717102}, {"x": 0.8589861751152076, "y": 0.0, "ox": 0.8589861751152076, "oy": 0.0, "term": "automated decision", "cat25k": 0, "ncat25k": 27, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07361041562343515, "os": -0.38345924061895476}, {"x": 0.8534562211981568, "y": 0.0, "ox": 0.8534562211981568, "oy": 0.0, "term": "value decision", "cat25k": 0, "ncat25k": 27, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07661492238357537, "os": -0.37677673593693184}, {"x": 0.8405529953917051, "y": 0.0, "ox": 0.8405529953917051, "oy": 0.0, "term": "active finding opportunities", "cat25k": 0, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08512769153730596, "os": -0.3574144908059346}, {"x": 0.8350230414746544, "y": 0.0, "ox": 0.8350230414746544, "oy": 0.0, "term": "effective strategies", "cat25k": 0, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08813219829744617, "os": -0.35003129748210116}, {"x": 0.3778801843317973, "y": 0.0, "ox": 0.3778801843317973, "oy": 0.0, "term": "Presenting Communicating", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3224837255883826, "os": -0.12674006210536498}, {"x": 0.8294930875576039, "y": 0.0, "ox": 0.8294930875576039, "oy": 0.0, "term": "external parties", "cat25k": 0, "ncat25k": 24, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09163745618427642, "os": -0.3454909608933913}, {"x": 0.7917050691244242, "y": 0.0, "ox": 0.7917050691244242, "oy": 0.0, "term": "Quality", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11116675012518779, "os": -0.29941253394378287}, {"x": 0.814746543778802, "y": 0.0, "ox": 0.814746543778802, "oy": 0.0, "term": "g multi dimensional OLAP structures summary tables", "cat25k": 0, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09914872308462695, "os": -0.3238918209858171}, {"x": 0.7843317972350232, "y": 0.0, "ox": 0.7843317972350232, "oy": 0.0, "term": "Take", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11517275913870807, "os": -0.2939738347368784}, {"x": 0.7898617511520738, "y": 0.0, "ox": 0.7898617511520738, "oy": 0.0, "term": "interfaces", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11216825237856785, "os": -0.2956480558944271}, {"x": 0.5400921658986176, "y": 0.0, "ox": 0.5400921658986176, "oy": 0.0, "term": "Cross", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23985978968452681, "os": -0.16896259823519158}, {"x": 0.6801843317972351, "y": 0.0, "ox": 0.6801843317972351, "oy": 0.0, "term": "Positive", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17075613420130198, "os": -0.22631485560599424}, {"x": 0.8221198156682029, "y": 0.0, "ox": 0.8221198156682029, "oy": 0.0, "term": "SSIS", "cat25k": 0, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09614421632448673, "os": -0.33095323707204516}, {"x": 0.7198156682027651, "y": 0.0, "ox": 0.7198156682027651, "oy": 0.0, "term": "OLAP", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1512268402603906, "os": -0.24600897800369584}, {"x": 0.6617511520737328, "y": 0.0, "ox": 0.6617511520737328, "oy": 0.0, "term": "etc Design implement", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17926890335503257, "os": -0.21891229993876832}, {"x": 0.5953917050691245, "y": 0.0, "ox": 0.5953917050691245, "oy": 0.0, "term": "ad hoc unstructured data models", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21432148222333502, "os": -0.19126346853334725}, {"x": 0.5778801843317973, "y": 0.0, "ox": 0.5778801843317973, "oy": 0.0, "term": "API etc Design", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.22183274912368553, "os": -0.185482682072517}, {"x": 0.4350230414746544, "y": 0.0, "ox": 0.4350230414746544, "oy": 0.0, "term": "code Scala Experience working Agile environment Experience building data processing pipelines", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2929394091136705, "os": -0.13919164546736776}, {"x": 0.4175115207373272, "y": 0.0, "ox": 0.4175115207373272, "oy": 0.0, "term": "Amazing working environment Employee referral scheme ETL Scala", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3014521782674011, "os": -0.13450016373701065}, {"x": 0.32534562211981577, "y": 0.0, "ox": 0.32534562211981577, "oy": 0.0, "term": "Competitive Salary Company Bonus Private Healthcare Life Insurance Income protection Pension Scheme company contribution", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.34802203304957435, "os": -0.11831317822841526}, {"x": 0.3225806451612904, "y": 0.0, "ox": 0.3225806451612904, "oy": 0.0, "term": "analytics pipelines", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3495242864296445, "os": -0.11792573028898956}, {"x": 0.29677419354838713, "y": 0.0, "ox": 0.29677419354838713, "oy": 0.0, "term": "Competitive Salary Company Bonus Private Healthcare Life Insurance Income", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3610415623435153, "os": -0.11392916453156157}, {"x": 0.24423963133640558, "y": 0.0, "ox": 0.24423963133640558, "oy": 0.0, "term": "big data experience", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3875813720580871, "os": -0.10531641169146472}, {"x": 0.21290322580645163, "y": 0.0, "ox": 0.21290322580645163, "oy": 0.0, "term": "Scala Experience", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4041061592388583, "os": -0.10174295853609412}, {"x": 0.20921658986175118, "y": 0.0, "ox": 0.20921658986175118, "oy": 0.0, "term": "sell days", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.40610916374561845, "os": -0.1003899600434777}, {"x": 0.19354838709677422, "y": 0.0, "ox": 0.19354838709677422, "oy": 0.0, "term": "production handsoff batch systems", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.414621932899349, "os": -0.09755881448962467}, {"x": 0.5013824884792628, "y": 0.0, "ox": 0.5013824884792628, "oy": 0.0, "term": "Scala", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.25888833249874815, "os": -0.15633381580186256}, {"x": 0.8497695852534564, "y": 0.0, "ox": 0.8497695852534564, "oy": 0.0, "term": "social events", "cat25k": 0, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08012018027040561, "os": -0.3711047733623777}, {"x": 0.6672811059907835, "y": 0.0, "ox": 0.6672811059907835, "oy": 0.0, "term": "Virtual company", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17626439659489235, "os": -0.22156958603625435}, {"x": 0.49493087557603693, "y": 0.0, "ox": 0.49493087557603693, "oy": 0.0, "term": "Virtual", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2623935903855784, "os": -0.15552550751170974}, {"x": 0.8516129032258066, "y": 0.0, "ox": 0.8516129032258066, "oy": 0.0, "term": "Team player excellent communication skills", "cat25k": 0, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.0771156735102654, "os": -0.37267799624996495}, {"x": 0.3391705069124425, "y": 0.0, "ox": 0.3391705069124425, "oy": 0.0, "term": "Exposure Business Intelligence tools Business Objects", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.34101151727591394, "os": -0.12005856278752125}, {"x": 0.24239631336405534, "y": 0.0, "ox": 0.24239631336405534, "oy": 0.0, "term": "Business Objects Informatica", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3885828743114672, "os": -0.10518067259805636}, {"x": 0.23963133640553, "y": 0.0, "ox": 0.23963133640553, "oy": 0.0, "term": "developing testing ETL interfaces", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3900851276915373, "os": -0.10505154189115862}, {"x": 0.23686635944700468, "y": 0.0, "ox": 0.23686635944700468, "oy": 0.0, "term": "Exposure Business Intelligence", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.39158738107160745, "os": -0.1049685497636986}, {"x": 0.6119815668202766, "y": 0.0, "ox": 0.6119815668202766, "oy": 0.0, "term": "Teradata Oracle MS SQL", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2058087130696044, "os": -0.19980301030090697}, {"x": 0.33640552995391715, "y": 0.0, "ox": 0.33640552995391715, "oy": 0.0, "term": "MDM", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.342513770655984, "os": -0.11936157956356498}, {"x": 0.7612903225806453, "y": 0.0, "ox": 0.7612903225806453, "oy": 0.0, "term": "Kinesis Riak", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12719078617926893, "os": -0.269337257568918}, {"x": 0.8691244239631338, "y": 0.0, "ox": 0.8691244239631338, "oy": 0.0, "term": "Aurora Dynamo", "cat25k": 0, "ncat25k": 29, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06559839759639459, "os": -0.4069752754210053}, {"x": 0.31059907834101386, "y": 0.0, "ox": 0.31059907834101386, "oy": 0.0, "term": "Python SQL Spark Scala Extensive Experience SQL", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3550325488232349, "os": -0.11602232423400105}, {"x": 0.2276497695852535, "y": 0.0, "ox": 0.2276497695852535, "oy": 0.0, "term": "big data years", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.39609414121181774, "os": -0.10372812145642032}, {"x": 0.5612903225806453, "y": 0.0, "ox": 0.5612903225806453, "oy": 0.0, "term": "NoSQL solutions", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23034551827741614, "os": -0.17824562795687804}, {"x": 0.9244239631336406, "y": 0.0, "ox": 0.9244239631336406, "oy": 0.0, "term": "display excellent judgment", "cat25k": 0, "ncat25k": 41, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.03805708562844266, "os": -0.5841339784272672}, {"x": 0.9115207373271891, "y": 0.0, "ox": 0.9115207373271891, "oy": 0.0, "term": "difficult tradeoffs", "cat25k": 0, "ncat25k": 38, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.043565348022033046, "os": -0.533195289670246}, {"x": 0.910599078341014, "y": 0.0, "ox": 0.910599078341014, "oy": 0.0, "term": "new information", "cat25k": 0, "ncat25k": 38, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.04406609914872309, "os": -0.5322321640750884}, {"x": 0.6976958525345623, "y": 0.0, "ox": 0.6976958525345623, "oy": 0.0, "term": "BA BS Degree Computer Science Engineering discipline Statistics Information Systems", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16224336504757136, "os": -0.23593641242799313}, {"x": 0.8580645161290323, "y": 0.0, "ox": 0.8580645161290323, "oy": 0.0, "term": "Statistics Information Systems", "cat25k": 0, "ncat25k": 27, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07411116675012519, "os": -0.38163289460504046}, {"x": 0.8396313364055301, "y": 0.0, "ox": 0.8396313364055301, "oy": 0.0, "term": "BA BS Degree Computer Science Engineering", "cat25k": 0, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.085628442663996, "os": -0.3557199375380461}, {"x": 0.647004608294931, "y": 0.0, "ox": 0.647004608294931, "oy": 0.0, "term": "another quantitative field", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1872809213820731, "os": -0.21377589250397455}, {"x": 0.8755760368663595, "y": 0.0, "ox": 0.8755760368663595, "oy": 0.0, "term": "statistical modeling discriminative methods", "cat25k": 0, "ncat25k": 30, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06209313970956435, "os": -0.4209833157876231}, {"x": 0.870967741935484, "y": 0.0, "ox": 0.870967741935484, "oy": 0.0, "term": "extraction analysis", "cat25k": 0, "ncat25k": 29, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06459689534301452, "os": -0.40922294174727125}, {"x": 0.7548387096774195, "y": 0.0, "ox": 0.7548387096774195, "oy": 0.0, "term": "Experience areas data", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.13069604406609917, "os": -0.26540964686265434}, {"x": 0.8958525345622121, "y": 0.0, "ox": 0.8958525345622121, "oy": 0.0, "term": "Mathematics Engineering technology", "cat25k": 0, "ncat25k": 34, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.05207811717576365, "os": -0.47866307565369526}, {"x": 0.7926267281105992, "y": 0.0, "ox": 0.7926267281105992, "oy": 0.0, "term": "Possess bachelor degree", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11066599899849774, "os": -0.3000842426313818}, {"x": 0.4294930875576038, "y": 0.0, "ox": 0.4294930875576038, "oy": 0.0, "term": "data stores data", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2954431647471207, "os": -0.1373295768551446}, {"x": 0.3529953917050692, "y": 0.0, "ox": 0.3529953917050692, "oy": 0.0, "term": "model evaluation validation Enthusiasm big data translating data", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.33450175262894344, "os": -0.12206507739731101}, {"x": 0.3290322580645162, "y": 0.0, "ox": 0.3290322580645162, "oy": 0.0, "term": "unstructured data Proficient building robust data pipelines", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.34601902854281424, "os": -0.11867580983446299}, {"x": 0.2811059907834102, "y": 0.0, "ox": 0.2811059907834102, "oy": 0.0, "term": "data processing tools", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.36905358037055586, "os": -0.11090778461818321}, {"x": 0.2700460829493088, "y": 0.0, "ox": 0.2700460829493088, "oy": 0.0, "term": "leading successful data engineering projects", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.37506259389083624, "os": -0.10877653505957513}, {"x": 0.24976958525345624, "y": 0.0, "ox": 0.24976958525345624, "oy": 0.0, "term": "reliable data services stakeholders", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.385578367551327, "os": -0.10615786617720031}, {"x": 0.18433179723502305, "y": 0.0, "ox": 0.18433179723502305, "oy": 0.0, "term": "Agile project development experience", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.41962944416624937, "os": -0.09638698232107122}, {"x": 0.5235023041474656, "y": 0.0, "ox": 0.5235023041474656, "oy": 0.0, "term": "Data Engineer Machine Learning Engineer", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.24887330996494744, "os": -0.16132838497858767}, {"x": 0.503225806451613, "y": 0.0, "ox": 0.503225806451613, "oy": 0.0, "term": "Kafka Apache Spark", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2583875813720581, "os": -0.15674280371498323}, {"x": 0.40184331797235034, "y": 0.0, "ox": 0.40184331797235034, "oy": 0.0, "term": "analyze present data answer business questions Experience data visualization tools", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.30996494742113173, "os": -0.13024052882216658}, {"x": 0.3308755760368664, "y": 0.0, "ox": 0.3308755760368664, "oy": 0.0, "term": "Experience data induction validation source systems Experience working Capital Projects", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.34501752628943416, "os": -0.11895907318738357}, {"x": 0.2986175115207374, "y": 0.0, "ox": 0.2986175115207374, "oy": 0.0, "term": "Advanced SQL knowledge years data extraction experience", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3600400600901352, "os": -0.11407915018193526}, {"x": 0.2755760368663595, "y": 0.0, "ox": 0.2755760368663595, "oy": 0.0, "term": "UAT Expert normalizing data", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.37205808713069605, "os": -0.10996487779063929}, {"x": 0.2672811059907835, "y": 0.0, "ox": 0.2672811059907835, "oy": 0.0, "term": "Familiarity Finance Operations Retail Contact Center data", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3765648472709064, "os": -0.10829634861822347}, {"x": 0.2543778801843319, "y": 0.0, "ox": 0.2543778801843319, "oy": 0.0, "term": "Desire end end ownership work Flexibility balance directional changes ability", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3835753630445669, "os": -0.10647287412837618}, {"x": 0.1972350230414747, "y": 0.0, "ox": 0.1972350230414747, "oy": 0.0, "term": "Strong analytical skills ability", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.41261892839258896, "os": -0.09838132360719304}, {"x": 0.18156682027649773, "y": 0.0, "ox": 0.18156682027649773, "oy": 0.0, "term": "day day", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4211316975463195, "os": -0.09602483799699868}, {"x": 0.16589861751152074, "y": 0.0, "ox": 0.16589861751152074, "oy": 0.0, "term": "business support Ability deal ambiguity Proactive driven individual comfortable working global matrixed fast paced environment", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.42914371557336006, "os": -0.09262913794101406}, {"x": 0.5290322580645163, "y": 0.0, "ox": 0.5290322580645163, "oy": 0.0, "term": "multiple deadline specific projects", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.24586880320480722, "os": -0.16526412707755744}, {"x": 0.5133640552995392, "y": 0.0, "ox": 0.5133640552995392, "oy": 0.0, "term": "Oracle Teradata Vertica Hadoop", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2528793189784677, "os": -0.15945197399708616}, {"x": 0.6728110599078342, "y": 0.0, "ox": 0.6728110599078342, "oy": 0.0, "term": "k Savings Plan Company Match Paid Vacations", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1742613920881322, "os": -0.22345371813855597}, {"x": 0.6589861751152074, "y": 0.0, "ox": 0.6589861751152074, "oy": 0.0, "term": "Safety Quality First Valuing Ethics Integrity Diversity Passion", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.18077115673510266, "os": -0.21786728633712793}, {"x": 0.6368663594470048, "y": 0.0, "ox": 0.6368663594470048, "oy": 0.0, "term": "Competitive Salary Comprehensive Health Wellness Income Protection Benefits", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19228843264897347, "os": -0.20940863170631388}, {"x": 0.5198156682027651, "y": 0.0, "ox": 0.5198156682027651, "oy": 0.0, "term": "Safety Quality First Valuing Ethics Integrity Diversity Passion Serving Our Customers Globally Dedication", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2508763144717076, "os": -0.16076297727581734}, {"x": 0.31336405529953926, "y": 0.0, "ox": 0.31336405529953926, "oy": 0.0, "term": "Bachelor Master degree Computer Science", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3540310465698548, "os": -0.11649773090275982}, {"x": 0.19631336405529956, "y": 0.0, "ox": 0.19631336405529956, "oy": 0.0, "term": "Servant Leadership", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.41311967951927897, "os": -0.09817125190556365}, {"x": 0.26359447004608305, "y": 0.0, "ox": 0.26359447004608305, "oy": 0.0, "term": "Pig Hive Impala Experience integration data multiple data sources", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.37856785177766655, "os": -0.10796286620225859}, {"x": 0.19078341013824887, "y": 0.0, "ox": 0.19078341013824887, "oy": 0.0, "term": "TDD Continuous Integration Experience refactoring code scale production mind", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.41612418627941916, "os": -0.09736988811170011}, {"x": 0.18894009216589863, "y": 0.0, "ox": 0.18894009216589863, "oy": 0.0, "term": "Solid knowledge data structures", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4171256885327992, "os": -0.09698355156850443}, {"x": 0.6359447004608295, "y": 0.0, "ox": 0.6359447004608295, "oy": 0.0, "term": "Experience Big Data ML", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1927891837756635, "os": -0.20869677142925264}, {"x": 0.16497695852534563, "y": 0.0, "ox": 0.16497695852534563, "oy": 0.0, "term": "services Experience building stream processing systems", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4296444667000501, "os": -0.09241711435125108}, {"x": 0.615668202764977, "y": 0.0, "ox": 0.615668202764977, "oy": 0.0, "term": "Good knowledge Big Data querying tools", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2038057085628443, "os": -0.20099237611174836}, {"x": 0.6018433179723504, "y": 0.0, "ox": 0.6018433179723504, "oy": 0.0, "term": "Big Data ML", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21031547320981475, "os": -0.19518619507994617}, {"x": 0.7041474654377881, "y": 0.0, "ox": 0.7041474654377881, "oy": 0.0, "term": "Lambda Architecture", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15873810716074113, "os": -0.23793255814418016}, {"x": 0.32073732718894016, "y": 0.0, "ox": 0.32073732718894016, "oy": 0.0, "term": "advantages", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.35052578868302453, "os": -0.11776160211560725}, {"x": 0.9004608294930877, "y": 0.0, "ox": 0.9004608294930877, "oy": 0.0, "term": "technical data role", "cat25k": 0, "ncat25k": 35, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.04957436154231347, "os": -0.500394449949293}, {"x": 0.8976958525345624, "y": 0.0, "ox": 0.8976958525345624, "oy": 0.0, "term": "good data governance", "cat25k": 0, "ncat25k": 34, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.05107661492238357, "os": -0.4838663900846458}, {"x": 0.8940092165898619, "y": 0.0, "ox": 0.8940092165898619, "oy": 0.0, "term": "Unstructured data experience", "cat25k": 0, "ncat25k": 34, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.05257886830245368, "os": -0.4779894232724996}, {"x": 0.8838709677419356, "y": 0.0, "ox": 0.8838709677419356, "oy": 0.0, "term": "Implement meta data solutions", "cat25k": 0, "ncat25k": 32, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.057085628442663995, "os": -0.4467435476822709}, {"x": 0.8562211981566822, "y": 0.0, "ox": 0.8562211981566822, "oy": 0.0, "term": "Microsoft business intelligence visualisation technologies", "cat25k": 0, "ncat25k": 27, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07511266900350526, "os": -0.3809036736078383}, {"x": 0.8368663594470048, "y": 0.0, "ox": 0.8368663594470048, "oy": 0.0, "term": "knowledge share Quality control work Degree information technology", "cat25k": 0, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08713069604406609, "os": -0.3508167895023947}, {"x": 0.8000000000000002, "y": 0.0, "ox": 0.8000000000000002, "oy": 0.0, "term": "Stakeholder management internal external Assist development others", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10716074111166751, "os": -0.3047965569910911}, {"x": 0.774193548387097, "y": 0.0, "ox": 0.774193548387097, "oy": 0.0, "term": "SSRS Power BI IT infrastructure e g storage networking servers", "cat25k": 0, "ncat25k": 20, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12018027040560841, "os": -0.2811919717859573}, {"x": 0.7603686635944702, "y": 0.0, "ox": 0.7603686635944702, "oy": 0.0, "term": "team dynamics performance", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12769153730595895, "os": -0.26918776980416415}, {"x": 0.7594470046082951, "y": 0.0, "ox": 0.7594470046082951, "oy": 0.0, "term": "mathematics engineering actuarial science related discipline", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.128192288432649, "os": -0.26889963365660247}, {"x": 0.7308755760368665, "y": 0.0, "ox": 0.7308755760368665, "oy": 0.0, "term": "specifically personal unsecured loans Business process monitoring", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14371557336004007, "os": -0.25164484400606724}, {"x": 0.7262672811059909, "y": 0.0, "ox": 0.7262672811059909, "oy": 0.0, "term": "Quality Detail orientation", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14672008012018029, "os": -0.24848610858967718}, {"x": 0.6525345622119817, "y": 0.0, "ox": 0.6525345622119817, "oy": 0.0, "term": "availability accuracy Monitor", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.18427641462193292, "os": -0.21659097966998947}, {"x": 0.6230414746543781, "y": 0.0, "ox": 0.6230414746543781, "oy": 0.0, "term": "SSRS Power BI", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.199799699549324, "os": -0.20451929120527723}, {"x": 0.4663594470046084, "y": 0.0, "ox": 0.4663594470046084, "oy": 0.0, "term": "Stakeholder", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2774161241862795, "os": -0.14988714731648578}, {"x": 0.4654377880184333, "y": 0.0, "ox": 0.4654377880184333, "oy": 0.0, "term": "Unstructured", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2779168753129695, "os": -0.14987211495177338}, {"x": 0.47926267281106, "y": 0.0, "ox": 0.47926267281106, "oy": 0.0, "term": "data processing systems Experience", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.27090635953930897, "os": -0.1516777669832962}, {"x": 0.47741935483870973, "y": 0.0, "ox": 0.47741935483870973, "oy": 0.0, "term": "years experience schema", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.27190786179268905, "os": -0.1514932832759122}, {"x": 0.39815668202764987, "y": 0.0, "ox": 0.39815668202764987, "oy": 0.0, "term": "internal clients Experience designing building", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3119679519278919, "os": -0.13000512543694193}, {"x": 0.3004608294930876, "y": 0.0, "ox": 0.3004608294930876, "oy": 0.0, "term": "communicating data warehouse", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3595393089634452, "os": -0.11467879431909697}, {"x": 0.2903225806451613, "y": 0.0, "ox": 0.2903225806451613, "oy": 0.0, "term": "troubleshooting skills Process oriented great documentation skills", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3645468202303455, "os": -0.11293294996645513}, {"x": 0.2746543778801844, "y": 0.0, "ox": 0.2746543778801844, "oy": 0.0, "term": "dimensional data", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.37255883825738606, "os": -0.1099017050163106}, {"x": 0.2580645161290323, "y": 0.0, "ox": 0.2580645161290323, "oy": 0.0, "term": "keen sense customer service BS MS degree", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.38157235853780674, "os": -0.10714540299962905}, {"x": 0.831336405529954, "y": 0.0, "ox": 0.831336405529954, "oy": 0.0, "term": "data Optimize tune data warehouse query performance analytical workloads", "cat25k": 0, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09063595393089635, "os": -0.3483897249454589}, {"x": 0.8258064516129033, "y": 0.0, "ox": 0.8258064516129033, "oy": 0.0, "term": "SQL Server Experience developing software code", "cat25k": 0, "ncat25k": 24, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09364046069103656, "os": -0.33497106424339673}, {"x": 0.8248847926267282, "y": 0.0, "ox": 0.8248847926267282, "oy": 0.0, "term": "integrations BI tools third party productivity applications years engineering experience Expert SQL", "cat25k": 0, "ncat25k": 24, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.0941412118177266, "os": -0.3330073320350035}, {"x": 0.8193548387096776, "y": 0.0, "ox": 0.8193548387096776, "oy": 0.0, "term": "data warehouse structure table", "cat25k": 0, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09764646970455683, "os": -0.32882220181428906}, {"x": 0.8119815668202767, "y": 0.0, "ox": 0.8119815668202767, "oy": 0.0, "term": "Python Java Scala Ruby Experience managing database data warehouse technologies bonus Redshift Snowflake Experience", "cat25k": 0, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10065097646469705, "os": -0.3185683629683777}, {"x": 0.8055299539170508, "y": 0.0, "ox": 0.8055299539170508, "oy": 0.0, "term": "robust data", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1041562343515273, "os": -0.3106453651909319}, {"x": 0.8046082949308757, "y": 0.0, "ox": 0.8046082949308757, "oy": 0.0, "term": "resolve data quality issues", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10465698547821733, "os": -0.3105694528121413}, {"x": 0.8036866359447006, "y": 0.0, "ox": 0.8036866359447006, "oy": 0.0, "term": "Bonus Stitch Fivetran Matillion Understanding data analytics ecosystem", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10515773660490736, "os": -0.30874469695322676}, {"x": 0.8018433179723504, "y": 0.0, "ox": 0.8018433179723504, "oy": 0.0, "term": "data analysis Design", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10615923885828743, "os": -0.3065687925531719}, {"x": 0.799078341013825, "y": 0.0, "ox": 0.799078341013825, "oy": 0.0, "term": "visualization tools based requirements", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10766149223835754, "os": -0.3039911188824627}, {"x": 0.7944700460829495, "y": 0.0, "ox": 0.7944700460829495, "oy": 0.0, "term": "Business Intelligence tools", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10966449674511768, "os": -0.3029124735012113}, {"x": 0.8414746543778804, "y": 0.0, "ox": 0.8414746543778804, "oy": 0.0, "term": "ETL tools", "cat25k": 0, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08462694041061593, "os": -0.3578982776415653}, {"x": 0.7815668202764978, "y": 0.0, "ox": 0.7815668202764978, "oy": 0.0, "term": "Spark Kafka AWS Glue Amazon Kinesis Sqoop Flume Flink Experience", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11617426139208813, "os": -0.29064923019008587}, {"x": 0.7732718894009218, "y": 0.0, "ox": 0.7732718894009218, "oy": 0.0, "term": "Bonus Looker Experience", "cat25k": 0, "ncat25k": 20, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12068102153229845, "os": -0.2800258172511725}, {"x": 0.7419354838709679, "y": 0.0, "ox": 0.7419354838709679, "oy": 0.0, "term": "Snowflake Redshift PostgreSQL", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.13770655983975966, "os": -0.25981171761898747}, {"x": 0.7299539170506913, "y": 0.0, "ox": 0.7299539170506913, "oy": 0.0, "term": "Bonus Stitch Fivetran Matillion Understanding", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1442163244867301, "os": -0.2515842946721736}, {"x": 0.7290322580645162, "y": 0.0, "ox": 0.7290322580645162, "oy": 0.0, "term": "Redshift Snowflake", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14471707561342015, "os": -0.250499632222606}, {"x": 0.7290322580645162, "y": 0.0, "ox": 0.7290322580645162, "oy": 0.0, "term": "Snowflake Redshift", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14471707561342015, "os": -0.250499632222606}, {"x": 0.6626728110599079, "y": 0.0, "ox": 0.6626728110599079, "oy": 0.0, "term": "Bonus Looker", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17876815222834253, "os": -0.21923371252316287}, {"x": 0.607373271889401, "y": 0.0, "ox": 0.607373271889401, "oy": 0.0, "term": "Kinesis Sqoop", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2083124687030546, "os": -0.1982445927440822}, {"x": 0.5843317972350232, "y": 0.0, "ox": 0.5843317972350232, "oy": 0.0, "term": "Business Intelligence", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21882824236354534, "os": -0.18670848099271403}, {"x": 0.582488479262673, "y": 0.0, "ox": 0.582488479262673, "oy": 0.0, "term": "Spark Kafka", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21982974461692542, "os": -0.1864707166054903}, {"x": 0.51889400921659, "y": 0.0, "ox": 0.51889400921659, "oy": 0.0, "term": "one relevant tools", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2513770655983976, "os": -0.16063721510286622}, {"x": 0.45714285714285724, "y": 0.0, "ox": 0.45714285714285724, "oy": 0.0, "term": "troubleshoot", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.28192288432648976, "os": -0.14642586482378483}, {"x": 0.4516129032258065, "y": 0.0, "ox": 0.4516129032258065, "oy": 0.0, "term": "users", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.28492739108662996, "os": -0.14371873909373678}, {"x": 0.7253456221198158, "y": 0.0, "ox": 0.7253456221198158, "oy": 0.0, "term": "Architect", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14722083124687033, "os": -0.24816440314407348}, {"x": 0.5391705069124425, "y": 0.0, "ox": 0.5391705069124425, "oy": 0.0, "term": "JSON ProtocolBuffers XML", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.24036054081121683, "os": -0.1689485925449067}, {"x": 0.5161290322580646, "y": 0.0, "ox": 0.5161290322580646, "oy": 0.0, "term": "Numpy Scipy Experience query APIs", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2523785678517777, "os": -0.16024031848873493}, {"x": 0.4193548387096775, "y": 0.0, "ox": 0.4193548387096775, "oy": 0.0, "term": "JSON ProtocolBuffers", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.30045067601402103, "os": -0.1349159272141298}, {"x": 0.3824884792626729, "y": 0.0, "ox": 0.3824884792626729, "oy": 0.0, "term": "Numpy Scipy", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.31997996995493244, "os": -0.127311806643223}, {"x": 0.3714285714285715, "y": 0.0, "ox": 0.3714285714285715, "oy": 0.0, "term": "algebra ML", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3259889834752128, "os": -0.1250773868012535}, {"x": 0.2866359447004609, "y": 0.0, "ox": 0.2866359447004609, "oy": 0.0, "term": "RDB MPP DB", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.36604907361041567, "os": -0.11159771340175242}, {"x": 0.2682027649769586, "y": 0.0, "ox": 0.2682027649769586, "oy": 0.0, "term": "Oozie Big data warehousing RDB", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3760640961442164, "os": -0.10835509556596774}, {"x": 0.7649769585253458, "y": 0.0, "ox": 0.7649769585253458, "oy": 0.0, "term": "Apple benefits programmes", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12518778167250877, "os": -0.2727011862354563}, {"x": 0.7511520737327191, "y": 0.0, "ox": 0.7511520737327191, "oy": 0.0, "term": "Apple benefits", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1326990485728593, "os": -0.2633896485488394}, {"x": 0.7382488479262674, "y": 0.0, "ox": 0.7382488479262674, "oy": 0.0, "term": "Apple programmes", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1397095643465198, "os": -0.2574818427013218}, {"x": 0.2211981566820277, "y": 0.0, "ox": 0.2211981566820277, "oy": 0.0, "term": "Apple important resource soul people", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.399599399098648, "os": -0.10280906435128735}, {"x": 0.67926267281106, "y": 0.0, "ox": 0.67926267281106, "oy": 0.0, "term": "Apple chance share company success", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.171256885327992, "os": -0.2262445490581903}, {"x": 0.15852534562211984, "y": 0.0, "ox": 0.15852534562211984, "oy": 0.0, "term": "Supporting data collection curation data provenance", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4326489734601903, "os": -0.09127487512769487}, {"x": 0.6211981566820277, "y": 0.0, "ox": 0.6211981566820277, "oy": 0.0, "term": "stock grants employees levels company", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.20080120180270405, "os": -0.2042975316464902}, {"x": 0.5705069124423964, "y": 0.0, "ox": 0.5705069124423964, "oy": 0.0, "term": "special employee pricing", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2253380070105158, "os": -0.18173971415469709}, {"x": 0.08294930875576037, "y": 0.0, "ox": 0.08294930875576037, "oy": 0.0, "term": "benefits privileges", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4717075613420131, "os": -0.0790749916346076}, {"x": 0.5465437788018435, "y": 0.0, "ox": 0.5465437788018435, "oy": 0.0, "term": "many benefits", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23685528292438662, "os": -0.17099248764539685}, {"x": 0.07741935483870968, "y": 0.0, "ox": 0.07741935483870968, "oy": 0.0, "term": "distributed systems blob storage elastic compute virtual instances Familiarity Software Development Life Cycles tools methodologies", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4747120681021533, "os": -0.0779782840503056}, {"x": 0.05622119815668204, "y": 0.0, "ox": 0.05622119815668204, "oy": 0.0, "term": "reasonable accommodation applicants", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.48422633950926397, "os": -0.07291834912815039}, {"x": 0.05529953917050692, "y": 0.0, "ox": 0.05529953917050692, "oy": 0.0, "term": "Familiarity Software Development Life Cycles", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.484727090635954, "os": -0.07242771859425544}, {"x": 0.0543778801843318, "y": 0.0, "ox": 0.0543778801843318, "oy": 0.0, "term": "reasonable accommodation", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.485227841762644, "os": -0.07187575670860522}, {"x": 0.8617511520737329, "y": 0.0, "ox": 0.8617511520737329, "oy": 0.0, "term": "employees", "cat25k": 0, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07210816224336505, "os": -0.392589514555878}, {"x": 0.47096774193548396, "y": 0.0, "ox": 0.47096774193548396, "oy": 0.0, "term": "charitable contributions reimburse continuing education", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2754131196795193, "os": -0.15070953818900323}, {"x": 0.4543778801843319, "y": 0.0, "ox": 0.4543778801843319, "oy": 0.0, "term": "programmes", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.28342513770655986, "os": -0.14509061586564598}, {"x": 0.48847926267281117, "y": 0.0, "ox": 0.48847926267281117, "oy": 0.0, "term": "country subject eligibility requirements", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2658988482724086, "os": -0.15316322584690856}, {"x": 0.34377880184331805, "y": 0.0, "ox": 0.34377880184331805, "oy": 0.0, "term": "Apple products", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3390085127691538, "os": -0.12095000959594951}, {"x": 0.3373271889400922, "y": 0.0, "ox": 0.3373271889400922, "oy": 0.0, "term": "meaningful ways", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.34201301952929397, "os": -0.11952322311806535}, {"x": 0.21013824884792628, "y": 0.0, "ox": 0.21013824884792628, "oy": 0.0, "term": "Experience Scala", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.40560841261892844, "os": -0.1009397914821711}, {"x": 0.1373271889400922, "y": 0.0, "ox": 0.1373271889400922, "oy": 0.0, "term": "option", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.44366549824737106, "os": -0.08784142540757642}, {"x": 0.25898617511520744, "y": 0.0, "ox": 0.25898617511520744, "oy": 0.0, "term": "source systems data", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.38107160741111673, "os": -0.10717385177869436}, {"x": 0.21105990783410142, "y": 0.0, "ox": 0.21105990783410142, "oy": 0.0, "term": "published data sources", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4051076614922384, "os": -0.1014157335502289}, {"x": 0.14930875576036867, "y": 0.0, "ox": 0.14930875576036867, "oy": 0.0, "term": "Create manage data sources", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4376564847270907, "os": -0.08970449733942487}, {"x": 0.143778801843318, "y": 0.0, "ox": 0.143778801843318, "oy": 0.0, "term": "ETL programs data pipelines", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.44016024036054086, "os": -0.08892446367563044}, {"x": 0.1317972350230415, "y": 0.0, "ox": 0.1317972350230415, "oy": 0.0, "term": "AWS Redshift Python R Hadoop Spark technologies Work", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.44667000500751125, "os": -0.08660622192240722}, {"x": 0.12718894009216591, "y": 0.0, "ox": 0.12718894009216591, "oy": 0.0, "term": "unstructured data Competitive wages", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.44917376064096143, "os": -0.08581785239687616}, {"x": 0.12626728110599078, "y": 0.0, "ox": 0.12626728110599078, "oy": 0.0, "term": "practical demonstrable hands work experience SQL", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.44967451176765155, "os": -0.08566355131490817}, {"x": 0.12534562211981568, "y": 0.0, "ox": 0.12534562211981568, "oy": 0.0, "term": "relational NoSQL columnar data stores", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.45017526289434157, "os": -0.08563284278577898}, {"x": 0.10967741935483873, "y": 0.0, "ox": 0.10967741935483873, "oy": 0.0, "term": "open source cloud based environment", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4581872809213821, "os": -0.08329604284991994}, {"x": 0.09585253456221199, "y": 0.0, "ox": 0.09585253456221199, "oy": 0.0, "term": "Python Java Scala R Sharp attention detail ability", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4651977966950426, "os": -0.08140729130707522}, {"x": 0.08755760368663595, "y": 0.0, "ox": 0.08755760368663595, "oy": 0.0, "term": "Health Savings Account Medical Dependent Care Flexible Spending Accounts Wellness Program Membership TPC", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4692038057085629, "os": -0.07981171632429489}, {"x": 0.07649769585253456, "y": 0.0, "ox": 0.07649769585253456, "oy": 0.0, "term": "database design execution Work", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4752128192288433, "os": -0.0779520770637937}, {"x": 0.07557603686635946, "y": 0.0, "ox": 0.07557603686635946, "oy": 0.0, "term": "Health Savings Account Medical Dependent Care Flexible Spending Accounts", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4757135703555333, "os": -0.07754323918394523}, {"x": 0.07373271889400923, "y": 0.0, "ox": 0.07373271889400923, "oy": 0.0, "term": "Redshift Python R Hadoop", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.47671507260891344, "os": -0.07738714621649502}, {"x": 0.06175115207373272, "y": 0.0, "ox": 0.06175115207373272, "oy": 0.0, "term": "data release testing processes", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4827240861291938, "os": -0.07414544786981007}, {"x": 0.23778801843317976, "y": 0.0, "ox": 0.23778801843317976, "oy": 0.0, "term": "multiple tasks", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3910866299449174, "os": -0.10497024446858984}, {"x": 0.2764976958525346, "y": 0.0, "ox": 0.2764976958525346, "oy": 0.0, "term": "Data Engineering", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.37155733600400603, "os": -0.11020407379025396}, {"x": 0.6608294930875578, "y": 0.0, "ox": 0.6608294930875578, "oy": 0.0, "term": "Spark development years", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1797696544817226, "os": -0.21817021791054858}, {"x": 0.6239631336405531, "y": 0.0, "ox": 0.6239631336405531, "oy": 0.0, "term": "data engineering ETL pipeline development years", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19929894842263396, "os": -0.20488974374424923}, {"x": 0.5695852534562214, "y": 0.0, "ox": 0.5695852534562214, "oy": 0.0, "term": "preferred years", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.22583875813720583, "os": -0.1815798941706476}, {"x": 0.5548387096774194, "y": 0.0, "ox": 0.5548387096774194, "oy": 0.0, "term": "Python preferred Experience", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23335002503755636, "os": -0.17440876605261948}, {"x": 0.5447004608294932, "y": 0.0, "ox": 0.5447004608294932, "oy": 0.0, "term": "Big Data Technologies Hadoop MapReduce Hive", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23785678517776665, "os": -0.17006869284912773}, {"x": 0.47465437788018444, "y": 0.0, "ox": 0.47465437788018444, "oy": 0.0, "term": "Big Data Technologies Hadoop MapReduce Hive etc Spark experience", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.27341011517275915, "os": -0.1510966969558833}, {"x": 0.44700460829493094, "y": 0.0, "ox": 0.44700460829493094, "oy": 0.0, "term": "SSAS SSRS Degree Information Technology", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2869303955933901, "os": -0.14278098774602535}, {"x": 0.4423963133640554, "y": 0.0, "ox": 0.4423963133640554, "oy": 0.0, "term": "Full SQL Stack", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.28893340010015023, "os": -0.14082120066458048}, {"x": 0.4046082949308757, "y": 0.0, "ox": 0.4046082949308757, "oy": 0.0, "term": "SQL knowledge experience", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3084626940410616, "os": -0.13109623145028262}, {"x": 0.4202764976958526, "y": 0.0, "ox": 0.4202764976958526, "oy": 0.0, "term": "Five seven years", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.299949924887331, "os": -0.13516439156845453}, {"x": 0.735483870967742, "y": 0.0, "ox": 0.735483870967742, "oy": 0.0, "term": "SQL NoSQL database experience", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1412118177265899, "os": -0.25648655007826393}, {"x": 0.06543778801843318, "y": 0.0, "ox": 0.06543778801843318, "oy": 0.0, "term": "challenge", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.48122183274912367, "os": -0.07525145166809963}, {"x": 0.3788018433179724, "y": 0.0, "ox": 0.3788018433179724, "oy": 0.0, "term": "data analytic pipelines", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.32198297446169255, "os": -0.12677103232751036}, {"x": 0.34930875576036874, "y": 0.0, "ox": 0.34930875576036874, "oy": 0.0, "term": "Experience data movement management Pharmaceutical industry", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3365047571357036, "os": -0.12150871131016996}, {"x": 0.3124423963133641, "y": 0.0, "ox": 0.3124423963133641, "oy": 0.0, "term": "Computer Science Bioinformatics related degree years experience data movement data wrangling delivery data analytics pipelines", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.35453179769654486, "os": -0.11641254938683596}, {"x": 0.29585253456221206, "y": 0.0, "ox": 0.29585253456221206, "oy": 0.0, "term": "diverse omic data types", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3615423134702053, "os": -0.11385380528660682}, {"x": 0.28847926267281115, "y": 0.0, "ox": 0.28847926267281115, "oy": 0.0, "term": "RNA Seq DNA Seq Chip Seq WES WGS ATAC seq microbiome proteomic metabolomic data", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3650475713570356, "os": -0.11190527103572032}, {"x": 0.28018433179723506, "y": 0.0, "ox": 0.28018433179723506, "oy": 0.0, "term": "Familiarity data mining machine", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.36955433149724587, "os": -0.11073129986286477}, {"x": 0.2165898617511521, "y": 0.0, "ox": 0.2165898617511521, "oy": 0.0, "term": "RNA Seq DNA Seq Chip Seq WES WGS ATAC", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4021031547320982, "os": -0.10221884382688619}, {"x": 0.18525345622119818, "y": 0.0, "ox": 0.18525345622119818, "oy": 0.0, "term": "scientific fields Experience core components Hadoop stack", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.41912869303955935, "os": -0.09658761896365323}, {"x": 0.10506912442396314, "y": 0.0, "ox": 0.10506912442396314, "oy": 0.0, "term": "judgement balance pace", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4606910365548323, "os": -0.0825262388343462}, {"x": 0.07096774193548389, "y": 0.0, "ox": 0.07096774193548389, "oy": 0.0, "term": "honest open conversations", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4782173259889835, "os": -0.07680181100445424}, {"x": 0.06820276497695853, "y": 0.0, "ox": 0.06820276497695853, "oy": 0.0, "term": "Operating pace", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.47971957936905363, "os": -0.0758520477242576}, {"x": 0.06451612903225806, "y": 0.0, "ox": 0.06451612903225806, "oy": 0.0, "term": "rigour risk", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4817225838758138, "os": -0.07491640658456278}, {"x": 0.05714285714285715, "y": 0.0, "ox": 0.05714285714285715, "oy": 0.0, "term": "agile decision making", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.48372558838257385, "os": -0.07315770796381384}, {"x": 0.04884792626728112, "y": 0.0, "ox": 0.04884792626728112, "oy": 0.0, "term": "Cloud computing HPC systems", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4867300951427141, "os": -0.06957150950793554}, {"x": 0.04700460829493088, "y": 0.0, "ox": 0.04700460829493088, "oy": 0.0, "term": "artificial intelligence techniques", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.48723084626940416, "os": -0.06782687574643652}, {"x": 0.41658986175115215, "y": 0.0, "ox": 0.41658986175115215, "oy": 0.0, "term": "HDFS Apache Spark", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3019529293940912, "os": -0.13441605835478762}, {"x": 0.9207373271889402, "y": 0.0, "ox": 0.9207373271889402, "oy": 0.0, "term": "Agile Engineering Kanban Lean Hybrid agile experience", "cat25k": 0, "ncat25k": 40, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.04006009013520281, "os": -0.5600561712355718}, {"x": 0.8184331797235025, "y": 0.0, "ox": 0.8184331797235025, "oy": 0.0, "term": "Python SQL Elastic visualise data surfacing tool Experience developing machine learning systems Experience Amazon Quicksite advantage", "cat25k": 0, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09814722083124687, "os": -0.32763716428111583}, {"x": 0.7834101382488481, "y": 0.0, "ox": 0.7834101382488481, "oy": 0.0, "term": "exploration visualisation Experience statistical models times", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11567351026539809, "os": -0.29135263036164843}, {"x": 0.7529953917050692, "y": 0.0, "ox": 0.7529953917050692, "oy": 0.0, "term": "Degree educated Data Science similar Strong experience data preparation techniques", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.13169754631947922, "os": -0.2652549507712826}, {"x": 0.7483870967741937, "y": 0.0, "ox": 0.7483870967741937, "oy": 0.0, "term": "regression classification Strong skills", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1342013019529294, "os": -0.2625672916149315}, {"x": 0.6949308755760369, "y": 0.0, "ox": 0.6949308755760369, "oy": 0.0, "term": "Python SQL Elastic", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16374561842764146, "os": -0.233190791158125}, {"x": 0.6387096774193549, "y": 0.0, "ox": 0.6387096774193549, "oy": 0.0, "term": "series analysis", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1912869303955934, "os": -0.21002528457369385}, {"x": 0.8175115207373272, "y": 0.0, "ox": 0.8175115207373272, "oy": 0.0, "term": "Splunk Hadoop", "cat25k": 0, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09864797195793691, "os": -0.3263027573257299}, {"x": 0.6036866359447005, "y": 0.0, "ox": 0.6036866359447005, "oy": 0.0, "term": "insightful data performance visualizations", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.20931397095643467, "os": -0.19565044697536516}, {"x": 0.5861751152073733, "y": 0.0, "ox": 0.5861751152073733, "oy": 0.0, "term": "optimized pipelines data acquisition", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21782674011016526, "os": -0.1885559299049776}, {"x": 0.5797235023041476, "y": 0.0, "ox": 0.5797235023041476, "oy": 0.0, "term": "algorithm variants", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2208312468703055, "os": -0.1863277909505755}, {"x": 0.25622119815668204, "y": 0.0, "ox": 0.25622119815668204, "oy": 0.0, "term": "Expertise Python programming functional object", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.38257386079118677, "os": -0.10664755076072875}, {"x": 0.7096774193548389, "y": 0.0, "ox": 0.7096774193548389, "oy": 0.0, "term": "limited personnel policies policies", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1557336004006009, "os": -0.23989703090071807}, {"x": 0.599078341013825, "y": 0.0, "ox": 0.599078341013825, "oy": 0.0, "term": "University Administrative Guide http", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2123184777165749, "os": -0.19290563969950608}, {"x": 0.5898617511520738, "y": 0.0, "ox": 0.5898617511520738, "oy": 0.0, "term": "comply applicable University policies procedures", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21682523785678517, "os": -0.18944006631356136}, {"x": 0.5640552995391707, "y": 0.0, "ox": 0.5640552995391707, "oy": 0.0, "term": "University Administrative Guide", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.22884326489734605, "os": -0.17861246646481085}, {"x": 0.7972350230414748, "y": 0.0, "ox": 0.7972350230414748, "oy": 0.0, "term": "unsolicited services", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10816224336504757, "os": -0.30375669934033167}, {"x": 0.5373271889400923, "y": 0.0, "ox": 0.5373271889400923, "oy": 0.0, "term": "Linux system administration command line tools", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2413620430645969, "os": -0.16841188259451137}, {"x": 0.5253456221198157, "y": 0.0, "ox": 0.5253456221198157, "oy": 0.0, "term": "Strong analytical thinking", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2478718077115674, "os": -0.16394498252980755}, {"x": 0.4331797235023042, "y": 0.0, "ox": 0.4331797235023042, "oy": 0.0, "term": "Excellent programming skills C C Python Java", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2939409113670506, "os": -0.13836614278517984}, {"x": 0.3870967741935485, "y": 0.0, "ox": 0.3870967741935485, "oy": 0.0, "term": "minimum experience", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.31747621432148226, "os": -0.12796620928200514}, {"x": 0.26635944700460834, "y": 0.0, "ox": 0.26635944700460834, "oy": 0.0, "term": "production software", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3770655983975964, "os": -0.1081450702626184}, {"x": 0.5336405529953918, "y": 0.0, "ox": 0.5336405529953918, "oy": 0.0, "term": "Experience data tools", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.24336504757135705, "os": -0.16729347147892848}, {"x": 0.46267281105990793, "y": 0.0, "ox": 0.46267281105990793, "oy": 0.0, "term": "streaming data processing Ability", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2789183775663495, "os": -0.14906946035930752}, {"x": 0.4211981566820277, "y": 0.0, "ox": 0.4211981566820277, "oy": 0.0, "term": "Scala preferred Proficient schema design data", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.299449173760641, "os": -0.13524852045916655}, {"x": 0.40921658986175125, "y": 0.0, "ox": 0.40921658986175125, "oy": 0.0, "term": "analytic skills Ability program several scripting languages Python Perl Bash Experience workflow management tools", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3059589384076114, "os": -0.13244284190974367}, {"x": 0.39170506912442404, "y": 0.0, "ox": 0.39170506912442404, "oy": 0.0, "term": "high volume data Apache Hadoop ecosystem", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3154732098147221, "os": -0.12912208000707284}, {"x": 0.3170506912442397, "y": 0.0, "ox": 0.3170506912442397, "oy": 0.0, "term": "Oozie Airflow Azkaban", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3520280420630947, "os": -0.11695752566213621}, {"x": 0.16129032258064518, "y": 0.0, "ox": 0.16129032258064518, "oy": 0.0, "term": "Python Perl Bash", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4311467200801202, "os": -0.09145669103817104}, {"x": 0.15299539170506915, "y": 0.0, "ox": 0.15299539170506915, "oy": 0.0, "term": "Oozie Airflow Azkaban etc Experience", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4356534802203305, "os": -0.09014548379849507}, {"x": 0.1327188940092166, "y": 0.0, "ox": 0.1327188940092166, "oy": 0.0, "term": "working cross functional projects", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.44616925388082124, "os": -0.08669534775390914}, {"x": 0.05806451612903226, "y": 0.0, "ox": 0.05806451612903226, "oy": 0.0, "term": "one object oriented programming languages", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.48322483725588383, "os": -0.07327529057284067}, {"x": 0.050691244239631346, "y": 0.0, "ox": 0.050691244239631346, "oy": 0.0, "term": "Passion customer privacy Strong interpersonal skills", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.486229344016024, "os": -0.0708353801579834}, {"x": 0.8626728110599079, "y": 0.0, "ox": 0.8626728110599079, "oy": 0.0, "term": "Cassandra Neo4J", "cat25k": 0, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07060590886329493, "os": -0.39309699602751175}, {"x": 0.2976958525345623, "y": 0.0, "ox": 0.2976958525345623, "oy": 0.0, "term": "MongoDB Cassandra", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.36054081121682524, "os": -0.11407306634806502}, {"x": 0.5741935483870969, "y": 0.0, "ox": 0.5741935483870969, "oy": 0.0, "term": "SSIS standard ETL", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.22333500250375565, "os": -0.18502395712681174}, {"x": 0.4986175115207374, "y": 0.0, "ox": 0.4986175115207374, "oy": 0.0, "term": "strong Stored Procs", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.26039058587881825, "os": -0.1560976090024442}, {"x": 0.4451612903225807, "y": 0.0, "ox": 0.4451612903225807, "oy": 0.0, "term": "Stored Procs", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2879318978467702, "os": -0.14202215680089195}, {"x": 0.38617511520737335, "y": 0.0, "ox": 0.38617511520737335, "oy": 0.0, "term": "serious interest", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3179769654481723, "os": -0.12791085065371352}, {"x": 0.36313364055299546, "y": 0.0, "ox": 0.36313364055299546, "oy": 0.0, "term": "SQL Dev", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.33049574361542317, "os": -0.1233111149795148}, {"x": 0.30322580645161296, "y": 0.0, "ox": 0.30322580645161296, "oy": 0.0, "term": "MapReduce Spark Spark SQL", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.35853780671006513, "os": -0.11505728455454008}, {"x": 0.24147465437788024, "y": 0.0, "ox": 0.24147465437788024, "oy": 0.0, "term": "Java Scala Extensive experience Hadoop ecosystem technologies", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3890836254381573, "os": -0.105079815781696}, {"x": 0.18709677419354842, "y": 0.0, "ox": 0.18709677419354842, "oy": 0.0, "term": "Spark Streaming Hive YARN MR2 Expertise building", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4181271907861793, "os": -0.09670324961310343}, {"x": 0.0903225806451613, "y": 0.0, "ox": 0.0903225806451613, "oy": 0.0, "term": "Java Scala Extensive", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4682023034551828, "os": -0.08042415813793687}, {"x": 0.3658986175115208, "y": 0.0, "ox": 0.3658986175115208, "oy": 0.0, "term": "Scala Python Apple", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.32899349023535307, "os": -0.12410767425440432}, {"x": 0.3419354838709678, "y": 0.0, "ox": 0.3419354838709678, "oy": 0.0, "term": "Scala Python Apple important resource soul people", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3400100150225338, "os": -0.12053475686551895}, {"x": 0.23133640552995396, "y": 0.0, "ox": 0.23133640552995396, "oy": 0.0, "term": "self sufficient Experience", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.39409113670505763, "os": -0.10408294411834655}, {"x": 0.1990783410138249, "y": 0.0, "ox": 0.1990783410138249, "oy": 0.0, "term": "distributed systems services scale Experience", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4116174261392088, "os": -0.09855707143302415}, {"x": 0.1861751152073733, "y": 0.0, "ox": 0.1861751152073733, "oy": 0.0, "term": "Preference experience", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.41862794191286934, "os": -0.09664197337274795}, {"x": 0.1557603686635945, "y": 0.0, "ox": 0.1557603686635945, "oy": 0.0, "term": "health wellness resources time", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4341512268402604, "os": -0.09083275000383159}, {"x": 0.11336405529953919, "y": 0.0, "ox": 0.11336405529953919, "oy": 0.0, "term": "similar technologies production contexts", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.45668502754131196, "os": -0.0839534419726521}, {"x": 0.08940092165898618, "y": 0.0, "ox": 0.08940092165898618, "oy": 0.0, "term": "SOLR Spark Hadoop Kafka", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.46870305458187284, "os": -0.08033060573141021}, {"x": 0.0792626728110599, "y": 0.0, "ox": 0.0792626728110599, "oy": 0.0, "term": "years software engineering experience", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4737105658487732, "os": -0.078289345813229}, {"x": 0.07465437788018434, "y": 0.0, "ox": 0.07465437788018434, "oy": 0.0, "term": "responsible self", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.47621432148222337, "os": -0.07743480578534312}, {"x": 0.45622119815668216, "y": 0.0, "ox": 0.45622119815668216, "oy": 0.0, "term": "Redis Apache Spark similar tools Experience regression testing data pipelines", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2824236354531798, "os": -0.14626102605016955}, {"x": 0.4359447004608296, "y": 0.0, "ox": 0.4359447004608296, "oy": 0.0, "term": "instance Docker Kubernetes Terraform CloudFormation Ansible Chef Puppet Salt Splunk Elastic ELK Stack Sentry Datadog similar tools Knowledge Machine Learning Computer Vision", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2924386579869805, "os": -0.13924465340851092}, {"x": 0.3852534562211982, "y": 0.0, "ox": 0.3852534562211982, "oy": 0.0, "term": "Experience DevOps application monitoring tools", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3184777165748623, "os": -0.12783323870378516}, {"x": 0.37603686635944705, "y": 0.0, "ox": 0.37603686635944705, "oy": 0.0, "term": "AWS RDS Apache Kafka AWS Kinesis", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.32348522784176265, "os": -0.12631053200292025}, {"x": 0.3566820276497697, "y": 0.0, "ox": 0.3566820276497697, "oy": 0.0, "term": "Knowledge Machine Learning Computer Vision", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.33350025037556336, "os": -0.12246244475598195}, {"x": 0.26451612903225813, "y": 0.0, "ox": 0.26451612903225813, "oy": 0.0, "term": "Proficient scripting functional programming languages", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.37806710065097654, "os": -0.10801734109366186}, {"x": 0.25714285714285723, "y": 0.0, "ox": 0.25714285714285723, "oy": 0.0, "term": "Docker Kubernetes Terraform CloudFormation Ansible", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.38207310966449676, "os": -0.1068524204997524}, {"x": 0.24700460829493093, "y": 0.0, "ox": 0.24700460829493093, "oy": 0.0, "term": "RDS Apache Kafka", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3865798698047071, "os": -0.10562460944433988}, {"x": 0.20645161290322583, "y": 0.0, "ox": 0.20645161290322583, "oy": 0.0, "term": "Redis Apache", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4076114171256886, "os": -0.1003121022813186}, {"x": 0.20552995391705073, "y": 0.0, "ox": 0.20552995391705073, "oy": 0.0, "term": "streaming solutions instance", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4081121682523786, "os": -0.1002757993994672}, {"x": 0.11705069124423964, "y": 0.0, "ox": 0.11705069124423964, "oy": 0.0, "term": "Kinesis RabbitMQ", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.45468202303455185, "os": -0.08424366220201969}, {"x": 0.07004608294930877, "y": 0.0, "ox": 0.07004608294930877, "oy": 0.0, "term": "Python Scala Bash Groovy Ruby Experience database message", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4787180771156735, "os": -0.07654553160802807}, {"x": 0.7207373271889402, "y": 0.0, "ox": 0.7207373271889402, "oy": 0.0, "term": "working Batch Real Time data processing systems Ability work", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15072608913370059, "os": -0.2466504073648503}, {"x": 0.7142857142857144, "y": 0.0, "ox": 0.7142857142857144, "oy": 0.0, "term": "large scale data processing", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15373059589384078, "os": -0.24367300090622152}, {"x": 0.7050691244239633, "y": 0.0, "ox": 0.7050691244239633, "oy": 0.0, "term": "machine learning solutions scale Experience", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1582373560340511, "os": -0.23820208068779886}, {"x": 0.6967741935483872, "y": 0.0, "ox": 0.6967741935483872, "oy": 0.0, "term": "based systems Experience custom ETL design implementation maintenance Experience", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1627441161742614, "os": -0.23511953131853158}, {"x": 0.686635944700461, "y": 0.0, "ox": 0.686635944700461, "oy": 0.0, "term": "data storage principles", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16775162744116173, "os": -0.22915210701248473}, {"x": 0.6811059907834103, "y": 0.0, "ox": 0.6811059907834103, "oy": 0.0, "term": "Knowledge distributed systems", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17025538307461194, "os": -0.22669233693056343}, {"x": 0.9096774193548389, "y": 0.0, "ox": 0.9096774193548389, "oy": 0.0, "term": "data management", "cat25k": 0, "ncat25k": 37, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.044566850275413114, "os": -0.5281708307931772}, {"x": 0.6543778801843319, "y": 0.0, "ox": 0.6543778801843319, "oy": 0.0, "term": "data storage cloud computing Understanding administration AWS Docker Linux", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.18327491236855284, "os": -0.21702577197834355}, {"x": 0.6663594470046084, "y": 0.0, "ox": 0.6663594470046084, "oy": 0.0, "term": "Hadoop Spark Dataflow Airflow Knowledge practical experience machine", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1767651477215824, "os": -0.22137517527315737}, {"x": 0.6460829493087559, "y": 0.0, "ox": 0.6460829493087559, "oy": 0.0, "term": "traditional distributed systems", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.18778167250876318, "os": -0.212925869798807}, {"x": 0.2285714285714286, "y": 0.0, "ox": 0.2285714285714286, "oy": 0.0, "term": "Competitive Salary Equity 401k Company Match Gym Public Transportation Subsidy Student Loan Assistance Relocation Assistance Unlimited PTO", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3955933900851277, "os": -0.10379979563939636}, {"x": 0.20276497695852538, "y": 0.0, "ox": 0.20276497695852538, "oy": 0.0, "term": "Competitive Salary Equity 401k Company Match Gym Public Transportation Subsidy Student Loan Assistance Relocation Assistance", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.40961442163244866, "os": -0.09959556104802586}, {"x": 0.14654377880184333, "y": 0.0, "ox": 0.14654377880184333, "oy": 0.0, "term": "Unlimited PTO", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4386579869804707, "os": -0.0895151988254552}, {"x": 0.5364055299539171, "y": 0.0, "ox": 0.5364055299539171, "oy": 0.0, "term": "Opportunity work", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.24186279419128695, "os": -0.16816468097755227}, {"x": 0.4728110599078342, "y": 0.0, "ox": 0.4728110599078342, "oy": 0.0, "term": "AI fundamentals", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.27441161742613923, "os": -0.1508514957333013}, {"x": 0.4847926267281107, "y": 0.0, "ox": 0.4847926267281107, "oy": 0.0, "term": "Batch Real Time", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2679018527791688, "os": -0.15265217092096506}, {"x": 0.6414746543778803, "y": 0.0, "ox": 0.6414746543778803, "oy": 0.0, "term": "Computer Science Statistics Engineering", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19028542814221333, "os": -0.21151565790704446}, {"x": 0.34285714285714297, "y": 0.0, "ox": 0.34285714285714297, "oy": 0.0, "term": "higher quantitative technical field", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3395092638958438, "os": -0.12054902996014624}, {"x": 0.2949308755760369, "y": 0.0, "ox": 0.2949308755760369, "oy": 0.0, "term": "Working knowledge data design architecture", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.36204306459689534, "os": -0.11384647308359314}, {"x": 0.09493087557603687, "y": 0.0, "ox": 0.09493087557603687, "oy": 0.0, "term": "401K Gym public transportation subsidy Relocation assistance", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.46569854782173264, "os": -0.08115576084075647}, {"x": 0.08663594470046083, "y": 0.0, "ox": 0.08663594470046083, "oy": 0.0, "term": "fastest growing financial startups Competitive salary equity Health dental vision insurance", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4697045568352529, "os": -0.0797318723057307}, {"x": 0.0783410138248848, "y": 0.0, "ox": 0.0783410138248848, "oy": 0.0, "term": "K Gym", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.47421131697546326, "os": -0.07798021174513123}, {"x": 0.5308755760368664, "y": 0.0, "ox": 0.5308755760368664, "oy": 0.0, "term": "data ingest enrichment analysis visualization dissemination", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.24486730095142717, "os": -0.16605242908954335}, {"x": 0.4580645161290323, "y": 0.0, "ox": 0.4580645161290323, "oy": 0.0, "term": "Spark Knime Exposure AWS Data Services Experience Architect design implement", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2814221331997997, "os": -0.1465992718429829}, {"x": 0.41566820276497707, "y": 0.0, "ox": 0.41566820276497707, "oy": 0.0, "term": "Spark Knime Exposure AWS Data Services", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3024536805207812, "os": -0.13429186103594265}, {"x": 0.41105990783410146, "y": 0.0, "ox": 0.41105990783410146, "oy": 0.0, "term": "Data transformation experience", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3049574361542314, "os": -0.13261189066500795}, {"x": 0.31428571428571433, "y": 0.0, "ox": 0.31428571428571433, "oy": 0.0, "term": "data repositories", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3535302954431648, "os": -0.11664916516292281}, {"x": 0.17142857142857146, "y": 0.0, "ox": 0.17142857142857146, "oy": 0.0, "term": "largest growth", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.42613920881321987, "os": -0.09323036846455562}, {"x": 0.14101382488479264, "y": 0.0, "ox": 0.14101382488479264, "oy": 0.0, "term": "indices", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.44166249374061095, "os": -0.08827530475425763}, {"x": 0.13548387096774195, "y": 0.0, "ox": 0.13548387096774195, "oy": 0.0, "term": "Graph Databases", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4446670005007512, "os": -0.08746012240642784}, {"x": 0.13087557603686636, "y": 0.0, "ox": 0.13087557603686636, "oy": 0.0, "term": "enhancements", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4471707561342014, "os": -0.08660608483586547}, {"x": 0.33179723502304154, "y": 0.0, "ox": 0.33179723502304154, "oy": 0.0, "term": "working day year", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.34451677516274415, "os": -0.11896389798067955}, {"x": 0.23502304147465444, "y": 0.0, "ox": 0.23502304147465444, "oy": 0.0, "term": "data enterprise systems SAP Security management Data modelling ETL development", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.39208813219829747, "os": -0.1045314606249528}, {"x": 0.6129032258064517, "y": 0.0, "ox": 0.6129032258064517, "oy": 0.0, "term": "Annual Bonus Plan Discretionary Cash Award Group Personal Pension Plan", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2053079619429144, "os": -0.20023660897900963}, {"x": 0.20184331797235025, "y": 0.0, "ox": 0.20184331797235025, "oy": 0.0, "term": "additional days", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4101151727591388, "os": -0.09937253034251799}, {"x": 0.1566820276497696, "y": 0.0, "ox": 0.1566820276497696, "oy": 0.0, "term": "tools Data Integrator Services Experience experience", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.43365047571357035, "os": -0.09110822710993935}, {"x": 0.12903225806451615, "y": 0.0, "ox": 0.12903225806451615, "oy": 0.0, "term": "agile project management", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4481722583875814, "os": -0.08629701348561582}, {"x": 0.12811059907834102, "y": 0.0, "ox": 0.12811059907834102, "oy": 0.0, "term": "Medical Travel Health Life Insurances", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4486730095142714, "os": -0.08605144251234166}, {"x": 0.12165898617511522, "y": 0.0, "ox": 0.12165898617511522, "oy": 0.0, "term": "data engineering domain", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4521782674011017, "os": -0.08445030954258961}, {"x": 0.1207373271889401, "y": 0.0, "ox": 0.1207373271889401, "oy": 0.0, "term": "Data Integrator Services", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.45267901852779174, "os": -0.08440117670359212}, {"x": 0.11428571428571431, "y": 0.0, "ox": 0.11428571428571431, "oy": 0.0, "term": "free car parking gym site team", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.45618427641462195, "os": -0.0839680190034545}, {"x": 0.11244239631336407, "y": 0.0, "ox": 0.11244239631336407, "oy": 0.0, "term": "schemas dimensional modelling normalisation", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.45718577866800203, "os": -0.08394993083799997}, {"x": 0.09953917050691245, "y": 0.0, "ox": 0.09953917050691245, "oy": 0.0, "term": "Strong knowledge concepts", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.46319479218828247, "os": -0.08182324964040064}, {"x": 0.3244239631336406, "y": 0.0, "ox": 0.3244239631336406, "oy": 0.0, "term": "yearly basis taxable benefit Employee Stock Purchase Program Free snacks", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3485227841762644, "os": -0.11803364780367072}, {"x": 0.28387096774193554, "y": 0.0, "ox": 0.28387096774193554, "oy": 0.0, "term": "spark Experience Scala Python Experience building batch pipelines data event data", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.36755132699048576, "os": -0.11136068732267497}, {"x": 0.27188940092165903, "y": 0.0, "ox": 0.27188940092165903, "oy": 0.0, "term": "Employee Stock Purchase Program Free", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3740610916374562, "os": -0.109362176945107}, {"x": 0.23870967741935492, "y": 0.0, "ox": 0.23870967741935492, "oy": 0.0, "term": "Experience building data pipelines", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.39058587881822737, "os": -0.10500572967046706}, {"x": 0.15207373271889402, "y": 0.0, "ox": 0.15207373271889402, "oy": 0.0, "term": "data systems AWS", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4361542313470205, "os": -0.09005158094229739}, {"x": 0.14562211981566822, "y": 0.0, "ox": 0.14562211981566822, "oy": 0.0, "term": "NoSQL APIs Competitive health insurance benefits Competitive salary Annual target bonus commission", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4391587381071608, "os": -0.08941527404150612}, {"x": 0.11612903225806452, "y": 0.0, "ox": 0.11612903225806452, "oy": 0.0, "term": "Vacation", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4551827741612419, "os": -0.08407208146693344}, {"x": 0.4027649769585254, "y": 0.0, "ox": 0.4027649769585254, "oy": 0.0, "term": "scalable data pipelines data processing frameworks", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3094641962944417, "os": -0.13068187388296815}, {"x": 0.2405529953917051, "y": 0.0, "ox": 0.2405529953917051, "oy": 0.0, "term": "Depth knowledge Data Operations Data Quality management space Experience layered geospatial data structures data representations", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3895843765648473, "os": -0.10506497746361186}, {"x": 0.223963133640553, "y": 0.0, "ox": 0.223963133640553, "oy": 0.0, "term": "modern cloud native processing frameworks", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3980971457185779, "os": -0.10318082253979695}, {"x": 0.21566820276497697, "y": 0.0, "ox": 0.21566820276497697, "oy": 0.0, "term": "high volume data processing organization business division", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.40260390585878825, "os": -0.10219207544685374}, {"x": 0.2046082949308756, "y": 0.0, "ox": 0.2046082949308756, "oy": 0.0, "term": "computing frameworks geospatial processing indexing", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.40861291937906863, "os": -0.10023212669199427}, {"x": 0.1981566820276498, "y": 0.0, "ox": 0.1981566820276498, "oy": 0.0, "term": "data quality management", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.41211817726589883, "os": -0.09840706398374821}, {"x": 0.1732718894009217, "y": 0.0, "ox": 0.1732718894009217, "oy": 0.0, "term": "Expertise processing", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4251377065598398, "os": -0.09408682729470308}, {"x": 0.1087557603686636, "y": 0.0, "ox": 0.1087557603686636, "oy": 0.0, "term": "scalable cloud native backend compute capabilities REST APIs microservices", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4586880320480721, "os": -0.08326533237996392}, {"x": 0.10414746543778802, "y": 0.0, "ox": 0.10414746543778802, "oy": 0.0, "term": "distributed computing environment years", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4611917876815223, "os": -0.08250189114014567}, {"x": 0.42211981566820284, "y": 0.0, "ox": 0.42211981566820284, "oy": 0.0, "term": "Inspire", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.29894842263395094, "os": -0.13548690398139912}, {"x": 0.19539170506912446, "y": 0.0, "ox": 0.19539170506912446, "oy": 0.0, "term": "intellectual curiosity Show passion innovation continuous improvement initiate efforts", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.413620430645969, "os": -0.09784392945256624}, {"x": 0.17235023041474656, "y": 0.0, "ox": 0.17235023041474656, "oy": 0.0, "term": "Extensive experience relational database development", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4256384576865298, "os": -0.09387955246708084}, {"x": 0.1686635944700461, "y": 0.0, "ox": 0.1686635944700461, "oy": 0.0, "term": "Experience scripting automation language", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.42764146219328997, "os": -0.09280579589577627}, {"x": 0.15391705069124426, "y": 0.0, "ox": 0.15391705069124426, "oy": 0.0, "term": "technical direction problem", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4351527290936405, "os": -0.09043450972696875}, {"x": 0.1382488479262673, "y": 0.0, "ox": 0.1382488479262673, "oy": 0.0, "term": "organisation best practice quality standards", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.44316474712068105, "os": -0.08793017508876348}, {"x": 0.12995391705069126, "y": 0.0, "ox": 0.12995391705069126, "oy": 0.0, "term": "Ensure third party development", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4476715072608914, "os": -0.08656987239370366}, {"x": 0.10599078341013825, "y": 0.0, "ox": 0.10599078341013825, "oy": 0.0, "term": "exceptional problem", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4601902854281422, "os": -0.08259616105282391}, {"x": 0.10046082949308757, "y": 0.0, "ox": 0.10046082949308757, "oy": 0.0, "term": "Knowledge investment management", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4626940410615924, "os": -0.08194957921732175}, {"x": 0.09400921658986175, "y": 0.0, "ox": 0.09400921658986175, "oy": 0.0, "term": "support team", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.46619929894842266, "os": -0.08114841262999756}, {"x": 0.08571428571428573, "y": 0.0, "ox": 0.08571428571428573, "oy": 0.0, "term": "Interest NoSQL database", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.47020530796194293, "os": -0.07940552468669598}, {"x": 0.5115207373271891, "y": 0.0, "ox": 0.5115207373271891, "oy": 0.0, "term": "Embrace", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2538808212318478, "os": -0.1591317514604616}, {"x": 0.1751152073732719, "y": 0.0, "ox": 0.1751152073732719, "oy": 0.0, "term": "functional team environment Apple Equal Opportunity Employer", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4241362043064597, "os": -0.09423285587057326}, {"x": 0.167741935483871, "y": 0.0, "ox": 0.167741935483871, "oy": 0.0, "term": "relationships Ability", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.42814221331998, "os": -0.09275985588537539}, {"x": 0.15483870967741936, "y": 0.0, "ox": 0.15483870967741936, "oy": 0.0, "term": "HTML CSS Javascript Strong interpersonal skills verbal written Ability", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4346519779669505, "os": -0.09049752938567537}, {"x": 0.14285714285714288, "y": 0.0, "ox": 0.14285714285714288, "oy": 0.0, "term": "day day business support", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.44066099148723087, "os": -0.08891525292557619}, {"x": 0.14009216589861753, "y": 0.0, "ox": 0.14009216589861753, "oy": 0.0, "term": "directional changes ability", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.442163244867301, "os": -0.08825784118123912}, {"x": 0.13640552995391705, "y": 0.0, "ox": 0.13640552995391705, "oy": 0.0, "term": "Apple Equal Opportunity Employer", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4441662493740611, "os": -0.08781034620277667}, {"x": 0.09861751152073735, "y": 0.0, "ox": 0.09861751152073735, "oy": 0.0, "term": "similar Proficient data access preparation methods", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4636955433149725, "os": -0.08181442033929165}, {"x": 0.07281105990783411, "y": 0.0, "ox": 0.07281105990783411, "oy": 0.0, "term": "Proficient scripting glue languages", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.47721582373560345, "os": -0.07713597863064903}, {"x": 0.06912442396313365, "y": 0.0, "ox": 0.06912442396313365, "oy": 0.0, "term": "data elements sources", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4792188282423636, "os": -0.07615121489233179}, {"x": 0.06267281105990784, "y": 0.0, "ox": 0.06267281105990784, "oy": 0.0, "term": "PHP Python web technologies", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4822233350025038, "os": -0.074605705643951}, {"x": 0.5244239631336407, "y": 0.0, "ox": 0.5244239631336407, "oy": 0.0, "term": "PHP", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2483725588382574, "os": -0.1631153796491118}, {"x": 0.7161290322580647, "y": 0.0, "ox": 0.7161290322580647, "oy": 0.0, "term": "Minimum five years data analytics programming database administration data management experience", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1527290936404607, "os": -0.2438102125077615}, {"x": 0.6267281105990784, "y": 0.0, "ox": 0.6267281105990784, "oy": 0.0, "term": "requisite skills", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19779669504256386, "os": -0.20616239854731622}, {"x": 0.6258064516129033, "y": 0.0, "ox": 0.6258064516129033, "oy": 0.0, "term": "less experience", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1982974461692539, "os": -0.20564896932640234}, {"x": 0.583410138248848, "y": 0.0, "ox": 0.583410138248848, "oy": 0.0, "term": "applications candidates", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21932899349023535, "os": -0.1866146151190337}, {"x": 0.36129032258064525, "y": 0.0, "ox": 0.36129032258064525, "oy": 0.0, "term": "The stated experience level guide", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3309964947421132, "os": -0.12288654090869425}, {"x": 0.3299539170506913, "y": 0.0, "ox": 0.3299539170506913, "oy": 0.0, "term": "Medical Health Insurance Onsite Wellness Clinic Long Term Disability Life Insurance Dental Vision Coverage", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3455182774161242, "os": -0.11876575785054228}, {"x": 0.30875576036866365, "y": 0.0, "ox": 0.30875576036866365, "oy": 0.0, "term": "cruises anniversary Medical Health Insurance Onsite Wellness Clinic Long Term Disability Life Insurance Dental Vision Coverage", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.35603405107661495, "os": -0.11561866185305845}, {"x": 0.3050691244239632, "y": 0.0, "ox": 0.3050691244239632, "oy": 0.0, "term": "Legal Insurance", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.35753630445668505, "os": -0.11530223028072924}, {"x": 0.3023041474654379, "y": 0.0, "ox": 0.3023041474654379, "oy": 0.0, "term": "K Plan Pet Care Insurance", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.35903855783675515, "os": -0.11503487834157274}, {"x": 0.2930875576036867, "y": 0.0, "ox": 0.2930875576036867, "oy": 0.0, "term": "Data design experience Experience data cleansing optimization data consumption Experience source control tools Git TFS", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3630445668502754, "os": -0.11356860203955775}, {"x": 0.22949308755760373, "y": 0.0, "ox": 0.22949308755760373, "oy": 0.0, "term": "Consumer Websites Experience consumer facing", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.39509263895843766, "os": -0.10388458987438359}, {"x": 0.11981566820276497, "y": 0.0, "ox": 0.11981566820276497, "oy": 0.0, "term": "data management systems", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.45317976965448176, "os": -0.08438112006662318}, {"x": 0.11797235023041476, "y": 0.0, "ox": 0.11797235023041476, "oy": 0.0, "term": "Experience Azure Service Fabric", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4541812719078618, "os": -0.08427996334437433}, {"x": 0.10322580645161292, "y": 0.0, "ox": 0.10322580645161292, "oy": 0.0, "term": "Working familiarity front end web framework", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4616925388082123, "os": -0.08236406530354042}, {"x": 0.0838709677419355, "y": 0.0, "ox": 0.0838709677419355, "oy": 0.0, "term": "CSV JSON XML data formats", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.471206810215323, "os": -0.07917391897925374}, {"x": 0.08018433179723503, "y": 0.0, "ox": 0.08018433179723503, "oy": 0.0, "term": "Dedicated Employee Enrichment Recognition Programs", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4732098147220831, "os": -0.07846703372727493}, {"x": 0.0663594470046083, "y": 0.0, "ox": 0.0663594470046083, "oy": 0.0, "term": "mobile systems", "cat25k": 0, "ncat25k": 5, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.48072108162243365, "os": -0.07531814145465768}, {"x": 0.43778801843317977, "y": 0.0, "ox": 0.43778801843317977, "oy": 0.0, "term": "data engineering tasks", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2914371557336004, "os": -0.1400845271989995}, {"x": 0.42857142857142866, "y": 0.0, "ox": 0.42857142857142866, "oy": 0.0, "term": "Expertise Hadoop related technologies", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.29594391587381075, "os": -0.13708406841235385}, {"x": 0.4064516129032259, "y": 0.0, "ox": 0.4064516129032259, "oy": 0.0, "term": "large scale data warehousing mining analytic systems Ability work analysts", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.30746119178768155, "os": -0.13209322724280284}, {"x": 0.39723502304147473, "y": 0.0, "ox": 0.39723502304147473, "oy": 0.0, "term": "Spark Streaming Spark SQL Map", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3124687030545819, "os": -0.1297324401815479}, {"x": 0.39078341013824897, "y": 0.0, "ox": 0.39078341013824897, "oy": 0.0, "term": "big data pipelines", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3159739609414121, "os": -0.12905603876549493}, {"x": 0.375115207373272, "y": 0.0, "ox": 0.375115207373272, "oy": 0.0, "term": "Azkaban Oozie Impala Hive Pig Expertise", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3239859789684527, "os": -0.1260895166119866}, {"x": 0.3447004608294931, "y": 0.0, "ox": 0.3447004608294931, "oy": 0.0, "term": "Proficiency data processing", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.33850776164246377, "os": -0.12095450545023395}, {"x": 0.3096774193548388, "y": 0.0, "ox": 0.3096774193548388, "oy": 0.0, "term": "Map Reduce Expertise Hadoop", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3555332999499249, "os": -0.11565073785622584}, {"x": 0.2737327188940093, "y": 0.0, "ox": 0.2737327188940093, "oy": 0.0, "term": "Kafka Flume Storm Experience", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3730595893840762, "os": -0.10976119585652011}, {"x": 0.2331797235023042, "y": 0.0, "ox": 0.2331797235023042, "oy": 0.0, "term": "Spark Streaming", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.39308963445167755, "os": -0.10441602783796856}, {"x": 0.2175115207373272, "y": 0.0, "ox": 0.2175115207373272, "oy": 0.0, "term": "Kafka Flume Storm", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4016024036054081, "os": -0.10229045409018014}, {"x": 0.21474654377880187, "y": 0.0, "ox": 0.21474654377880187, "oy": 0.0, "term": "HDFS Azkaban Oozie", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.40310465698547826, "os": -0.10219007970467098}, {"x": 0.4267281105990784, "y": 0.0, "ox": 0.4267281105990784, "oy": 0.0, "term": "broad variety audiences", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.29694541812719083, "os": -0.136966241524824}, {"x": 0.3889400921658987, "y": 0.0, "ox": 0.3889400921658987, "oy": 0.0, "term": "complex technical concepts", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.31697546319479225, "os": -0.12834261956171472}, {"x": 0.3649769585253457, "y": 0.0, "ox": 0.3649769585253457, "oy": 0.0, "term": "object oriented programming languages", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3294942413620431, "os": -0.12397745123276696}, {"x": 0.26082949308755765, "y": 0.0, "ox": 0.26082949308755765, "oy": 0.0, "term": "BS BA Technical Field Computer Science Mathematics Knowledge Python Java Experience", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3800701051577366, "os": -0.10763178720300788}, {"x": 0.18801843317972353, "y": 0.0, "ox": 0.18801843317972353, "oy": 0.0, "term": "BA Technical Field Computer Science Mathematics Knowledge Python", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.41762643965948926, "os": -0.09691763714744647}, {"x": 0.15944700460829495, "y": 0.0, "ox": 0.15944700460829495, "oy": 0.0, "term": "SQL ETL", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4321482223335003, "os": -0.09130859346643895}, {"x": 0.11889400921658988, "y": 0.0, "ox": 0.11889400921658988, "oy": 0.0, "term": "MapReduce MPP", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.45368052078117177, "os": -0.08431994370536677}, {"x": 0.5917050691244241, "y": 0.0, "ox": 0.5917050691244241, "oy": 0.0, "term": "Large scale ETL Apache beam Apache spark High scale Restful Services Cloud experience", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21582373560340515, "os": -0.18977044060485465}, {"x": 0.5078341013824885, "y": 0.0, "ox": 0.5078341013824885, "oy": 0.0, "term": "B Tech Computer Science IT", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2558838257386079, "os": -0.15764682239246702}, {"x": 0.49400921658986185, "y": 0.0, "ox": 0.49400921658986185, "oy": 0.0, "term": "Google Cloud Platform Azure AWS", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2628943415122684, "os": -0.15538998014619315}, {"x": 0.4368663594470047, "y": 0.0, "ox": 0.4368663594470047, "oy": 0.0, "term": "ETL Apache", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2919379068602905, "os": -0.13998913277292258}, {"x": 0.35023041474654387, "y": 0.0, "ox": 0.35023041474654387, "oy": 0.0, "term": "SQL document stores", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.33600400600901353, "os": -0.12161325249200518}, {"x": 0.3410138248847927, "y": 0.0, "ox": 0.3410138248847927, "oy": 0.0, "term": "BSc B", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3405107661492238, "os": -0.12051812850237843}, {"x": 0.1806451612903226, "y": 0.0, "ox": 0.1806451612903226, "oy": 0.0, "term": "Python Data", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.42163244867300953, "os": -0.09549394525315116}, {"x": 0.8700460829493089, "y": 0.0, "ox": 0.8700460829493089, "oy": 0.0, "term": "Experience Azure Data Factory Data Bricks Data Lake", "cat25k": 0, "ncat25k": 29, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06509764646970455, "os": -0.40902533962167537}, {"x": 0.8506912442396315, "y": 0.0, "ox": 0.8506912442396315, "oy": 0.0, "term": "Bricks Data Lake", "cat25k": 0, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07961942914371557, "os": -0.37243542102984023}, {"x": 0.44147465437788025, "y": 0.0, "ox": 0.44147465437788025, "oy": 0.0, "term": "solid understanding relational NoSQL database technologies Experience visualization data mining statistical tools", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2894341512268403, "os": -0.14066382322141793}, {"x": 0.43963133640553004, "y": 0.0, "ox": 0.43963133640553004, "oy": 0.0, "term": "massive complex datasets", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2904356534802203, "os": -0.14041220866304713}, {"x": 0.3944700460829494, "y": 0.0, "ox": 0.3944700460829494, "oy": 0.0, "term": "metrics statistical information", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.313970956434652, "os": -0.12925107826495985}, {"x": 0.37419354838709684, "y": 0.0, "ox": 0.37419354838709684, "oy": 0.0, "term": "familiar ETL tools", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.32448673009514273, "os": -0.12607359624827358}, {"x": 0.367741935483871, "y": 0.0, "ox": 0.367741935483871, "oy": 0.0, "term": "robust data analytic pipelines", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.327991987981973, "os": -0.12446032602150546}, {"x": 0.33824884792626736, "y": 0.0, "ox": 0.33824884792626736, "oy": 0.0, "term": "Expertise various ETL technologies", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.34151226840260396, "os": -0.11989789672334838}, {"x": 0.2829493087557604, "y": 0.0, "ox": 0.2829493087557604, "oy": 0.0, "term": "e g Python Scala comfortable developing code", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.36805207811717583, "os": -0.1112324154236448}, {"x": 0.17419354838709677, "y": 0.0, "ox": 0.17419354838709677, "oy": 0.0, "term": "Solr Kafka", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4246369554331497, "os": -0.09413845583201864}, {"x": 0.12442396313364056, "y": 0.0, "ox": 0.12442396313364056, "oy": 0.0, "term": "e g Oozie Airflow", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4506760140210316, "os": -0.08531458400313623}, {"x": 0.09308755760368664, "y": 0.0, "ox": 0.09308755760368664, "oy": 0.0, "term": "Oozie Airflow Have", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4667000500751127, "os": -0.08094722882502266}, {"x": 0.3474654377880185, "y": 0.0, "ox": 0.3474654377880185, "oy": 0.0, "term": "relational data Postgres programming experience", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3370055082623936, "os": -0.12136334235050526}, {"x": 0.3345622119815669, "y": 0.0, "ox": 0.3345622119815669, "oy": 0.0, "term": "unstructured data APIs Experience ETL integration", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3435152729093641, "os": -0.11923097987664825}, {"x": 0.3179723502304148, "y": 0.0, "ox": 0.3179723502304148, "oy": 0.0, "term": "DMS Stitch Experience data analysis visualization tools Mode Working knowledge message", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.35152729093640467, "os": -0.11716846321342424}, {"x": 0.2921658986175116, "y": 0.0, "ox": 0.2921658986175116, "oy": 0.0, "term": "tech debt Experience business operations tools", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3635453179769655, "os": -0.11330050026738155}, {"x": 0.2617511520737328, "y": 0.0, "ox": 0.2617511520737328, "oy": 0.0, "term": "technology landscape Experience AWS services", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3795693540310466, "os": -0.107663816210816}, {"x": 0.2221198156682028, "y": 0.0, "ox": 0.2221198156682028, "oy": 0.0, "term": "data science machine", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.39909864797195793, "os": -0.1030918509653616}, {"x": 0.18986175115207374, "y": 0.0, "ox": 0.18986175115207374, "oy": 0.0, "term": "positive attitude empathy Self awareness desire", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4166249374061092, "os": -0.09713632680965924}, {"x": 0.16958525345622122, "y": 0.0, "ox": 0.16958525345622122, "oy": 0.0, "term": "Dog Friendly Office", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4271407110665999, "os": -0.0928955052023868}, {"x": 0.14193548387096777, "y": 0.0, "ox": 0.14193548387096777, "oy": 0.0, "term": "deep understanding data engineering concepts database", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4411617426139209, "os": -0.08828668416926307}, {"x": 0.08202764976958525, "y": 0.0, "ox": 0.08202764976958525, "oy": 0.0, "term": "Lambda DynamoDB etc Competitive salary Employee Stock Option Plan Generous health commuter benefits", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4722083124687031, "os": -0.0787906137150222}, {"x": 0.08110599078341015, "y": 0.0, "ox": 0.08110599078341015, "oy": 0.0, "term": "Advanced SQL knowledge", "cat25k": 0, "ncat25k": 6, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.4727090635953931, "os": -0.07849836121334558}, {"x": 0.4820276497695853, "y": 0.0, "ox": 0.4820276497695853, "oy": 0.0, "term": "Informatica Talend Pentaho DataStage Experience interest Big Data technologies", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2694041061592389, "os": -0.1522210157422785}, {"x": 0.47649769585253465, "y": 0.0, "ox": 0.47649769585253465, "oy": 0.0, "term": "Azure Strong SQL experience", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2724086129193791, "os": -0.15137278176524632}, {"x": 0.4755760368663595, "y": 0.0, "ox": 0.4755760368663595, "oy": 0.0, "term": "Data security governance expertise", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.27290936404606914, "os": -0.15113759605568922}, {"x": 0.5963133640552997, "y": 0.0, "ox": 0.5963133640552997, "oy": 0.0, "term": "structured unstructured data Extensive AWS Experience", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21382073109664498, "os": -0.19139645380973164}, {"x": 0.5686635944700462, "y": 0.0, "ox": 0.5686635944700462, "oy": 0.0, "term": "Python preferred Experience designing data architecture ground Experience", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.22633950926389587, "os": -0.18157096827241986}, {"x": 0.4967741935483872, "y": 0.0, "ox": 0.4967741935483872, "oy": 0.0, "term": "working data systems years", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.26139208813219833, "os": -0.15567686152655805}, {"x": 0.48571428571428577, "y": 0.0, "ox": 0.48571428571428577, "oy": 0.0, "term": "Spark Hadoop years", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.26740110165247877, "os": -0.15282459867884607}, {"x": 0.5557603686635946, "y": 0.0, "ox": 0.5557603686635946, "oy": 0.0, "term": "Bachelor Degree computer science engineering mathematics related fields equivalent experience Expert SQL knowledge experience", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23284927391086632, "os": -0.17497171454108826}, {"x": 0.5474654377880186, "y": 0.0, "ox": 0.5474654377880186, "oy": 0.0, "term": "large datasets Masters Degree computer science engineering mathematics related fields equivalent experience", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23635453179769655, "os": -0.17116601584592436}, {"x": 0.49216589861751164, "y": 0.0, "ox": 0.49216589861751164, "oy": 0.0, "term": "large scale data warehouse platform Hands experience", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.26389584376564845, "os": -0.1547022116262329}, {"x": 0.4838709677419356, "y": 0.0, "ox": 0.4838709677419356, "oy": 0.0, "term": "engineering experience years", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2684026039058588, "os": -0.15260717055522227}, {"x": 0.6165898617511522, "y": 0.0, "ox": 0.6165898617511522, "oy": 0.0, "term": "Python C C Experience data visualization presentation", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.20330495743615423, "os": -0.201037192570378}, {"x": 0.5529953917050692, "y": 0.0, "ox": 0.5529953917050692, "oy": 0.0, "term": "familiar data analysis tools", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23385077616424638, "os": -0.17339202623504754}, {"x": 0.5327188940092167, "y": 0.0, "ox": 0.5327188940092167, "oy": 0.0, "term": "large scale data", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2438657986980471, "os": -0.16687902033312804}, {"x": 0.5594470046082951, "y": 0.0, "ox": 0.5594470046082951, "oy": 0.0, "term": "online caches real time systems BA BS Degree Computer Science Engineering discipline Statistics Information Systems", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2313470205307962, "os": -0.17693863646805866}, {"x": 0.8930875576036867, "y": 0.0, "ox": 0.8930875576036867, "oy": 0.0, "term": "Data Warehouse", "cat25k": 0, "ncat25k": 34, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.053079619429143715, "os": -0.47572565547102336}, {"x": 0.8995391705069126, "y": 0.0, "ox": 0.8995391705069126, "oy": 0.0, "term": "Travel", "cat25k": 0, "ncat25k": 35, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.0500751126690035, "os": -0.5}, {"x": 0.7317972350230415, "y": 0.0, "ox": 0.7317972350230415, "oy": 0.0, "term": "sit shoulder shoulder", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14321482223335005, "os": -0.2521062200211917}, {"x": 0.6764976958525346, "y": 0.0, "ox": 0.6764976958525346, "oy": 0.0, "term": "challenging encouraging", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17225838758137207, "os": -0.22509652287488446}, {"x": 0.47373271889400936, "y": 0.0, "ox": 0.47373271889400936, "oy": 0.0, "term": "New Hire Orientation", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.27391086629944916, "os": -0.15092983266980362}, {"x": 0.7769585253456222, "y": 0.0, "ox": 0.7769585253456222, "oy": 0.0, "term": "Robust Perks generous PTO 401k contributions tuition assistance entertainment discounts", "cat25k": 0, "ncat25k": 20, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1186780170255383, "os": -0.28747978728803447}, {"x": 0.5880184331797236, "y": 0.0, "ox": 0.5880184331797236, "oy": 0.0, "term": "massage volunteer opportunities", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21732598898347524, "os": -0.18875255544797798}, {"x": 0.49769585253456233, "y": 0.0, "ox": 0.49769585253456233, "oy": 0.0, "term": "Vibrancy Wellness Program Yoga fitness classes", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.26089133700550826, "os": -0.15576784338299685}, {"x": 0.463594470046083, "y": 0.0, "ox": 0.463594470046083, "oy": 0.0, "term": "employee coverage", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2784176264396595, "os": -0.14940716080804645}, {"x": 0.5170506912442397, "y": 0.0, "ox": 0.5170506912442397, "oy": 0.0, "term": "monthly", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.25187781672508763, "os": -0.16025646241133118}, {"x": 0.7806451612903227, "y": 0.0, "ox": 0.7806451612903227, "oy": 0.0, "term": "healthy food utmost convenience", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11667501251877817, "os": -0.29013041626376423}, {"x": 0.5815668202764978, "y": 0.0, "ox": 0.5815668202764978, "oy": 0.0, "term": "market boundaries", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.22033049574361543, "os": -0.18646369080383335}, {"x": 0.5124423963133641, "y": 0.0, "ox": 0.5124423963133641, "oy": 0.0, "term": "phenomenal team individuals", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2533800701051578, "os": -0.1594336685563522}, {"x": 0.551152073732719, "y": 0.0, "ox": 0.551152073732719, "oy": 0.0, "term": "Previously healthcare experience", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23485227841762646, "os": -0.17304816931866904}, {"x": 0.7585253456221199, "y": 0.0, "ox": 0.7585253456221199, "oy": 0.0, "term": "g Storm Spark Streaming ETL tools", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12869303955933903, "os": -0.26869597101325365}, {"x": 0.7336405529953919, "y": 0.0, "ox": 0.7336405529953919, "oy": 0.0, "term": "sensitive available time resource constraints", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14221331997996997, "os": -0.2547128163673255}, {"x": 0.7465437788018435, "y": 0.0, "ox": 0.7465437788018435, "oy": 0.0, "term": "g Cassandra MongoDB Stream processing systems", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.13520280420630948, "os": -0.2617929772323031}, {"x": 0.7437788018433181, "y": 0.0, "ox": 0.7437788018433181, "oy": 0.0, "term": "g MapReduce Hive Pig SQL", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.13670505758637957, "os": -0.26006350310777615}, {"x": 0.6875576036866361, "y": 0.0, "ox": 0.6875576036866361, "oy": 0.0, "term": "Hadoop based technologies", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16725087631447172, "os": -0.23049066193624146}, {"x": 0.5981566820276498, "y": 0.0, "ox": 0.5981566820276498, "oy": 0.0, "term": "data storage retrieval specific use cases", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2128192288432649, "os": -0.19250115112901423}, {"x": 0.5649769585253458, "y": 0.0, "ox": 0.5649769585253458, "oy": 0.0, "term": "Cloud computing architectures", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.228342513770656, "os": -0.17863785419673928}, {"x": 0.5493087557603687, "y": 0.0, "ox": 0.5493087557603687, "oy": 0.0, "term": "NoSQL technologies", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23535302954431647, "os": -0.17191718187118085}, {"x": 0.4617511520737328, "y": 0.0, "ox": 0.4617511520737328, "oy": 0.0, "term": "Legacy modern database", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2794191286930396, "os": -0.14871504874729785}, {"x": 0.6193548387096776, "y": 0.0, "ox": 0.6193548387096776, "oy": 0.0, "term": "user defined functions table functions", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.20180270405608414, "os": -0.20330731714504}, {"x": 0.6350230414746545, "y": 0.0, "ox": 0.6350230414746545, "oy": 0.0, "term": "career growth", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19328993490235355, "os": -0.20829848016563715}, {"x": 0.727188940092166, "y": 0.0, "ox": 0.727188940092166, "oy": 0.0, "term": "smart people", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14621932899349024, "os": -0.24920231342436183}, {"x": 0.9235023041474654, "y": 0.0, "ox": 0.9235023041474654, "oy": 0.0, "term": "Data Platform Administration Engineering", "cat25k": 0, "ncat25k": 41, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.0385578367551327, "os": -0.5802608325275285}, {"x": 0.6248847926267282, "y": 0.0, "ox": 0.6248847926267282, "oy": 0.0, "term": "Bachelor Degree Computer Science related field years", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19879819729594395, "os": -0.2049910260541008}, {"x": 0.5216589861751153, "y": 0.0, "ox": 0.5216589861751153, "oy": 0.0, "term": "Bachelor Degree Computer Science", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.24987481221832752, "os": -0.16121851462217482}, {"x": 0.6562211981566821, "y": 0.0, "ox": 0.6562211981566821, "oy": 0.0, "term": "Excellent understanding manipulation analysis", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.18227341011517276, "os": -0.21728822248292234}, {"x": 0.8654377880184333, "y": 0.0, "ox": 0.8654377880184333, "oy": 0.0, "term": "modern tech tools hi tech equipment", "cat25k": 0, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06960440660991488, "os": -0.39760980352123837}, {"x": 0.7797235023041476, "y": 0.0, "ox": 0.7797235023041476, "oy": 0.0, "term": "extra cash pocket", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11717576364546821, "os": -0.28975208664196556}, {"x": 0.6838709677419356, "y": 0.0, "ox": 0.6838709677419356, "oy": 0.0, "term": "opportunity work friends", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16875312969454181, "os": -0.22736418796824281}, {"x": 0.7225806451612904, "y": 0.0, "ox": 0.7225806451612904, "oy": 0.0, "term": "A commitment open inclusive diverse work culture", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14872308462694042, "os": -0.24748737341529156}, {"x": 0.8027649769585254, "y": 0.0, "ox": 0.8027649769585254, "oy": 0.0, "term": "Data Warehouse Big Data", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10565848773159739, "os": -0.3076526822182555}, {"x": 0.7907834101382489, "y": 0.0, "ox": 0.7907834101382489, "oy": 0.0, "term": "SQL Data Warehouse Data Catalog Azure Analysis Services Data Bricks Storage Account", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11166750125187781, "os": -0.29749303806346744}, {"x": 0.7152073732718895, "y": 0.0, "ox": 0.7152073732718895, "oy": 0.0, "term": "SQL Server preferable multi dimensional Data Warehousing environment", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15322984476715076, "os": -0.2438033886700973}, {"x": 0.7133640552995393, "y": 0.0, "ox": 0.7133640552995393, "oy": 0.0, "term": "Data Warehousing", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15423134702053082, "os": -0.24272143011851388}, {"x": 0.711520737327189, "y": 0.0, "ox": 0.711520737327189, "oy": 0.0, "term": "Enterprise Data Analytics solution architecture years", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15523284927391087, "os": -0.2403999217607881}, {"x": 0.6930875576036868, "y": 0.0, "ox": 0.6930875576036868, "oy": 0.0, "term": "SQL Programming PL SQL", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16474712068102154, "os": -0.23287946322862224}, {"x": 0.6746543778801845, "y": 0.0, "ox": 0.6746543778801845, "oy": 0.0, "term": "Python SQL Strong", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17325988983475216, "os": -0.224689484624443}, {"x": 0.671889400921659, "y": 0.0, "ox": 0.671889400921659, "oy": 0.0, "term": "SQL Programming PL SQL T", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17476214321482225, "os": -0.22335128900588627}, {"x": 0.6433179723502306, "y": 0.0, "ox": 0.6433179723502306, "oy": 0.0, "term": "Spark Pyspark Python Scala Pig Experience Big Data Management BDM relational non relational data formats", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.18928392588883328, "os": -0.21202442135182098}, {"x": 0.6423963133640554, "y": 0.0, "ox": 0.6423963133640554, "oy": 0.0, "term": "Python SQL Strong analytical abilities", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1897846770155233, "os": -0.21164149852154907}, {"x": 0.6285714285714287, "y": 0.0, "ox": 0.6285714285714287, "oy": 0.0, "term": "Microsoft SQL Server preferable expert MDX DAX", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19679519278918378, "os": -0.20703469502850227}, {"x": 0.614746543778802, "y": 0.0, "ox": 0.614746543778802, "oy": 0.0, "term": "Azure", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.20430645968953431, "os": -0.20098489178587403}, {"x": 0.6138248847926268, "y": 0.0, "ox": 0.6138248847926268, "oy": 0.0, "term": "SQL U", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.20480721081622436, "os": -0.20089742862003127}, {"x": 0.5944700460829494, "y": 0.0, "ox": 0.5944700460829494, "oy": 0.0, "term": "mobile solutions years", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21482223335002507, "os": -0.19100864235267895}, {"x": 0.8820276497695855, "y": 0.0, "ox": 0.8820276497695855, "oy": 0.0, "term": "Power BI", "cat25k": 0, "ncat25k": 31, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.05808713069604406, "os": -0.4416069429767577}, {"x": 0.6552995391705071, "y": 0.0, "ox": 0.6552995391705071, "oy": 0.0, "term": "Hive Hadoop", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.18277416124186283, "os": -0.21724809127631192}, {"x": 0.8995391705069126, "y": 0.0, "ox": 0.8995391705069126, "oy": 0.0, "term": "Hackathons", "cat25k": 0, "ncat25k": 35, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.0500751126690035, "os": -0.5}, {"x": 0.823041474654378, "y": 0.0, "ox": 0.823041474654378, "oy": 0.0, "term": "metrics consumers", "cat25k": 0, "ncat25k": 24, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09514271407110665, "os": -0.33223519667364926}, {"x": 0.7078341013824886, "y": 0.0, "ox": 0.7078341013824886, "oy": 0.0, "term": "Work data science teams", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.156735102653981, "os": -0.2396672665936658}, {"x": 0.8599078341013826, "y": 0.0, "ox": 0.8599078341013826, "oy": 0.0, "term": "data curation management strategies", "cat25k": 0, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07310966449674511, "os": -0.38918825822108627}, {"x": 0.8571428571428573, "y": 0.0, "ox": 0.8571428571428573, "oy": 0.0, "term": "laboratory research data management processes procedures", "cat25k": 0, "ncat25k": 27, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.07461191787681523, "os": -0.3816026826685257}, {"x": 0.7788018433179725, "y": 0.0, "ox": 0.7788018433179725, "oy": 0.0, "term": "biomedical data management data engineering quality assurance", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11767651477215824, "os": -0.2895911173183732}, {"x": 0.8442396313364057, "y": 0.0, "ox": 0.8442396313364057, "oy": 0.0, "term": "Excellent skills R programming experience", "cat25k": 0, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08312468703054582, "os": -0.36143384280121754}, {"x": 0.742857142857143, "y": 0.0, "ox": 0.742857142857143, "oy": 0.0, "term": "development specimen data management related discipline Demonstrated proficiency molecular biology concepts ability support", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.13720580871306962, "os": -0.25986939621340654}, {"x": 0.7410138248847928, "y": 0.0, "ox": 0.7410138248847928, "oy": 0.0, "term": "systematic relational approaches data integration data processing", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1382073109664497, "os": -0.25971964457451074}, {"x": 0.7373271889400923, "y": 0.0, "ox": 0.7373271889400923, "oy": 0.0, "term": "Detailed knowledge experience case report form design central laboratories", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14021031547320983, "os": -0.2566657538720929}, {"x": 0.703225806451613, "y": 0.0, "ox": 0.703225806451613, "oy": 0.0, "term": "Working knowledge Windows Linux operating systems", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15923885828743117, "os": -0.2379221853752902}, {"x": 0.7023041474654379, "y": 0.0, "ox": 0.7023041474654379, "oy": 0.0, "term": "query resolution data validation Computer", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1597396094141212, "os": -0.23791839599797238}, {"x": 0.7013824884792628, "y": 0.0, "ox": 0.7013824884792628, "oy": 0.0, "term": "SAS data", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16024036054081123, "os": -0.2369375616559698}, {"x": 0.6995391705069125, "y": 0.0, "ox": 0.6995391705069125, "oy": 0.0, "term": "detailed knowledge", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1612418627941913, "os": -0.23632787962891302}, {"x": 0.6755760368663596, "y": 0.0, "ox": 0.6755760368663596, "oy": 0.0, "term": "action patient response Proven ability work team environment clinical personnel study monitors", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17275913870806212, "os": -0.22493300745906294}, {"x": 0.7953917050691246, "y": 0.0, "ox": 0.7953917050691246, "oy": 0.0, "term": "strong capacity independent thinking ability", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10916374561842765, "os": -0.30311044025919304}, {"x": 0.6405529953917052, "y": 0.0, "ox": 0.6405529953917052, "oy": 0.0, "term": "Oracle Clinical Clintrial preferred experience", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19078617926890337, "os": -0.21149425625540824}, {"x": 0.6341013824884794, "y": 0.0, "ox": 0.6341013824884794, "oy": 0.0, "term": "Strong understanding LIMS systems", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1937906860290436, "os": -0.20799451592306467}, {"x": 0.6202764976958527, "y": 0.0, "ox": 0.6202764976958527, "oy": 0.0, "term": "Java C C Extensive practical experience", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.20130195292939412, "os": -0.2034380937296319}, {"x": 0.750230414746544, "y": 0.0, "ox": 0.750230414746544, "oy": 0.0, "term": "database design implementation", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.13319979969954931, "os": -0.2633007061731964}, {"x": 0.7576036866359448, "y": 0.0, "ox": 0.7576036866359448, "oy": 0.0, "term": "complex dynamic environment", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12919379068602904, "os": -0.26858899793131974}, {"x": 0.7668202764976959, "y": 0.0, "ox": 0.7668202764976959, "oy": 0.0, "term": "Along programming proficiency", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12418627941912869, "os": -0.27349523622496774}, {"x": 0.6027649769585255, "y": 0.0, "ox": 0.6027649769585255, "oy": 0.0, "term": "least one data management system", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2098147220831247, "os": -0.19555915659452677}, {"x": 0.7400921658986176, "y": 0.0, "ox": 0.7400921658986176, "oy": 0.0, "term": "additional computer languages", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.13870806209313974, "os": -0.2590320061014618}, {"x": 0.7474654377880185, "y": 0.0, "ox": 0.7474654377880185, "oy": 0.0, "term": "high level scientific datasets", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.13470205307961947, "os": -0.2620566298265912}, {"x": 0.7004608294930877, "y": 0.0, "ox": 0.7004608294930877, "oy": 0.0, "term": "medical writers", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16074111166750127, "os": -0.23684338057549567}, {"x": 0.5723502304147466, "y": 0.0, "ox": 0.5723502304147466, "oy": 0.0, "term": "organizational skills", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2243365047571357, "os": -0.1842583305619832}, {"x": 0.7059907834101384, "y": 0.0, "ox": 0.7059907834101384, "oy": 0.0, "term": "direct assess implementation", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15773660490736105, "os": -0.23886021823481585}, {"x": 0.5382488479262674, "y": 0.0, "ox": 0.5382488479262674, "oy": 0.0, "term": "computational biologists biostatisticians", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2408612919379069, "os": -0.168482790171373}, {"x": 0.534562211981567, "y": 0.0, "ox": 0.534562211981567, "oy": 0.0, "term": "Familiarity Amazon Web Services", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.242864296444667, "os": -0.1673963436863618}, {"x": 0.6691244239631338, "y": 0.0, "ox": 0.6691244239631338, "oy": 0.0, "term": "research hypotheses", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.17576364546820233, "os": -0.22215052701757504}, {"x": 0.6488479262672812, "y": 0.0, "ox": 0.6488479262672812, "oy": 0.0, "term": "underlying biological questions", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.18627941912869306, "os": -0.21572536433234923}, {"x": 0.6294930875576038, "y": 0.0, "ox": 0.6294930875576038, "oy": 0.0, "term": "query interfaces", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19629444166249377, "os": -0.20720885136958953}, {"x": 0.6322580645161292, "y": 0.0, "ox": 0.6322580645161292, "oy": 0.0, "term": "diverse highly connected scientific knowledge collections", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19479218828242365, "os": -0.20778117327233503}, {"x": 0.7235023041474656, "y": 0.0, "ox": 0.7235023041474656, "oy": 0.0, "term": "Perl Python PHP S", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1482223335002504, "os": -0.24750243893915352}, {"x": 0.8009216589861753, "y": 0.0, "ox": 0.8009216589861753, "oy": 0.0, "term": "Experience integration data", "cat25k": 0, "ncat25k": 22, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10665998998497747, "os": -0.3061197055953717}, {"x": 0.5852534562211983, "y": 0.0, "ox": 0.5852534562211983, "oy": 0.0, "term": "Enriched Tuition reimbursement training learning programs", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21832749123685533, "os": -0.18687053861954167}, {"x": 0.8331797235023043, "y": 0.0, "ox": 0.8331797235023043, "oy": 0.0, "term": "multiple partners", "cat25k": 0, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08913370055082623, "os": -0.3498759579292246}, {"x": 0.6009216589861752, "y": 0.0, "ox": 0.6009216589861752, "oy": 0.0, "term": "Track record", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21081622433650477, "os": -0.19418352986099446}, {"x": 0.8783410138248849, "y": 0.0, "ox": 0.8783410138248849, "oy": 0.0, "term": "Knowledge sharing activities", "cat25k": 0, "ncat25k": 31, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06009013520280421, "os": -0.43301270189221913}, {"x": 0.3539170506912443, "y": 0.0, "ox": 0.3539170506912443, "oy": 0.0, "term": "preferred Data modeling experience", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3340010015022534, "os": -0.12216490597570924}, {"x": 0.5437788018433181, "y": 0.0, "ox": 0.5437788018433181, "oy": 0.0, "term": "advantageous Pair programming experience Scrum agile experience Kanban agile experience JIRA experience Release search applications cloud environment", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23835753630445672, "os": -0.169916620633979}, {"x": 0.47188940092165904, "y": 0.0, "ox": 0.47188940092165904, "oy": 0.0, "term": "Experience graph database", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2749123685528293, "os": -0.15076914791486395}, {"x": 0.39907834101382494, "y": 0.0, "ox": 0.39907834101382494, "oy": 0.0, "term": "Kafka Apache Spark Experience big data technologies Hadoop Kafka Akka Mesos", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3114672008012018, "os": -0.13017654140787527}, {"x": 0.287557603686636, "y": 0.0, "ox": 0.287557603686636, "oy": 0.0, "term": "highly desirable Experience Semantic Web RDF OWL SPARQL", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3655483224837256, "os": -0.11163470685335324}, {"x": 0.22672811059907838, "y": 0.0, "ox": 0.22672811059907838, "oy": 0.0, "term": "dev ops", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3965948923385078, "os": -0.10363085896182385}, {"x": 0.34562211981566826, "y": 0.0, "ox": 0.34562211981566826, "oy": 0.0, "term": "specific Big Data DevOps roles", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.33800701051577364, "os": -0.12108364118391396}, {"x": 0.2912442396313365, "y": 0.0, "ox": 0.2912442396313365, "oy": 0.0, "term": "Most Big Data Engineers", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3640460691036555, "os": -0.11329143908025392}, {"x": 0.2847926267281107, "y": 0.0, "ox": 0.2847926267281107, "oy": 0.0, "term": "Machine Learning Big Data", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3670505758637957, "os": -0.11152667202799516}, {"x": 0.2691244239631337, "y": 0.0, "ox": 0.2691244239631337, "oy": 0.0, "term": "Machine Learning Big Data infrastructure", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.37556334501752636, "os": -0.10856545141988287}, {"x": 0.2516129032258065, "y": 0.0, "ox": 0.2516129032258065, "oy": 0.0, "term": "Flume Experience various messaging systems", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.38457686529794693, "os": -0.10617142750165334}, {"x": 0.4276497695852535, "y": 0.0, "ox": 0.4276497695852535, "oy": 0.0, "term": "GCP AWS Azure year experience", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.29644466700050076, "os": -0.13699243532987082}, {"x": 0.37327188940092176, "y": 0.0, "ox": 0.37327188940092176, "oy": 0.0, "term": "Python Scala Golang R year experience provisioned demand cloud computing platforms", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3249874812218328, "os": -0.1254420525051685}, {"x": 0.22488479262672814, "y": 0.0, "ox": 0.22488479262672814, "oy": 0.0, "term": "computing fundamentals ability design scalability", "cat25k": 0, "ncat25k": 7, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.39759639459188784, "os": -0.10338511316948835}, {"x": 0.5069124423963135, "y": 0.0, "ox": 0.5069124423963135, "oy": 0.0, "term": "g Git Jira", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.256384576865298, "os": -0.15763667247359767}, {"x": 0.495852534562212, "y": 0.0, "ox": 0.495852534562212, "oy": 0.0, "term": "etc Knowledge", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.26189283925888834, "os": -0.15563719556224642}, {"x": 0.4506912442396314, "y": 0.0, "ox": 0.4506912442396314, "oy": 0.0, "term": "Git Jira", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.28542814221332, "os": -0.14357577909763924}, {"x": 0.407373271889401, "y": 0.0, "ox": 0.407373271889401, "oy": 0.0, "term": "year experience working data lake environment Experience collecting transforming", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.30696044066099154, "os": -0.1322153505950354}, {"x": 0.36682027649769594, "y": 0.0, "ox": 0.36682027649769594, "oy": 0.0, "term": "working data engineering", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.328492739108663, "os": -0.12434614423480325}, {"x": 0.3576036866359448, "y": 0.0, "ox": 0.3576036866359448, "oy": 0.0, "term": "data pipelines machine", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.33299949924887334, "os": -0.12257758626678851}, {"x": 0.32626728110599085, "y": 0.0, "ox": 0.32626728110599085, "oy": 0.0, "term": "large amounts data", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.34752128192288434, "os": -0.11840454760605743}, {"x": 0.3078341013824885, "y": 0.0, "ox": 0.3078341013824885, "oy": 0.0, "term": "Bachelor degree experience", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.35653480220330497, "os": -0.11551900945507304}, {"x": 0.2940092165898618, "y": 0.0, "ox": 0.2940092165898618, "oy": 0.0, "term": "year experience", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3625438157235854, "os": -0.11380125699350808}, {"x": 0.26267281105990786, "y": 0.0, "ox": 0.26267281105990786, "oy": 0.0, "term": "Java Python Knowledge Hadoop Spark big data processing frameworks", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.37906860290435657, "os": -0.10774802099970915}, {"x": 0.2599078341013826, "y": 0.0, "ox": 0.2599078341013826, "oy": 0.0, "term": "Bachelor degree Master degree computer science field Computer Science Information Sciences Informatics Experience", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.38057085628442666, "os": -0.10757175308528029}, {"x": 0.8672811059907836, "y": 0.0, "ox": 0.8672811059907836, "oy": 0.0, "term": "Relevant degree work experience", "cat25k": 0, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06659989984977466, "os": -0.4}, {"x": 0.7345622119815669, "y": 0.0, "ox": 0.7345622119815669, "oy": 0.0, "term": "This full time exempt position", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14171256885327993, "os": -0.2551551815399144}, {"x": 0.7870967741935485, "y": 0.0, "ox": 0.7870967741935485, "oy": 0.0, "term": "real world experience AWS EMR E2 Kinesis S3", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11367050575863795, "os": -0.29479980173745224}, {"x": 0.36866359447004615, "y": 0.0, "ox": 0.36866359447004615, "oy": 0.0, "term": "Bonus points", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3274912368552829, "os": -0.12450281619874627}, {"x": 0.823041474654378, "y": 0.0, "ox": 0.823041474654378, "oy": 0.0, "term": "agile methodologies", "cat25k": 0, "ncat25k": 24, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09514271407110665, "os": -0.33223519667364926}, {"x": 0.6331797235023043, "y": 0.0, "ox": 0.6331797235023043, "oy": 0.0, "term": "Scala Java C", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1942914371557336, "os": -0.20797941691547805}, {"x": 0.8516129032258066, "y": 0.0, "ox": 0.8516129032258066, "oy": 0.0, "term": "Data serialization JSON avro parquet", "cat25k": 0, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.0771156735102654, "os": -0.37267799624996495}, {"x": 0.8737327188940094, "y": 0.0, "ox": 0.8737327188940094, "oy": 0.0, "term": "Building Cube Cube", "cat25k": 0, "ncat25k": 30, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06309464196294441, "os": -0.42007327207320844}, {"x": 0.8239631336405532, "y": 0.0, "ox": 0.8239631336405532, "oy": 0.0, "term": "products", "cat25k": 0, "ncat25k": 24, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09464196294441662, "os": -0.33235585784531946}, {"x": 0.8359447004608296, "y": 0.0, "ox": 0.8359447004608296, "oy": 0.0, "term": "Docker Apache Mesos Kubernetes", "cat25k": 0, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08763144717075613, "os": -0.35020975003718274}, {"x": 0.8211981566820278, "y": 0.0, "ox": 0.8211981566820278, "oy": 0.0, "term": "Cluster managers eg Docker Apache Mesos Kubernetes", "cat25k": 0, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09664496745117677, "os": -0.3307189138830738}, {"x": 0.8672811059907836, "y": 0.0, "ox": 0.8672811059907836, "oy": 0.0, "term": "401k retirement savings plan", "cat25k": 0, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06659989984977466, "os": -0.4}, {"x": 0.7391705069124425, "y": 0.0, "ox": 0.7391705069124425, "oy": 0.0, "term": "LA best restaurants", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.13920881321982975, "os": -0.258448099280998}, {"x": 0.5907834101382489, "y": 0.0, "ox": 0.5907834101382489, "oy": 0.0, "term": "Daily catered lunches", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21632448673009516, "os": -0.18968443873813}, {"x": 0.8433179723502305, "y": 0.0, "ox": 0.8433179723502305, "oy": 0.0, "term": "profile", "cat25k": 0, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08362543815723585, "os": -0.3608563763907032}, {"x": 0.6700460829493089, "y": 0.0, "ox": 0.6700460829493089, "oy": 0.0, "term": "Indemnity", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1752628943415123, "os": -0.2222496308952425}, {"x": 0.7520737327188941, "y": 0.0, "ox": 0.7520737327188941, "oy": 0.0, "term": "meet business processes priorities", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1321982974461693, "os": -0.26402130893931103}, {"x": 0.5317972350230415, "y": 0.0, "ox": 0.5317972350230415, "oy": 0.0, "term": "application enhancements", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.24436654982473713, "os": -0.16610922813886098}, {"x": 0.46820276497695856, "y": 0.0, "ox": 0.46820276497695856, "oy": 0.0, "term": "3rd party vendors", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.27641462193289934, "os": -0.1499963630597183}, {"x": 0.3815668202764978, "y": 0.0, "ox": 0.3815668202764978, "oy": 0.0, "term": "3rd party", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.32048072108162245, "os": -0.12728178540132457}, {"x": 0.8451612903225807, "y": 0.0, "ox": 0.8451612903225807, "oy": 0.0, "term": "academic experience data engineering capacity Experience Docker Apache Spark ElasticSearch", "cat25k": 0, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08262393590385579, "os": -0.36210453245489227}, {"x": 0.8202764976958526, "y": 0.0, "ox": 0.8202764976958526, "oy": 0.0, "term": "similar Hands experience", "cat25k": 0, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09714571857786679, "os": -0.3297077374077779}, {"x": 0.7889400921658988, "y": 0.0, "ox": 0.7889400921658988, "oy": 0.0, "term": "queue technology Apache Kafka", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1126690035052579, "os": -0.2955345133407626}, {"x": 0.7861751152073734, "y": 0.0, "ox": 0.7861751152073734, "oy": 0.0, "term": "real time systems production stage years", "cat25k": 0, "ncat25k": 21, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.11417125688532799, "os": -0.29448829192011783}, {"x": 0.7723502304147466, "y": 0.0, "ox": 0.7723502304147466, "oy": 0.0, "term": "Excellent experience", "cat25k": 0, "ncat25k": 20, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12118177265898848, "os": -0.279650054693208}, {"x": 0.7640552995391707, "y": 0.0, "ox": 0.7640552995391707, "oy": 0.0, "term": "Apache Kafka", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1256885327991988, "os": -0.27194719512881005}, {"x": 0.9861751152073732, "y": 0.0, "ox": 0.9861751152073732, "oy": 0.0, "term": "Google Analytics", "cat25k": 0, "ncat25k": 267, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 3, "s": 0.007511266900350526, "os": -3.771236166328253}, {"x": 0.8672811059907836, "y": 0.0, "ox": 0.8672811059907836, "oy": 0.0, "term": "Agile Scrum working practices", "cat25k": 0, "ncat25k": 28, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.06659989984977466, "os": -0.4}, {"x": 0.5603686635944701, "y": 0.0, "ox": 0.5603686635944701, "oy": 0.0, "term": "Masters degree years experience Experience proficiency Scala Experience proficiency", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23084626940410619, "os": -0.17816088344728648}, {"x": 0.4608294930875577, "y": 0.0, "ox": 0.4608294930875577, "oy": 0.0, "term": "interest applying scale Experience data cleaning preparation feature building selection techniques", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.27991987981972966, "os": -0.14871048382753108}, {"x": 0.4082949308755761, "y": 0.0, "ox": 0.4082949308755761, "oy": 0.0, "term": "random effect models", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3064596895343015, "os": -0.1323894597368409}, {"x": 0.39354838709677425, "y": 0.0, "ox": 0.39354838709677425, "oy": 0.0, "term": "Effective communication interpersonal teamwork skills Ability", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3144717075613421, "os": -0.12922528656774165}, {"x": 0.7539170506912444, "y": 0.0, "ox": 0.7539170506912444, "oy": 0.0, "term": "duties", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1311967951927892, "os": -0.2653069489951205}, {"x": 0.4829493087557605, "y": 0.0, "ox": 0.4829493087557605, "oy": 0.0, "term": "Information Technology experience", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2689033550325488, "os": -0.1522572743825056}, {"x": 0.4811059907834102, "y": 0.0, "ox": 0.4811059907834102, "oy": 0.0, "term": "years Information Technology experience Proficiency domain driven design domain modeling Experience NoSql solutions Gemfire Cassandra HBase", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.26990485728592895, "os": -0.15198243745717668}, {"x": 0.455299539170507, "y": 0.0, "ox": 0.455299539170507, "oy": 0.0, "term": "CI CD tools", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.28292438657986985, "os": -0.14530301036766655}, {"x": 0.4258064516129033, "y": 0.0, "ox": 0.4258064516129033, "oy": 0.0, "term": "Bachelor Degree years Information Technology experience", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.29744616925388084, "os": -0.1369179017013489}, {"x": 0.3926267281105991, "y": 0.0, "ox": 0.3926267281105991, "oy": 0.0, "term": "MySQL SQL Server Oracle", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3149724586880321, "os": -0.12913955168649477}, {"x": 0.7225806451612904, "y": 0.0, "ox": 0.7225806451612904, "oy": 0.0, "term": "A good understanding adherence data security standards", "cat25k": 0, "ncat25k": 18, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.14872308462694042, "os": -0.24748737341529156}, {"x": 0.5566820276497697, "y": 0.0, "ox": 0.5566820276497697, "oy": 0.0, "term": "Python Golang Clojure R year experience provisioned demand cloud computing platforms GCP AWS Azure year experience", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23234852278417628, "os": -0.1750624026113325}, {"x": 0.5935483870967743, "y": 0.0, "ox": 0.5935483870967743, "oy": 0.0, "term": "data solutions AWS Experience building data vision strategy", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21532298447671508, "os": -0.19013537452588347}, {"x": 0.5410138248847927, "y": 0.0, "ox": 0.5410138248847927, "oy": 0.0, "term": "FinTech related area", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.23935903855783677, "os": -0.16897485425119663}, {"x": 0.7557603686635946, "y": 0.0, "ox": 0.7557603686635946, "oy": 0.0, "term": "Chicago Top Company Culture Entrepreneur Top Workplace Chicago Tribune", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.13019529293940912, "os": -0.266809985091919}, {"x": 0.6940092165898618, "y": 0.0, "ox": 0.6940092165898618, "oy": 0.0, "term": "Crain Chicago Business", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16424636955433153, "os": -0.23295725700107855}, {"x": 0.5087557603686637, "y": 0.0, "ox": 0.5087557603686637, "oy": 0.0, "term": "Best Consumer Web Company", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2553830746119179, "os": -0.15773919093580982}, {"x": 0.5004608294930876, "y": 0.0, "ox": 0.5004608294930876, "oy": 0.0, "term": "one Chicago Best Places Work Women", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.25938908362543817, "os": -0.15626353070323856}, {"x": 0.44055299539170517, "y": 0.0, "ox": 0.44055299539170517, "oy": 0.0, "term": "Best Consumer", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2899349023535303, "os": -0.14061437639929256}, {"x": 0.8341013824884794, "y": 0.0, "ox": 0.8341013824884794, "oy": 0.0, "term": "Experience HTTP REST SSL identity authentication", "cat25k": 0, "ncat25k": 25, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08863294942413621, "os": -0.34992710611188255}, {"x": 0.8460829493087559, "y": 0.0, "ox": 0.8460829493087559, "oy": 0.0, "term": "data infrastructure cloud", "cat25k": 0, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.08212318477716575, "os": -0.36432994274734615}, {"x": 0.6009216589861752, "y": 0.0, "ox": 0.6009216589861752, "oy": 0.0, "term": "Comfortable building", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21081622433650477, "os": -0.19418352986099446}, {"x": 0.8101382488479264, "y": 0.0, "ox": 0.8101382488479264, "oy": 0.0, "term": "happy hours wind", "cat25k": 0, "ncat25k": 23, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.10165247871807712, "os": -0.3179222345227429}, {"x": 0.6082949308755761, "y": 0.0, "ox": 0.6082949308755761, "oy": 0.0, "term": "Spontaneous nerf gun wars", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.20781171757636457, "os": -0.19925608179072685}, {"x": 0.8276497695852536, "y": 0.0, "ox": 0.8276497695852536, "oy": 0.0, "term": "Thursday", "cat25k": 0, "ncat25k": 24, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.09263895843765649, "os": -0.33624459928872646}, {"x": 0.8516129032258066, "y": 0.0, "ox": 0.8516129032258066, "oy": 0.0, "term": "Excellent verbal written communication skills", "cat25k": 0, "ncat25k": 26, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.0771156735102654, "os": -0.37267799624996495}, {"x": 0.4488479262672812, "y": 0.0, "ox": 0.4488479262672812, "oy": 0.0, "term": "Java PHP Years database work mysql Postgres RedShift Experience", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.28642964446670005, "os": -0.14332420635301724}, {"x": 0.4433179723502305, "y": 0.0, "ox": 0.4433179723502305, "oy": 0.0, "term": "Oriented Programming Python Java Database Technologies Redshift Postgres Spark Presto Amazon Web Services S3 SQS Kinesis ECS ECR EMR", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2884326489734602, "os": -0.14161612397159756}, {"x": 0.7631336405529955, "y": 0.0, "ox": 0.7631336405529955, "oy": 0.0, "term": "B S Computer Science Object", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.12618928392588885, "os": -0.2715207773002158}, {"x": 0.535483870967742, "y": 0.0, "ox": 0.535483870967742, "oy": 0.0, "term": "System availability Data Availability Data Quality", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.242363545317977, "os": -0.16767511730825083}, {"x": 0.49124423963133645, "y": 0.0, "ox": 0.49124423963133645, "oy": 0.0, "term": "SAP Data Services Talend", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2643965948923385, "os": -0.15441623526012638}, {"x": 0.4903225806451614, "y": 0.0, "ox": 0.4903225806451614, "oy": 0.0, "term": "SAP Data Services", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2648973460190286, "os": -0.1534258056780586}, {"x": 0.359447004608295, "y": 0.0, "ox": 0.359447004608295, "oy": 0.0, "term": "MS SQL Server Strong programming experience", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.33199799699549326, "os": -0.12280292292682438}, {"x": 0.7566820276497697, "y": 0.0, "ox": 0.7566820276497697, "oy": 0.0, "term": "hard promote change industry", "cat25k": 0, "ncat25k": 19, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.1296945418127191, "os": -0.2668791876143248}, {"x": 0.631336405529954, "y": 0.0, "ox": 0.631336405529954, "oy": 0.0, "term": "Share success", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19529293940911369, "os": -0.20745177879623483}, {"x": 0.6184331797235023, "y": 0.0, "ox": 0.6184331797235023, "oy": 0.0, "term": "success", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2023034551827742, "os": -0.201405874836723}, {"x": 0.6055299539170508, "y": 0.0, "ox": 0.6055299539170508, "oy": 0.0, "term": "way", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.20881321982974463, "os": -0.19752221759144914}, {"x": 0.5105990783410139, "y": 0.0, "ox": 0.5105990783410139, "oy": 0.0, "term": "RDS redshift S3 Experience consuming cleaning data third party APIs sources", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2543815723585378, "os": -0.15912486899648629}, {"x": 0.4783410138248849, "y": 0.0, "ox": 0.4783410138248849, "oy": 0.0, "term": "Hive Hadoop Spark", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.271407110665999, "os": -0.151628352099855}, {"x": 0.38341013824884795, "y": 0.0, "ox": 0.38341013824884795, "oy": 0.0, "term": "data Strong communication skills", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3194792188282424, "os": -0.12759013214934853}, {"x": 0.31520737327188947, "y": 0.0, "ox": 0.31520737327188947, "oy": 0.0, "term": "various AWS services", "cat25k": 0, "ncat25k": 8, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3530295443164747, "os": -0.1166561697933288}, {"x": 0.6276497695852536, "y": 0.0, "ox": 0.6276497695852536, "oy": 0.0, "term": "unlimited vacation k plan", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19729594391587382, "os": -0.206501589067071}, {"x": 0.6000000000000001, "y": 0.0, "ox": 0.6000000000000001, "oy": 0.0, "term": "benefits health vision life dental insurance", "cat25k": 0, "ncat25k": 14, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.21181772658988485, "os": -0.19324732974665484}, {"x": 0.566820276497696, "y": 0.0, "ox": 0.566820276497696, "oy": 0.0, "term": "cupcakes", "cat25k": 0, "ncat25k": 13, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.22734101151727593, "os": -0.18132504449774048}, {"x": 0.43870967741935496, "y": 0.0, "ox": 0.43870967741935496, "oy": 0.0, "term": "competitive compensation equity packages", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2909364046069104, "os": -0.14041064090401453}, {"x": 0.4875576036866361, "y": 0.0, "ox": 0.4875576036866361, "oy": 0.0, "term": "A collaborative nature entrepreneurial spirit", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.26639959939909863, "os": -0.15288086229220466}, {"x": 0.37695852534562224, "y": 0.0, "ox": 0.37695852534562224, "oy": 0.0, "term": "SVN C unit test strategy", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.32298447671507263, "os": -0.1267332446868575}, {"x": 0.7069124423963135, "y": 0.0, "ox": 0.7069124423963135, "oy": 0.0, "term": "internal tools utilities Set unit test strategy", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15723585378067104, "os": -0.23903939105397062}, {"x": 0.527188940092166, "y": 0.0, "ox": 0.527188940092166, "oy": 0.0, "term": "revision control", "cat25k": 0, "ncat25k": 12, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.2468703054581873, "os": -0.1647858453898881}, {"x": 0.3963133640552996, "y": 0.0, "ox": 0.3963133640552996, "oy": 0.0, "term": "disk Experience Large Scale Big Data methods MapReduce Hadoop Spark Hive Impala Storm Strong", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.3129694541812719, "os": -0.12969484287639418}, {"x": 0.48018433179723513, "y": 0.0, "ox": 0.48018433179723513, "oy": 0.0, "term": "automated reports data visualisation solutions", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.27040560841261896, "os": -0.15183137909670907}, {"x": 0.44976958525345634, "y": 0.0, "ox": 0.44976958525345634, "oy": 0.0, "term": "modern data solutions", "cat25k": 0, "ncat25k": 10, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.28592889334001004, "os": -0.14335444337582653}, {"x": 0.40552995391705077, "y": 0.0, "ox": 0.40552995391705077, "oy": 0.0, "term": "Python applications data", "cat25k": 0, "ncat25k": 9, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.30796194291437157, "os": -0.131109809335983}, {"x": 0.6304147465437789, "y": 0.0, "ox": 0.6304147465437789, "oy": 0.0, "term": "SQL Comfort", "cat25k": 0, "ncat25k": 15, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.19579369053580373, "os": -0.20724073749274}, {"x": 0.966820276497696, "y": 0.0, "ox": 0.966820276497696, "oy": 0.0, "term": "LI PA1", "cat25k": 0, "ncat25k": 67, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.016024036054081123, "os": -0.9428090415820632}, {"x": 0.7124423963133641, "y": 0.0, "ox": 0.7124423963133641, "oy": 0.0, "term": "truly global company offices countries", "cat25k": 0, "ncat25k": 17, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.15473209814722086, "os": -0.24249775370159418}, {"x": 0.8829493087557605, "y": 0.0, "ox": 0.8829493087557605, "oy": 0.0, "term": "Ball games", "cat25k": 0, "ncat25k": 31, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.05758637956935403, "os": -0.4440152067627612}, {"x": 0.5059907834101384, "y": 0.0, "ox": 0.5059907834101384, "oy": 0.0, "term": "Monthly team", "cat25k": 0, "ncat25k": 11, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.256885327991988, "os": -0.15739762924864026}, {"x": 0.6903225806451614, "y": 0.0, "ox": 0.6903225806451614, "oy": 0.0, "term": "Teradata MS SQL", "cat25k": 0, "ncat25k": 16, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.16574862293440162, "os": -0.2311173227856114}, {"x": 0.027649769585253465, "y": 0.0, "ox": 0.027649769585253465, "oy": 0.0, "term": "SSRS", "cat25k": 0, "ncat25k": 4, "neut25k": 0, "neut": 0, "extra25k": 0, "extra": 0, "cat": 0, "ncat": 0, "s": 0.49323985978968454, "os": -0.05238701675479337}], "docs": {"categories": ["data scientist", "data engineer"], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "texts": ["", "years relevant experience preferred Healthcare industry knowledge experience preferred", "Pursuing PhD MS CS Math Statistics Physics Economics quantitative field expected graduation date Winter Spring Summer We also consider candidates quantitative backgrounds currently enrolled business school Ability think execute multiple altitudes strategy vision execution Interpersonal skills demonstrated ability influence outcomes communicate technical content general audiences including ability story tell data Ability write mentor code development SQL Python R Experience dashboard design data viz tools e Tableau plus Experience building data pipelines plus Stock yearly employee travel coupon Competitive salary Paid time Medical dental vision insurance Life disability coverage 401K Flexible Spending Accounts Apple equipment Daily breakfast lunch dinner", "", "PhD MS computational biology computer science statistics related quantitative science field years MS project based work computational quantitative data analysis biology related fields Proficiency analysing data R Matlab Python Strong interested biology immunological diseases liaise scientists Immunology Inflammation help define address biological questions computational analytical approach Proficiency biostatistics linear non linear regression models dimensionality reduction clustering AI machine learning methods Ability develop benchmark apply predictive algorithms identify novel biomarkers dissect gene disease relationships generate hypotheses Experience Bayesian analysis causal inference Excellent written oral communication skills Excellent interpersonal team skills", "Bachelor degree accredited college university Computer Science Computational Linguistics Statistics Mathematics Engineering Bioinformatics Physics Operations Research related fields Minimum years relevant work experience bachelor degree minimum years relevant work experience master degree proven track record driving value commercial setting using data science skills In depth knowledge various modeling algorithms e g Linear GLMs trees based models neural networks clustering PCA time series models Proficiency R e g ggplot2 cluster dplyr caret Python e g pandas scikit learn bokeh nltk Spark MLlib H20 statistical tools In depth knowledge databases data modeling Hadoop distributed computing frameworks Experience software development environment Agile code management versioning e g git Strong SQL skills experience knowledge Ability understand complex ambiguous business needs applying right tools approaches Must curious self motivating driven passion problem solving Collaborative team player Excellent communication skills written verbal Experience developing testing machine learning statistical projects Master degree accredited college university Business Analytics Computer Science Machine Learning Computational Linguistics Statistics Mathematics Engineering Bioinformatics Physics Operations Research related fields Experience agriculture commodity businesses Experience deep learning neural networks Experience weather geospatial data Experience computer vision applications images video Experience back testing strategies Experience working cloud environment e g Amazon Web Services Experience Big Data development Hadoop Spark frameworks", "Strong working knowledge variety machine learning analytical techniques understanding applicable Software engineering programing skills coding experience using Java Scala Python addition machine learning data mining libraries Experience working high performance computing distributed parallel systems e g Hadoop Tez Spark Strong mathematical statistical background thorough understanding probability Experience data science machine learning degree Computer Science Mathematics another empirical science Commercial experience building deploying scalable software solutions employ machine learning algorithms production environments Self starter comfortable juggling multiple projects strong communication skills Experience NLP techniques tools plus Have developed production data science solutions healthcare ad tech web search Prior experience building recommendation systems natural language processing solutions Healthcare Domain expertise", "", "", "", "Master degree relevant technical discipline Math Engineering Computer Science Statistics similar field least years job experience Bachelor degree relevant technical discipline years job experience Minimum years experience programming languages data science Python Java R etc Strong mathematical statistics skills Strong interpersonal communication skills written oral Ability communicate complex technical statistical concepts non technical audience PhD relevant technical discipline preferred Credit risk management fraud detection industry experience developing scoring models Experiences advanced machine learning algorithms including Deep learning boosting tree based methods Experience using cloud distributed computing frameworks Hadoop SPARK AWS EMR BigQuery etc Demonstrated ability apply modern data exploration visualization techniques deliver actionable insights", "", "", "Bachelor Degree plus years experience data analytics Master Degree PhD At least year experience open source programming languages large scale data analysis At least year experience machine learning Master Degree PhD Experience working AWS At least years experience Python Scala R At least years experience machine learning", "", "", "", "", "PhD MS computational biology computer science statistics related quantitative science field years MS project based work computational quantitative data analysis biology related fields Proficiency analyzing data R MatLab Python Strong interested biology immunological diseases liaise scientists Immunology Inflammation help define address biological questions computational analytical approache Proficiency biostatistics linear non linear regression models dimensionality reduction clustering AI machine learning methods Ability develop benchmark apply predictive algorithms identify novel biomarkers dissect gene disease relationships generate hypotheses Experience Bayesian analysis causal inference Excellent written oral communication skills Excellent interpersonal team skills", "Bachelors degree Computer Science related degree years related work experience Experience working Open Source project plus required Good English language skills", "PhD MS degree Computer Science Statistics Electrical Engineering Applied Math Operations Research Econometrics related fields Deep understanding statistical modeling machine learning deep learning data mining concepts track record solving problems methods Proficient one programming languages Python Java Scala C Familiar one machine learning statistical modeling tools R scikit learn Spark MLlib Knowledge experience working relational databases SQL Strong analytical quantitative problem solving ability Experience big data techniques Hadoop MapReduce Hive Pig Spark years experience machine learning data mining information retrieval statistical analysis Knowledge cloud platforms AWS Azure experience developing applications cloud platforms using various cloud services", "", "", "", "", "Ph D degree highly quantitive field Computer Science Machine Learning Operational Research Statistics Mathematics etc equivalent experience years hands experience Principal Data Scientist Experience building DMP DSP ID Graph MarTech AdTech highly desirable Ability develop experimental analytic plans data modeling processes use strong baselines ability accurately determine cause effect relations Demonstrable track record dealing well ambiguity prioritizing needs delivering results dynamic environment Job function EngineeringInformation Technology", "", "Upstream oil gas industry experience preferred particularly areas Drilling Completion Production Operations", "", "", "", "", "", "", "", "", "", "", "Bachelor Degree plus years experience data analytics Master Degree plus year experience data analytics PhD At least year experience open source programming languages large scale data analysis At least year experience machine learning At least year experience relational databases Master Degree PhD At least year experience working AWS At least years experience Python Scala R At least years experience machine learning At least years experience SQL", "", "", "", "", "", "", "", "", "", "", "Experience Data Visualizaiton using tools Tableau", "Experience data mining Understanding machine learning operations research Analytical mind business acumen Strong math skills e g statistics algebra Problem solving aptitude Excellent communication presentation skills BSc BA Computer Science Engineering relevant field graduate degree Data Science quantitative field preferred", "", "", "PhD bioinformatics computer science similar experience Experience relational database management systems Solid skills R Python Linux Experience systems biology research data Solid data visualization skills Basic knowledge web development Experience data work\ufb02ow management tools advantage Experience big data cloud computing advantage Ability work team pursue goals focused way Excellent written oral communication skills English", "Employment payment social benefits consistent research institutes", "", "", "", "Master PhD degree Engineering Neuroscience Bioinformatics quantitative fields strong analysis programming experience Excellent understanding machine learning techniques algorithms Experience common data science toolkits libraries scikit learn Pandas NumPy SciPy Matlab etc Programming languages Python Working knowledge Linux OS SQL years Python programming product development experience Great verbal written skills Be team player able work independently", "", "", "", "", "", "", "Bachelor Master degree quantitative field Knowledge Python R Knowledge algorithms data mining machine learning natural language processing Possess understanding statistical procedures used advanced analytics Experience processing large amounts structured unstructured data using Spark Hive Big Data technologies Experience building scalable data models performing complex relational database queries using SQL Oracle MySQL etc Attention detail demonstrated ability detect resolve data analytics quality issues Outstanding verbal written communication skills Experienced user data visualization tools e g Tableau matplotlib ggplot2 etc", "", "", "", "Experience multi touch attribution modeling media mix modeling data visualization big plus", "", "", "Strong experience designing quantitative modeling experiments solve fuzzy real world problems Good communication skills clearly understand problems experts outside field well collaborate data scientists Deep understanding deep learning models methods allow design redesign models solve new applications Strong experimental design allow verify utility models practice Passion research curiosity calls go beyond good enough create something innovative exciting Masters quantitative field computer science electrical engineering statistics biostatistics applied math etc PhD preferred years working data science deep learning required Experience deep learning libraries pytorch tensorflow keras etc well statistical modeling software scikit learn statsmodels python R Experience directly interfacing customers particularly medical professionals Experience turning research projects consumer products Ability write beautiful production ready code", "", "", "", "Social environment built bars", "", "Ph D life sciences related field expertise molecular cellular biology experience Omics data analysis Experience data analysis compound screens strong plus Experience toxicogenomics plus Experience R based data analysis plus Excellent communication skills ability interact professionally levels staff collaborators customers Experience working interdisciplinary teams Fluency English A permanent position within vigorous exciting professional environment promoted open culture spirit community A diverse international workforce dynamic working environment fosters creativity innovations teamwork Capital forming benefits holiday pay annual bonus payment depending performance", "PhD required computer science related discipline equivalent combination educational training relevant experience accomplishments Strong coding algorithm prototyping skills ability explain document work Proficiency one following Python C C SQL Experience working data analysis statistics machine learning scientific computing address basic research questions commensurate achievements Strong problem solving skills passion answering hard questions data The ability communicate complex ideas relevant stakeholders Experience collaborative multi disciplinary research environment Eagerness collaborate technical non technical colleagues Experience database design building data driven web applications", "", "", "", "", "", "First must true startup spirit Be willing wear multiple hats deliver end end Ability thinking box evaluating results based customer value years industry experience applying AI ML preferably well known security products services malware detection anomaly detection security analytics data security Experience applying AI ML one domains highly desirable Hands experience relevant technology stacks CUDA Python R Spark Flink Tensorflow Hands experience using modern big data pipeline Natural language process NLP data mining experience highly desirable Security research experience strong security domain knowledge highly desirable Energetic self starter desire work dynamic fast paced environment Excellent verbal written communication skills Ability influence without authority PhD Computer Science Statistics Electrical Engineering equivalent technical degree", "", "Bachelors M S quantitative discipline Mathematics Statistics Physics Computer Science Engineering Background linear algebra multivariable calculus Experience Python plus Experience cleaning visualizing data plus", "PhD Bioinformatics related field Proficiency database management scientific curation bioinformatics software engineering Proficiency MySQL Oracle graph databases Python R Java programming skills Demonstrated understanding posttranslational modifications cell signaling", "", "MS Statistics Machine Learning Operations Research Applied Math equivalent years data science experience Experience statistical mathematical software Proven ability develop system prototypes SQL skills Excellent oral written communication skills Strong documentation skills Understanding machine learning techniques ability invent Big data experience Hadoop Spark Map reduce Hive etc Light lifting lbs office environment Office Standard office equipment work usually performed office setting free disagreeable elements", "Ph D degree Bioinformatics Computer Science Biostatistics Applied Mathematics Applied Physics related discipline Experience analyzing multimodal OMICs data cancer immunotherapy patients Knowledge immunology tumor immunology tumor biology genetics Proficiency Python R", "", "A degree computer science statistics econometrics mathematics information science related field years experience data science years experience digital analytics ideally media Proven ability digital metrics systems Google Analytics Adobe Analytics BigQuery experience plus Facile statistical computing using R SAS SPSS S Plus Data Science Studio experience plus Hands knowledge database manipulation environments MySQL Proven ability Python similar Solid experience machine learning data mining Expertise decomposing problem working technical approach attacking problem systematic way Experience working digital product teams Agile environment Strong analysis experimental design skills keen sense data gaps inconsistencies Experience managing data driven research project inception client communication Experience developing data visualization independently tools Excellent oral written visual communication skills particularly explaining complex quantitative information non technical audiences Strong collaboration skills Not tolerance zeal multitasking At time show clear sense priorities commitment follow Ability work independently little supervision well collaborative team environment Self starter ability work constantly changing environment", "", "Minimum years experience upstream O G reservoir engineer data scientist petrophysicist MSc petroleum engineering related major Algorithmic thinking Working knowledge upstream data Experience analytical simulation tools field Familiarity reservoir simulation PhD petroleum engineering related major Demonstrated experience statistical analysis quantitative analytics forecasting predictive analytics multivariate testing optimization algorithms", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Restaurant Retail industry experience nice", "The Jobs Rated Report The Best Jobs The Toughest Jobs Fill The Best Jobs Retail Time Holiday Shopping Jobs Rated Report The Best Jobs The Best Jobs Advertising", "", "Managing functions complex environment multiple constituencies Complex modeling analytical methodology including longitudinal analyses multi level modeling multivariate analyses variance Summarizing presenting findings complex analytical modeling exercises Creating standard reports presents complex data Developing selling driving suitable partnerships alliances transactions closure Performing ongoing analytic projects support business strategies tactics including network optimization incorporation unstructured information ROI analysis Working multi source data integration development BI tool Cognos Tableau Applying industry best practices analytic processes create time efficiencies Making recommendations data architecture strategy Developing deploying analytical tools data science techniques analyze complex data sets Monitoring trends data science alternative sources", "Strong quantitative skills knowledge Deep Machine Learning Highly motivated infinitely curious self starter passion AI Python proficiency expertise PyTorch Tensorflow essential Perseverant capable thinking outside box Excellent communication skills Team player capable leading independent research efforts Master degree PhD quantitative field data science machine learning mathematics physics statistics engineering computational neuroscience biology computer science Deep understanding AI Machine Learning theory algorithms techniques evidenced completion foundational Deep Learning relevant coursework linear algebra advanced calculus mathematical optimization advanced statistics signal processing information theory AI Machine Learning classes etc Substantial experience designing implementing neural networks Python using PyTorch Tensorflow Experience working range real world data types stages data science Machine Learning pipeline data fetching pre processing visualization modeling interpretation etc Ability distill complex ideas results core essence communicate clearly non specialists Presentations Top tier AI Deep Machine Learning conferences Publications AI Machine Deep Learning peer reviewed journals Enthusiasm AI Deep learning demonstrated Kaggle contributions github commits relevant community activities Working knowledge high performance distributed computing code optimization parallelization GPU clusters Git method version control Proficient C C Solid understanding SQL query development MySQL SQLite Postgres", "", "", "You passionate subjects experimental design data visualization statistical analysis techniques Experience Looker Tableau data visualization software plus", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "MSc PhD level field Computer Science Machine Learning Applied Statistics Mathematics Experience statistical modelling machine learning techniques Programming experience least two following languages R Python Scala SQL Experience applying data science methods business problems Experience applying advanced analytical statistical methods commercial world Strong presentation communication skills ability explain complex analytical concepts people fields Knowledge distributed computing NoSQL technologies bonus Technical non technical training courses Attendance one international ML conference per year e g NIPS ICML McKinsey benefits competitive salary annual bonus generous pension scheme etc excellent healthcare Office events", "Bachelor Degree STEM field Science Technology Engineering Math accredited college university Minimum years experience analytics development industrial applications commercial industrial setting Desired Characteristics Master Degree STEM field Science Technology Engineering Math accredited college university Ph D STEM field Science Technology Engineering Math accredited college university Demonstrated skill data management methods Demonstrated skill feature extraction realtime analytics development deployment", "", "", "Subject call back times Ability travel area organization local remote needed Must provide transportation Required sit extended periods Ability understand complex verbal written communications respond verbally writing appropriate Typical mediums communication include face face dialog telephone memos electronic mail Ability interpret equipment status indicators determine appropriate operating condition Indicators may include visual auditory techniques cues Ability read understand technical manuals documentation determine correct action safety precautions conditions proper hardware software operation Ability work varying hours due accessibility individuals equipment involved different projects need minimize system downtime user interruption recover hardware software failures Will occasionally experience stressful working conditions due tight project schedules hardware software problems Ability occasionally lift move equipment pounds without assistance Must occasionally lift move equipment pounds assistance Ability occasionally crouch kneel bend crawl access inspect connect position perform operations equipment Some locations user equipment locations may present close quarters Ability occasionally use small hand tools able manipulate small equipment components screws nuts fastening devices usually found computer equipment Subject regular periods repetitive hand motion operation computer terminals equipment", "", "", "PhD computational quantitative discipline e g statistics computer science biomedical informatics genetics physics epidemiology health economics Master Degree similar field study Deep understanding ML including strong knowledge mathematical underpinnings behind various methods e g regression techniques neural networks decision trees clustering pattern recognition dimensionality reduction Proven experience applied statistics ML business setting Deep understanding tools trade including variety modern programming languages R Python JavaScript open source technologies Linux TensorFlow Hadoop Spark Experience effective data visualization approaches keen eye detail visual communication findings Comfort working communicating non technical teams translate business questions analytically actionable questions A strong desire build meaningful solutions life sciences business Task oriented ability set goals complete deliverables Domain knowledge clinical data real world data life sciences related research data Expertise data science related tools e g SQL Tableau D3", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "years professional experience Data Scientist Machine Learning Engineer working developing optimizing implementing machine learning models least projects Professional experience machine learning libraries scikit learn mllib Professional experience implementing multiple machine learning models production environment Bachelor Data Science Analytics Statistics Mathematics Physics Economics Computer Science equivalent experience Deep understanding statistical concepts applying real world problems Master degree PhD Data Science Analytics Statistics Mathematics Physics Economics Computer Science another quantitative discipline Experience petabytes data Experience deep learning frameworks tensorflow keras", "Familiarity AWS ecosystem plus", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "Bachelor degree preferably mathematically intensive field Enthusiasm analytically intensive work Excitement learn technology customer operations analytics Enthusiasm improve business performance Journey Analytics clients Understanding statistical advanced analytic methods descriptive statistics predictive analytics machine learning Ability work collaboratively team environment effectively people levels organization Confidence sharing views perspectives senior clients colleagues", "", "Bachelors degree statistics computer science economics physics quantitative field Experience using applied statistics machine learning Proficiency Python R Experience working imperfect data Passion eagerness constantly learn teach others Masters PhD student statistics computer science economics physics quantitative field Internship work experience applied statistics machine learning years experience", "", "", "Experience MS Office Word Access Excel PowerPoint Outlook required Experience managing employees Experience SAS SQL logistic regression multiple regression required Excellent written oral presentation skills Ability explain present complicated advanced analytical methodology results non technical audiences Ability provide strategic insights improve client campaign performance Ability execute advanced analytic tasks including limited modeling segmentation DOE forecasting etc create meaningful analytical outputs Must experience modeling statistical concepts Experiences applying statistical techniques regression ANOVA cluster analysis factor analysis time series forecasting experimental design etc solve business problems Possess core database marketing knowledge understanding Merkle client data relational database concepts direct marketing concepts", "Graduate degree Computer Science Electrical Engineering Applied Math related STEM majors machine learning algorithms development experience years industry experience Extensive knowledge details algorithm used Machine learning Experienced building large scale data analysis system Extensive knowledge experience successfully developing implementing Machine Learning projects Familiar Python PHP R HTML CSS SQL MongoDB Apache Hadoop Spark AWS Good written verbal presentation communication skills Strong project management leadership skills", "MS years experience new Ph D Deep technical skills including computer programming R Python similar Data management SQL data visualization techniques Multivariate analysis data science Unit operation model building mechanistic Machine learning Bioprocess economic modelling packages Biosolve SuperPro Bio G similar Total Cost Ownership Net Present Value analysis Approaches systems biology proteomics analysis Understanding scripting approaches build automation across platforms DeltaV Pi SIPAT Tecan similar Approaches chemometric modeling spectral data sources Approaches complex Residence Time Distribution Modeling", "Experience turn research results commercialization highly valued", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "M B A B S M S Statistics Economics Engineering Computer Science Mathematics related quantitative field required position Proven track record end end experience building analytical frameworks inform business strategy Deep knowledge understanding statistical econometric modeling methods significance testing causal inference These methods include limited regression analysis forecasting bootstrapping outlier detection feature selection decision trees At least years industrial experience working analytics business strategy role Exceptional programming skills Python R Knowledge Tableau data visualization tools preferred Strong knowledge databases related languages tools SQL NoSQL Hive etc Ability work dynamic cross functional environment strong attention detail Effective communication presentation skills ability explain complex analyses simple terms business leaders Strong relationship building collaborative skills Exceptional problem solving skills Inspiring company mission Amazing work environment San Francisco CA Competitive compensation including equity", "The qualifications listed minimum acceptable considered position Salary offers based candidates education level years experience relevant position also take account information provided hiring manager organization regarding work level position The qualifications listed minimum acceptable considered position Salary offers based candidates education level years experience relevant position also take account information provided hiring manager organization regarding work level position The qualifications listed minimum acceptable considered position Salary offers based candidates education level years experience relevant position also take account information provided hiring manager organization regarding work level position The qualifications listed minimum acceptable considered position Salary offers based candidates education level years experience relevant position also take account information provided hiring manager organization regarding work level position", "", "Degrees Physics Mathematics Computer Science Engineering plus", "Degree analytical field e g Computer Science Engineering Mathematics Statistics Operations Research Management Science years experience role data analysis metrics development years hands experience analyzing interpreting data drawing conclusions defining recommended actions reporting results across stakeholders years SQL development experience writing queries years hands project management experience years experience data visualization tools years experience packages R Tableau SPSS SAS STATA etc years experience scripting Python PHP Experience leveraging data driven models drive business decisions Experience using data access tools building visualizations using large datasets multiple data sources Experience thinking analytically Experience communicating data organizational levels Experienced packages NumPy SciPy pandas scikit learn dplyr ggplot2 Knowledge statistics optimization techniques Hands experience medium large datasets e data extraction cleaning analysis presentation", "", "", "Master Degree required Mathematics Information Technology Statistics Data Science related field At least plus years progressively responsible hands quantitative modeling skills SQL SAS R Python experience Significant experience working relational databases associated query extraction languages Strong knowledge predictive models classification regression models decision trees time series data mining etc Ability stay organized meet deadlines Willingness work team member A self starter able administer number open ongoing assignments one time assignments routinely unstructured requiring autonomy independent judgment In depth experience successfully harmonizing diverse competing interests Ability clearly articulate position sound logic supporting empirical evidence impartiality Ability effectively represent organization variety internal external constituencies Superior verbal written communication skills Ensures behavior behavior others consistent highest ethical standards aligns values organization Ability promote collaboration unifying teams setting common goals incentivizing collaborative behavior Demonstrated success establishing maintaining positive working relationships others internally externally achieve goals organization Strong ability build credibility organize effectively solve problems quickly communicate clearly Possesses balance emotional intelligence required meet diverse needs divisions offices Proven ability navigate resolve various types conflict timely productive manner Proven transformation skills include ability consistently execute high level drive positive change desire build established programs teams Demonstrated agility ability navigate complex environments Ability foster environment creativity innovation focusing empowerment support staff tools continuous process improvement Supports individuals teams process excellence project management problem solving value creation drive toward required outcomes Surfaces capacity pacing resourcing issues requiring leadership attention Ensures organizational alignment effective stakeholder engagement communication Demonstrated ability think broadly strategically including ability translate long term goals objectives short term tactical plans operational activities Effectively assesses progress identifying articulating clear consistent key performance indicators", "years relevant industry experience A graduate degree statistics applied mathematics computer science physical sciences similar technical field Experience developing deploying machine learning deep learning solutions The versatility communicate clearly technical non technical audiences Python numpy pandas sklearn xgboost TensorFlow MySQL Hive Java Google Cloud Platform", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Pursuing graduated Masters quantitative field Operation Research Computer Science Engineering Applied Math Statistics Physics Analytics etc equivalent work experience Proven leadership applying scaling Analytic techniques deliver impactful insights data academics industry Strong written verbal communication skills influence others take action Able balance multiple priorities Good social skills self motivated dynamic mentality Strong enthusiasm curiosity intersection business technology years Data Science Experience Experience disrupting current business practices CPG related industries help crafting new go market models Experience Analytical Tools Applications including Unix Linux Big Data Ecosystem Hadoop Spark MapReduce SQL HIV Scientific Computing R Python C Java Scala etc High Performance Parallel Distributing Computing Deep Learning frameworks Keras Tensorflow Data Visualization Data Management Systems Business Intelligence tools KNIME Tableau", "Experience SQL querying MongoDB Solr Indexes", "", "", "Be pursuing M S BS Computer Science Information systems Mechanical Engineering Materials Engineering Chemical Engineering Electrical Engineering Chemistry Physics Expertise engineering analysis tools data analysis scripting methods order automate train standard analytical tasks required Prior experience machine learning algorithms artificial intelligence image processing numerical computing plus", "", "", "Bachelor degree Experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics GPA least point scale Experience real world data thesis research internships work experience Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Advanced degree data science equivalent field sub field Experience working data rich problems research programs Experience computer programming user experience user interface Ability successfully complete projects large incomplete data provide solutions Strong written verbal communication skills A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "PhD computational quantitative discipline e g statistics computer science biomedical informatics genetics physics epidemiology health economics Master Degree similar field study Deep understanding ML including strong knowledge mathematical underpinnings behind various methods e g regression techniques neural networks decision trees clustering pattern recognition dimensionality reduction Proven experience applied statistics ML business setting Deep understanding tools trade including variety modern programming languages R Python JavaScript open source technologies Linux TensorFlow Hadoop Spark Experience effective data visualization approaches keen eye detail visual communication findings Comfort working communicating non technical teams translate business questions analytically actionable questions A strong desire build meaningful solutions life sciences business Task oriented ability set goals complete deliverables Domain knowledge clinical data real world data life sciences related research data Expertise data science related tools e g SQL Tableau D3", "B A B S Statistics Math Economics Finance Computer Science similar field Database experience including proficiency SQL Excellent communication organization analytical skills experience presenting various business contacts levels company Real passion working product management engineering Ability thrive fun dynamic start environment A roll sleeves attitude An excellent sense humor Coding experience scripting languages R Python Experience visualization tools like Tableau Contributions data science community Background online advertising Masters degree statistics math related field", "", "", "Master PhD preferably engineering statistics technology science role Analytics Familiarity common advanced analysis tools SQL Python R SAS preferred Demonstrate familiarity work experience Github account OOP concepts Python Java Scala skills big plus Machine Learning Deep Learning NLP experience also working Hadoop Spark environment Ability ask tackle important analytical questions view driving product impact", "US citizenship required We DO NOT offer sponsorships contracting work This position Charlottesville Bachelor Degree technical field Prior Work experience related field working portfolio clearly demonstrates abilities Casual Work Environment Intellectually Challenging Work Health Insurance Short Term Disability Insurance Generous Defined Benefit Retirement Very Flexible Vacation Policy Want know Check recruitment video https www youtube com watch v W b2EY1tlRM Commonwealth Computer Research Inc discriminate basis race sex color religion age national origin marital status disability veteran status genetic information sexual orientation gender identity reason prohibited law provision employment opportunities benefits", "You worked seriously huge datasets", "", "Master degree behavioral sciences relevant field training research methodology statistics Two years experience various data analysis visualization tools Strong communication data presentation skills Experience SPSS Excel PowerPoint Word Ph D behavioral sciences relevant field rigorous training research methodology statistics psychometrics Expertise Python R Expertise using applying machine learning deep learning models systems Professional experience human capital consulting", "", "", "Qualifications may warrant placement different job level", "You proud say work Stitch Fix know work brings joy clients every day", "years experience working Intelligence Community teams working fields related Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical Modeling Geo spatial analytics Data Munging Cleaning Bachelor Degree Ability work datasets different sizes formats across multiple databases Knowledge experience specific techniques neural networks cluster analysis feature engineering extraction reduction web scraping decision trees CART collaborative filtering geo spatial analysis Experience PCAP data Elastic Search Hadoop HDFS git Spark MLLib SQL OS Experience Windows Linux Windows Ability compile results deliver presentations senior level leadership Strong communication skills ability present material audiences differing technical aptitude R R shiny R studio Python Sci kit Tensorflow Intelligence Community Experience Machine Learning Statistical modeling Experience multi TB dataset manipulation cleaning querying modeling Experience scikit learn tensorflow R caret Experience curating datasets supervised unsupervised machine learning methods Experience C Java R Javascript PhP MatLab Pig Hive Impala PySpark Scala Ruby Pytorch", "", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "You bachelor degree computer science information systems mathematics statistics related quantitative discipline Applicants data related expertise professional background media also encouraged apply years professional experience media company preferred An enthusiasm The Wall Street Journal understanding product must You entrepreneurial attitude toward work sweat details well healthy skepticism status quo You experience using analytics tools SQL Tableau Excel interest advanced topics analytics artificial intelligence data engineering You worked visualization machine learning libraries either R Python Experience building web applications agile development plus", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Messages sorted date thread subject author", "You must U S Citizen National apply Required pass background investigation fingerprint check Registered Selective Service applicable Successful completion one year probationary period Meet education experience requirements Complete Occupational Questionnaire submit resume supporting documents Organizational Performance Analysis Problem Solving Database Management Systems Planning Evaluating An applicant disability needs accommodation equal opportunity apply job An employee disability needs accommodation perform essential job duties gain access workplace An employee disability needs accommodation receive equal access benefits details training office sponsored events", "", "Conduct planning development implementation administration systems acquisition storage retrieval data Consult customers apply analytical processes planning design implementation new improved information systems meet business requirements customer organizations Identify adapt manage changes data analysis tools response evolving user needs Provide technical advice Group Director Deputy Director collecting analyzing interpreting communicating insights data Develop database system proposals coordinate efforts necessary translate business requirements effective IT data system solutions You must U S Citizen National apply position You subject background suitability investigation Optional Form Declaration Federal Employment Background Suitability Investigation A background suitability investigation required selectees Appointment subject successful completion investigation favorable adjudication Failure successfully meet requirements may grounds appropriate personnel action In addition hired reinvestigation supplemental investigation may required later time If selected Optional Form required prior final job offer Click obtain copy Optional Form Form I Employment Verification Electronic Eligibility Verification Program CMS participates Electronic Employment Eligibility Verification Program E Verify E Verify helps employers determine employment eligibility new hires validity Social Security numbers If selected Form I required time processing Click information E Verify obtain copy Form I Standard Form Appointment Affidavits If selected Standard Form required time processing Click obtain copy Standard Form Best Qualified superior evaluation criteria Well Qualified excel evaluation criteria Qualified meet minimum qualification requirements Official Position Title include series grade Federal job Duties specific describing duties Employer name address Supervisor name phone number Start end dates including month day year e g June April Full time part time status include hours worked per week Salary To begin click Apply access online application You need logged USAJOBS account apply If USAJOBS account need create one beginning application Follow prompts select resume supporting documents included application package You opportunity upload additional documents include application submitted Your uploaded documents may take several hours clear virus scan process After acknowledging reviewed application package complete Include Personal Information section deem appropriate click continue application process You taken online application must complete order apply position Complete online application verify required documentation included application package submit application First week September The announcement open period midnight day applications received Early September First round reviews Written Assessment Mid September Second round reviews hour phone calls Early October Hiring manager interviews qualifying applicants Mid late October Tentative job offers sent applicants An applicant disability needs accommodation equal opportunity apply job An employee disability needs accommodation perform essential job duties gain access workplace An employee disability needs accommodation receive equal access benefits details training office sponsored events", "", "Messages sorted date thread subject author", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "Gated dog run located outside LA location", "", "Bachelor Degree Data Science Computer Science Mathematics Statistics Master Degree Data Science Computer Science Mathematics Statistics preferred years experience leading data analytics initiatives using statistical modeling analytics platforms tools producing high quality data analytics products Excellent verbal written communication skills ability effectively communicate collaborate internal stakeholders analytics vendor partners Demonstrated ability analyze large complex data sets demonstrated aptitude conducting quantitative qualitative analysis Understanding analytical techniques support cybersecurity program goals objectives Deep understanding statistics artificial intelligence machine learning models application models support cybersecurity objectives Ability develop intuitive analytics reports visualizations improves risk management decision making optimizes cybersecurity operations orchestration automation Experience working large scale analytics event management platforms Hadoop Splunk Qradar Experience statistical analytics reporting visualization tools Power BI Excel Tableau SSPS statistics modeler Mature self starting self motivating capable making decisions independently Proficiency data management languages e g SAS R Python etc Develop implement cybersecurity analytics product tools This includes development maintenance continuous improvement cybersecurity statistical models predictive analytics reports visualizations Partner stakeholders define analytics requirements program needs Provide direct support incident handling vulnerability management teams IT risk teams providing expertise exploratory data analysis pattern discovery advanced analytical techniques anticipate detect undiscovered threats Work internal stakeholders vendors partners optimize analytics systems detect manage external internal threats Coordinate data infrastructure needs appropriate stakeholders Develop high quality compelling intuitive data dashboards research papers visualizations stories presentations Coordinate cybersecurity analytics program activities This includes coordinating development activities initiatives analytics stakeholders architects engineers Communicate analytics initiatives status Ensure data analytics initiatives aligned support cyber analytics program objectives requirements Effectively manage shifting priorities timelines Mentor coach cybersecurity risk management staff team members Communicate analytics gaps needs leadership Effectively work within team support goals objectives analytics program", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "You background engineering mechanics inertial sensing signal processing You working knowledge system identification statistical inference modeling You working knowledge MATLAB", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "", "Experience digital sound processing Excellent medical dental vision life disability benefits 401k program Ability work closely customers hungry product make positive impact livelihood world A focus community involvement career development We equal opportunity employer value diversity company We committed creating inclusive environment employees", "", "A Bachelor Master Degree Computer Science related field focus data science machine learning preferred A minimum years hands experience data science machine learning years experience data engineering analytics business intelligence At least years experience C C Java At least years current experience Deep Learning Hands experience deep learning neural networks Highly proficient Python SQL Proficient Tensor Flow Keras Theano Experience Jupyter notebooks docker containers Strong mathematics statistics data analytics abilities Have solid understanding relational NoSQL database technologies Skilled working stream batch data extremely large data sets Experience leading small technical teams people project management Track record successful projects data engineering machine learning product Experience advanced data analytics visualization techniques Experience advanced machine learning techniques complex data pipelines ingest configurations systems Experience developing leveraging distributed computing GPU systems frameworks Experience developing implementing predictive solutions anomaly detection large scale systems Prior experience research labs environments exploring evaluating new technologies products publishing research creating white papers etc Experience complex networks big data mobile media wireless environments Experience data processing storage frameworks like Hadoop Scala Spark Storm Cassandra Kafka etc", "Degree computer science mathematics statistics equivalent experience years work experience data science analytics Senior level SQL Python R alternate analytic programming language experience Methodical detail oriented approach know information accurate able keep schedule Tenacious unstoppable attitude want get job done quickly efficiently Ability effectively work wide variety personalities skill levels", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "Bachelor degree Minimum year experience predictive statistical modeling using SAS R Python Proficient MS Office applications Excel proficiency Pivots V Lookups Formulas Bilingual Spanish English Master Degree Experience performing data analysis Experience extracting data using SQL data exploration tools SAS R Experience data analytics design Experience working large databases Health care industry experience Demonstrated ability effectively gather requirements probe deeper understanding translate deep technical concepts non technical well technical senior stakeholders marketing customers data scientists Demonstrated ability manage people prioritize deliverables Proven organizational skills ability flexible work ambiguity", "years recent experience data science data analyst role Familiarity measuring UX customer engagement planning analyzing AB experiments Comfortable well versed working predictive causal problems A passion improving customer experience refining product Excellent presentation communication social skills strong attention detail Strong business mindset possessing ability condense complex analysis technical concepts clear concise takeaways business leaders Ability operate comfortably effectively dynamic highly cross functional fast paced environment Excellent time management skills ability manage work tight deadlines handle pressure product launches executive requests Well versed SQL languages experienced big data technologies Hadoop Spark Familiarity Python R data visualization tools Tableau full stack data analysis insight synthesis presentation Ability comprehensively understand data elements sources relationships business technical terms", "United States Preferred", "Must least years actual working experience performing advanced quantitative analyses Must actual working knowledge Python SQL Working knowledge SAS R plus Working knowledge big data manipulation tool plus Ability apply advanced statistical methodologies mixed model random fixed effects simultaneous equations ARIMA neural networks multinomial discrete choice Ability apply mathematical operations tasks cluster analytics sampling theory design experiments analysis variance correlation techniques factor analysis Ability apply advanced optimization methodologies linear mixed integer optimization Ability apply advanced simulation modeling methodologies techniques Utilize complex computer operations intermediate programming 3rd 4th generation languages relational databases operating systems advanced features software packages word processing spreadsheet graphics etc Must relational database experience A strong passion empirical research answering tough questions data Demonstrated experience organizing prioritizing coordinating complex team efforts Experience working executives strategic planning departments set manage corporate level strategies plus Experience business support software applications MS Office Word PowerPoint Excel Project required", "", "BS graduate degree Computer Science Statistics Mathematics Economics similar quantitative field emphasis predictive analytics data mining statistics machine learning algorithms etc years data science experience working closely product engineering Ability translate business objectives problems analytical problems use quantitative qualitative skills deliver simple logical actionable solutions Experience data visualization Tableau presentation Advanced proficiency R Python Excel Proficiency SQL Hadoop Map Reduce scripting language Proven ability data science initiatives end end Ability build predictive modeling time series k nearest neighbors random forests ensemble methods Understanding applied math topics probability statistics linear algebra basic optimization techniques etc", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "years experience quantitative analysis consulting role Advanced data modeling experience SQL skills ETL design Experience advanced data analytics data transformation data management projects Dimensional modeling BI support In depth experience analyzing data creating reports working data identify trends make recommendations", "Ability tie together disparate unique vintage data sources cohesive automated stable data output utilization models Expertise SQL MS Access VBA Excel SAS query modeling languages tools Ability leverage industry standard operations modeling techniques Regression Six Sigma address ongoing ad hoc modeling needs e g working actuaries remove operations impact reserving models Expertise one analytics packages SAS R Python required Experience building advanced analytics models Artificial Neural Nets k Nearest Neighbors Ability creatively problem solve collaborative fashion Ability explain highly technical complicated issues simple non technical language Keen analytical thinker strong research capabilities Ability perform independent research industry trends around analytics Excellent written verbal skills years work experience", "years proven top performance data science analytics space Must least years direct experience models built maintained production focused large commercial business problems tend billion dollar plus scope opportunity Must expert level understanding ability explain code underlying math used algorithms models Must excellent coding proficiency demonstrated expertise python java R etc Expert level knowledge AI ML models frameworks keras pytorch etc libraries packages apis e g scikit Must least years developing models algorithms independently writing code developing strategy algorithmic experimentation deploying production Must worked batch streaming models production Advanced knowledge math probability statistics models Experience Hadoop AWS distributed compute services Exposure data structures data modeling software architecture skills Excellent communication skills Excellent cross functional collaboration skills Outstanding analytical problem solving skills", "", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Ability work team oriented collaborative environment", "PhD computer science computer engineering MS years experience related field Demonstrated history driving delivering analytics models solutions Deep knowledge fundamentals machine learning data mining statistical predictive modeling extensive experience applying methods real world problems Strong skills software prototyping engineering expertise applicable programming analytics languages Python R C C various open source machine learning analytics packages generate deliverable modules prototype demonstrations work Desired interdisciplinary skills include big data technologies ETL statistics causal inference Deep Learning modeling simulation Breadth skills experience machine learning diverse types data diverse data sources different types learning models diverse learning settings Ability inclination work multi disciplinary environments desire see ideas realized practice Experience knowledge services domains business process outsourcing systems transportation systems healthcare systems financial services valued Demonstrated ability propose novel solutions problems performing experiments show feasibility solutions working refine solutions real world context Prior experience similar role required Please include requirements appropriate Must currently eligible work US employer without sponsorship", "", "years working experience", "Knowledge GIS principles concepts methods Working knowledge experience ArcGIS Desktop address processing geocoding Demonstrable expertise cartographic design production Ability work identify patterns large data repositories cross correlate metadata across multiple data sources Proficiency required programming languages scripting languages Python JavaScript SQL databases SQL query language Ability develop implement GIS automation applications quality assurance protocols metadata standards Proven ability conceptualize complete complex projects thorough documentation demonstration applied logic e flow charts Ability communicate effectively supervisors project leader co workers orally writing Ability work team environment well goal oriented individual functions highest level integrity professionalism Ability multitask work fast paced environment deadlines", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "Visualization tell story explain point", "", "", "Healthcare Data analysis experience clinical environment strongly preferred year equivalent exposure Business Objects Tableau Understands data integration processes tune performance years SQL experience Oracle preferred SSIS ok Ability develop work plans follow assignments minimal guidance Ability work business system owners obtain requirements manage expectations years experience SAS Oncology data experience preferred", "", "", "", "PhD computer science computer engineering MS years experience related field Demonstrated history driving delivering analytics models solutions Deep knowledge fundamentals machine learning data mining statistical predictive modeling extensive experience applying methods real world problems Strong skills software prototyping engineering expertise applicable programming analytics languages Python R C C various open source machine learning analytics packages generate deliverable modules prototype demonstrations work Desired interdisciplinary skills include big data technologies ETL statistics causal inference Deep Learning modeling simulation Breadth skills experience machine learning diverse types data diverse data sources different types learning models diverse learning settings Ability inclination work multi disciplinary environments desire see ideas realized practice Experience knowledge services domains business process outsourcing systems transportation systems healthcare systems financial services valued Demonstrated ability propose novel solutions problems performing experiments show feasibility solutions working refine solutions real world context Prior experience similar role required Please include requirements appropriate Must currently eligible work US employer without sponsorship", "", "years experience performing statistical predictive analytics within video games industry Expert machine learning Expertise R Python Must passing familiarity Behavioral Science Psychology Social Science Eligibility Requirements Interested candidates must submit resume CV online considered Must unrestricted work authorization work United States Must covered Solutions NBCU Alternative Dispute Resolution Program Desired Characteristics Expertise Java C C plus Understanding Big Data technologies Cassandra Spark Hadoop strongly preferred Are fan The Fast Furious Jurassic World Back Future Have ever dreamed working innovative games based favorite movies TV shows If The Universal Games Digital Platforms group looking Join diverse group creative talent crafting groundbreaking interactive experiences inspired world valuable brands Operating start mindset business unit nimble explores new emerging platforms AR VR stay forefront innovation They currently looking even movers shakers group GROWING Could next member team really fun games NBCUniversal policy provide equal employment opportunities applicants employees without regard race color religion creed gender gender identity expression age national origin ancestry citizenship disability sexual orientation marital status pregnancy veteran status membership uniformed services genetic information basis protected applicable law NBCUniversal consider employment qualified applicants criminal histories manner consistent relevant legal requirements including City Los Angeles Fair Chance Initiative For Hiring Ordinance applicable", "", "Experience managing small teams projects", "", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "", "PhD computational quantitative discipline e g statistics computer science biomedical informatics genetics physics epidemiology health economics Master Degree similar field study Deep understanding ML including strong knowledge mathematical underpinnings behind various methods e g regression techniques neural networks decision trees clustering pattern recognition dimensionality reduction Proven experience applied statistics ML business setting Deep understanding tools trade including variety modern programming languages R Python JavaScript open source technologies Linux TensorFlow Hadoop Spark Experience effective data visualization approaches keen eye detail visual communication findings Comfort working communicating non technical teams translate business questions analytically actionable questions A strong desire build meaningful solutions life sciences business Task oriented ability set goals complete deliverables Domain knowledge clinical data real world data life sciences related research data Expertise data science related tools e g SQL Tableau D3", "", "Technical Expertise years experience applying advanced analytics techniques data mining descriptive statistics visualization solve complex business problems including years deep technical experience predictive analytics machine learning optimization Fluent multiple technologies Python Azure ML IBM SPSS Modeler R comparable technologies required Strong database skills required Experience visualization techniques preferred Experience optimization software preferred Technology Leadership Strong working knowledge contemporary analysis technology software platforms methodologies ability apply manufacturing processes The ability educate senior leaders impact benefit analytics descriptive predictive prescriptive cognitive operations Project Leadership Small medium scale project management experience including limited scope schedule cost risk resource change management Possibly including initiatives global reach technology processes cross functional teams partner team members Consulting skills Proven track record influencing decision problem solving processes The ability understand business economic drivers align goals across functional lines organizational boundaries execution Global Experience understands communicates effectively interacts people across cultures achieve business results Prior experience participating collaborating cross functional cultural teams beneficial Analytics Has demonstrated experience applying statistical techniques solve business problems Visualization Has experience effective utilization visualization techniques explore data find root causes well presentation results Optimization Demonstrated experience various optimization techniques including linear programming integer programming non linear programming dynamic programming Leadership Recognized expert field ability help define problem move quickly resolution Someone sought bring resolution issue timely cost effective manner Consultative Skills Ability influence business partners decision making Shape solutions helping partners articulate need Problem Solving Strong intrinsic problem solving skills Ability structure solve problems conduct interpret analysis independently demonstrated analytical quantitative skills Diversity Understands communicates effectively interacts people across cultures Effectively achieves business results working across multi national teams Communication Strong presentation communication skills ability explain complex analytical concepts people fields External Technology Knowledge Keeps abreast latest technological developments areas push technology roadmaps realization Constantly looks opportunities incorporate new solution methods solve existing problems Unconditional commitment safety Competes Analytics Adaptability Ability respond quickly demands moment A flexible person stay productive demands work pull many different directions Shifts focus necessary maintain effectiveness variety environments Can quickly come speed project contributor Accountability Knows needs done gets done Willingly takes responsibility organization whole unafraid owning results actions decisions self organization Committed follow completion excuses rationalizations totally unacceptable Curiosity Naturally curious leading one seek knowledge people things stretch beyond one work environment Thrives dynamic work environment new subject matter learned quickly put practice An information sponge constantly absorbing new methods technologies approaches deliver business outcomes Decisive Is able make decision competing analytics conditions high uncertainty Weighs risks prioritizes actions deliver organizational effectiveness speed Risk Taker Innovator Is willing push envelope meet stretch goals Not satisfied status quo willing aggressive implement next breakthrough technology get operations next level", "", "Team outings sports games happy hours game nights", "years professional industry experience quantitative analysis A proven track record using analysis impact key business product decisions The ability clearly effectively communicate results complex analyses Experience writing production datasets SQL Hive OR building internal production data tools ETL experimentation exploration scripting language Python R etc A solid grasp basic statistical applications methods experimentation probabilities regression Experience software engineering data engineering consulting academic research plus", "Background image processing concepts e g filtering morphology transforms compression etc desired", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Never ending ping pong tournaments", "", "Master Degree accredited Institution Minimum years experience data analytics Employees must legally authorized work United States Verification employment eligibility required time hire Visa sponsorship available position MS PhD accredited institution Applied Mathematics Operations Research Industrial Engineering Mathematics focus Machine Learning Physics similar quantitative discipline years experience delivering computation approach outcomes solving complex analytical problems using quantitative approaches unique blend analytical mathematical engineering skills Experience Manufacturing Understanding statistical predictive modeling concepts machine learning approaches clustering classification techniques recommendation optimization algorithms Accomplished use statistical analysis environments R MATLAB SPSS SAS Experience BI tools Tableau MicroStrategy Comfortable relational databases Hadoop based data mining open sources frameworks Familiar SQL Python Java C C Experience isogeometric analysis", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "Bachelor degree Statistics Computer Science related field years experience working large datasets drawing business insights Fluency Python programming Experience using machine learning solve complex business problems Strong understanding statistics modeling techniques Knowledge predictive modeling Experienced leveraging structured unstructured data sources Experience relational databases SQL Willingness ability learn new technologies job Demonstrated ability communicate complex results technical non technical audiences Demonstrated ability work minimal supervision Experience distributed computing big data technologies Spark related technologies Experienced statistical methodologies tools R SAS SPSS etc Experience Natural Language Processing Information Retrieval Recommender Systems", "", "Possess Bachelor degree higher completed verified prior start accredited institution Minimum two combined years experience one following areas data analytics data visualization statistical analysis predictive modeling application development private public government military environment Project Management experience Extensive knowledge experience using Excel Access Power Point MS Word Experience working across functions influencing teams Continuous improvement mindset Experience data modeling tools e g SAP PA Python R SAS MS Azure Experience business intelligence data visualization tools Power BI Google Analytics Tableau Domo Qlikview Data integration experience including extract transform load ETL processes Experience databases complex data queries Greenbelt certified Strong organizational skills Self motivated independent Excellent oral written communication skills Ability work rapidly changing environment", "", "Master degree higher Statistics Math Computer Science related field years industry work experience SQL R Python implement statistical models machine learning analysis Recommenders Prediction Classification Clustering etc big data environment Experience large scale computing systems like COSMOS Hadoop MapReduce similar systems preferred Experience programming skills e g Java C plus Familiarity deep learning toolkits e g CNTK TensorFlow etc plus Exceptional written verbal communication educate work cross functional teams", "", "", "Creates statistical approaches analyze data generated multiple applications processes trends data understand opportunities focused investigation Develops reports emphasizing clarity accuracy methodologies degree statistical support conclusions Communicates effectively various channels including written reports oral presentations Assists new business development proof concepts required", "Currently pursuing bachelors masters Computer Science Computer Science Engineering Engineering Computer Science Math Computer Science Mathematical Engineering Mathematical Science Mathematics Statistics Strong data wrangling skills Strong Python SQL skills Ability manipulate JSON XML data Experience Splunk Experience data manipulation platforms Experience Ansible Puppet Jenkins Chef", "As member analytics group may opportunities get hands dirty developing analytics solutions time time", "PhD computer science computer engineering MS years experience related field Demonstrated history driving delivering analytics models solutions Deep knowledge fundamentals machine learning data mining statistical predictive modeling extensive experience applying methods real world problems Strong skills software prototyping engineering expertise applicable programming analytics languages Python R C C various open source machine learning analytics packages generate deliverable modules prototype demonstrations work Desired interdisciplinary skills include big data technologies ETL statistics causal inference Deep Learning modeling simulation Breadth skills experience machine learning diverse types data diverse data sources different types learning models diverse learning settings Ability inclination work multi disciplinary environments desire see ideas realized practice Experience knowledge services domains business process outsourcing systems transportation systems healthcare systems financial services valued Demonstrated ability propose novel solutions problems performing experiments show feasibility solutions working refine solutions real world context Prior experience similar role required Please include requirements appropriate Must currently eligible work US employer without sponsorship", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "", "Expertise natural language processing machine learning classification feature engineering information extraction structured prediction clustering semi supervised learning topic modeling ranking Proficiency data science analytics including statistical analyses A B testing Experience designing conducting analyzing interpreting experiments investigations Strong programming skills expert knowledge algorithms data structures Python Java equivalent Excellent problem solving critical thinking creativity organizational design interpersonal skills ability work well levels engineers Confirmed ability handle multiple projects strict deadlines", "", "years experience related work building statistical models advanced data analysis Master degree PhD candidate Mat Economics Statistics Data Science Experience Logistic Regression Linear Regression Time Series Analysis Decision Trees Cluster Analysis Advanced programming skills include knowledge statistical programs e g SQL SAS SPSS R Python Must eligible full time employment Salary range Full Benefits Cigna Healthcare MetLife Dental VSP Vision 401K Voya Paid Time Off", "", "", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "We connect everything people process data things use connections change world better", "", "Minimally candidates bachelor degree statistics math computer science informatics economics related fields Advanced degrees subject areas preferred General knowledge statistical techniques concepts regression properties distributions statistical tests etc Novice understanding Python SQL Understanding Hadoop Java preferred Strong problem solving skills emphasis data driven solutions Excellent written verbal communication skills coordinating across teams Ability analyze policies procedures able recommend improvements Excellent oral written communication skills Ability work independently anticipate problems initiate corrective actions Ability effectively prioritize variety projects functions Ability research document findings Ability establish maintain effective working relationships", "Advanced statistics modeling data visualization knowledge Strong data visualization skills Substantial data analysis experience working large scale data Ability learn new technologies quickly grasp complex problems Significant experience using relational databases MySQL preferred Excellent written verbal communication skills Strong scripting language skills e g R Python Experience working Hadoop Map Reduce Experience working Hadoop Map Reduce", "", "At point successful candidate shown prowess data scientist right promoted They leading projects making major impact business", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "At least years experience generating implementing short term trading alphas production trading strategies Advanced knowledge modern statistical machine learning techniques Proficiency scripting language Python R MATLAB Proficiency least one statistical package one machine learning package one languages Demonstrated experience working tick data Degree quantitative discipline Statistics Computer Science Mathematics Engineering etc Experience developing software systems object oriented language plus", "Demonstrated energy passion extends beyond field study Are computer scientist writes poetry A mathematician loves psychology An engineer passionate public policy We want build something", "Ability apply common sense understanding carry instructions furnished written oral diagram form", "", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "Strong experience implementing real time analytics dashboard business intelligence reporting Strong experience data visualization tools Tableau d3 js Experience building end end data science workflow Experience programming Python R A software engineering mindset Documentation Source control release cycles Repeatability sharing Experience implementing ETL report generation large volume data Ability work within small high achieving team well independently Self driven highly motivated innovative Strong communication skills written verbal Computer Science degree another highly quantitative degree engineering physics mathematics Graph Databases Janus Neo4J Apache Spark Scala AWS Linux Machine learning tools", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "", "", "", "", "Bachelor degree computer science computer engineering related field equivalent combination education related experience Fundamental knowledge one following high performance computing scientific data analysis statistical analysis knowledge discovery computer security systems programming large scale data management big data technologies Skilled aspects software project life cycle feasibility requirements design implementation integration test deployment Fundamental experience developing software C C Java Python R Matlab software applications Linux UNIX Windows environments data analysis algorithms data management approaches relational databases machine learning algorithms Ability effectively handle concurrent technical tasks conflicting priorities approach difficult problems enthusiasm creativity change focus necessary work independently implement research concepts multi disciplinary team environment commitments deadlines important project success Sufficient interpersonal skills necessary interact levels personnel Included Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules depending project needs", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Access opportunities expand skill set share knowledge others across organization", "Many unique benefits including floating holidays lunch every Wednesday paid volunteer time fuel efficient vehicle purchase assistance transit fare contribution first time homebuyer payment assistance", "As always interviews screening call conducted via video call", "An eye great data visualization Matplotlib Plotly ggplot Tableau", "years Data Science experience outside academia Title commensurate experience Advanced degree quantitative discipline applied mathematics statistics computer science physics related field leading academic institution Expert Python SQL Must experience writing production level code Proficiency working Spark process large data sets Excellent communication skills demonstrated success presenting complex data analysis qualitative quantitative clear compelling manner inspires action Strong understanding statistical analysis A strong passion empirical research answering hard questions data A passion problem solving comfort ambiguity creativity A flexible analytic approach allows results varying levels precision Quick learner ability initiate drive projects completion minimal guidance Ability thrive dynamic fast paced environment Drive change collaborate effectively variety individuals organizations", "", "Interest politics educational policy", "", "years Professional industry experience quantitative analysis role Proficiency SQL experience programming language like Python R etc Ability identify complex business problems provide sound analytical modeling solutions Ability communicate clearly effectively cross functional partners varying technical levels Ability define relevant metrics guide influence stakeholders appropriate accurate insights Experience willingness learn tools create data pipelines using Airflow Ability build clear easy understand dashboards presentations years industry experience Experience Python R Experience Tableau Ability model run experiments Ability ramp data science manager role near future Stock yearly employee travel coupon Competitive salary Paid time Medical dental vision insurance Life disability coverage 401K Flexible Spending Accounts Apple equipment Daily breakfast lunch dinner", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "Undergraduate Graduate degree preferred major Computer Science Mathematics Statistics Physics Engineering related STEM major At least years relevant experience preferably digital domain Experience productionising machine learning models Programming experience either Python R plus one general purpose programming language Java C C SQL relational database experience must experience noSQL Big Data stack preferred Strong foundation inferential statistics machine learning algorithms Experience visualization tools Tableau PowerBI etc Strong capacity communicate complex concepts easy understand terminology Ability translate data insight value driving business plan Experience shelf models AWS GCP Natural Language Processing desired", "", "At least year experience working within Retail eCommerce company", "", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "Bachelor degree computer science computer engineering related field equivalent combination education related experience Fundamental knowledge one following high performance computing scientific data analysis statistical analysis knowledge discovery computer security systems programming large scale data management big data technologies Skilled aspects software project life cycle feasibility requirements design implementation integration test deployment Fundamental experience developing software C C Java Python R Matlab software applications Linux UNIX Windows environments data analysis algorithms data management approaches relational databases machine learning algorithms Ability effectively handle concurrent technical tasks conflicting priorities approach difficult problems enthusiasm creativity change focus necessary work independently implement research concepts multi disciplinary team environment commitments deadlines important project success Sufficient interpersonal skills necessary interact levels personnel Included Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules depending project needs", "years experience Data Scientist preferably Big Data Environment years programming experience Java Scala Python Hadoop stack HIVE Pig Hadoop streaming MapReduce HBase comparable NoSQL SQL database experience Experience Google products Google Cloud Storage Google Analytics Google Big Query plus Bachelor degree quantitative related field Design build predictive customer behavior models targeting personalization Implement Machine Learning statistics based algorithms prediction optimization deliver production Build maintain code populate HDFS Hadoop log Kafka data loaded SQL production systems Design build support algorithms data transformation conversion computation Hadoop Spark distributed Big Data Systems", "Parties All night LAN", "", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "University student final year STEM related field Ops Research Statistics Applied Math Engineering Business Analytics expected graduation date December May Or currently completing first year non business year masters program less years work experience Deep understanding statistical predictive modeling concepts machine learning approaches clustering classification techniques recommendation optimization algorithms Experience one programming languages R Python C etc Ability easily understand complex algorithm logic process data Experience working large volume data ability solve performance issues Practitioner statistical data quality procedures test driven approach quality assurance Basic business intuition clear expertise analyses ability describe analytic processes including specific approaches favored Excellent communication presentation skills ability visualize report insights creatively variety formats various stakeholders Ability deliver deadline driven environment Team player passion coaching colleagues clients", "years recent experience data science data analyst role Familiarity measuring UX customer engagement planning analyzing AB experiments Comfortable well versed working predictive causal problems A passion improving customer experience refining product Excellent presentation communication social skills strong attention detail Strong business mindset possessing ability condense complex analysis technical concepts clear concise takeaways business leaders Ability operate comfortably effectively dynamic highly cross functional fast paced environment Excellent time management skills ability manage work tight deadlines handle pressure product launches executive requests Well versed SQL languages experienced big data technologies Hadoop Spark Familiarity Python R data visualization tools Tableau full stack data analysis insight synthesis presentation Ability comprehensively understand data elements sources relationships business technical terms", "Designing data architecture table dashboard", "", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "", "years Data Science experience outside academia Title commensurate experience Advanced degree quantitative discipline applied mathematics statistics computer science physics related field leading academic institution Expert Python SQL Must experience writing production level code Proficiency working Spark process large data sets Excellent communication skills demonstrated success presenting complex data analysis qualitative quantitative clear compelling manner inspires action Strong understanding statistical analysis A strong passion empirical research answering hard questions data A passion problem solving comfort ambiguity creativity A flexible analytic approach allows results varying levels precision Quick learner ability initiate drive projects completion minimal guidance Ability thrive dynamic fast paced environment Drive change collaborate effectively variety individuals organizations", "", "", "Minimum years relevant data science experience Ph D Master Degree operations research applied statistics data mining machine learning physics related quantitative discipline preferred Experience Hive SQL Spark Python Scala Deep understanding statistical predictive modeling concepts machine learning approaches clustering classification techniques recommendation optimization algorithms Strong analytical problem solving skills", "Collaborative team player values contribution others", "Being passionate Data Science disciplined work confident humble", "", "Dog friendly office", "Currently pursuing degree graduated within last months degree following field Electrical Engineering Computer Science Data Science Statistics relevant fields PhD aforementioned fields MS BS years experience aforementioned fields Strong background machine learning statistics years experience probabilistic graphical models Bayesian networks deep learning modeling paradigms Experience Python R Scala similar Research publications plus BS MS aforementioned fields Experience developing C C Java C scripting language Experience database systems systems engineering Experience designing developing high scale distributed systems plus Knowledge lambda architectures plus Knowledge machine learning data visualization AI plus BS MS aforementioned fields business management marketing communication similar Experience project product program management customer design Excellent storytelling team work written oral communication skills", "Previous message Jobs Fwd inedinfo Fwd JOB Statistician fte Next message Jobs NPD Group", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "B S CS statistics applied math physics quantitative discipline years experience role developing predictive explanatory models experimentation processes Experience working data analytics Experience moderate large scale data sets 100GB preferred Core mathematical ability understand utilize innovate state art machine learning algorithms statistical modeling Expertise least one production quality programming languages e g java python scala C Exceptional communication skills Expertise Hadoop ecosystem especially spark plus", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "Bachelor Computer Science Statistics Quantitative social sciences related field Minimum years experience technical projects database components R Python programming proficiency Proficiency data integration data quality development Programming experience mySQL shell programming Django Some data visualization experience including R Shiny Python DASH Experience technologies like Github Amazon AWS Excellent problem solving skills proven track record Experience communicating technical topics non technical audience Interest educational applications", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "", "", "", "Masters PhD computer science analytics relevant line study required At least years experience performing advanced quantitative analyses Experience data visualization tools Excellent understanding machine learning techniques algorithms k NN Kmeans NLP Naive Bayes SVM etc Experience recommendation engines Applied statistics skills distributions statistical testing regression etc Experience common data science toolkits R Python Experience working AWS environments Experience relational databases proficiency query languages SQL", "Nordstrom Stock Purchase Plan", "", "BS MSc PhD machine learning data science math physics computer science equivalent degree plus two four year experience Game economy optimization knowledge IAP plus Experience reinforcement learning mobile video games Exceptional understanding machine learning concepts data science programming Excellent communication skills ability collaborate data scientists engineers product managers Open mind motivation learn spirit excel", "", "", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "Pursuing Ph D M S quantitative discipline graduating Passion machine learning Proficiency Python R SQL Authorization work United States", "Experience Spark distributed computing frameworks", "", "An open work environment everyone even new folks voice", "BS degree Computer Science related technical field equivalent practical experience years proven working experience software developer data engineer Strong track record delivery using graph databases Neo4j TitanDB OrientDB Fluency graph query languages Gremlin Cypher SPARQL Experience designing creating maintaining recommendation engines Experience Java Scala development Knowledge scripting language like Python Ruby Strong experience RESTful API interfaces microservice architectures Knowledge statistics experience using statistical packages analyzing large datasets R Excel SPSS SAS etc Experience Microsoft Azure Amazon Web Services AWS Experience Agile software development Experience developing knowledge based systems different contexts information retrieval intelligent agents dialog systems recommendation systems Experience scalability performance issues concerning large knowledge stores Experience information extraction creation application layer Experience developing REST JSON applications multi threaded applications Strong background computer science algorithms data structures concurrency distributed systems Strong OO Programming OO Design knowledge Knowledge professional software engineering practices best practices full software development life cycle including coding standards code reviews source control management build processes testing operations Technical expertise regarding data models database design development data mining segmentation techniques Technical capabilities Cloud Services Micro Services Patterns API Management Azure AWS Services Strong communication verbal written collaboration abilities addition technical depth Comfortable delivering within agile program", "", "Self starter results orientated able work minimal guidance", "", "", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Bachelor degree Data Science Analytics Engineering Mathematics Industrial Engineering Computer Science Information Technology Economics Finance At least years related experience Data Science Information Technology working combination big data advanced data analytics machine learning programming data bases With master degree least years relevant experience acceptable Experience complex business operations analysis including engineering design manufacturing logistics finance market forecasting Ability generate effectively communicate analytical insights visualization reporting tools SAS JMP MS PowerBI HANA Qlik R Markdown Proficiency data science object oriented programming languages python R ruby Proficiency database languages MSSQL Oracle PostgreSQL MySQL neo4j HANA Hadoop Familiarity operational business systems preferred SAP Salesforce Enovia Excellent communication customer interfacing skills verbal written Ability work independently multi tasking deadline driven environment Manages time prioritizes tasks effectively Master degree Data Science Analytics Engineering Mathematics Industrial Engineering Computer Science Information Technology Economics Finance equivalent professional experience Experience stochastic process modeling design experiments non linear regression simulation optimization methods Competency Natural Language algorithms processing generation NLP NLG Competency machine learning development Knowledge Aerospace industry Certification Data Science Analytics", "Bachelor degree Computer Science Mathematics Engineering Statistics related field At least year experience R Python US Citizenship Advanced degree computer science data science business analytics similar analytics concentration business oriented Experience working federal agencies clients Big data experience Hive Spark Pig MapReduce Knowledge industry leading analytics big data technologies approaches tools Experience working fast paced collaborative environments Strong written oral presentation skills", "", "Proven ability perform complex queries analyses using SAS SQL experience BigQuery Python R plus Statistical modeling experience years experience marketing role decision support role High degree problem solving reasoning abilities Exceptional organizational communication skills Understanding efficient database data design principles An excellent total compensation package Enhanced k retirement package Health care including domestic partner family coverage across medical dental vision Flexible spending accounts health dependent care Life insurance including domestic partner dependent coverage Outdoor experience days addition Paid Time Off vacation holiday personal time Discounts L L Bean merchandise Outdoor Discovery School adventures Employee Store Equipment loan program Employee Use Room Tuition reimbursement", "Bachelor degree Master degree years work experience completing undergraduate degree years advanced analytics experience Deep familiarity analytics actuarial market landscape corresponding information needs knowledge insurance industry plus Very strong problem solving skills quantitative analytical thinking capabilities including experience familiarity multivariate predictive modeling analytics software SAS SPSS R etc Proven record leadership ability work collaboratively team environment Ability work effectively people levels organization Willingness travel time", "years experience leveraging data business impact A deep understanding statistical analysis e g hypothesis testing experimentation regressions machine learning algorithms supervised unsupervised models Demonstrated programming experience least one analytic tool R Python Scala etc Ability write optimize complex SQL queries Experience building deploying cloud based data pipelines applications GCP AWS plus Ability communicate clearly effectively cross functional partners varying technical levels Ability work independently proactively well collaborating team A good sense humor always big plus", "Strong experience Microsoft Suite e g Excel Word PowerPoint Experience facilitating meetings workshops quickly understand business processes related client business questions years implementing BI solutions working BI Tool e OBIEE Cognos Business Objects SAP years relevant experience delivering Visualizations Analytic Insight client facing role Experience including one following use multi tier architectures session management web based web enabled applications Public Key Infrastructure technology preferred", "", "Bachelor degree computer science computer engineering related field equivalent combination education related experience Comprehensive knowledge one following high performance computing scientific data analysis statistical analysis knowledge discovery computer security systems programming large scale data management big data technologies Skilled aspects software project life cycle feasibility requirements design implementation integration test deployment Experience developing software C C Java Python R Matlab software applications Linux UNIX Windows environments data analysis algorithms data management approaches relational databases machine learning algorithms Ability effectively handle concurrent technical tasks conflicting priorities approach difficult problems enthusiasm creativity change focus necessary work independently implement research concepts multi disciplinary team environment commitments deadlines important project success Effective interpersonal skills necessary interact levels personnel Effective advanced analytical problem solving decision making skills develop creative solutions complex problems Significant experience demonstrated expertise following technical languages concepts constructs one following advanced areas high performance computing scientific data analysis statistical analysis knowledge discovery computer security systems programming large scale data management big data technologies Included Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules depending project needs", "", "PhD Statistics Machine Learning related quantitative discipline Strong research background Passion solving real world problems Significant experience R Matlab Hadoop Scripting knowledge plus Competitive salary bonus program entrepreneurial environment Top notch health dental vision insurance Stock options fast growing tech company 401k plan matching contribution Generous paid time plan plus paid holidays Frequent company sponsored lunches happy hours fun events plenty snacks drinks Supplyframe equal opportunity employer", "Data Science years Preferred Master Required United States Required", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "", "", "", "Bachelor degree years equivalent work related experience Strong working stakeholders gather requirements present results Strong data mining data visualization Ability handle multiple competing priorities fast paced environment Experience various math statistics methodologies algorithms Strong least code bases Python Healthcare Population Health knowledge preferred Experience deploying maintaining machine learning models production environment plus", "", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "", "Must basic knowledge statistical concepts regression time series mixed model Bayesian methods clustering etc analyze data provide insights", "", "Experience working structured unstructured clinical data Solid understanding machine learning algorithms use cases Experience building deploying supervised unsupervised learning models including clustering anomaly detection Experience bioinformatics NLP plus Experience working Amazon AWS Microsoft Azure services Proficient Jupyter Python Spark SQL Able explain technical concepts results non technical audience BSc BA Computer Science Engineering relevant field graduate degree Data Science quantitative field preferred Experience bio statistics research methodologies would additional asset", "Leveraging educational background Science Mathematics Statistics Computer Science Data Science related discipline along relevant professional work experience lead execute coordinate innovative data analytics initiatives establish sustainable solutions Your experience statistical toolkits programming languages e g R Python valued asset drive diffusion AI within BASF work creatively new applications AI Your familiarity different analytical areas expertise AI e g machine reinforcement learning statistics analytics enable explore technical possibilities create ideas together internal non AI expert business partners", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Programming languages Python R SAS Java JavaScript PHP D3 JS Relational databases SQL SQL databases Machine learning models including probability statistical models addition time series analysis Modern ML techniques support vector machines categorical regression trees neural networks recommendation systems Microsoft office suite tools Windows OS Linux OS command line tools grep regex Big data technologies including HDFS Hadoop Hive HBase Spark Modern versioning systems git subversion", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "years experience working Intelligence Community teams working fields related Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical Modeling Geo spatial analytics Data Munging Cleaning Bachelor Degree Ability work datasets different sizes formats across multiple databases Knowledge experience specific techniques neural networks cluster analysis feature engineering extraction reduction web scraping decision trees CART collaborative filtering geo spatial analysis Experience PCAP data Elastic Search Hadoop HDFS git Spark MLLib SQL OS Experience Windows Linux Windows Ability compile results deliver presentations senior level leadership Strong communication skills ability present material audiences differing technical aptitude R R shiny R studio Python Sci kit Tensorflow Intelligence Community Experience Machine Learning Statistical modeling Experience multi TB dataset manipulation cleaning querying modeling Experience scikit learn tensorflow R caret Experience curating datasets supervised unsupervised machine learning methods Experience C Java R Javascript PhP MatLab Pig Hive Impala PySpark Scala Ruby Pytorch", "Degree Statistics Information Systems Mathematics Finance preferred A minimum years experience applied data science Experience hands practical casework agency corporate side Strong knowledge experience wide variety tools including SQL SAS R Alteryx Tableau Proficient Excel PowerPoint presentation communication skills written oral Hands experience manipulating deriving insight large datasets using advanced analytic techniques including time series regression cluster analysis decision trees etc Comfort efficient data acquisition warehousing practices structured unstructured datasets", "", "Data Visualization skills plus", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "Fun puzzle loving office SF Financial District", "Experience processing performing multi faceted analysis customer consumer behavior data Experience developing enhancing models applying machine learning artificial intelligence algorithms statistical analysis natural language processing Strong coding skills SQL Python R Julia Scala Experience working distributed computing e Hive Apache Spark Experience working Unix Linux environment Knowledge descriptive analytics data visualization Exceptional standards quality strong attention detail Experience full lifecycle agile application development supporting analytic requirement Modern machine learning models expert level years Required Statistical Algorithms years Required expert usage R Python years Required Unix years Required Master Preferred Dallas TX Preferred Authorized work US w sponsorship future Required United States Required", "Has familiarity marketing data email engagement metrics Has experience developing testing implementing customer segments Is fluent least one statistical computer language Python R etc Has utilized statistical analysis machine learning gain insight large data sets Has experience querying databases SQL Has created used leveraged supervised unsupervised machine learning algorithms components regression simulation scenario analysis modeling clustering decision trees neural networks etc Has visualized presented data key stakeholders accessible format Values Aligned Simple Energy mission actively understands need supports diversity openness different points view self aware positive proactive attitude Outcome orientation Driven help deliver critical company outcomes quantitative means Thought Process An appetite problem solving curiosity knack structured thinking process creation ability spot unusual patterns emphasis product development Growth Mindset Comfortable learning growing mistakes Drive continuously learn master new technologies techniques Great communicator Communicates proactively across team external stakeholders Excellent written verbal communication skills ability communicate results explain solutions technical non technical stakeholders", "", "", "", "", "", "Experience working large data sets distributed computing tools Hive Redshift plus", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "SQL experience", "", "You years quantitative data analysis years SQL Hive experience years experience Python R scripting languages Experience designing analytic solutions open ended problems PREFERRED QUALIFICATIONS Experience designing data quality metrics implementing ETL validations Experience Druid columnar data stores Experience BI tools Tableau Looker", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "Master degree quantitative discipline e g Statistics Operations Research Economics Computer Science Mathematics Physics Electrical Engineering Industrial Engineering equivalent practical experience years experience working role focused statistical data analysis linear models multivariate analysis stochastic models sampling methods Machine Learning PhD Data Science Statistics similar technical quantitative field Ability initiate drive multiple successful improvement initiatives inside across organization Ability communicate clearly persuasively creating commitment drive success teams peers", "", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Master Computer Science Math related quantitative field BS BA Computer Science Math related quantitative field years data mining experience Work experience Hadoop SAS HBASE Cassandra similar development platforms years experience data mining statistical analysis Previous work experience ecommerce Experience large scale data analysis demonstrated ability identify key Strong communication data presentation skills Ability quickly adapt new technologies tools techniques Flexible responsive able perform fast paced dynamic work environment meet aggressive deadlines", "Passionate empirical research asking answering questions large datasets finding patterns insights within structured unstructured data Strong communication interpersonal skills ability work team environment Quick learner adapts well fast moving environment gets things done Combines creativity problem solving skills attitude overcome obstacle Understanding statistical predictive descriptive modeling concepts machine learning approaches clustering classification techniques recommendation optimization algorithms Familiar data visualization using tools like Python R Experience web based visualization tool Shiny D3 Plotly Knowledge machine learning algorithms using creating Knowledge geospatial Experience designing evaluating results complex controlled experiments Experience computer programming using technologies languages like C Java R Python Scala related Knowledge relational database multi dimensional concepts ability perform complex queries SQL Server environment", "Bachelor Science Arts degree higher Computer Science Masters Science PhD candidate discipline requiring strong mathematics statistical methods years developing software Java python C high level languages Relevant experience described solid background machine learning statistical analysis software development Solid background machine learning statistical analysis clustering algorithms Strong software development skills Knowledge experience predictive modeling including Multivariate Regression Logistic Regression Combinatorial Optimization Stochastic Processes Complex Analysis Principal Component Analysis Time Series Analysis Experience Matlab R Weka Experience using Agile software development methodology develop deliver software support continuous integration continuous deployment process Working knowledge Linux Strong communication presentation skills must able explain present hypotheses analysis results wide audience clear concise manner", "Data science dynamic evolving profession looking people love learn find unique solutions without micro managed freedom try new things test solutions technologies tell us better path You know way around cloud console handled pretty large volumes data time series plus You familiar machine learning frameworks like TensorFlow PyTorch You got experience deep learning Maybe used enterprise products past high throughput data ingestion analysis", "PhD computer science computer engineering MS years experience related field Demonstrated history driving delivering analytics models solutions Deep knowledge fundamentals machine learning data mining statistical predictive modeling extensive experience applying methods real world problems Strong skills software prototyping engineering expertise applicable programming analytics languages Python R C C various open source machine learning analytics packages generate deliverable modules prototype demonstrations work Desired interdisciplinary skills include big data technologies ETL statistics causal inference Deep Learning modeling simulation Breadth skills experience machine learning diverse types data diverse data sources different types learning models diverse learning settings Ability inclination work multi disciplinary environments desire see ideas realized practice Experience knowledge services domains business process outsourcing systems transportation systems healthcare systems financial services valued Demonstrated ability propose novel solutions problems performing experiments show feasibility solutions working refine solutions real world context Prior experience similar role required Please include requirements appropriate Must currently eligible work US employer without sponsorship", "", "", "", "Bachelor degree Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics GPA least scale Experience real world data thesis research internships work experience Creativity Initiative Integrity Leadership abilities Problem solving skills Advanced degree data science equivalent field sub field Experience working data rich problems research programs Experience computer programming user experience user interface Ability successfully complete projects large incomplete data provide solutions Bachelor degree Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics GPA least scale Resume Cover letter specify qualifications position Please address want work role differentiates applicants Unofficial transcripts degrees A writing sample five pages MAXIMUM single spaced technical analytic paper focuses current area expertise interest related interest positions CIA You excerpt longer papers", "Bachelor Science years data science experience OR Master Science years data science experience years experience SQL relational databases example DB2 Oracle SQL Server years experience statistical programming languages example SAS R Bachelor degree Statistics Economics Analytics Mathematics years experience analytics related field Certificate business analytics data mining statistical analysis Doctoral degree Statistics Economics Analytics Mathematics year experience analytics related field Demonstrates date expertise applies development execution improvement action plans Develops analytical models drive analytics insights Leads small participates large data analytics project teams Models compliance company policies procedures supports company mission values standards ethics integrity Participates continuous improvement data science analytics Presents data insights recommendations key stakeholders", "Commuter Benefits Flexible Spendi", "", "Bachelor Master degree math statistics economics related analytical field Solid SQL skills ability build manage databases data labs Knowledge least one scripting language R Python preferred ability interest learn Python Demonstrable knowledge hypothesis testing distributions Bayesian methods Demonstrable knowledge healthcare data e g claims electronic health records Experience relating data science approaches lay businesspeople Expert data visualization package e g matplotlib seaborn ggplot Tableau years experience working data science team focused healthcare problems Proficient using Microsoft Word Excel PowerPoint Strong interpersonal skills demonstrated ability influence motivate teams Highly detail oriented ability coordinate initiatives little supervision Strong oral written presentation skills levels organization Ability apply independent thought judgment organize work priorities meet specific objectives tight project deadlines Ability organize manage concurrent projects", "", "", "M S PhD Computer Science Statistics Applied Math quantitative field strong background machine learning data mining Strong knowledge experiences machine learning statistical modeling e g neural networks decision trees clustering regression analysis required Expertise data warehouse SQL programming required Expertise one statistical programing languages Python R SAS Base SAS Stats SAS Enterprise Miner required Experience payment fraud detection prevention plus Familiarity open source Python based ML libraries plus", "A graduate degree machine learning computer science artificial intelligence applied mathematics statistics physics related technical field Python numpy pandas sklearn xgboost TensorFlow etc Java", "Expert programming skills Java Python Scala years relevant work experience Experience building using large scale knowledge graphs including Linked Data ontologies RDF S OWL SPARQL Strong command linear algebra statistics ability quickly translate ideas efficient elegant code Development experience Python Java Scala good command respective data pipelining matrix algebra statistics libraries Experience NLP methods LSA LDA Semantic Hashing Word2Vec LSTM BiDAF etc Experience information retrieval tools Elastic Search Lucene Solr graph databases Neo4J OrientDB triple store Tuning optimization sequential deep learning models MS Computer Science emphasis Data Science Analytics Machine Learning PhD preferred", "", "", "", "years practical experience SAS ETL data processing database programming data analytics Experience predictive modeling Python SAS Alteryx Angos R Experience programming languages Java Python asset Extensive background data mining statistical analysis Experience analytics reporting tools Tableau MS Power BI Tibco Sisense Qlik SAP BO Experience mining Claims EMR data preferably Oncology related data Able understand various data structures common methods data transformation", "Education Bachelor degree Engineering Finance Mathematics Stats Econometrics quantitative field Intermediate Advanced English communications skills years experience data analytics Understanding applying structure schema source operational data PLAN TRACK VIEW SHARE databases PostgreSQL MySQL MUST Pentaho data integration experience MUST Create maintain ETL ELT processes Create maintain data warehouse data cubes Domo knowledge experience PLUS", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "Ph D MS degree Computer Science Applied Mathematics related field", "years experience Data Science analytics fields Experience programming languages R Python Scala Experience processing analyzing large scale data volumes semi structured unstructured data near real time throughput Experience applying right ML model solve business problems Ability passion learn new techniques stay cutting edge Experience working AWS Hadoop ecosystems Strong database knowledge expertise SQL Good storytelling presentation skills e able present business side story data presents c team business leaders Competitive health insurance benefits Competitive salary Annual target bonus commission Parental leave weeks dependent eligibility Paid vacation sick time Employee Stock Purchase Program Free snacks beverages Frequent company update talks leadership team Free listing HomeAway com Electronic adjustable stand desk Discounted Metro Rail pass", "Ability explain complex analytical concepts people fields", "PhD degree Statistics Biostatistics Mathematics Physics Operations Research Econometrics related field Exceptional interpersonal communication skills Ability work independently drive projects years relevant experience proven track record leveraging massive amounts data drive product innovation Strong statistical knowledge intuition ability tease incrementality vs correlations understanding predictive modeling time series probabilistic graphical models Strong skills SQL Python R Experience distributed analytic processing technologies Hive Pig Presto Spark Data visualization skills convey information results clearly Deep product sense", "PhD computer science computer engineering MS years experience related field Demonstrated history driving delivering analytics models solutions Deep knowledge fundamentals machine learning data mining statistical predictive modeling extensive experience applying methods real world problems Strong skills software prototyping engineering expertise applicable programming analytics languages Python R C C various open source machine learning analytics packages generate deliverable modules prototype demonstrations work Desired interdisciplinary skills include big data technologies ETL statistics causal inference Deep Learning modeling simulation Breadth skills experience machine learning diverse types data diverse data sources different types learning models diverse learning settings Ability inclination work multi disciplinary environments desire see ideas realized practice Experience knowledge services domains business process outsourcing systems transportation systems healthcare systems financial services valued Demonstrated ability propose novel solutions problems performing experiments show feasibility solutions working refine solutions real world context Prior experience similar role required Please include requirements appropriate Must currently eligible work US employer without sponsorship", "You bachelor degree computer science information systems mathematics statistics related quantitative discipline Applicants data related expertise professional background media also encouraged apply years professional experience media company preferred An enthusiasm The Wall Street Journal understanding product must You entrepreneurial attitude toward work sweat details well healthy skepticism status quo You experience using analytics tools SQL Tableau Excel interest advanced topics analytics artificial intelligence data engineering You worked visualization machine learning libraries either R Python Experience building web applications agile development plus", "PhD computer science computer engineering MS years experience related field Demonstrated history driving delivering analytics models solutions Deep knowledge fundamentals machine learning data mining statistical predictive modeling extensive experience applying methods real world problems Strong skills software prototyping engineering expertise applicable programming analytics languages Python R C C various open source machine learning analytics packages generate deliverable modules prototype demonstrations work Desired interdisciplinary skills include big data technologies ETL statistics causal inference Deep Learning modeling simulation Breadth skills experience machine learning diverse types data diverse data sources different types learning models diverse learning settings Ability inclination work multi disciplinary environments desire see ideas realized practice Experience knowledge services domains business process outsourcing systems transportation systems healthcare systems financial services valued Demonstrated ability propose novel solutions problems performing experiments show feasibility solutions working refine solutions real world context Prior experience similar role required Please include requirements appropriate Must currently eligible work US employer without sponsorship", "", "PhD computer science computer engineering MS years experience related field Demonstrated history driving delivering analytics models solutions Deep knowledge fundamentals machine learning data mining statistical predictive modeling extensive experience applying methods real world problems Strong skills software prototyping engineering expertise applicable programming analytics languages Python R C C various open source machine learning analytics packages generate deliverable modules prototype demonstrations work Desired interdisciplinary skills include big data technologies ETL statistics causal inference Deep Learning modeling simulation Breadth skills experience machine learning diverse types data diverse data sources different types learning models diverse learning settings Ability inclination work multi disciplinary environments desire see ideas realized practice Experience knowledge services domains business process outsourcing systems transportation systems healthcare systems financial services valued Demonstrated ability propose novel solutions problems performing experiments show feasibility solutions working refine solutions real world context Prior experience similar role required Please include requirements appropriate Must currently eligible work US employer without sponsorship", "", "Bring Years industry experience working Data Science team You hands experience NLP mining structured semi structured unstructured data You rich history crafting new solutions evolving problems You bring affinity Apple Media Products digital content general You enjoy paying attention details almost much big technical wins You passionate working large scale data sets You bring experience Solr Lucene Cassandra related technologies You experience machine learning tools libraries Spark You intuitive understanding machine learning algorithms supervised unsupervised modeling techniques You highly technical detail oriented creative motivated focused achieving results You excited reaching millions users across many platforms You share obsession quality We value strong interpersonal skills well experience driving decisions across diverse organizations You love collaborating tight deadlines tackles problems imaginative elegant solutions Your creative problem solving skills utilized daily", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "", "We expect would technical Masters PhD program", "Education Computer science Statistics Physics Mathematics Economics Specialization Certification", "", "Strong programming skills ability explore large data sets Excellent written verbal communication skills report research results methodologies Publications top tier journals focusing topics plus Preferred candidates pursuing masters Computer Science least years working experience within quantitative trading research role Experience top tier quantitative investment firms AQR Capital QMS Capital Two Sigma D E Shaw preferred Development experience Experience working startup Fast paced development environment Master", "", "Bachelor degree math statistics operations research computer science engineering econometrics quantitative social science quantitative field OR equivalent combination education work related experience years industry working experience performing advanced quantitative analyses Professional experience working Python R SQL Professional experience big data manipulation Proven ability apply advanced statistical methodologies multiple regression model mixed models time series models Bayesian preferred neural networks cluster analysis text mining prior experience optimization simulation marketing mix multivariate testing ensemble modeling graph algorithms Ability apply advanced optimization methodologies linear mixed integer optimization Ability apply advanced simulation modeling methodologies techniques Must relational database experience A strong passion empirical research answering hard questions data Curiosity humility empathy Masters degree Ph D Digital experience Professional experience software development practices", "Bachelor degree computer science computer engineering related field equivalent combination education related experience Comprehensive knowledge one following high performance computing scientific data analysis statistical analysis knowledge discovery computer security systems programming large scale data management big data technologies Skilled aspects software project life cycle feasibility requirements design implementation integration test deployment Experience developing software C C Java Python R Matlab software applications Linux UNIX Windows environments data analysis algorithms data management approaches relational databases machine learning algorithms Ability effectively handle concurrent technical tasks conflicting priorities approach difficult problems enthusiasm creativity change focus necessary work independently implement research concepts multi disciplinary team environment commitments deadlines important project success Effective interpersonal skills necessary interact levels personnel Effective advanced analytical problem solving decision making skills develop creative solutions complex problems Significant experience demonstrated expertise following technical languages concepts constructs one following advanced areas high performance computing scientific data analysis statistical analysis knowledge discovery computer security systems programming large scale data management big data technologies Included Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules depending project needs", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "Nice Experience working Database storage systems like Postgres Druid Aerospike Elasticsearch", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "PhD Masters Statistics Mathematics Computer Science Engineering related discipline Least one year research experience applying quantitative research e g artificial intelligence operations research solving real world problems At least one year experience Python Ability communicate complex ideas clear precise actionable manner Ability execute propose execute analytics plan collaborating colleagues well outside team Ability solve complicated problems decomposing problem gradually demonstrating progess Demonstrated industrial experience applying artificial intelligence optimization statistics drive key decisions Familiarity operations research CPLEX solving integer problems Experience basic machine learning techniques statistics mixed models well R programing languages", "", "years experience working SQL queries accessing data years consulting experience preferably Big similar firm Demonstrated expertise business analysis data analysis Experience writing requirements specifications IT systems", "Master degree computer science computer engineering related field equivalent combination education related experience Experience developing software Python C C Comprehensive experience implementing deep learning workflow using one following frameworks Theano Tensorflow Pytorch Keras Fundamental knowledge experience applying algorithms one following Machine Learning areas anomaly detection one shot learning deep learning unsupervised feature learning ensemble methods probabilistic graphical models reinforcement learning Broad knowledge network protocols DNS HTTPS Knowledge experience computer vulnerabilities buffer overflows code injection format string etc Ability effectively manage concurrent technical tasks contending priorities well approaching difficult problems enthusiasm creativity change focus necessary Lead multidisciplinary teams areas machine learning deep learning algorithms Pursue program development opportunities co authoring proposals proposing ideas address sponsor needs Identify program growth opportunities existing customers understanding customer space needs Ph D degree computer science computer engineering related field Experience high performance computing parallel programing cloud computing Experience Modbus DNP3 IEC IEC protocols Familiarity full stack software development Included Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules depending project needs", "", "", "Preferred Bachelors Science Computer Science Math Scientific Computing Data Analytics Machine Learning Business Analyst nanodegree equivalent experience Requires years experience PhD Masters approved field minimum years relevant experience", "", "Post Grad Degree equivalent Statistics Mathematics Data Science Analytics related area At least years solid experience marketing analytics arena Advanced knowledge R Experience SAS SPSS Experience writing SQL queries Exposure Big Data technologies Hadoop Hive Advanced knowledge Excel Experience handling integrating modelling digital behavioural data Including segmentation predictive analytics Retrieving information webpages product characteristics reviews etc Ability transform scraped data usable format Integrating scraped data data sources", "", "Multiple years proven track record application ML NLP As global business rely diversity culture thought deliver goals", "", "Bachelor Degree Economics Math Science Finance engineering similar discipline least year experience Comfortable developing statistical models using Python SAS R statistical packages Master Degree Economics Math Statistics Finance Engineering similar discipline year experience business application machine learning techniques statistical analysis Experience Python development highly desired Strong data analysis communication skills", "", "", "", "", "", "years experience multi faceted software engineer Strong back end orientation experience architecting schemas building databases Experience scripting languages building maintaining data pipelines Possess good organizational communication analytical technical writing skills Experience working scientists R D systems would beneficial Background machine learning data science statistics Exceptional multitasking skills attention detail ability work independently Excellent communication presentation skills Self motivated passionate comfortable working fast paced environment", "", "BS MS PhD healthcare related field Minimum years experience solving data science problems healthcare domain Masters PhD Application data science solutions industrial projects", "", "A love games", "A Bachelor degree business economics statistics related field minimum years general management experience business marketing analytics field equivalent combination experience training provides required knowledge skills abilities Master Degree Preferred Strong analytical skills Curiosity Attention detail data accuracy Proven experience working large datasets relational database analytical tools Alteryx Tableau SAS JMP similar Highly skilled Excel proficient PowerPoint Keynote Advanced statistical skills plus multi variate analysis cluster analysis etc CRM retail consumer loyalty analytics experience highly desired Excellent project coordination management skills Comfortable reaching business partners adept cross functional collaboration Must able develop analytic plans manage multiple projects simultaneously Adept translating data concise insightful business friendly executive summaries presentations Strong written verbal skills Travel air overnight required amount time Lifting bending pounds amount weight", "", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "", "", "", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "", "Master Degree Computer Science Engineering Statistics quantitative fields Theoretical knowledge Machine Learning Algorithms Statistics etc Basic coding ability Python R Programming skills Java Scala plus Full cycle machine learning engine implementation via internship school project", "Bachelor degree Minimum year experience predictive statistical modeling using SAS R Python Proficient MS Office applications Excel proficiency Pivots V Lookups Formulas Bilingual Spanish English Master Degree Experience performing data analysis Experience extracting data using SQL data exploration tools SAS R Experience data analytics design Experience working large databases Health care industry experience Demonstrated ability effectively gather requirements probe deeper understanding translate deep technical concepts non technical well technical senior stakeholders marketing customers data scientists Demonstrated ability manage people prioritize deliverables Proven organizational skills ability flexible work ambiguity", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "You find excited tell people building Fetch You wake truly excited know today directly impact young growing company", "", "", "External Technology Knowledge Keeps abreast latest technological developments areas push technology roadmaps realization Constantly looks opportunities incorporate new solution methods solve existing problems", "Bonus points Building analyzing web mobile applications business intelligence tools", "", "Bachelor degree higher studies Data Analytics Statistics Mathematics Computer Science related field Completion MHS Lean Six Sigma Green Belt curriculum required within years job placement years experience data analysis operations improvement work computer science business intelligence work related experience Must strong problem solving skills keen drive learn explore datasets Understanding application interpretation statistical tools Hypothesis Testing Non Parametric Tests Analysis Variation Various forms Regression factor analysis well various forecasting prediction techniques Basic understanding Structured Query Language SQL code process ETL techniques extracting data systems transforming data forms necessary analysis Experience statistical computer packages Minitab SPSS SAS manipulate data draw insights large data sets Basic understanding relational database RDB systems explore various data architectures using standard tools Ex Microsoft SQL Management Studio Oracle SQL Developer etc Basic understanding data mining concepts", "And More Like site cafeteria free parking access Crown Center fitness center", "Bachelor Master degree highly quantitative field CS machine learning mathematics statistics equivalent experience MS years BS years experience machine learning statistical modeling data mining analytics techniques Experience Python statistical machine learning software Experience applying various machine learning techniques understanding key parameters affect performance Experience developing experimental analytic plans data modeling processes use strong baselines ability accurately determine cause effect relationships Experience one natural language processing topics tagging syntactic parsing word sense disambiguation topic modeling contextual text mining application deep learning NLP Previous experience ML data scientist role large technology company Fluency language English", "Deep expertise search preferably e commerce Excellent knowledge improving search incrementally well making step changes applying NLP text mining etc Proven track record building robust search systems achieving strong results Expertise personalization recommender systems Able guide team engineers identify break necessary architecture services support search personalization services Able guide work well team engineers implement Machine Learning algorithms models well implementing necessary software Solid understanding search metrics implementing tracking measure performance Solid understanding search engines utilizing features effectively Familiarity ElasticSearch plus Hands experience developing implementing Machine Learning algorithms models Background Machine Learning Statistics Information Retrieval Design implement test robust technical solutions high traffic site apps rely Write clean code testable maintainable solves right problem well Code proud Phd Masters equivalent experience quantitative field computer science physics mathematics bioinformatics etc plus means must Experience programming functional languages Scala Golang Haskell Clojure etc plus must Knowledge scripting languages like Python R familiarity web frameworks plus Experience Java Scala microservices plus Understanding A B testing Able key influencer team strategy contribute significantly team planning showing good judgement making technical trade offs team short term long term business needs needs company whole Strong team player Superb communication skills thrives collaborative environment committed success team whole Critical thinking ability track complex data engineering issues evaluate different algorithmic approaches analyze data solve problems Creativity conceive new data driven products features technologies Results prioritize focusing ideas features significant measurable impact Planning estimation ability set meet project objectives milestones Communicate results progress internally externally meetings presentations tech talks Passion technology Our developers always evaluating new tools technologies make us better What attracted interest lately", "years experience data scientist Tools R Python Analytical Methods Regression modeling forecasting machine learning algorithms including ensemble models neural nets Bayesian models model selection validation The ability take digital marketing data translate valuable insights clients Education Master Degree Statistics Quantitative Analysis Business Analytics Biostatistics related discipline You love data You enjoy taking new challenges afraid chasing answer You lifelong learner You enjoy reading new trends data science learning new tool trending connecting data junkies You experience working clients enjoy helping business grow answering complicated business needs implementation data science project You impeccable attention detail", "New York NY", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "", "Master degree quantitative technical field Math Statistics Engineering Economics Physics Computer Science etc Experience data exploration machine learning tools found R Python Demonstrated ability applying advanced statistical modeling techniques solve problems Ability craft rigorous research evaluation design approaches based upon understanding clients research needs Advanced knowledge experience querying languages SQL etc Understanding modern software development engineering practices including scrum agile Git DevOps Competitive Compensation Full Health Benefits Medical Dental Vision 401k Paid Time Off Tuition Reimbursement Full Service Gym Game Lounge Area Basketball Court Free Healthy Snacks Refreshments Subsidized Public Transit", "BS Master degree Computer Science Electrical Engineering related degree equivalent experience years experience software engineering infrastructure design skills Write well structured maintainable idiomatic code good documentation Strong work ethic passion problem solving real world Experience Python We make generous use tools like Celery MongoDB Pandas Scikit Learn Django Experience data science fundamentals machine learning natural language processing Development deployment software within Linux environments", "years work experience years work experience applying scientific methods solve real world problems Degree computer science applied statistics economics etc Ability write structured efficient SQL queries large data sets A proven track record using analysis impact key business product decisions Familiar data pipelines knowledge transform raw production external data user friendly tables Fluent data science libraries Python R Comfortable Amazon Web Services Apache Spark Tensorflow etc Ability organize clearly communicate insights stakeholders", "Huge technical problems solve constantly learning pushing boundaries working smartest people around", "", "Masters degree Data Science Statistics Operations Research highly quantitative field e g Computer Science Operations Research Systems Engineering Physics equivalent experience years industry experience predictive modeling data science analysis Programming experience Python R equivalent Demonstrated experience data science data analysis Desire pursue challenging questions extensive operational data analysis experience data analysis regression analysis Demonstrated outstanding written verbal communication skills Comfortable Linux environment Experience Amazon Web Services AWS e g DynamoDB AuroraDB MySQL S3 SQS SNS EC2 Interest experience experimental design Background applied statistics machine learning", "", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "PhD computer science computer engineering MS years experience related field Demonstrated history driving delivering analytics models solutions Deep knowledge fundamentals machine learning data mining statistical predictive modeling extensive experience applying methods real world problems Strong skills software prototyping engineering expertise applicable programming analytics languages Python R C C various open source machine learning analytics packages generate deliverable modules prototype demonstrations work Desired interdisciplinary skills include big data technologies ETL statistics causal inference Deep Learning modeling simulation Breadth skills experience machine learning diverse types data diverse data sources different types learning models diverse learning settings Ability inclination work multi disciplinary environments desire see ideas realized practice Experience knowledge services domains business process outsourcing systems transportation systems healthcare systems financial services valued Demonstrated ability propose novel solutions problems performing experiments show feasibility solutions working refine solutions real world context Prior experience similar role required Please include requirements appropriate Must currently eligible work US employer without sponsorship", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "", "Three five years experience positions increasing responsibility working large datasets conducting statistical quantitative modeling melding analytics strong programming data mining clustering segmentation Bachelor degree combination years education work experience predictive modelling machine learning related quantitative field Computer Science Physics Mathematics Statistics Bioinformatics etc Strong data statistical programming skills e g SQL Python R Stata SAS SQL Hadoop Hive large data systems Data scientist depth knowledge experience machine learning predictive analytics proficiency R Python programming languages tools used data manipulation visualization experience working data warehouses In depth knowledge relevant clinical informatics software systems highly complex concepts principles policies methodologies techniques best practices regulations standards practices involved patient care electronic medical data management UC health care system Broadly encompassing highly depth knowledge machine learning deployment predictive analytics operational environments Knowledge controlled terminology clinical workflows user interface optimization clinical decision support rules development data integration mining clinical ontologies adoption technology clinical domain knowledge preferred required may developed expanded hiring Advanced organizational project management skills ability lead team prioritize tasks see projects inception completion schedule Advanced interpersonal communications skills convey highly technical information instructions levels clinical users clear concise manner provide technical support develop deliver training materials needed Ability apply advanced problem resolution skills highly complex issues quickly diagnose problems develop test implement appropriate effective solutions timely manner Advanced analytical skills expertise documentation reporting ability apply metrics design run queries collect analyze performance data produce sophisticated reports analyses management use Advanced ability serve technical leader information resource work collaboratively senior staff management across departments providing advice counsel analysis issues policy functionality system efficiency upgrades business analytics industry advances trends Strong interest working health care data understanding challenges face complex health care delivery systems The flexibility orient work UCSF Medical Center locations Completion one two years undergraduate graduate level coursework Statistics Master degree Doctorate computer science related area Background STATA SAS Prior experience healthcare data particular Epic derived healthcare data Demonstrates service excellence following Everyday PRIDE Guide UCSF Medical Center standards expectations communication behavior These standards expectations convey specific behavior associated Medical Center values Professionalism Respect Integrity Diversity Excellence provide guidance communicate patients visitors faculty staff students virtually everyone every day every encounter These standards include limited personal appearance acknowledging greeting patients families introductions using AIDET managing service recovery managing delays expectations phone standards electronic communication team work cultural sensitivity competency Uses effective communication skills patients staff demonstrates proper telephone techniques etiquette acts escort patient family member needing directions shows sensitivity differences culture demonstrates positive supportive manner patients families colleagues perceive interactions positive supportive Exhibits team work skills positively acknowledge recognize colleagues uses personal experiences model teach Living PRIDE standards Exhibits tact professionalism difficult situations according PRIDE Values Practices Demonstrates understanding adheres privacy confidentiality security policies procedures related Protected Health Information PHI sensitive personal information Demonstrates understanding adheres safety infection control policies procedures Assumes accountability improving quality metrics associated department unit meeting organizational departmental targets Keeps working areas neat orderly clutter free including hallways Adheres cleaning processes puts things back belong Removes reports broken equipment furniture Picks disposes litter found throughout entire facility Posts flyers posters designated areas post walls doors windows Knows Environment Care Manual kept department corrects reports unsafe conditions appropriate departments Protects physical environment equipment damage theft", "Previous message Jobs Fwd OMB seeking applications Chief Statistician Next message Jobs Tenure track position University Hawaii Messages sorted date thread subject author", "years experience applying machine learning techniques optimization statistics drive key decisions Extensive hands experience development predictive models machine learning AI based solutions Solid programming skills Python R similar data science language Advanced proficiency data visualization Prefer financial services industry experience Prefer experience CRM financial analysis financial advisory Bachelors Master degree Computer Science Math Data Science Statistics Be United States citizen", "FORTUNE World Most Admired Companies Corporate Responsibility Magazine Best Corporate Citizens InformationWeek Elite Women Business Enterprise National Council America Top Corporations Women Business Enterprises Reputation Institute World Most Reputable Companies", "", "", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Master degree Mathematics Physics Statistics Computer Science Engineering Economics Operations Research Bioinformatics Computational Biology similar quantitative field equivalent practical experience Experience statistical software database languages e g SQL R Python MATLAB Experience using applied statistics analyze data Experience training deploying Machine Learning models PhD degree scientific field leveraging statistics Experience Machine Learning libraries e g TensorFlow Scikit learn Keras Theano Torch Experience Google Cloud Platform Ability draw conclusions data recommend actions Ability break technical concepts simple terms present diverse technical non technical audiences Effective written verbal communication skills", "", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "", "Doctorate Preferred", "Master Degree Bachelor Degree years experience engineering computer science statistics bioinformatics related field Strong background statistical analysis machine learning data mining including regression analysis classification predictive modeling feature engineering hypothesis testing etc Solid understanding probability theory statistics Experience manipulating large data sets time series intermittent data Strong communication organization skills Proven ability contribute emerging cross disciplinary fields Experience performing independent research Experience working Python development language emphasis data science Experience Python data analysis packages Scikit Learn Pandas SciPy Comfortable working Linux based environment Experience working database types MongoDB MySQL Postgres Knowledge Bayesian data analysis methods model comparison Markov chain Monte Carlo sampling Hierarchical modeling Generalized linear models Bayesian Neural Networks Experience working clinical data", "MS PhD degree Computer Science Artificial Intelligence Machine Learning related technical field Prior experience Numerical topic modeling Technologies Linux Python", "years experience working Intelligence Community teams working fields related Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical Modeling Geo spatial analytics Data Munging Cleaning Bachelor Degree Ability work datasets different sizes formats across multiple databases Knowledge experience specific techniques neural networks cluster analysis feature engineering extraction reduction web scraping decision trees CART collaborative filtering geo spatial analysis Experience PCAP data Elastic Search Hadoop HDFS git Spark MLLib SQL OS Experience Windows Linux Windows Ability compile results deliver presentations senior level leadership Strong communication skills ability present material audiences differing technical aptitude R R shiny R studio Python Sci kit Tensorflow Intelligence Community Experience Machine Learning Statistical modeling Experience multi TB dataset manipulation cleaning querying modeling Experience scikit learn tensorflow R caret Experience curating datasets supervised unsupervised machine learning methods Experience C Java R Javascript PhP MatLab Pig Hive Impala PySpark Scala Ruby Pytorch", "Must Master degree foreign equivalent Statistical Science Mathematics related quantitative field plus three years experience position offered Vice President Data Scientist Senior Statistician related position Must three years experience within financial industry extracting useful insights large messy data sets developing applying statistical methods solving complex problems performing quantitative research programming multiple languages including Python Java C C SQL R writing well structured robust code research production utilizing large scale distributed computing technology including Spark Hadoop analyzing financial datasets utilizing natural language processing techniques", "You experience data mining machine learning statistical modeling underlying methods algorithms You extensive experience analyzing large data sets using software R Python Power BI You proficient working SQL databases Experience Microsoft Azure cloud computing platform plus You proven track record using data provide actionable impactful business results Prior experience within insurance financial services healthcare industry preferred Effective communications skills instill confidence internal external audiences translate complex concepts non technical stakeholders help enable understanding drive informed business decisions A low ego team oriented collaborative approach keeping corporate culture Solutions oriented mind set able work effectively complex problems Easily establish trusted partner ability build effective partnerships across areas organization colleagues levels The ability influence variety stakeholders drive cultural organizational change Intellectual curiosity passion data results orientation", "Messages sorted date thread subject author", "", "At least years progressive experience data science statistical analysis data modeling years experience statistical software Insurance industry experience preferred Professional experience building sophisticated models via regression segmentation decision tree time series design experiments multivariate analysis Experience machine learning techniques algorithms SVM Random Forests Neural etc Experience statistical packages one R SAS SPSS Statistica STATA Alteryx KNIME etc required Python scikit computer language experience plus Experience BI tools like Tableau MSBI etc plus", "Advanced Degree including MBA preferred", "Work engineers define manage data sources Design implement new distributed machine learning methods Implement data warehouses real time ETL batch processing data support modeling needs Build maintain internal data processing visualization tools years data science work academic experience Deep experience python Experience shipping products features early often Experience working large datasets especially using Dask Kinesis Background time series analysis hidden Markov models Gaussian processes variational inference Familiarity node js front end back end JavaScript", "", "Project portfolio GitHub personal website Model deployment experience data engineering web development business aspects Entrepreneurial mindset Translate business math tech Apply analytics make better faster consistent business decisions measurable ROI Prescriptive analytics experience active learning causal inference cost sensitive classification design experiments interactive machine learning reinforcement learning Hadoop experience Typically requires Bachelor degree least years experience quantitative discipline like Statistics Math Computer Science Engineering Operations Research OR Master Degree experience OR Normal office environment", "At least years experience Java Spring MySQL relational database Python At least years experience Data Scientist Experience databases including NoSQL Experience machine learning frameworks libraries Supervised Unsupervised learning Machine learning concepts techniques Regularization Boosting Random Forests Decision Trees Bayesian models Neural networks Support Vector Machines SVM Experience whole ETL data cycle extract validate transform clean aggregate audit archive Computer Science Mathematics Physics degree Excellent communication analytical skills Willingness work hard hrs per week Very good English Experience Apache Spark Natural Language Processing tokenization tagging sentiment analysis entity recognition summarization R programming language Modeling complex problems discovering insights identifying opportunities use statistical algorithmic mining visualization techniques Participating areas architecture design implementation testing Proposing innovative ways look problems using data mining approaches set information available Designing experiments testing hypotheses building models Conducting advanced data analysis designing highly complex algorithm Applying advanced statistical predictive modeling techniques build maintain improve multiple real time decision systems Very competitive salary based prior experience qualifications Potential stock options first year Raise advancement opportunities based periodic evaluations Visa sponsorship working outside US sponsorship granted months company based performance Health benefits case working office Washington DC This position location requirement performed either remotely including outside U S WalletHub offices downtown Washington DC If intending work outside US please aware position entails working least hour per week requires overlap EST business hours 8am 7pm ET including hour break", "", "Experience querying databases using statistical computer languages R Python SLQ etc Experience creating using advanced machine learning algorithms statistics regression simulation scenario analysis modeling clustering decision trees neural networks etc Experience analyzing data 3rd party providers Google Analytics Adobe Analytics Experience distributed data computing tools Map Reduce Hadoop Hive Spark Experience visualizing presenting data", "", "BS Computer Science Statistics Applied Mathematics Physics Engineering MS PhD preferred Excellent communication collaborative skills years professional experience applications machine learning data science analysis Deep expertise least one ML frameworks like Scikit Learn Keras TensorFlow etc Proficient least one programming language like Python R C Java", "", "United States Preferred", "", "years experience working Intelligence Community teams working fields related Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical Modeling Geo spatial analytics Data Munging Cleaning Bachelor Degree Ability work datasets different sizes formats across multiple databases Knowledge experience specific techniques neural networks cluster analysis feature engineering extraction reduction web scraping decision trees CART collaborative filtering geo spatial analysis Experience PCAP data Elastic Search Hadoop HDFS git Spark MLLib SQL OS Experience Windows Linux Windows Ability compile results deliver presentations senior level leadership Strong communication skills ability present material audiences differing technical aptitude R R shiny R studio Python Sci kit Tensorflow Intelligence Community Experience Machine Learning Statistical modeling Experience multi TB dataset manipulation cleaning querying modeling Experience scikit learn tensorflow R caret Experience curating datasets supervised unsupervised machine learning methods Experience C Java R Javascript PhP MatLab Pig Hive Impala PySpark Scala Ruby Pytorch", "Experience distributed software packages This full time year term appointment possibility extension conversion Career appointment based upon satisfactory job performance continuing availability funds ongoing operational needs", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "", "masters level degree statistics biostatistics related fields experience SAS SPSS years experience research setting using quantitative methods principles statistics", "At least MSc PhD preferred degree Math Applied Maths Electrical Engineering Computer Science related field Experience leveraging Software Development Machine Learning years Advanced Analytics AI Graph Theory Numerical Analysis etc Strong mathematical background Strong software skills Python numeric scientific computation libraries equivalent query languages like SQL derivatives used datastores e g HiveQL Bigquery etc Experience using complex data structures algorithms Experience implementation optimization strategies Experience applying machine learning computational math topics ecommerce sales marketing PhD degree Computer Science Computer Engineering Electrical Engineering related field Excellent communication management skill Can lead team towards execution product vision Experience evaluating making decisions around use new existing tools project Ready able coordinate cross disciplinary teams throughout phases development Ability make right trade offs schedule resources scope order deliver project Competitive Base Salary Equity Stake Competitive benefits", "PhD computer science computer engineering MS years experience related field Demonstrated history driving delivering analytics models solutions Deep knowledge fundamentals machine learning data mining statistical predictive modeling extensive experience applying methods real world problems Strong skills software prototyping engineering expertise applicable programming analytics languages Python R C C various open source machine learning analytics packages generate deliverable modules prototype demonstrations work Desired interdisciplinary skills include big data technologies ETL statistics causal inference Deep Learning modeling simulation Breadth skills experience machine learning diverse types data diverse data sources different types learning models diverse learning settings Ability inclination work multi disciplinary environments desire see ideas realized practice Experience knowledge services domains business process outsourcing systems transportation systems healthcare systems financial services valued Demonstrated ability propose novel solutions problems performing experiments show feasibility solutions working refine solutions real world context Prior experience similar role required Please include requirements appropriate Must currently eligible work US employer without sponsorship", "Apply data science techniques support early warning conflict instability diagnostics related fragility relationship international development challenges Assist USAID subject matter experts data science focused analytical thinking improved planning monitoring evaluation reporting programs conflict affected fragile environments Design develop deliver data analysis visualization products support DCHA CMM conflict fragility violence work emphasis early warning Acquire process manage analyze data range sources improved decision making areas conflict fragility violence Collaborate team interdisciplinary experts particularly USAID GeoCenter interagency partners regional bureaus Develop manage interim early warning tool coordination technical staff DCHA CMM Serve technical advisor team responsible adapting evolving early warning tools Provide consultation non technical audiences inside outside USAID develop implement guidance integrating data analysis work related conflict fragility violence Prepare concept papers background analyses briefings build support use data analytics data science techniques early warning conflict instability dynamics related fragility Participate discussions among key USAID stakeholders articulate vision plan integrating data science development work related conflict fragility violence Provide training capacity building services non technical audiences accessing analyzing visualizing data An advanced quantitative degree Statistics Physics Math Computer Science Economics Engineering related technical field Strong quantitative background experience data collection cleaning processing applied analysis visualization using statistical software programming languages Python Stata SAS R SPSS MATLAB Tableau PowerBI Ability produce compelling data visualization products using Adobe applications Illustrator Photoshop InDesign Ability create interactive web based products using HTML CSS JavaScript Curious self motivated individual excellent communications skills must able distill highly technical quantitative methods policy relevant snippets Experience translating statistical regression visualization results briefing documents presentations senior leadership Experience working data science pertains conflict fragility violence within foreign policy realm Experience applying data science analytical techniques foreign policy programming Ability apply data science analytical techniques problems data sets spanning diverse sectors agriculture democracy governance economic growth education environment health Strategic project leadership experience leading facilitating projects concept iterative design development delivery ongoing support Strong interpersonal skills experience working across different offices agencies", "Bachelor Master Degree Engineering Math Statistics Finance Computer Science Logistics Transportation related industry experience years hands experience statistical analysis applying various machine learning techniques predictive modeling data mining years experience data querying languages e g SQL scripting languages e g Python statistical mathematical software e g R SAS Matlab Experience articulating business questions using quantitative techniques arrive solution using available data Master degree higher Engineering Math Finance Statistics Computer Science technical field accredited university Ability develop experimental analytic plans data modeling processes use strong baselines ability accurately determine cause effect relations Demonstrable track record dealing well ambiguity prioritizing needs delivering results dynamic environment Excellent verbal written communication skills ability effectively advocate technical solutions research scientists engineering teams business audiences Experience processing filtering presenting large quantities Millions Billions rows data", "", "", "", "Interest causal inference", "PhD computer science computer engineering MS years experience related field Demonstrated history driving delivering analytics models solutions Deep knowledge fundamentals machine learning data mining statistical predictive modeling extensive experience applying methods real world problems Strong skills software prototyping engineering expertise applicable programming analytics languages Python R C C various open source machine learning analytics packages generate deliverable modules prototype demonstrations work Desired interdisciplinary skills include big data technologies ETL statistics causal inference Deep Learning modeling simulation Breadth skills experience machine learning diverse types data diverse data sources different types learning models diverse learning settings Ability inclination work multi disciplinary environments desire see ideas realized practice Experience knowledge services domains business process outsourcing systems transportation systems healthcare systems financial services valued Demonstrated ability propose novel solutions problems performing experiments show feasibility solutions working refine solutions real world context Prior experience similar role required Please include requirements appropriate Must currently eligible work US employer without sponsorship", "Bachelor graduate degree Computer Science Applied Statistics equivalent quantitative field Demonstrated knowledge multivariate statistical modelling techniques Strong background R Python SQL Experience using SAS including SAS Enterprise Guide manipulate data SMART Well rounded emotional intelligence clear SME areas ENGAGED Small business owner mentality CURIOUS Always learning questioning FUN Good attitude stress pressure pleasant work TEAM PLAYER Recognizes others helps possible looks contribute broader goal", "Data science dynamic evolving profession looking people love learn find unique solutions without micro managed freedom try new things test solutions technologies tell us better path You know way around cloud console handled pretty large volumes data You familiar machine learning frameworks like TensorFlow PyTorch Maybe used enterprise products past high throughput data ingestion analysis", "Master degree computer science mathematics years experiences software engineer data engineer data scientist Proficiency R Python Spark Proficiency SQL HiveQL Knowledge data visualization Experience advanced analytics Strong interest gaming industry", "", "", "", "", "", "The qualifications listed minimum acceptable considered position Salary offers based candidates education level years experience relevant position also take account information provided hiring manager organization regarding work level position The qualifications listed minimum acceptable considered position Salary offers based candidates education level years experience relevant position also take account information provided hiring manager organization regarding work level position The qualifications listed minimum acceptable considered position Salary offers based candidates education level years experience relevant position also take account information provided hiring manager organization regarding work level position The qualifications listed minimum acceptable considered position Salary offers based candidates education level years experience relevant position also take account information provided hiring manager organization regarding work level position", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "", "Bachelor degree Minimum year experience predictive statistical modeling using SAS R Python Proficient MS Office applications Excel proficiency Pivots V Lookups Formulas Bilingual Spanish English Master Degree Experience performing data analysis Experience extracting data using SQL data exploration tools SAS R Experience data analytics design Experience working large databases Health care industry experience Demonstrated ability effectively gather requirements probe deeper understanding translate deep technical concepts non technical well technical senior stakeholders marketing customers data scientists Demonstrated ability manage people prioritize deliverables Proven organizational skills ability flexible work ambiguity", "Advanced Degree Mathematics Statistics Economics Computer Science related fields", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "", "PhD computer science computer engineering MS years experience related field Demonstrated history driving delivering analytics models solutions Deep knowledge fundamentals machine learning data mining statistical predictive modeling extensive experience applying methods real world problems Strong skills software prototyping engineering expertise applicable programming analytics languages Python R C C various open source machine learning analytics packages generate deliverable modules prototype demonstrations work Desired interdisciplinary skills include big data technologies ETL statistics causal inference Deep Learning modeling simulation Breadth skills experience machine learning diverse types data diverse data sources different types learning models diverse learning settings Ability inclination work multi disciplinary environments desire see ideas realized practice Experience knowledge services domains business process outsourcing systems transportation systems healthcare systems financial services valued Demonstrated ability propose novel solutions problems performing experiments show feasibility solutions working refine solutions real world context Prior experience similar role required Please include requirements appropriate Must currently eligible work US employer without sponsorship", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "Experience working Amazon Web Services AWS", "M S quantitative field years professional experience Data Scientist NLP experience must Experience unstructured text data performing tasks text mining sentiment analysis language modeling classification information retrieval tasks Proficient R Python", "In process receiving graduate degree analytical area Machine learning Computer Science Physics Mathematics Statistics Engineering similar Experience Analytics quantitative disciplines Experience modeling analysis including machine learning statistical analysis operations research management science data mining Strong interpersonal communication skills Must able explain technical concepts analyses implications clearly wide audience able translate business objectives actionable analyses Experience SQL variations thereof Python PySpark Scala preferred though experience analytics software SAS STATA MATLAB Mathematica R SparklyR acceptable Familiarity AWS solutions Glue S3 Redshift Proven analytical quantitative skills use hard data metrics back assumptions develop business cases complete root cause analyses Capable taking responsibility initiative working minimal direction self starter even assignments vague undefined In process receiving PhD quantitative field Mathematics Statistics Analytics Economics Knowledge experience Agile development practices Experience Demand Planning Forecasting Supply Chain Inventory Management plus Demonstrated ability manage multiple competing priorities simultaneously drive projects completion", "Minimum years experience since obtaining bachelor degree Experience data science projects Experience signal processing digital communications Familiarity one following programming languages Python C C MATLAB within Unix Linux programming environments Working knowledge Machine Learning libraries language Strong written verbal communication skills This position requires ability obtain maintain security clearance issued U S government U S citizenship required obtain security clearance Advanced degree area digital communications computer science machine learning signal processing Experience working Linux development Linux platform Hands experience implementing data science solutions Python Familiarity TensorFlow Keras PyTorch scikit learn Familiarity GNU Radio Experience implementing data science algorithms GPUs Familiarity Agile methodology Current active secret special access clearances", "Academic background technical quantitative field graduate degree plus equivalent experience Working knowledge statistics pertains machine learning distributions statistical testing regression etc Proficiency using SQL several major DBMS DW engines Experience variety Big Data technologies distributed machine learning computing frameworks S3 Spark Hadoop Elasticsearch TensorFlow etc Good scripting programming skills Python UNIX shell Data manipulation skills extract data relational non relational databases files multiple formats clean join slice dice organize analyze explain Experience Python data science ecosystem Pandas NumPy SciPy scikit learn NLTK Gensim etc You able hit ground running tools fast Experience partitioning clustering techniques K Means DBSCAN etc Experience text mining parsing classification using state art techniques Experience information retrieval Natural Language Processing Natural Language Understanding Neural Language Modeling Chat Dialog Modeling technologies Strong background machine learning unsupervised supervised techniques In particular excellent understanding machine learning techniques algorithms k NN Naive Bayes SVM Decision Forests logistic regression MLPs RNNs etc Ability evaluate quality ML models define right performance metrics models accordance requirements business", "Bachelor higher degrees business mathematics computer science industrial engineering related fields least years experience performing advanced quantitative analyses Ability manipulate analyzes interprets terabytes data Ability organize findings translate actionable insights using original innovative techniques style Ability apply advanced statistical methodologies mathematical operations tasks cluster analytics sampling theory design experiments analysis variance correlation techniques factor analysis Intermediate advanced experience Statistical Software e g R SAS SPSS database applications Working knowledge SAS required Must relational database experience", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "Excellent understanding machine learning techniques algorithms k NN Naive Bayes SVM Decision Forests etc Great communication skills Experience data visualisation tools D3 js GGplot etc Proficiency using query languages SQL Experience NoSQL databases Good applied statistics skills distributions statistical testing regression etc Good scripting programming skills Python Java B S Computer Science Software Engineering Information Science Mathematics Statistics Electrical Engineering Physics related fields", "Excellent understanding machine learning techniques algorithms clustering decision trees neural networks etc Proficiency using Python numpy pandas scikit learn tensorflow keras etc R manipulate visualize data build machine learning pipelines Experience SQL noSQL databases ElasticSearch Excellent understanding math especially probability theory statistics Good understanding general computer science algorithms sorting hashing etc Good communication presentation skills ability explain technical concepts non technical audience Ability work minimum supervision Experience cloud technologies Hadoop Spark etc would plus Knowledge Java Scala would plus Minimum Bachelor degree Statistics Mathematics Computer Science MIS related degree seven years relevant experience combination education training experience Master degree Ph D Statistic Mathematics Computer Science ten years experience highly preferred An equivalent combination education experience training Analysis identify understand issues problems opportunities compare data different sources draw conclusions Communication clearly convey information ideas variety media individuals groups manner engages audience helps understand retain message Exercise judgment decision making use effective approaches choosing course action developing appropriate solutions recommend take action consistent available facts constraints probable consequences Technical professional knowledge demonstrate satisfactory level technical professional skill knowledge position related areas remains current developments trends areas expertise Building effective relationships develop use collaborative relationships facilitate accomplishment work goals Client Focus make internal external clients needs primary focus actions develop sustain productive client relationships Opportunity work bleeding edge projects Work highly motivated dedicated team Competitive salary Flexible schedule Medical insurance Benefits program Corporate social events Professional development opportunities", "Bachelor degree Computer Science Management Information Systems Statistics Healthcare Administration related field years hands experience machine learning Command principles machine learning statistical analysis data mining algorithms mathematical segmentation modeling Demonstrated ability use knowledge current techniques develop new methodologies years experience healthcare industry Proven ability experience design development solutions increasing yield Proven analytical skills experience handling large volume data Experience dealing imperfections data Experience implementing Data Visualization solutions Working knowledge statistical programming languages R Python", "", "You proud say work Stitch Fix know work brings joy clients every day", "You must deep hands experience You think strategically love getting hands dirty Bachelor degree mathematics statistics engineering computer science technical discipline Experience ETL development patterns tooling Experience real time incremental batch data ingestion Expertise schema design developing data models complex data sets Expert knowledge mathematical programming language R Python preferred Strong SQL experience ability develop tune debug complex SQL applications Experience PowerBI equivalent BI tool create impactful reports visualizations interactive dashboards Ability communicate complex findings clear precise actionable manner Able translate high level ideas well defined problems", "Bachelor degree statistics actuarial science related field study years PROFESSIONAL experience PYTHON R SAS including academic experience Internships Experience working large data sets Experience data wrangling cleansing statistical modeling programming Experience Tableau similar visualization tool Up Travel Master Degree statistics actuarial science related field study Experience data mining predictive modeling experience Extensive knowledge tools data mining statistics Experience HR Analytics Strong knowledge MS Office products Solid statistical understanding Good oral written communication skills Ability effectively work team environment individual Strong work ethic desire help clients improve businesses Strong desire success Business analytics experience one following industries Insurance Consumer Products Packaged Goods Human Resources", "Ability work cross functionally measurement teams product teams members wider analytical teams", "", "Extensive experience software development expertise architecting delivering new technologies product features scale highly reliable cloud services Experience developing scalable SaaS monitoring automation logging solutions highly reliable service offerings Prior technical paper publications public speaking engagements Extensive software development experience one following C JAVA C Python Experience across Windows Linux plus Strong algorithmic problem solving skills Distributed systems experience Ability see present big picture offer solutions make better An extraordinarily intelligent rigorous thinker operate successfully among bright charismatic people Strong customer facing relationship building skills You effective working independently team setting Ability uncover business challenges develop custom solutions solve challenges years work experience technology industry", "", "years revenue forecasting experience needed preferably within retailing domain Excellent statistical skills applied regression spatial time series modeling Deep understanding design experiments principles Proven working knowledge SQL Proven working knowledge SAS R Experience scripting automation data extraction transformation modeling outputs Experience Data Visualization Tableau Apple Equal Opportunity Employer committed inclusion diversity We also take affirmative action offer employment advancement opportunities applicants including minorities women protected veterans individuals disabilities Apple discriminate retaliate applicants inquire disclose discuss compensation applicants", "Prior experience finance", "", "A solid understanding ad networks media campaigns work", "", "You proud say work Stitch Fix know work brings joy clients every day", "Ph D degree Computer Science Engineering Applied Mathematics Expert knowledge scientific computing language R Python SQL Data Science prototyping experience physical systems Experience distributed storage compute tools e g Hive Spark Experience bringing prototypes production Hadoop Spark platforms containerized services Experience Natural Language Processing Deep Learning using Tensorflow CNN RNN LSTM GANs Streaming Analytics e Spark Streaming Experience Data Visualization Tools Tableau Plotly Bokeh etc Experience working remote global teams Results driven positive attitude", "", "", "", "", "BS Statistics Computer Science Engineering Operational Research Marketing Business Economics Applied Mathematics another quantitative field study Experience Google Analytics Google Tag Management Experience performing advanced data transformations SQL Excel excited learn Google BigQuery Advanced knowledge least one scripting language Experience A B testing collecting leveraging user event data analysis Experience analyzing visualizing presenting data Excellent oral written communication skills Must able interact cross functionally technical non technical people Ability handle large workload efficiently prioritize Forward thinking dynamic innovative years applicable experience Experience Digital Media Experience using BI visualization software Familiarity Unix Linux environment automating processes shell scripting Familiarity R SAS SPSS statistical modeling clustering classification machine learning data text mining", "M S Ph D math statistics operations research computer science econometrics quantitative field Must least years actual working experience performing advanced quantitative analyses Advanced hands working knowledge Python SQL required Ability apply advanced statistical methodologies mixed model random fixed effects simultaneous equations ARIMA neural networks multinomial discrete choice Ability apply mathematical operations tasks cluster analytics sampling theory design experiments analysis variance correlation techniques factor analysis Ability apply advanced optimization methodologies linear mixed integer optimization Ability apply advanced simulation modeling methodologies techniques Utilize complex computer operations intermediate programming 3rd 4th generation languages relational databases operating systems advanced features software packages word processing spreadsheet graphics etc Experience AWS Data Machine Learning services plus Must relational database experience A strong passion empirical research answering hard questions data Working knowledge SAS R preferred Working knowledge big data manipulation plus Experience deploying models highly scalable production environment preferred Experience AWS Data Machine Learning services plus", "Bachelors Degree quantitative discipline years analytics experience Masters Degree quantitative discipline years analytics experience Hands experience applied machine learning either Python R years using data mining methods clustering anomaly detection understand data patterns select appropriate predictive techniques Proficient understanding relational SQL e g Oracle SQL Server PostgreSQL NoSQL Mongo Neo4j databases data structures Excellent communication skills able interact directly non technical client stakeholders act business technical translation role Experience working onsite client technical consulting environment preferred Experience working within Agile Scrum Framework Self motivated self managing Proficient creating reasonable accurate time estimates assigned tasks Masters Degree PhD Experience modern natural language processing techniques embeddings deep learning NLP Experience advanced deep learning methods Experience deploying machine learning models AWS", "BA BS computer science statistics healthcare informatics similar degree years applicable analytics data science experience Deep knowledge machine learning techniques statistical modeling predictive modeling natural language processing Demonstrated ability apply machine learning solve complex business problems Proficiency Python R programming Extensive experience exploratory data analysis feature engineering data visualization Experience SQL relational databases Ability communicate collaborate effectively technical non technical audiences High degree personal initiative strong problem solving skills Masters degree computer science statistics healthcare informatics similar degree Familiarity industry experience working healthcare data especially oncology population health Experience model explanation interpretation methodologies LIME Shapley values Strong data visualization skills", "LI BSTEWARD", "Pursuant San Francisco Fair Chance Ordinance consider employment qualified applicants arrest conviction records We E Verify company", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "", "", "", "", "Fluent English", "", "Development languages including Python R Javascript Machine learning frameworks Tensorflow Keras Data Science algorithms decision trees linear regression clustering word embeddings Cloud ML resources like Google Cloud Platform NET Experience plus OCR Experience plus Experience implementing successful machine learning systems", "year experience developing machine learning models using deep learning methods classification regression Experience Python R Scala Java C C related languages Comfort SQL NoSQL DB MapReduce Apache Spark Kafka large scale data processing tools performing various tasks related machine learning data science activities including data cleanup data transformation data mashing algorithm parallelization Experience Caffe Torch TensorFlow Theano Matlab similar deep learning toolkit Machine Learning year Python years AWS year Linux Various flavors", "Bachelor Degree concentration Mathematics Statistics Computer Science equivalent work experience Master plus MUST HAVE minimum years experience Data Scientist A Data Geek looking people love data comfortable working numbers patterns If like solve puzzles free time right track Detail Oriented Process Driven looking folks see data patterns quickly help create new process efficiencies improved Knowledge variety machine learning statistical modeling techniques business setting Ability choose best technique given problem even solution involve ML Proficiency Python R scripting languages well toolkits like pandas NumPy etc Experience writing production ready code plus Experience GCP cloud platforms plus A mindset research lead actionable results Excited tell us want work kinds challenges looking Can talk intelligently passionately interesting challenges projects presented A sense humor perspective Preference given local candidates Mass relocation offered position", "Experience applying wide variety unsupervised semi supervised supervised machine learning techniques ability turn big data actionable intelligence Familiarity network endpoint security concepts technologies Ability analyze retrain improve machine learning models Ability work part remote team Ability provide receive scientific critiques work towards data driven solutions Significant development experience Python Matlab R Scala Ability document explain technical details clearly concisely peer reviewed publications preferred Minimum years experience data science data analytics required B S Computer Science equivalent experience M S Ph D preferred Strong written verbal communication skills Experience sklearn pandas numpy similar packages Familiarity malware host forensics network traffic analysis concepts Experience Linux command line bash scripting Experience reverse engineering malware Experience AWS infrastructure Experience deep learning frameworks TensorFlow Theano MXNet Experience GPU accelerated computing hardware e g NVIDIA DGX Experience using Hadoop Spark Experience using relational non relational databases Experience web frameworks visualize large datasets", "", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "Provide consultation data science machine learning Strong interests machine learning fast learner Bachelor degree necessary We using rich customer insights advanced technology data science build cloud native InsurTech solution This person work closely growing inter disciplinary team Physicians Research scientists Software developers challenge status quo Experience using statistics propensity model building algorithms manipulate data draw insights large data sets Exciting experience data science analytics hottest topics HP Analytics team covering wide range exciting fast growing business You report directly Triplebytes Head Machine Learning work alongside team machine learning engineers data scientists Use data understand business patterns trends You analyze data understand business market trends order increase company revenue Experience data mining advanced data manipulation machine learning statistical analysis Identifies meaningful insights large data metadata The Data Scientist Advanced Analytics responsible leveraging data analytics visualization advanced analytics data science help driving Possess end end data expertise including data sourcing consolidation integration manipulation visualization Fluent highly adept SQL Python R years industry experience proven ability apply scientific methods solve real world problems web scale data You prototype new ideas build existing systems collaborating data scientists product managers front end developers dedicated Past experience clinical science AI assisted diagnostics big plus years proven track record successfully applying ML predictive modeling Skilled data scientist machine learning image analysis statistical analysis experience Machine Learning years Required", "", "Work home Wednesdays", "BS BA quantitative field Math Statistics Computer Sciences related field years professional experience data science advanced analytics Experience business environment large scale complex datasets Proficient SQL experience efficient processing large data sets Ability write sophisticated optimized queries large databases Familiarity columnar databases like Redshift Understand database optimization Experience math stats software R SAS Python Tableau build clear actionable dashboards Experience conveying key insights complex analysis summarized business terms A Graduate degree MS MBA PhD etc quantitative field highly valued required Experience Big Data solutions well AWS solutions Business Acumen understand business drivers framework driven process analyzing business problems developing solutions Communication share insights way easy grasp actionable build relationships help drive adoption data insights driven decision making", "Minimum years experience solving data science problems Masters PhD Application data science solutions industrial projects Domain expertise energy healthcare finance logistics", "Masters PhD degree quantitative discipline Statistics Computer Science Engineering Math Economics evidence exceptional ability related fields year plus experience quantitative analysis Strong passion curiosity data data driven decision making solve complex business problems Solid communication skill acute attention detail Proficiency SQL R Python Experience Java Tableau Hive Spark MongoDB plus Deep knowledge applied statistics including predictive modeling Bayesian statistics Time Series analysis Machine Learning Experience interest data visualization techniques Ability convey complex analyses efficient intuitive visual methods", "Experience AWS cloud computing technologies e g EMR etc", "Proven ability solve business problems developing implementing machine learning algorithms statistical models Must previous predictive analytics segmentation experience Experience building web mobile interfaces displaying interactive visual insights Demonstrated ability listen quickly learn innovate drive insights disparate data sets fluid environment Must able work independently identify customer opportunities trends patterns Ability prototype transform ideas actionable insights quickly Curiosity ability work pressure creativity positive attitude must Proven ability manage multiple priorities keeping team first perspective Demonstrated ability assimilating real life experiences objective data accelerates learning behavio Responsible ensuring security availability confidentiality privacy policies andcontrols adhered Masters Degree equivalent experience Maths Statistics Computer Science years experience creating analyzing interpreting presenting complex data Extensive experience D3 another front end JS data visualization library Experience analyzing data using Python R another programming language Strong skillsin machine learning data text mining advanced statistical analysis model evolution validation testing Experience relational SQL NoSQL databases SalesForce Ticketing systems plus Experience working Agile environment", "PhD computational quantitative discipline e g statistics computer science biomedical informatics genetics physics epidemiology health economics Master Degree similar field study Deep understanding ML including strong knowledge mathematical underpinnings behind various methods e g regression techniques neural networks decision trees clustering pattern recognition dimensionality reduction Proven experience applied statistics ML business setting Deep understanding tools trade including variety modern programming languages R Python JavaScript open source technologies Linux TensorFlow Hadoop Spark Experience effective data visualization approaches keen eye detail visual communication findings Comfort working communicating non technical teams translate business questions analytically actionable questions A strong desire build meaningful solutions life sciences business Task oriented ability set goals complete deliverables Domain knowledge clinical data real world data life sciences related research data Expertise data science related tools e g SQL Tableau D3", "Bachelor degree quantitative field Statistics Computer Science Economics Mathematics equivalent work experience years experience business intelligence statistical modeling data collection aggregation analysis year experience machine learning Experience designing implementing machine learning solutions plus Demonstrated experience following technologies R Python programming SQL Server MySQL PostgreSQL Self driven passion finding collaboratively solving problems", "Bachelor degree year work experience advanced mathematical statistical engineering physics related quantitative field OR Actuarial credential Master degree advanced mathematical statistical engineering physics related quantitative field without experience OR years experience advanced mathematical statistical engineering physics related quantitative field Learning growth mindset Customer focused Interpersonal verbal written communication skills Experience least three following six areas data analysis relational style query languages machine learning statistical modeling data visualization high level programming language distributed computing understanding healthcare Masters Ph D quantitative field bachelors degree significant healthcare experience", "PhD computer science computer engineering MS years experience related field Demonstrated history driving delivering analytics models solutions Deep knowledge fundamentals machine learning data mining statistical predictive modeling extensive experience applying methods real world problems Strong skills software prototyping engineering expertise applicable programming analytics languages Python R C C various open source machine learning analytics packages generate deliverable modules prototype demonstrations work Desired interdisciplinary skills include big data technologies ETL statistics causal inference Deep Learning modeling simulation Breadth skills experience machine learning diverse types data diverse data sources different types learning models diverse learning settings Ability inclination work multi disciplinary environments desire see ideas realized practice Experience knowledge services domains business process outsourcing systems transportation systems healthcare systems financial services valued Demonstrated ability propose novel solutions problems performing experiments show feasibility solutions working refine solutions real world context Prior experience similar role required Please include requirements appropriate Must currently eligible work US employer without sponsorship", "Bachelor degree Enrolled graduate program study full time student GPA least point scale Expertise working data using combination mathematics computation visualization interaction Experience thesis research internships work experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Physics Quantitative finance Statistics Availability work least one day tour prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "The qualifications listed minimum acceptable considered position Salary offers based candidates education level years experience relevant position also take account information provided hiring manager organization regarding work level position The qualifications listed minimum acceptable considered position Salary offers based candidates education level years experience relevant position also take account information provided hiring manager organization regarding work level position The qualifications listed minimum acceptable considered position Salary offers based candidates education level years experience relevant position also take account information provided hiring manager organization regarding work level position The qualifications listed minimum acceptable considered position Salary offers based candidates education level years experience relevant position also take account information provided hiring manager organization regarding work level position", "Full time student pursuing Bachelor degree technical field GPA least point scale Availability work two day tours prior graduation Attending school full time basis following internship Creativity Initiative Integrity Leadership abilities Problem solving skills Ability work diverse team environment Interest experience science technology engineering mathematics STEM related field Computational social science Computer science Data analytics Economics Engineering Geospatial analysis Mathematics Operations research Quantitative finance Statistics A thorough medical psychological exam A polygraph interview A comprehensive background investigation", "", "Strong programming skills e g Python R JavaScript Proficiency writing SQL queries Ability desire present complex findings simple approachable way non technical audiences e g writing reporting tools person presentations Experience cleaning structuring transforming data via ETL processes Ability design deploy machine learning algorithms models", "US citizenship required We offer sponsorships years experience data scientist machine learning engineer similar role Understanding structure theory common machine learning models Familiarity common machine learning libraries implementation sklearn weka tensorflow torch Proficiency one Python Scala Java R Julia Matlab Expertise subfield machine learning computer vision natural language processing Ability understand implement new models literature Project team leadership Experience presenting team progress results Technical writing experience including reports proposals Experience distributed analytics processing Spark Hadoop Experience geospatial data analytics Active TS security clearance Familiarity Agile development", "", "Extensive experience solving analytical problems using quantitative approaches Comfort manipulating analyzing complex high volume high dimensionality data varying sources A strong passion empirical research answering hard questions data A flexible analytic approach allows results varying levels precision Ability communicate complex quantitative analysis clear precise actionable manner Familiarity relational databases SQL Expert knowledge analysis tool R Matlab SAS Strong working knowledge financials Acquired skills would include Data Warehousing ETL BI Data Mining Machine Learning Strong written verbal skills able explain work plain language", "PhD computer science computer engineering MS years experience related field Demonstrated history driving delivering analytics models solutions Deep knowledge fundamentals machine learning data mining statistical predictive modeling extensive experience applying methods real world problems Strong skills software prototyping engineering expertise applicable programming analytics languages Python R C C various open source machine learning analytics packages generate deliverable modules prototype demonstrations work Desired interdisciplinary skills include big data technologies ETL statistics causal inference Deep Learning modeling simulation Breadth skills experience machine learning diverse types data diverse data sources different types learning models diverse learning settings Ability inclination work multi disciplinary environments desire see ideas realized practice Experience knowledge services domains business process outsourcing systems transportation systems healthcare systems financial services valued Demonstrated ability propose novel solutions problems performing experiments show feasibility solutions working refine solutions real world context Prior experience similar role required Please include requirements appropriate Must currently eligible work US employer without sponsorship", "", "", "", "", "", "", "", "Ping pong scooters foosball beautiful trails nearby name", "", "Masters degree computer science related field Experience machine learning text analysis NLP Experience algorithm design modeling Experience designing working ontologies Programming skills Java Python similar language", "", "", "", "", "Experience end end ETL work using Python SQL Strong systems design knowledge know architect data pipelines storage compute fits together Prior experience making large datasets accessible familiarity Hive Presto parquet plus Experience compute frameworks job orchestration systems Experience Google Cloud Platform plus years industry experience Health insurance premium covered dependent children Flexible vacation paid time Up weeks paid family leave Equity plan employees Retirement benefits employer match Fertility adoption benefits Free lunch snacks offices Education reimbursement Dog friendly workplace New York office Commuter benefit form reduced tax Ireland pretax US", "", "", "Bachelor degree computer science software engineering related fields years experience data engineering years experience working Python NodeJS years experience working Kafka based pipeline development Strong knowledge SQL required year hands experience Apache Airflow Experience distributed computing using Hadoop ecosystem Spark Presto Knowledge Java Scala Knowledge Kafka connect ecosystem", "", "Must minimum years Cyber Security Engineering experience include application cyber security methodologies Enterprise environment Must experience following Security Frameworks NIST 171r2 Candidates must ability obtain maintain DOD Secret level security clearance condition continued employment Preferred Qualifications Certifications Degrees The ideal candidate Master degree STEM related discipline years experience Cyber Security Engineering Professional technical certifications CISSP CISM CCSP Security Plus AWS Certified Security Specialty AWS Certified Solutions Architect Azure Security Engineer Azure Solutions Architect DoD IAT IAM Level II III certificationSecurity Skills Senior level cyber security engineering architecture experience Experience interpreting implementing security compliance standards guidance including Governance Risk Compliance GRC policies procedures NIST security control framework Experience areas system security network application security Knowledge current emerging cyber security threats vulnerabilities controls Contributor architectural industry changes area cyber securityTechnical Skills Experience evaluating designing configuring implementing cloud services models SaaS PaaS IaaS Experience Linux Windows operating systems Experience operating Agile DevOps environment Experience Scripting Knowledge application program interface API ability manipulate API integrate different toolsets Advanced knowledge cybersecurity principles networking architecture servers systems design virtual hosts configuration management Identity Access Management encryption intrusion detection systems IDS intrusion prevention systems IPS Experience supporting deployment configuring managing maintaining technologies Directory Services Centralized Authentication Active Directory Red Hat Identity Manager Vulnerability scanning management databases operating systems web applications IDS IPS anti malware tools technologiesProcess Skills Experience Agile Scrum Application Lifecycle Management ALM Experience operating Agile DevOps environmentSoft skills Exceptional verbal written communications Quickly learn adapt new changing business technical concepts requirements skills tools Goal oriented team player committed quality detail Proven track record driving decisions collaboratively resolving conflicts ensuring follow Innovative strategic thinker positive proactive readily embraces change", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Experience Data Warehouses Lakes Big Query RedShift Snowflake NoSQL Cassandra Redis Stream Processing Engines Dataflow Flink Workflow Management Tools Airflow Pachyderm Big Data solutions highly appreciated", "", "Great perks vary location include employee discounts transportation reimbursements subsidized cafes fitness facilities conveniences dry cleaning car washes recycling programs", "knowledge relevant engineering best practices data management fundamentals data storage principles current recent advances distributed systems pertains data storage computing years experience designing building maintaining data architecture infrastructure relational non relational years maintaining data warehouse systems working large scale data transformation using SQL Hadoop Hive Big Data technologies experience ETL tools plus years data modeling experience able use data models improve performance software services experience Cloud Based Solution AWS Redshift GCP Big Query programming language Python Java plus experience communicating colleagues engineering analytics business backgrounds degree Engineering Math Statistics Computer Science related discipline equivalent experience plus able legally work Europe holder EU Passport holder EU residency permit holder Schengen Work Visa", "Education B Sc Computer Science related fields Knowledge Experience years deployment integration server management well experience writing scripts using Python Bash Advanced knowledge SQL non SQL databases Strong analytic skills related working unstructured datasets A strong knowledge manipulating processing extracting value large disconnected datasets Experience big data tools Hadoop Spark Kafka etc Experience data pipeline workflow management tools Azkaban Luigi Airflow etc Experience stream processing systems Storm Spark Streaming etc Experience object oriented object function scripting languages Python Java C Scala etc Experience AWS cloud services EC2 EMR RDS Redshift", "Lead implementation teams concept completion leveraging best practices Big Data Participate analysis architecture design data hub Builds robust Big Data solution systems eye long term maintenance support Application Work part team design develop code scripts data pipelines leverage structured unstructured data integrated multiple sources Looks leverage reusable code modules solve problems across team including Data Preparation Transformation Data export synchronization Design develop automated test cases verify solution feasibility interoperability include performance assessments Act Big Data delivery liaison Infrastructure security application development testing team Helps drive cross team design development via technical leadership mentoring Keep current latest Big Data technologies products including hands evaluations depth research Consult advise solution architects overall enterprise wide analytics solutions include Data Hub Component Works Project Manager perform detailed planning risks issues escalation Requirements Big Data Engineer Healthcare Analytics Senior years experience working batch processing tools Hadoop tech stack e g MapReduce Yarn Pig Hive HDFS Oozie years experience working tools stream processing tech stack e g Spark Storm Samza Kafka Avro Experience developing applications work NoSQL stores e g ElasticSearch Hbase Cassandra MongoDB CouchDB Experience developing TB level data stores 10Gbps ingest speeds High capacity data ingest Hadoop Spark highly desired Hands experience least one major Hadoop Distribution Cloudera Horton Works MapR IBM Big Insights System usage optimization tools Splunk plus At least years experience delivering enterprise IT solutions solutions architect years experience SQL least two major RDBMS years systems integrator Linux systems shell scripting years Data related benchmarking performance analysis tuning years Java experience Solid programming experience preference towards Java Python DBA Data Modeling experience Experience operational business level metadata management Bachelor degree Computer Science Information Systems Information Technology related field years software development DW BI experience Health care experience plus Excellent verbal written communication skills Hands experience Cloudera higher Horton Works higher MapR higher Experience Map Reduce solution design development ETL Solution experience preferable Hadoop Experience industry leading Business Intelligence Qualifications", "We offer ability work newest tech stack talented engineers IoT industry", "Fluency English written spoken", "Roughly years Industry experience data machine learning team Proficiency modern programming languages Go Python Java Scala etc SQL Some practical experience probability statistical modeling machine learning Backend developer experience optimizing data access layer mature web applications Experience building working real time compute streaming infrastructures Kafka Kinesis Flink Storm Beam etc Experience writing debugging ETL jobs using distributed data framework A deep abiding appreciation agile software processes data driven development reliability responsible experimentation A collaborative attitude helpful personality Health dental vision life insurance 401k matching program Commuter benefits Catered lunch unlimited snacks Unlimited reimbursement work related books", "", "You aware challenges associated building ML datasets computer vision models definition coverage target data distribution bias You creativity good sense product enable intuition model expected work eg face detector model could potentially fail eg low light pale dark skin etc data used test failure patterns You strong Python coding skills enable manipulate data scale run ML models You come data driven solutions facing situations trade offs decision uncertainty", "Experience search technologies Solr ElasticSearch Lucene", "", "BS computer science systems engineering similar technical field relevant work experience An understanding data model design database schemas optimizing database applications A breadth understanding database technologies including relational non relational solutions Experience manipulating large data sets time series intermittent data Experience using version control software Experience designing developing database access layers schemas contain multiple databases containing unique data types access requirements Experience working Python primary development language emphasis data management processing Experience MySQL MongoDB Experience producing software clinical setting utilizes clinical patient data e g labs physiologic signals administrative data An understanding clinical data driven research data aggregation methodologies standpoint study design subject protections statistical analysis Experience Agile software development methodologies continuous integration delivery", "Minimum four years experience planning design implementation security solutions including Minimum two years experience leading design implementation troubleshooting operation security technologies Minimum two years technical leadership role without direct reports Bachelor degree Computer Science CIS related field Minimum eight years experience IT operations environment technical experience distributed technologies systems development networking Additional equivalent work experience may substituted degree requirement Preferred Qualifications Three years experience building technology solutions meet corporate industry IT regulatory requirements Three years experience design implementation complex data infrastructure solutions Three years experience IT infrastructure consulting Primary Location California Pleasanton Pleasanton Tech Cntr Building F Owens Dr Scheduled Weekly Hours Shift Day Workdays Mon Tue Wed Thu Fri Working Hours Start AM Working Hours End PM Job Schedule Full time Job Type Standard Employee Status Regular Employee Group Union Affiliation Salaried Non Union Exempt Job Level Individual Contributor Job Category Information Technology Specialty IT ENG Infrastructure Department DCSS A2O Travel Yes Time", "", "Gym membership compensation", "BS MS degree Computer Science Math Statistics technical field years applied software engineering experience especially startups big data Python years team lead managerial role Python Expertise classes inheritance generators decorators docstrings pylint pytest etc Numpy pandas experience preferred SQL Hive Expertise clauses joins group bys windowing functions exploding Spark Expertise SparkSQL pyspark Caching Checkpointing Dataframes RDDs Expertise building monitoring maintaining reliable ETL pipelines Ability write well abstracted extensible object oriented code components Enjoy working fast paced highly collaborative ambitious startup work environment Basic understanding probability statistics experience evaluating data quality scale Experience Amazon Web Services RDS S3 EC2 EMR Data Pipeline PyCharm Github JIRA equivalents Experience open source search platforms Solr ElasticSearch like Experience Unix OSX CLI bash Background data wrangling various structured unstructured data sets consuming APIs e g rate limiting exponential back offs like Knowledge graph storage computation frameworks e g GraphX TitanDB Neo4J Familiarity Scala Java Apache Spark internals job optimization Significant interest background big data politics advertising finance technology Experience working directly data scientists basic knowledge common machine learning techniques Experience agile development similar methodologies continuous development product technology", "Developer tools Git SDLC OOP etc experience required", "Experience advanced courses data science machine learning", "Strong communication skills including ability identify communicate data driven insight", "Experience business intelligence analytics equivalent analyst position experience SQL additional object oriented programming language e g Python Java High level expertise data modeling Effective problem solving analytical skills Ability manage multiple projects report simultaneously across different stakeholders Structured thinking ability easily break ambiguous problems propose impactful data modeling designs Attention detail effective verbal written communication skills Bachelor degree Engineering Computer Science Statistics Economics Mathematics Finance related quantitative field equivalent practical experience years experience consulting business intelligence analytics equivalent analyst position experience SQL Python", "Gym membership compensation", "", "Knowledge digital AdTech landscape", "Creative analytic problem solver diligent attention detail", "Demonstrated fluency modern programming languages data science covering wide gamut data storage engineering frameworks machine learning libraries", "Experience Cloudera", "", "Experience one following languages functional programming general Scala Haskell Java JavaScript Experience one following technologies Distributed logging systems Kafka Pulsar Kinesis etc Stream processing Flink Spark Storm Beam etc Batch processing Spark Hadoop IDL Avro Protobuf Thrift MPP databases Redshift Vertica Query execution Columnar storage push downs Hive Presto Parquet Workflow management Airflow Oozie Azkaban Cloud storage S3 GCS Distributed logging systems Kafka Pulsar Kinesis etc Stream processing Flink Spark Storm Beam etc Batch processing Spark Hadoop IDL Avro Protobuf Thrift MPP databases Redshift Vertica Query execution Columnar storage push downs Hive Presto Parquet Workflow management Airflow Oozie Azkaban Cloud storage S3 GCS Understanding distributed systems concepts principles consistency availability liveness safety durability reliability fault tolerance consensus algorithms Eager learn new things passionate technology Experience contributing open source software Experience following Cassandra DynamoDB RocksDB LevelDB Graphite StatsD CollectD About WeWork WeWork Technology bridging gap physical digital platforms providing delightful flawless powerful experience members employees We build software hardware enables members connect space around like never We augment community culture teams tools build We believe macro shift toward new way workingone focused movement towards meaning purpose WeWork Technology proud shaping movement We team passionate fearless collaborative problem solvers distributed globally one goal mind humanize technology across world We equal opportunity employer value diversity company We discriminate basis race religion color national origin gender sexual orientation age marital status veteran status disability status", "Computer Science Engineering Bioinformatics Master level plus years relevant experience Excellent programming skills Python C R Experience designing implementing RESTful APIs webservices An ability interact various data sources structured unstructured e g HDFS SQL noSQL Experience working across multiple scientific compute environments create data workflows pipelines e g HPC cloud Unix Linux systems Expertise biological health data Experience modelling data information graph network representation Experience working metadata models controlled vocabularies ontologies Ability understand map integrate document complex data relationship business rules Familiarity data quality cleaning masking techniques Modern frameworks concepts scalable distributed computation containerization orchestration e g k8s specialized frameworks Spark Hadoop Experience image processing computer graphics Experience cloud computing", "", "Bachelor degree Experience designing developing medium large data environments associated services e g data pipelines data cataloging enterprise applications analytics projects Proven experience fusing mining preparing data sets using SQL Oracle Elastic technologies Experience performing machine learning ML functions data preparation automation data services e g data quality measures utilization mapping etc Familiarity hybrid cloud infrastructures Experience Python Java relevant scripting languages", "", "As always interviews screening call conducted via video call", "", "", "Bachelor degree math statistics computer science finance equivalent experience years experience Data Engineer BI Engineer Business Financial Analyst Systems Analyst SQL writing experience experience ETL Expert understanding best practices handle extremely large volume data Ability create extensible scalable data schema lay foundation downstream analysis A clear passion learning new BI skills techniques independently continuously Ability prioritize multiple concurrent projects still delivering timely accurate results Experience working lean successful start new product team continuous innovation desired ambiguity norm Experience mentoring others SQL modeling forecasting use large datasets Proficiency scripting languages Unix systems Python perl bash etc Experience following plus Looker Tableau Microstrategy", "", "Willingness travel", "Python Django Flask", "Gym membership compensation", "", "Gym membership compensation", "Responsible staying current enterprise standards industry standards technologies methodologies best practices", "", "", "", "You data engineer previous experience business intelligence data warehousing You know work high volume heterogeneous data preferably distributed systems Kafka Spark MPP databases Snowflake You comfortable building deploying applications public clouds particular AWS cloud You know write distributed high volume services Golang Scala Java You hands experience large number technologies programming languages It allows choose right tool job afraid contributing systems across whole FindHotel organisation You knowledgeable data modeling data access data storage techniques You appreciate agile software processes data driven development reliability responsible experimentation You strive excellence clarity transparency shipping business value early possible building incrementally afterwards For remote candidates Based time zone UTC UTC Experience e commerce clickstream data event tracking Experience interest data analysis We continue hire grow look survived Corona crisis also thrived This year helping 1M customers around world find better hotel deals using data transparency industry leading features We fast growth mode growing bookings Year Over Year past years plan continue coming years From beginnings organisation excelled User Acquisition grown Engineering Product driven organisation Our independence maturity achieved terms User Acquisition Engineering Product enables us disruptive build customer features nobody else industry Plenty chances learn grow surrounded brightest minds city part culture values sharing knowledge every day budget attend conferences develop A profitable company fast growth great scale opportunity A competitive compensation package perks benefits including Stock Appreciation Rights Flexible time take many holidays need chance work remotely measure results time spent office You part highly international team fun work environment We value good food offer catered lunches various cuisines great coffee ice cream fridge occasional bbq garden How survive refocus thrive travel startup corona times Our hiring process", "", "Final meeting engineering leadership via video person hour", "", "", "", "Gym membership compensation", "", "", "", "Competitive compensation visa relocation support needed", "We offer ability work newest tech stack talented engineers IoT industry", "", "Willingness travel", "Due business requirements successful candidate must based Ireland Candidates based EU willing relocate Ireland also considered Python experience years years software development experience Good command Linux Front end development experience required creating supporting internal tools Back end development experience required creating supporting internal tools Python web frameworks like twisted aiohttp django flask databases Understanding web technologies JavaScript HTML CSS HTTP Strong analytics skills related working unstructured datasets Excellent written English Strong web crawling web scraping skills Scrapy knowledge browser automation experience Splash experience plus Experience handling mid size large datasets organizing parallel processing Good spoken English Strong record open source activity", "pension plans employee benefits", "", "", "Weekly catered lunches stocked kitchen full fruit energy bars popcorn coconut water healthy snacks", "Gym membership compensation", "Significant competence SQL", "Understanding data visualization tools", "Minimum years experience data engineering Extensive knowledge different programming scripting languages Java C Python PHP Ruby Perl Scala Bash etc Proficient SQL Solid understanding relational NoSQL database technologies Experience designing building maintaining end end data pipelines ETL infrastructure using tools Hadoop Spark Kafka Samza Amazon Kinesis etc Experience AWS Strong familiarity working Linux environment Excellent critical thinking problem solving analytical skills Must authorized work United States Gaming industry experience Experience Redshift Machine learning experience", "", "Strong understanding security including threat propagation malware analysis", "Advanced working SQL knowledge experience working relational databases query authoring SQL well working familiarity variety databases Experience building optimizing big data data pipelines architectures data sets Experience performing root cause analysis internal external data processes answer specific business questions identify opportunities improvement Strong analytic skills related working unstructured datasets Build processes supporting data transformation data structures metadata dependency workload management A successful history manipulating processing extracting value large disconnected datasets Working knowledge message queuing stream processing highly scalable big data data stores Strong project management organizational skills Experience supporting working cross functional teams dynamic environment Experience big data tools Hadoop Spark Kafka etc Experience relational SQL NoSQL databases including Postgres Cassandra Experience data pipeline workflow management tools Azkaban Luigi Airflow etc Experience AWS cloud services EC2 EMR RDS Redshift Experience stream processing systems Storm Spark Streaming etc", "", "Knowledge commonly used third party analytics tools like Periscope Tableau Segment Heap", "You design develop applications data processing one languages Python Java Scala Create chains data ingestion relational DBs noSQL storage Utilize Unix Linux OS write data preprocessing scripts Develop data processing systems Hadoop Spark Storm Impala etc", "Bachelor degree Computer Science Engineering Technical Science years experience programming building large scale data analytics solutions operating production environments Minimum years expertise designing implementing large scale data pipelines data curation feature engineering machine learning using Spark combination pySpark Java Scala Python either premise Cloud AWS Google Azure Minimum year designing building performant data tiers refactoring existing ones supports scaled AI Analytics using different Cloud native data stores AWS Azure Google Redshift S3 Big Query SQLDW etc well using NoSQL Graph Stores Minimum year designing building streaming data ingestion analysis processing pipelines using Kafka Kafka Streams Spark Streaming similar cloud native technologies Minimum year designing building secured governed Big Data ETL pipelines using Talend Informatica technologies data curation analysis large production deployed solutions Experience implementing smart data preparation tools Palate Trifacta Tamr enhancing analytics solutions Minimum year building Business Data Catalogs Data Marketplaces powering business analytics using technologies Alation Collibra Informatica custom solutions", "Sense humor must ash Mustache Get Mustache", "", "The curiosity determination understand improve data flows", "Python SQL Relational databases e g Postgres MySQL Distributed computation e g Spark Hive Athena Cloud infrastructure use AWS General application e g web API development Git collaboration", "", "", "", "Pet friendly office environment", "", "Fixed term contract option perm", "Components Frameworks including Hadoop HDFS Spark Storm HBase Pig Hive Scala Kafka PyScripts Unix Shell scripts", "", "Experience Agile Methodologies Scrum Kanban", "", "We strong preference someone experienced Python rather Java", "", "", "Gym membership compensation", "A Bachelor degree computer science information technology quantitative field years relevant experience ideally scientific computing environment Ability design informative accessible technical training materials Proven deep technical background including Linux administration Ability work demanding environment minimal supervision Strong track record implementing cloud based processing techniques Administration experience Azure AWS Google Cloud one major IaaS providers Google Cloud Platform preferred A passion data science including knowledge least one high level programming language Python R preferred Familiarity database usage basic administration tasks PostgreSQL preferred Experience leveraging established distributed computing frameworks Apache Spark Hadoop Experience handling large volumes spatiotemporal data", "", "", "Master degree areas like Mathematics Physics Computer Science Engineering Econometrics Business Analytics Information Management Minimum years hands relevant Big Data technologies implementations Experienced distributed computing distributed storage containerisation Spark PySpark Kafka SQL NoSQL e g Elastic Hive BigQuery Kafka KTables AWS S3 Docker Kubernetes Experienced programming Python Scala familiar micro services development REST API IoT Fluent English Fluent Dutch strong preference mandatory Good business communication skills able transform business requirements use cases A flexible transport arrangement suits personal situation electric car bicycle flexible budget including NS business card", "", "", "Minimum years experience programming language Scala R Python Java experience writing reusable efficient code automate analyses data processes Minimum years experience processing large amounts structured unstructured data cluster computing environment similar experience academia Interested candidates must submit resume CV www nbcunicareers com considered Must willing work New York NY Experience formulating opinions constructing data processing systems good knowledge principles systems scale using big data technologies like Spark Hive Impala Hadoop Databricks Good understanding AWS Azure cloud technologies including AWS services Athena Glue S3 Lambda Experience open source Enterprise software Experience building maintaining production data pipelines Familiarity relational databases SQL Team oriented collaborative approach demonstrated aptitude willingness learn new methods tools Ability communicate insights findings data visualization tools Tableau DOMO Shiny Ability work effectively across functions disciplines levels Experience media entertainment industry plus Experience television ratings digital measurement tools Nielsen Rentrak comScore Omniture etc Familiarity NoSQL Graph databases Experience large scale video assets Experience computer vision metadata generation video Master Degree specialization Computer Science Engineering Physics quantitative field equivalent", "Extensive experience software development expertise architecting delivering new technologies product features scale highly reliable cloud services Experience developing scalable SaaS monitoring automation logging solutions highly reliable service offerings Prior technical paper publications public speaking engagements Extensive software development experience one following C JAVA C Python Experience across Windows Linux plus Strong algorithmic problem solving skills Distributed systems experience Ability see present big picture offer solutions make better An extraordinarily intelligent rigorous thinker operate successfully among bright charismatic people Strong customer facing relationship building skills You effective working independently team setting Ability uncover business challenges develop custom solutions solve challenges years work experience technology industry", "Experience large scale data query optimization techniques Experience ETL data warehouse systems Experience AWS cloud services EC2 RDS Redshift AuroraExpert SQL NoSQL RDBMS Knowledge multiple scripting languages e g Python Knowledge cloud distributed systems stream processing systems Passionate learning new technologies solving hard problems fast paced environment Has Computer Science degree Has years experience enterprise SaaS environments Is student game thrives new challenges Enjoys learning teammates afraid teach others time Sees glass half full This new industry space vision could make difference Wants make lasting impact lifelong connections another paycheck", "CI CD Drone Gitlab CI", "", "Tuition reimbursement learning development programs", "Professional Development Program", "", "Knowledge Tableau QlikSense similar technologies", "Do strong communication skills ability present deep technical findings business audience", "Bachelor degree equivalent experience", "Roughly years Industry experience data machine learning team Proficiency modern programming languages Go Python Java Scala etc SQL Some practical experience probability statistical modeling machine learning Backend developer experience optimizing data access layer mature web applications Experience building working real time compute streaming infrastructures Kafka Kinesis Flink Storm Beam etc Experience writing debugging ETL jobs using distributed data framework A deep abiding appreciation agile software processes data driven development reliability responsible experimentation A collaborative attitude helpful personality Health dental vision life insurance 401k matching program Commuter benefits Catered lunch unlimited snacks Unlimited reimbursement work related books", "AWS Docker Kubernetes Terraform Vault", "High quality swag", "", "Gleaming new square foot headquarters complete foot climbing wall showers lockers bike parking", "Proficient English You read write proficiently speak conversational level English", "", "", "Gym membership compensation", "Relocation simplified paid accommodation well experienced relocation buddies guide visa application", "Always improve value personal progress want look back proudly done", "Transparency regular All Team meetings stay know going areas business", "Bachelor degree Computer Science related field Experience relational databases SQL map reduce languages Pig Hive Understanding different data storage engines work limitations SQL NoSQL key value stores Knowledge Java C C GO Node js Experience Druid time series based data storage solution Deep knowledge building high performance high availability distributed systems Experience Kafka Spark Cassandra Extensive experience working big data designing ETL pipelines end end Expert one RDMS familiarity PostgreSQL Redshift Knowledge ad serving platforms online advertising systems Experience game development", "Excellent medical dental vision benefits", "Total years IT preferably DW ETL BI projects Experience gathering end user requirements writing technical documentation Time management multitasking skills effectively meet deadlines Basic understanding data management concepts 3NF Dimensional specific applications SQL PL SQL experience analyzing transforming integrating data preferably one database technologies Oracle MSSQL DB2 Teradata Basic understanding DWH related terms example procedures functions triggers views indexes etc Ability analyze data various sources find meaningful insights well identify gaps inconsistencies Client facing team player skills Good command written spoken English Willingness develop competences area data analytics Availability mobility work projects Poland across Europe Previous experience ETL tools example ODI SAS DI IBM DataStage Informatica MS SSIS Experience Agile development methodologies Access leading edge Cloud technologies Career competence support including ongoing mentoring financing certificates different technologies tools Full work comfort private healthcare additionally life insurance sport packages Opportunity work global top clients innovative large international projects European level", "", "", "Knowledge experience financial markets banking exchanges", "", "http www showtimeanytime com", "", "http www showtimeanytime com", "", "Exceptionally detail oriented", "", "A deep understanding distributed computing frameworks Spark particularly SparkML SparkSQL tune optimize debug Spark jobs Hadoop Flink Experience big data AWS particular using EMR S3 Experience Docker container orchestration like Kubernetes Swarm similar Experience pipeline management tools like Airflow Luigi NiFi Experience programming languages Python Go Scala Good knowledge SQL RDBMS Experience command line shell scripting version control Git Excellent communication skills English oral written German nice Preferably experience automatic configuration management like Terraform Puppet Preferably experience modern agile software development practices like microservices test driven development pair programming CI CD etc Training opportunities individual management specialist career The provision necessary equipment need deliver top performances Employees self reliant free schedule work day Onboarding program including Welcome Day Trainings individual incorporation The chance work together goals also working create something new motivated colleagues cool office loft trendy district Kreuzberg", "", "", "", "", "Strong programming skills C Java Scala Python Deep understanding basic data structures algorithms Experience scaling data platforms hundreds terabytes petabytes using Spark Hadoop Familiarity modern machine learning techniques Creative collaborative product focused", "", "", "", "", "Minimum years development experience Experience data analytics business intelligence data science Proficient SQL Strong programming skills Experience designing building RESTful API services Strong experience ETL must able interact various data sources connecting data warehouse Must technically proficient able problem solve data extracted transformed loaded warehouse This role work collaboratively business departments supports must able understand requirements data analytics group requirements technologically executed Bachelor degree related field study Experience Amazon AWS Azure PowerBI preferred required Big Data Tools MapReduce Hadoop Spark Communication protocols JSON XML Amazon Redshift SnowflakeBottom Form", "Little travel", "We offering annual salary range USD", "Roughly years Industry experience data machine learning team Proficiency modern programming languages Go Python Java Scala etc SQL Some practical experience probability statistical modeling machine learning Backend developer experience optimizing data access layer mature web applications Experience building working real time compute streaming infrastructures Kafka Kinesis Flink Storm Beam etc Experience writing debugging ETL jobs using distributed data framework A deep abiding appreciation agile software processes data driven development reliability responsible experimentation A collaborative attitude helpful personality Health dental vision life insurance 401k matching program Commuter benefits Catered lunch unlimited snacks Unlimited reimbursement work related books", "Experience micro services kubernetes", "Strong Clevertech Community", "", "Experience streaming data", "Provide report predicting future data based existing information U SQL new big data query language Azure Data Lake Analytics service Experience providing technical leadership mentor engineers best practices data engineering space Able use data frame solve problems Be comfortable algorithms data structures dynamic array linked list stack queue binary Experience ingesting external data sources existing platform Create error reporting install metrics add data quality measures Follow best practices security standards data including personally identifiable data The Data Engineer I builds robust fault tolerant data Advanced knowledge application data infrastructure architecture disciplines BS BA degree equivalent experience The data engineer designs builds platforms tools solutions help bank manage secure generate value data Designs data solutions data distributions Verification data modeling data mining Automation data data platforms tools Improve data usability data quality data warehouse Experience dimensional data modeling schema design database data warehouse Around years experience working data engineer data warhousing projects managing petabytes data Data engineering years Preferred Data Vault data architecture Identify anomalies inconsistencies data Large scale data flows Kafka Strong written verbal communication skills Location DE position would remote start sit onsite Delaware post pandemic Experience building optimizing big data data pipelines architectures data sets Optimize maintain data pipelines architecture data Work data engineers data scientists drive efficient solutions platform Help define data story enable data driven solutions", "Gym membership compensation", "", "Company events happy hours bowling bocce league etc", "", "BS MS degree Computer Science Engineering related field Experience building processes extract process add value data sets multiple source systems Experiencing data modeling tuning relational well NoSQL datastores Oracle Red shift Impala HDFS Hive Athena etc Experience working distributed computing tools Spark Hive etc Experience AWS cloud services EC2 EMR RDS Redshift S3 Lambda Experience data pipeline workflow management tools Airflow etc Experience one general purpose programming languages including limited Java Scala C C C Swift Objective C Python JavaScript Experience working agile development methodologies Sprint Scrum", "", "Expert level SQL skills years experience database technologies e Postgres MySQL SQL Server Oracle RedShift etc Minimum years experience Data Warehousing Working knowledge dimensional modeling techniques Working knowledge data quality approaches techniques Experience Redshift highly desired Experience AWS tools S3 Redshift DynamoDB IAM highly desired Experience working standard ETL tool e Informatica SSIS Talend Pentaho etc Architectural insight store data modeling experience recommend structured make accessible performant resilient change An entrepreneurial spirit drive ship quickly familiarity agile software development practices The ability deal ambiguity communicate well partner teams technical non technical strong empathy customer experience Experience working Linux plus Programming language experience Python Java etc plus API development experience plus Working Agile Scrum development process plus", "Masters Degree years experience AWS", "Work awesome companies around world We partner great software companies world constantly get interact people great companies", "", "", "Working knowledge data integration data movement global database administration traffic shadowing test driven development software development life cycle Big data dimensional design leveraging star snowflake schema SQL Server Integration Services SSIS SQL Server Reporting Services SSRS SQL Server Analysis Services SSAS reporting services Python R Tableau programming languages analysis tools preferred required Knowledge Agile methodology frameworks like Scrum Kanban XP Build execute Big Data strategies systems platforms addressing capture data data storage data analysis search sharing transfer visualization querying updating information privacy data source Cluster enterprise relational document oriented databases RESTful services traffic mirroring Integrate database strategies data larger 1TB using relational databases especially MS SQL Server Database Administrator Database Administrator", "", "years field experience implementing ETL data integration enterprise IT environment Bachelor Degree computer science data sciences information sciences software engineering similar field required Commitment Full time hours week Travel basic expectation travel within North America approx Candidates required pass background screen including criminal history reference check bankruptcy drug screen", "Independent worker able manage project timelines priorities Advanced analytical thinking problem solving skills Strong communication skills ability compile present information Good interpersonal skills demonstrated ability work within team environment Experience working international organisation multicultural environment added advantage Understanding WFP Core mission values Language skills Fluent English spoken written", "Bachelor degree Computer Science Software Engineering MIS equivalent combination education experience Development experience building ETL graphs using Ab Initio GDE EME Co Operating system Strong SQL development skills Development experience least two different programming languages Python Java Scala etc Development experience Unix tools shell scripts Development experience least two different database platforms Teradata Oracle MySQL MS SQL etc Minimum years experience designing developing testing software aligned defined requirements Experience tuning SQL queries ensure performance reliability Competitive salary performance based bonus opportunities Single Family Health Insurance plans including Dental coverage Short Term Long Term disability Matching k Competitive Paid Time Off Training Certification opportunities eligible expense reimbursement Team building social activities", "", "", "years technologies experience Tech Lead experience plus Bachelor Computer Science related field equivalent experience years experience Spark Scala Java Python plus years experience working Hadoop SQL SQL platforms MongoDB plus years experience various data types AVRO JSON PARQUET plus Experience development management manipulation large complex datasets Demonstrated knowledge data management competencies implementation", "", "Be fan working agile scrum environments", "BS MS degree experience Ph D degree years experience drug development setting years biologics downstream process development experience using FPLC system e g AKTA Expertise method protocol development scale biologics purification including limited affinity cation exchange CEX anion exchange AEX viral filtration tangential flow filtration TFF required Familiarity HPLC based analytical methods SEC RP HPLC ion exchange hydrophobic interaction chromatography etc Prior experience IND regulatory requirements GMP environments quality documentation highly desired Demonstrated ability work independently minimal supervision Familiarity Design Experiment DOE comfortable working analytical tools create high quality unbiased analyses Prior experience successful technology process transfers third party vendors CRO CDMO CMO highly desired Experience mentoring coaching training junior staff members preferred Excellent interpersonal skills including clear succinct timely communication proven ability foster strong relationships team members stakeholders Highly self motivated detail oriented proven ability work dynamic fast moving team Comfortable working data driven team collaborating research scientists data scientists platform engineers Familiarity experience scripting statistical analysis data", "", "", "", "", "Bachelor Master degree Life Sciences Computer Science Engineering Experience Software Engineering Development Strong learning agility ability pick new technologies used support Commercialization data analysis needs Experience Planisware Strong experience working agile methodology DevOps Jenkins JIRA Github frameworks successful experience working collaborative team environment Experience working container technologies e g Docker developing microservices Proficiency software development languages including limited Java C Experience Cloud AWS databricks platforms HPC high performance computing environments Experience developing supporting web applications including familiarity web technologies frameworks EXTJS D3 JS React js Data analysis reporting experience using analytics visualization database technologies Oracle PL SQL Spotfire Tableau Python NumPy SciPy Pandas Expert R scripting R development R Shiny Experience processing analyzing large NGS data Expertise translating business requirements technical requirements recommend solutions Working leading agile development methodologies Sprint Scrum Knowledge experience Life Physical Computational Sciences Strong written oral communication skills", "Bachelor Degree required At least years employment data engineer professional setting relevant development experience Expert python Expert working cloud platforms AWS Google Cloud etc Experience Airflow workflow management software Ability define data model data storage strategies including knowledge distributed data systems Ability manage multiple competing priorities make right tradeoffs timely delivery features Experience familiarity geography geometry GIS systems Experience working satellite remote imagery Relevant education Coding Bootcamp Bachelors Computer Science equivalent experience Be part well funded early stage start Market competitive comp equity incentives give stake future Medical Vision Dental dependents Pre tax commuter parking benefits Flexible Time Off An upbeat collaborative work culture Company sponsored outings", "Experience Informatica tools PowerCenter Big Data Management Master Data Management Cloudera CDH ecosystem tools SOLR Spark Impala Hive Hue etc MarkLogic SAS Analytics python R Amazon Web Services preferred", "BS MS degree Computer Science Engineering related field years experience designing complex inter dependent data models analytic Machine learning use cases years experience architecting building processes extract process add value data sets multiple source systems Experiencing data modeling tuning relational well NoSQL datastores Oracle Red shift Impala HDFS Hive Athena etc Experience working distributed computing tools Spark Hive etc Experience AWS cloud services EC2 EMR RDS Redshift S3 Lambda Experience data pipeline workflow management tools Airflow etc years experience one general purpose programming languages including limited Java Scala C C C Swift Objective C Python JavaScript years experience working leading agile development methodologies Sprint Scrum Experience Software engineering best practices including limited version control Git TFS Subversion etc CI CD Jenkins Maven Gradle etc automated unit testing Dev Ops Experience Semantic technologies approaches plus Biotech Pharma experience plus Full stack development using infrastructure cloud services AWS preferred cloud native tools design patterns Containers Serverless Docker etc plus", "", "Advanced working SQL knowledge experience working relational databases query authoring SQL well working familiarity variety databases Experience building optimizing big data data pipelines architectures data sets Strong analytic skills related working unstructured datasets Build processes supporting data transformation data structures metadata dependency workload management We looking candidate years experience Data Engineer role attained degree Computer Science Statistics Informatics Information Systems relevant experience Below list type tech use though expect experience Big data tools Hadoop Storm Cassandra etc Relational SQL NoSQL databases including Postgres MySQL MSSQL Data pipeline workflow management tools Google Cloud Dataflow Cloud services AWS Redshift Google BigQuery etc Stream processing systems Kafka Storm Spark Streaming etc Object oriented object function scripting languages Python Java C Scala etc Big data tools Hadoop Storm Cassandra etc Relational SQL NoSQL databases including Postgres MySQL MSSQL Data pipeline workflow management tools Google Cloud Dataflow Cloud services AWS Redshift Google BigQuery etc Stream processing systems Kafka Storm Spark Streaming etc Object oriented object function scripting languages Python Java C Scala etc", "", "", "", "", "Clearance TS SCI TS SCI current CI scope Polygraph one year currency minimum OR willing undergo CI scope Polygraph based specific analytical position PLUS Education Bachelors Degree OR years direct relevant experience PLUS Experience years analytical experience years Identity Intelligence functional regional source analysis experience operational strategic level within DoD equivalent Government agencies Strong briefing skills include ability clearly articulate information senior members intelligence community Ability gather analyze collate fuse available intelligence products produce IIRs reports briefings including ability clearly articulate information Education Masters Degree related field Certification Counter Terrorism Counter Insurgency Global Regional Issues HUMINT CI POL MIL Geopolitical analysis Senior Intelligence Analysis familiarity ICD Competed OS301 Fundamentals Course Completed OS302 OSINT Analytic Tools Course Completed Basic Social Media Analysis Course Complete Advanced Social Media Analysis Course Competed OS301 Fundamentals Course Completed OS302 OSINT Analytic Tools Course Completed Basic Social Media Analysis Course Complete Advanced Social Media Analysis Course Experience years experience related specific labor category least portion experience within last years Equivalency Chief Warrant Officer Field Grade Officer O4 O5 JISE ACE Director Deputy Director", "", "", "Connections recruiters industry experts online live Devex events", "", "", "years application development support experience Deep knowledge distributed data architecture commonly used BI tools approaches packages deployed machine learning build Experience creating production software systems proven track record identifying resolving performance bottlenecks production systems Experience machine learning algorithm design feature engineering validation prediction recommendation measurement Experience complex high volume multi dimensional data well machine learning models based unstructured structured streaming datasets Good understanding Payments Banking Industry including aspects consumer credit consumer debit prepaid small business commercial co branded merchant Experience planning organising managing multiple large projects diverse cross functional teams Demonstrated ability incorporate new techniques solve business problems Post Graduate Degree Information Technology Qualification Computer Science Engineering ideal Certification Hadoop Cloudera Hortonworks Apache Spark Working knowledge Hadoop ecosystem associated technologies e g Apache Spark MLlib GraphX iPython sci kit Pandas Advanced experience writing optimizing efficient SQL queries Python scripts Scala C experience ideal Deliver results within committed scope timeline budget Very strong people project management skills experience Ability travel within CEMEA short notice Results oriented strong problem solving skills demonstrated intellectual analytical rigor Good business acumen track record solving business problems data driven quantitative methodologies Experience payment retail banking retail merchant industries preferred Team oriented collaborative diplomatic flexible style Very detailed oriented expected ensure highest level quality rigor reports data analysis Proven skills translating analytics output actionable recommendations delivery Experience presenting ideas analysis stakeholders whilst tailoring data driven results various audience levels Exhibits intellectual curiosity desire continuous learning Exhibits intellectual curiosity desire continuous learning Demonstrates integrity maturity constructive approach business challenges Role model organization implementing core Visa Values Respect Individuals levels workplace Strive Excellence extraordinary results Use sound insights judgments make informed decisions line business strategy needs Leadership skills include ability allocate tasks resources across multiple lines businesses geographies Leadership extends ability influence senior management within outside Analytics groups Ability successfully persuade influence internal stakeholders building best class solutions", "", "Be wary Google Hangout Skype interviews publicly listed numbers used verify legitimacy interviewer", "", "", "", "Connections recruiters industry experts online live Devex events", "", "BS MS degree Computer Science Engineering related field years experience architecting building processes extract process add value data sets multiple source systems Experiencing data modeling tuning relational well NoSQL datastores Oracle Red shift Impala HDFS Hive Athena etc Experience working distributed computing tools Spark Hive etc Experience AWS cloud services EC2 EMR RDS Redshift S3 Lambda Experience data pipeline workflow management tools Airflow etc years experience one general purpose programming languages including limited Java Scala C C C Swift Objective C Python JavaScript years experience working leading agile development methodologies Sprint Scrum Experience Software engineering best practices including limited version control Git TFS Subversion etc CI CD Jenkins Maven Gradle etc automated unit testing Dev Ops Experience Semantic technologies approaches plus Biotech Pharma experience plus", "", "", "Minimum years professional software development experience hands data centric role data engineering architecture streaming warehousing REQUIRED Experience least one modern server side language Python Java similar REQUIRED Experience least one relational database technology MySQL Postgres MS SQL etc REQUIRED Proficient SQL REQUIRED Familiarity cloud services infrastructure preferably AWS Familiarity columnar store databases Vertica Redshift Snowflake etc Experience building data ingest pipelines Experience building working within Extract Load Transform Data Lake architectures Comfortable working mix structured unstructured data variety sources preferred Experience schema design Experience Spark DataFrames pandas big plus Experience transforming partially fully unstructured data easily queryable formats Experience tuning databases performance Experience working agile environment Scrum Kanban Knowledge machine learning tools concepts plus Fun collaborative environment Optional work home Wednesdays Competitive compensation benefits package including medical dental vision insurance weeks PTO paid holidays total weeks 401k Stock options Commuter benefits Stocked kitchens coffee soda snacks Regular team activities including Mariners games ping pong tournaments movies etc", "", "", "", "A competitive salary", "", "", "", "BS Computer Science Computer Engineering Data Analytics Data Science Physics Mathematics Information Systems Engineering quantitative disciplines Experience extracting processing curating integrating analyzing data using Python Spark SQL Hands experience AWS services Kinesis S3 Glue Lambda Cloudformation RDS EC2 EMR HDFS Hadoop Yarn Hbase Hive Pig Hands experience ELT ETL dimensional data modeling Proficiency Python least one SQL language T SQL PL SQL Excellent knowledge relational non relational database systems Ability think creatively solve problems Ability work highly collaborative dynamic work environment Effective written oral communication skills Experience building production data pipelines using Python SQL Spark AWS environment Kinesis S3 Glue Lambda Cloudformation RDS HDFS Hadoop Yarn Hbase Hive Pig Strong programming experience Python Spark Scala Experience ETL ELT dimensional data modeling Experience working relational non relational databases advanced SQL NoSQL scripting Familiarity data pipeline workflow management tools Airflow AWS Step functions Nifi", "Understand business use data support work processes strategic business objectives Leverage data analytics data science techniques create business value solution delivery self service enablement Identifies acquires cleanses prepares data including data architecture aligned defined architecture patterns Collaborates data scientists identify build integrate advanced analytics models solutions Enables data scientists develop advanced analytics models Uses agile approach develop analytic solutions technical components platform data ingestion data preparation analytics processing visualization Deploys solution including model documentation training integration B S M S Computer Science related field years industry experience developing data products analytics solutions business intelligence data warehousing data science Data Architecture modeling Integration Experience Analytics Data Product solution architecture Hadoop Microsoft Azure Analytics Experience Data Extract Load transformation technics tools Hadoop SSIS Microsoft Azure Data Factory Understanding relational dimensional data models Experience Analytics Data Product solution architecture Hadoop Microsoft Azure Analytics Experience Data Extract Load transformation technics tools Hadoop SSIS Microsoft Azure Data Factory Understanding relational dimensional data models Data Visualization Analytics Experience analytics solutions Microsoft Azure Analytics Paas Saas Experience Data Visualization Spotfire PowerBI Experience analytics solutions Microsoft Azure Analytics Paas Saas Experience Data Visualization Spotfire PowerBI Software Engineering Experience software engineering Agile DevOps methodologies tools Jira Jenkins VSTS Experience programming languages scripting tools Java Python R C Experience information security management Experience software engineering Agile DevOps methodologies tools Jira Jenkins VSTS Experience programming languages scripting tools Java Python R C Experience information security management Learning Agility Work productively uncertain fast changing environments Finds opportunities ambiguity Embraces adapts change adept learning Work productively uncertain fast changing environments Finds opportunities ambiguity Embraces adapts change adept learning Analytical thinking problem solving Knowledge techniques tools promote effective analysis determine root cause problems create alternative solutions solve best interest business Knowledge techniques tools promote effective analysis determine root cause problems create alternative solutions solve best interest business", "years relevant experience BS MS PhD Computer Science related field Experience Java Scala Python Expert knowledge machine learning algorithms operationalization data science pipelines Demonstrable experience ETL ELT tools Expert Knowledge distributed data processing Hadoop ecosystem spark Strong knowledge SQL eg MySQL Linux Comfortable Data Security Concepts SDLC Familiarity leading cloud vendors GCP Azure AWS related tools", "", "Bachelors Degree At least years experience using database management tools SQL At least year experience creating data visualizations using Tableau At least year experience using relational database systems Snowflake PostgreSQL MySQL years coding experience years experience creating Tableau visualizations years experience relational database systems including Snowflake PostgreSQL MySQL years experience building data pipelines using ETL tools years experience creating automated solutions", "", "", "", "Experience demonstrated proficiency database development management Experience extracting cleaning transforming data analysis required Experience preferred higher education data analysis reporting setting institutional research enrollment analysis etc higher education IT setting Advanced knowledge SQL required Advanced knowledge relational databases required Experience preferred SQL server Oracle Advanced practical experience SQL based data query tools BRIO Hyperion Toad Toad Intelligence Central strongly preferred Practical experience data management tools Alteryx preferred Familiarity dimensional data modeling concepts e g Star Schema preferred Familiarity Python open source data engineering tools plus Strong orientation detail Strong organization skills Excellent interpersonal communication skills including strong customer service orientation Ability manage concurrent projects activities high degree quality data accuracy Ability meet deadlines deliver projects timely manner Bachelor degree required master degree preferred", "", "", "", "Bachelor degree Computer Science Engineering related field equivalent training fellowship work experience", "BS MS computational sciences computational biology bioinformatics related fields computer science applied math statistics Experience scientific programming Experience data analysis especially pertains protein sequence structure next generation DNA sequence analysis Excellent problem solving skills Knowledge biochemistry bioinformatics protein structures molecular biology NGS data analysis Ability execute automate standard statistical analyses using tools languages including UNIX Python R SQL etc Knowledge cloud computing AWS Docker etc Experience scientific software administration tool development Strong communication skills", "B S Degree Engineering related discipline years experience pharmaceutical biotech years experience Master Degree", "Bachelor degree equivalent experience None Database development knowledge experience e SQL Programming skills e Python R Java Computer Proficiency Oracle UNIX Linux Intermediate Analytic Data Sourcing Data Management skills Ability extract data various data sources Solid experience time task management Ability learn new technologies Strong attention detail Intermediate written verbal communication skills including ability effectively collaborate multi disciplinary groups organizational levels", "", "", "years working Agile devOps teams SCRUM Experience AWS cloud services EC2 EMR RDS Redshift S3 Lambda Experience data pipeline workflow management tools MuleSoft Informatica Cloud etc Familiarity various application technology stacks BI stacks technology domains Data Analytics Working experience data analytic tools e g Tableau Splunk Spotfire Hadoop Clear understanding Relational Dimensional database modeling Skilled programmer sufficient experience high level programming languages C C Java Python Visual Basic Experience programming compiled C C interpreted languages Python Ruby etc DevOps experience building deploying infrastructure cloud deployment build test automation technologies like ansible chef puppet docker jenkins etc Experience Big Data Advanced Analytic techniques Real Time data Full stack development using infrastructure cloud services AWS preferred cloud native tools design patterns Containers Serverless Docker etc Demonstrated ability adopt new cloud technologies paradigms emerging Big Data technologies Hadoop hive etc Exceptional teaming skills encompassing cross functional teams peer relationships informing understanding appreciating differences Proven experience member leader high performing team Strong ability convey influence complex technical issues manner easily understood actionable Experience applying change management methodologies large global corporate environments involving multiple businesses Certified Information Security Manager CISM CompTIA Security Certified Information Systems Security Professional CISSP", "Demonstrated knowledge SQL relational databases PostgreSQL Professional experience complex data systems strongly preferred experience public sector data data systems preferred Programming experience either Python R experience preferred Familiarity version control systems git preferred Ability balance many competing demands well demonstrate good decision making initiative Excellent written verbal communication skills including discussing technical concepts non technical users Ability work independently high degree initiative required Ability manage multiple concurrent tasks required Demonstrated judgment discretion handling sensitive information required Must able remain stationary position extended periods time Must able operate computer extensively four hours per day", "", "Bachelor Master Ph D degree computer science electrical engineering relevant field Proven significant experience building managing data pipelines Ability build manage data pipelines Python Scala Java Knowledge software engineering best practices code reviews testing frameworks maintainability readability Commercial client facing project experience helpful including working close knit teams Ability work across structured semi structured unstructured data extract information identify linkages across disparate data sets Meaningful experience multiple database technologies Hadoop MS SQL Server Oracle MySQL Teradata Confirmed ability clearly communicating complex solutions Deep understanding Information Security principles ensure compliant handling management process data Experience interest Cloud platforms AWS Azure Google Platform Familiarity data warehousing deploying ETL processes Python Extraordinary attention detail Strong organizational interpersonal skills get things done way optimizes results strengthens internal external relationships consideration resources Knowledge cGMP Health Authority regulations Quality Systems Work Environment Physical Demands Safety Considerations Ability work international global environment travel anticipated May work clean room environment requires gowning form hospital scrubs Ability sit stand move within work space extended periods", "Be wary Google Hangout Skype interviews publicly listed numbers used verify legitimacy interviewer", "", "You understand desire best place work trust foundation", "", "Proven attention detail proactive communication Proficient one following coding languages Python Java Scala Demonstrable experience writing SQL using RDBMS Redshift Postgres MySQL Teradata Oracle etc Experience Schema Design Dimensional data modeling Experience AWS Services like EC2 S3 Redshift Spectrum Glue Athena RDS Lambda API gateway Experience software DevOps CI CD tools Git Jenkins Linux Shell Script Experience Spark Hive Kafka Kinesis Spark Streaming Airflow Hands experience using Databricks Jupyter similar notebook environment Experience building data warehouses ETL pipelines plus Our culture makes Amgen special place work We powerful shared purpose around mission serve patients We respect one another recognize contributions embedded collaboration trust empowerment inclusion We equip staff members live well rounded healthy lives Most recently Amgen added benefits transgender employees continues pride industry leading family friendly offerings families compositions Amgen focuses areas high unmet medical need uses expertise strive solutions improve health outcomes dramatically improve people lives A biotechnology pioneer since Amgen grown one world leading independent biotechnology companies reached millions patients around world developing pipeline medicines breakaway potential Amgen Equal Opportunity employer consider without regard race color religion sex sexual orientation gender identity national origin protected veteran status disability status", "", "", "", "Embed billing team create billing pipelines enable granular bills help better users understand costs", "", "", "BS MS degree Computer Science Engineering related field years experience architecting building processes extract process add value data sets multiple source systems Experiencing data modeling tuning relational well NoSQL datastores Oracle Red shift Impala HDFS Hive Athena etc Experience working distributed computing tools Spark Hive etc Experience AWS cloud services EC2 EMR RDS Redshift S3 Lambda Experience data pipeline workflow management tools Airflow etc years experience one general purpose programming languages including limited Java Scala C C C Swift Objective C Python JavaScript years experience working leading agile development methodologies Sprint Scrum Experience Software engineering best practices including limited version control Git TFS Subversion etc CI CD Jenkins Maven Gradle etc automated unit testing Dev Ops Experience Semantic technologies approaches plus Biotech Pharma experience plus Full stack development using infrastructure cloud services AWS preferred cloud native tools design patterns Containers Serverless Docker etc plus", "An existing affinity Data Science Machine Learning Cloud Computing Networking Security Encryption RESTful interfaces DevOps", "Computer Science Computer Engineering Mathematics degree Strong analytical problem solving skills Coding proficiency least one modern programming language Python Ruby Java etc Experience data modeling ETL development data warehousing Data Warehousing Experience example Oracle Redshift Teradata etc Experience building data products incrementally integrating managing datasets multiple sources Knowledge Mathematical Statistics Experience Big Data Technologies Hadoop Hive Hbase Pig Spark etc plus Good English Free Glovo credits The opportunity change world see everyone uses product build Work international dynamic passionate environment great company culture We consider variants relocation Barcelona Spain We cover visa relocation costs", "Various experience levels considered Junior candidates must strong background coursework academic projects around data engineering machine learning scale appropriate industry experience contributing projects Senior candidates must demonstrate track record successful technical leadership execution large scale data projects Software Engineering Level appropriate experience software engineering SDLC stack may include Python Golang Scala Must consider code readability reuse extensibility priority developing solutions Big Data Engineering Experience building scalable data pipelines involving machine learning optimization prediction Big Data Devops Experience performing operations automation various big data ecosystems production environments AWS related cloud service Ability thrive fast paced cross regional diverse dynamic work environment Experience AWS data stack Redshift Athena EMR Kinesis DocumentDB DynamoDB Experience establishing well organized data lakes Experience setting optimizing data warehouses Background data modeling performance tuning relational SQL databases Experience data practices security data management governance Experience operations research machine learning optimization", "", "Graduate degree Computer Science Information Systems equivalent quantitative field years experience similar Data Engineer role Experience working extracting value large disconnected unstructured datasets Demonstrated ability build processes support data transformation data structures metadata dependency workload management Advanced working SQL knowledge experience working relational databases query authoring SQL well working familiarity variety databases Experience building optimizing big data data pipelines architectures data sets Experience performing root cause analysis internal external data processes answer specific business questions identify opportunities improvement Experience developing IT frameworks support business applications", "", "Connections recruiters industry experts online live Devex events", "", "years relevant experience BS MS PhD Computer Science related field Experience Java Scala Python Expert knowledge machine learning algorithms operationalization data science pipelines Demonstrable experience ETL ELT tools Expert Knowledge distributed data processing Hadoop ecosystem spark Strong knowledge SQL eg MySQL Linux Comfortable Data Security Concepts SDLC Familiarity leading cloud vendors GCP Azure AWS related tools", "", "", "", "", "", "", "years relevant experience data tools techniques manipulation required Education College Degree STEM related field Technical Knowledge Advanced knowledge data tools techniques manipulation preferred Examples limited Data Science Engineering Big data Cloud platforms Programming languages SAS SQL Spark Python R H2O KNIME Hive AWS Development Visualization platforms Python Notebook IDEs GitHub QlikView Tableau MicroStrategy Qlik Sense Experience Communication Skills Ability communicate thoughts designs ideas unambiguous manner adjusts communication based audience Exhibits active effective communication skills team members including active listening effective written verbal communication skills Effectively contributes communicates immediate team Able present complex technical concepts audiences varying size level Business Knowledge Partnership Able develop business partnerships influence business priorities solution identification aligned business objectives goals Able communicate business terms describe data capabilities concepts ways business understand Problem Solving Decision Making Able proficiently diagnose root causes solve complex issues Able evaluate alternative solutions assess risk taking action Has ability reach sound decisions quickly escalates appropriately Demonstrates ability optimize use available resources Team Orientation Able maintain enhance partnerships across organization achieve objectives Practices objectivity openness others views Able recognize support team priorities Leadership Accountable set technical goals priorities self team members Exhibits team leadership collaborates partners Planning Project Management Demonstrates ability identify critical project tasks establish clear priorities keeping bigger picture mind Able effectively collaborate Project Manager utilize sound project management practices Able manage time competing priorities Financial Awareness", "", "", "Experience Hadoop eco system HDFS Spark", "years work experience including years experience data engineering Processing extracting value large disconnected datasets Continuous integration systems Jenkins Travis Drone CI", "years work experience including years experience data engineering Processing extracting value large disconnected datasets Continuous integration systems Jenkins Travis Drone CI", "", "", "", "", "A competitive salary", "", "Work cool people impact millions daily players", "", "", "", "At least five years proficiency SQL Microsoft stack Banking financial sector experience beneficial Fove years Net Language experience Visualisation Storyboarding experience Stats experience Assist driving data services strategy across multiple platforms Building operation frameworks processes take data services next level excellence Building Big Data Platform consolidating Group Data provisioning via required channels Operational analytical data provisioning insights data landscape Understanding optimising Data Flow Patterns order rationalise data inputs Shaping unstructured data acquisition Realtime Data Integration Patterns Engagement shaping Data Initiatives ensure Strategic Alignment Group Architecture", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "career categories", "", "Experience designing implementing supporting highly scalable data systems services Java Scala Experience Hadoop ecosystem technologies particular MapReduce Spark Spark SQL Spark Streaming Hive YARN MR2 Experience building running large scale data pipelines including distributed messaging Kafka data ingest multiple sources feed batch near realtime streaming compute components Experience data modeling data architecture optimized big data patterns ie warehousing concepts efficient storage query HDFS data security privacy techniques Knowledgable distributed storage network resources level hosts clusters DCs troubleshoot prevent performance issues", "Minimum years experience analytics data engineering role BS MS degree quantitative field equivalent practical experience Mastery relational databases SQL MySQL Ability translate business processes data analytics solutions A strong foundation data modeling including least years relevant business people analytics experience commitment data governance Demonstrated ability manage technical non technical stakeholders drive collaboration Experience Python scripting language plus Experience Tableau plus Desired Attributes Outstanding written verbal visual communication capabilities Ability pivot widely divergent tasks subject matter short notice rapidly adapt varied audiences A record adding value work outcomes innovation orientation toward continuous refinement improvement Highly thorough detail oriented", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "years experience Software Engineer Excellent programming skills e g Python Go Java Excellent problem solving analytic skills Solid computer science systems foundations ability quickly learn new domains Proven system development skills UNIX type OS e g Linux Mac OS Experience working large data sets pipelines ideally using Apache software stack e g Spark HBase Experience continuous integration continuous development solutions e g Jenkins etc Experience cloud native deployment e g Kubernetes Good communication skills teamwork Passion building great products Curiosity desire learn The following experience nice required Data modeling Experience working search engines Machine learning Natural language processing", "", "Work clients model data landscape obtain data extracts define secure data exchange approaches Plan execute secure good practice data integration strategies approaches Acquire ingest process data multiple sources systems Big Data platforms Working across different environments technologies learning nuances Amazon Web Services SQL NoSQL Big Data Hadoop platforms Designing setting running ETL transformations using tools including Informatica PowerCenter Data Quality Informatica Cloud Create manage data environments Cloud Focus working financial services clients Collaborate data scientists map data fields hypotheses curate wrangle prepare data use advanced analytical models Keep date Information Security principles ensure compliant handling management client data Involved end end data management cutting edge Advanced Analytics Data Science A graduate relevant subject Management consulting experience leading client facing projects including working close knit teams Experience working projects within cloud preferably AWS In house experience within large financial institution preferred topics AML A proven ability clearly communicating complex solutions Strong development background experience least one scripting object oriented functional programming language etc SQL Python Java Scala C R Data Warehousing experience building operational ETL data pipelines across number sources constructing relational dimensional data models Distributed Systems experience Good experience least one Database technology Traditional RDBMS MS SQL Server Oracle MySQL PostgreSQL MPP AWS Redshift Oracle Exadata Teradata IBM Netezza Distributed Processing Spark Hadoop EMR NoSQL MongoDB DynamoDB Cassandra Vertica Neo4J Titan Experience least one ETL tool e g Informatica SAP BODS The ability work across structured semi structured unstructured data extracting information identifying linkages across disparate data sets Excellent interpersonal skills interacting clients verbally email written clear timely professional manner A deep personal motivation always produce outstanding work clients colleagues Excel team collaboration working others diverse skill sets backgrounds", "Completed BSc Computer Science degree similar Software Engineering Data Science etc experience software Two five years experience Data Engineering Hadoop Spark Data Processing products Big Query Redshift Spectrum S3 Athena Kafka Spark Storm Flink Beam Presto Hive ETL processes transformations Cloud experience ideally Google Cloud Platform DevOps Stack development experience Apache Airflow data pipeline tools Exposure Scala Java context data processing Experience proficiency Python Experience design implementation data flows Support sophisticated predictive data products maintaining data science production environments cloud based python ensuring outputs Data Science models available integrated system integrate coordinate maintain data flows various sources data Manage maintain cloud service integrations perform key data functions working towards replacing third party elements data pipeline using open source tools Make decisions around infrastructure layout processes data warehouse including working engineering team best track record data following data inconsistencies ensure corrected", "", "401K", "", "", "", "years hands experience business intelligence IT management role corporate consulting setting Strong development background experience least two scripting object oriented functional programming languages SQL Python Java Scala C R Client stakeholder engagement management Experience leading work stream managing small teams Agile projects Data Warehousing experience building operational ETL ELT pipelines comprised several sources architecting Data Models Layers Analytics Ability work across structured semi structured unstructured data extracting information identifying linkages across disparate data sets Experience multiple Database technologies Traditional RDBMS MS SQL Server Oracle MySQL PostgreSQL MPP AWS Redshift Oracle Exadata Teradata IBM Netezza Distributed Processing Spark Hadoop EMR NoSQL MongoDB DynamoDB Cassandra Vertica Neo4J Titan Experience developing solutions Cloud platforms Amazon Web Services Microsoft Azure Google Cloud Platform Experience generating Insights form reports KPIs dashboards ad hoc queries experience Tableau bonus Ability thrive lively project consulting setting often working different multiple projects time Excellent interpersonal skills interacting clients verbally email written clear timely professional manner Problem solving brainstorming solutions data integration Analytics challenges Passion developing knowledge skills technical aspects Data Technology industry personal professional development work life", "", "career categories", "", "career categories", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "career categories", "Identify data sources add value decision making Work source system owners analysts understand source data e g data profiling definition mapping Design implement efficient data loads using traditional structured data ETL techniques Design implement real time near real time data load solutions using technologies like data streaming Design implement unstructured data loads e g text speech images video Design implement load monitoring tools procedures perform continuous monitoring optimising loads Work analysts architect design implement effective efficient data models using appropriate modelling techniques Design implement data warehouse data models Design implement data pipelines ad hoc unstructured data models Design implement appropriate aggregation data structures enhance usability data e g multi dimensional OLAP structures summary tables etc Design implement maintain appropriate indexing tables enhance speed access Design implement data models support automated decision making analytics Continuously search data elements sources enhance existing data objects supplement enhance context Design implement interfaces data access e g batch exports real time decision API etc Design implement interface monitoring management solutions ensure availability accuracy Design implement data monitoring solutions procedures continuously monitor maintain integrity existing environment troubleshoot technical data issues make appropriate changes required Design implement meta data solutions assist understanding managing data Work together business owners analysts IT maintain good data governance Work together business owners analysts IT manage changes data organisation Provide technical data related support source system teams external parties exchange data Manage data growth usage implementing effective strategies e g archiving indexing Manage systems technology tools enable data management analytics liaise IT infrastructure IT Operations regarding system infrastructure management Take ownership work delivering high quality work time Show initiative pre active finding opportunities improve data processes Take ownership career development continuously improving skills knowledge application thereof designing implementing solutions Positive engagement team activities actively contribute ideas improve team dynamics performance Complex solution service design implementation Cross functional data team knowledge gathering sharing Responsible team activities team dynamics performance Manage project task delivery team Multiple stakeholder management internal external Assist development others e g mentoring knowledge share Quality control work Degree information technology engineering mathematics statistics actuarial related discipline At least years experience working data business intelligence analytics environment SQL Data analysis Data visualisation Data modelling Microsoft business intelligence data technologies SSIS SSAS SQL Server Data warehouse concepts best practices Information gathering problem analysis Applying professional specialist technical expertise Creating innovating Quality Detail orientation Planning organizing Presenting Communicating information Analysing Leadership", "", "We looking individuals proven big data experience either implementation data science prospective Expert knowledge least one big data technology Spark Hadoop Elasticsearch A strong coding background either Java Python Scala The desire learn code Scala Experience working Agile environment Experience building data processing pipelines use production handsoff batch systems including either traditional ETL pipelines analytics pipelines Competitive Salary Company Bonus Private Healthcare Life Insurance Income protection Pension Scheme company contribution contribute days annual leave option buy sell days Amazing working environment Employee referral scheme ETL Scala", "career categories", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "Virtual company sponsored social events", "Team player excellent communication skills", "", "Development experience least two different database platforms Teradata Oracle MS SQL Minimum years experience designing developing testing ETL interfaces aligned defined requirements Exposure Business Intelligence tools Business Objects Informatica SSRS Cognos MicroStrategy Tableau QlikView SpotFire etc Experience tuning ETL processes ensure performance reliability MDM experience Competitive salary performance based bonus opportunities Single Family Health Insurance plans including Dental coverage Short Term Long Term disability Matching k Competitive Paid Time Off Training Certification opportunities eligible expense reimbursement Team building social activities", "Experience Spark Google Big Query Redis Amazon Aurora Dynamo DB Kinesis Riak", "Completed BSc Computer Science degree similar Software Engineering Data Science etc experience software Two five years experience Data Engineering Hadoop Spark Data Processing products Big Query Redshift Spectrum S3 Athena Kafka Spark Storm Flink Beam Presto Hive ETL processes transformations Cloud experience ideally Google Cloud Platform DevOps Stack development experience Apache Airflow data pipeline tools Exposure Scala Java context data processing Experience proficiency Python Experience design implementation data flows Support sophisticated predictive data products maintaining data science production environments cloud based python ensuring outputs Data Science models available integrated system integrate coordinate maintain data flows various sources data Manage maintain cloud service integrations perform key data functions working towards replacing third party elements data pipeline using open source tools Make decisions around infrastructure layout processes data warehouse including working engineering team best track record data following data inconsistencies ensure corrected", "Machine learning statistical analysis", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "", "career categories", "", "years experience building traditional data warehouse solutions knowledgeable data modeling data access data storage techniques You understand standard methodologies ETL proficient debugging optimizing pipelines You easily transition one ETL tool set e g Informatica Kettle programmatic approaches Python SQL Spark Scala Extensive Experience SQL understanding NoSQL solutions You significant coding experience Java Python want apply skills processing big data years experience object oriented design coding testing patterns well experience engineering open source software platforms large scale data infrastructures You understanding distributed systems NoSQL solutions Redshift BigQuery Familiar Google Cloud cloud provider products servers You able work teams collaborate others clarify requirements You Bachelor degree Master information Technology relevant discipline Experience automation build tools release engineering Bonus Experience Spark Scala distributed data systems MPP databases", "You excellent written verbal communication skills You tenacious relentless determined You curious always learning new technologies rapidly synthesizing new information understanding You self directed capable operating amid ambiguity You poised display excellent judgment prioritizing across difficult tradeoffs You pragmatic letting perfect enemy good", "BA BS Degree Computer Science Engineering discipline Statistics Information Systems another quantitative field", "", "", "", "", "", "", "", "career categories", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "career categories", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "Experience areas data driven statistical modeling discriminative methods feature extraction analysis supervised learning", "", "", "Possess bachelor degree Computer Science Applied Mathematics Engineering technology related field", "", "Work cool people impact millions daily players", "", "", "", "", "", "", "Proficient designing accessing maintaining data stores data feeds data processing tools RDBMS NoSQL APIs Kafka Apache Spark ELK stack Experience AWS services EC2 S3 Lambda Glue Athena Redshift etc Proven experience deploying machine learning algorithms production Data Engineer Machine Learning Engineer similar role Proficiency using GitHub Docker Luigi Airflow Jenkins Terraform Proficient Python shell scripting Java plus familiar BI tools e g Power BI AWS QuickSight Tableu etc Proficient writing high quality scalable code integrating version control systems Knowledge statistical data mining techniques including model evaluation validation Enthusiasm big data translating data actionable insights demonstrable experience big data technologies structured unstructured data Proficient building robust data pipelines delivering reliable data services stakeholders Ability work complex fast paced environment maintaining high degree accuracy professionalism Excellent interpersonal verbal written communication skills Agile project development experience plus Experience leading successful data engineering projects operationalizing machine learning algorithms BS required years experience Master degree preferred years experience computer science applied mathematics engineering operations research related field", "", "Advanced degree systems electrical engineering equivalent experience systems engineering", "Advanced SQL knowledge years data extraction experience Should proficient writing advanced SQL tuning SQL code Semantic layer ESL development experience relational databases Oracle Teradata Vertica Hadoop desired Experience data induction validation source systems Experience working Capital Projects plus including writing requirements executing UAT Expert normalizing data reporting Strong analytical skills ability evaluate analyze present data answer business questions Experience data visualization tools e g Tableau plus Familiarity Finance Operations Retail Contact Center data desired Desire end end ownership work Flexibility balance directional changes ability support multiple deadline specific projects maintaining day day business support Ability deal ambiguity Proactive driven individual comfortable working global matrixed fast paced environment", "You excellent written verbal communication skills You tenacious relentless determined You curious always learning new technologies rapidly synthesizing new information understanding You self directed capable operating amid ambiguity You poised display excellent judgment prioritizing across difficult tradeoffs You pragmatic letting perfect enemy good", "", "", "Bachelor Master degree Computer Science related technical field equivalent professional experience Greater years experience Safety Quality First Valuing Ethics Integrity Diversity Passion Serving Our Customers Globally Dedication Each Other Through Servant Leadership Creating Value Shareholders Customers Employees Consistently Delivering Our Commitments Competitive Salary Comprehensive Health Wellness Income Protection Benefits k Savings Plan Company Match Paid Vacations Holidays Opportunities Flexible Work Arrangements Educational Reimbursement Program Employee Referral Program", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "Python", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You tenacious relentless determined You curious always learning new technologies rapidly synthesizing new information understanding You self directed capable operating amid ambiguity You poised display excellent judgment prioritizing across difficult tradeoffs You pragmatic letting perfect enemy good", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "BSc MSc Computer Science related field equivalent experience Strong analytical learning problem solving skills personal interest subjects math statistics machine learning AI analytics Solid knowledge data structures algorithms Unix Linux Proficient Scala Java SQL Strong experience Apache Spark Experience working Agile environment using TDD Continuous Integration Experience refactoring code scale production mind Familiar Git Python JavaScript HTML CSS Proficient understanding distributed computing principles Proficiency Hadoop v2 MapReduce HDFS Good knowledge Big Data querying tools Pig Hive Impala Experience integration data multiple data sources Experience NoSQL databases HBase Cassandra MongoDB Knowledge various ETL techniques frameworks Experience Big Data ML toolkits Mahout SparkML H2O Experience Cloudera MapR Hortonworks Management Hadoop cluster included services Experience building stream processing systems using solutions Storm Spark Streaming Good understanding Lambda Architecture along advantages drawbacks Experience various messaging systems Kafka RabbitMQ", "career categories", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "Identify data sources add value decision making Work source system owners analysts understand source data e g data profiling definition mapping Design implement efficient data loads using traditional structured data ETL techniques Design implement real time near real time data load solutions using technologies like data streaming Design implement unstructured data loads e g text speech images video Design implement load monitoring tools procedures perform continuous monitoring optimising loads Work analysts architect design implement effective efficient data models using appropriate modelling techniques Design implement data warehouse data models Design implement data pipelines ad hoc unstructured data models Design implement appropriate aggregation data structures enhance usability data e g multi dimensional OLAP structures summary tables etc Design implement maintain appropriate indexing tables enhance speed access Design implement data models support automated decision making analytics Continuously search data elements sources enhance existing data objects supplement enhance context Design implement interfaces data access e g batch exports real time decision API etc Design implement interface monitoring management solutions ensure availability accuracy Monitor maintain integrity existing environment troubleshoot technical data issues make appropriate changes required Implement meta data solutions assist understanding managing data Work together business owners analysts IT maintain good data governance Provide technical data related support source system teams external parties exchange data Manage data growth usage designing implementing effective strategies e g archiving indexing Manage systems technology tools enable data management analytics Take ownership work delivering high quality work time Show initiative pre active finding opportunities improve data processes Take ownership career development continuously improving skills knowledge application thereof designing implementing solutions Positive engagement team activities actively contribute ideas improve team dynamics performance Stakeholder management internal external Assist development others e g mentoring knowledge share Quality control work Degree information technology mathematics engineering actuarial science related discipline At least years technical data role preferably formal data data warehouse business intelligence environment SQL Data analysis Data visualisation Data modelling Microsoft business intelligence data technologies SSIS SSAS SQL Server Data warehouse concepts best practices Financial services knowledge specifically personal unsecured loans Business process monitoring optimising Microsoft business intelligence visualisation technologies SSRS Power BI IT infrastructure e g storage networking servers security Unstructured data experience Information gathering problem analysis Applying professional specialist technical expertise Creating innovating Quality Detail orientation Analysing", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "Knowledge best practices IT operations always always available service Experience knowledge Agile Software Development methodologies Excellent problem solving troubleshooting skills Process oriented great documentation skills Excellent oral written communication skills keen sense customer service BS MS degree Computer Science related technical field years Python Java development experience years SQL experience No SQL experience plus years experience schema design dimensional data modeling Ability managing communicating data warehouse plans internal clients Experience designing building maintaining data processing systems Experience working either Map Reduce MPP system size scale", "", "Bachelor Master degree Computer Science related technical field equivalent professional experience Greater years experience Safety Quality First Valuing Ethics Integrity Diversity Passion Serving Our Customers Globally Dedication Each Other Through Servant Leadership Creating Value Shareholders Customers Employees Consistently Delivering Our Commitments Competitive Salary Comprehensive Health Wellness Income Protection Benefits k Savings Plan Company Match Paid Vacations Holidays Opportunities Flexible Work Arrangements Educational Reimbursement Program Employee Referral Program", "Architect build data pipelines Architect implement data warehouse structure table schemas Develop data models enable end users effectively analyze data Optimize tune data warehouse query performance analytical workloads Identify troubleshoot resolve data quality issues Write complex SQL queries data analysis Design maintain robust data reporting visualization tools based requirements Develop integrations BI tools third party productivity applications years engineering experience Expert SQL preferably across number dialects commonly write Snowflake Redshift PostgreSQL MySQL SQL Server Experience developing software code one programming languages Python Java Scala Ruby Experience managing database data warehouse technologies bonus Redshift Snowflake Experience implementing ETL tools Bonus Stitch Fivetran Matillion Understanding data analytics ecosystem Experience one relevant tools Spark Kafka AWS Glue Amazon Kinesis Sqoop Flume Flink Experience implementing Business Intelligence tools Bonus Looker Experience developing data pipelines scratch", "", "", "", "", "Workflow scheduling orchestration Airflow Oozie Big data warehousing RDB MPP DB Oracle Teradata Postgress Hive Strong Python programming skills understanding data analytics linear algebra ML libraries Numpy Scipy Experience query APIs using JSON ProtocolBuffers XML", "Strong software development skills proficiency Object Oriented Functional Python required Demonstrated skill experience using PySpark SparkSQL Familiarity cloud based distributed systems blob storage elastic compute virtual instances Familiarity Software Development Life Cycles tools methodologies support git continuous integration issue tracking code reviews quality assurance processes scheduling Supporting data collection curation data provenance working machine learning models Exposure Signal Processing low level data collection Experience statistical inference methods scientific experimentation Experience Scala We ensure individuals disabilities provided reasonable accommodation participate job application interview process perform essential job functions receive benefits privileges employment Please contact us request accommodation Apple important resource soul people Apple benefits help well employees families meaningful ways No matter work Apple take advantage health wellness resources time away programmes We proud provide stock grants employees levels company also give employees option buy Apple stock discount offer everyone Apple chance share company success You discover many benefits working Apple programmes match charitable contributions reimburse continuing education give special employee pricing Apple products Apple benefits programmes vary country subject eligibility requirements Apple committed working providing reasonable accommodation applicants physical mental disabilities Apple drug free workplace", "", "Bachelor degree computer science information systems related field years Data Engineering AWS environment developing ETL tools years practical hands work experience data systems years practical demonstrable hands work experience SQL reading writing database management skills Experience one following Python Java Scala R Sharp attention detail ability effectively prioritize execute multiple tasks Excellent problem solving skills Ability communicate effectively stakeholders peers Experience working relational NoSQL columnar data stores Familiarity AWS AWS Lambda S3 Redshift MongoDB Graph Databases Azure cloud based technologies Contribute development newly established data warehouse ecosystem Communicate effectively define requirements wide range different teams Translate business requests database design execution Work closely domain experts understand source systems data Build robust scalable interfaces ETL programs data pipelines Develop maintain data dictionary published data sources Develop improve data release testing processes Create manage data sources integrate numerous APIs Ability identify resolve performance issues Operate open source cloud based environment includes AWS Redshift Python R Hadoop Spark technologies Work structured unstructured data Competitive wages including performance bonuses Medical Dental Life Disability insurance Paid time 401k employer match Employer funded retirement plan Health Savings Account Medical Dependent Care Flexible Spending Accounts Wellness Program Membership TPC Sawgrass", "Proficient SQL programming Python preferred Experience MPP databases preferred years experience data engineering ETL pipeline development years Spark development years experience Big Data Technologies Hadoop MapReduce Hive etc Spark experience preferred", "", "Data Engineer Five seven years experience big data tools Hadoop Spark Kafka Five seven years experience SQL knowledge experience working relational databases query authoring SQL well working familiarity variety databases Five seven years strong analytic skills related working unstructured datasets Experience AWS cloud services EC2 EMR RDS Redshift Full SQL Stack SSIS SSAS SSRS Degree Information Technology", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "Seeks challenge gets things done Math Stats Machine Learning background Data modeling SQL NoSQL database experience", "", "This position requires Computer Science Bioinformatics related degree years experience data movement data wrangling delivery data analytics pipelines Experience implementing maintaining data analytic pipelines Experience Big Data technologies Cloud based offerings Microsoft Azure GCP AWS etc corresponding tools Experience data movement management Pharmaceutical industry related scientific fields Experience core components Hadoop stack including HDFS Apache Spark ideally Cloudera based stack Background experience LIMS systems Next Generation Sequencing NGS workflows Cloud computing HPC systems Understanding diverse omic data types including RNA Seq DNA Seq Chip Seq WES WGS ATAC seq microbiome proteomic metabolomic data etc different sources Familiarity data mining machine learning artificial intelligence techniques Proven ability contribute development projects Operating pace agile decision making using evidence applying judgement balance pace rigour risk Committed delivering high quality results overcoming challenges focusing matters execution Continuously looking opportunities learn build skills share learning Sustaining energy well Building strong relationships collaboration honest open conversations", "", "Identify data sources add value decision making Work source system owners analysts understand source data e g data profiling definition mapping Design implement efficient data loads using traditional structured data ETL techniques Design implement real time near real time data load solutions using technologies like data streaming Design implement unstructured data loads e g text speech images video Design implement load monitoring tools procedures perform continuous monitoring optimising loads Work analysts architect design implement effective efficient data models using appropriate modelling techniques Design implement data warehouse data models Design implement data pipelines ad hoc unstructured data models Design implement appropriate aggregation data structures enhance usability data e g multi dimensional OLAP structures summary tables etc Design implement maintain appropriate indexing tables enhance speed access Design implement data models support automated decision making analytics Continuously search data elements sources enhance existing data objects supplement enhance context Design implement interfaces data access e g batch exports real time decision API etc Design implement interface monitoring management solutions ensure availability accuracy Design implement data monitoring solutions procedures continuously monitor maintain integrity existing environment troubleshoot technical data issues make appropriate changes required Design implement meta data solutions assist understanding managing data Work together business owners analysts IT maintain good data governance Work together business owners analysts IT manage changes data organisation Provide technical data related support source system teams external parties exchange data Manage data growth usage implementing effective strategies e g archiving indexing Manage systems technology tools enable data management analytics liaise IT infrastructure IT Operations regarding system infrastructure management Take ownership work delivering high quality work time Show initiative pre active finding opportunities improve data processes Take ownership career development continuously improving skills knowledge application thereof designing implementing solutions Positive engagement team activities actively contribute ideas improve team dynamics performance Complex solution service design implementation Cross functional data team knowledge gathering sharing Responsible team activities team dynamics performance Manage project task delivery team Multiple stakeholder management internal external Assist development others e g mentoring knowledge share Quality control work Degree information technology engineering mathematics statistics actuarial related discipline At least years experience working data business intelligence analytics environment SQL Data analysis Data visualisation Data modelling Microsoft business intelligence data technologies SSIS SSAS SQL Server Data warehouse concepts best practices Information gathering problem analysis Applying professional specialist technical expertise Creating innovating Quality Detail orientation Planning organizing Presenting Communicating information Analysing Leadership", "Agile Engineering Kanban Lean Hybrid agile experience big plus", "", "Degree educated Data Science similar Strong experience data preparation techniques including exploration visualisation Experience statistical models times series analysis multiple machine learning techniques clustering regression classification Strong skills using Python SQL Elastic visualise data surfacing tool Experience developing machine learning systems Experience Amazon Quicksite advantage", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "Splunk Hadoop similar", "", "", "Expertise Python programming functional object oriented Strong foundation statistical analysis Able develop optimized pipelines data acquisition pruning preprocessing insightful data performance visualizations iterating algorithm variants", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "Subject expected comply applicable University policies procedures including limited personnel policies policies found University Administrative Guide http adminguide stanford edu", "", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "NOT contact us unsolicited services offers", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "career categories", "", "", "", "Excellent programming skills C C Python Java Prior experience developing production software years minimum experience Linux system administration command line tools Strong analytical thinking Self motivated able work independently", "years experience developing ETL jobs analyzing processing high volume data Apache Hadoop ecosystem especially Spark Expert knowledge one object oriented programming languages Scala preferred Proficient schema design data modeling Experience data tools Jupyter Notebooks Zeppelin Excellent problem solving analytic skills Ability program several scripting languages Python Perl Bash Experience workflow management tools Oozie Airflow Azkaban etc Experience batch streaming data processing Ability learn research new technologies rapidly Passion customer privacy Strong interpersonal skills experience working cross functional projects", "Identify data sources add value decision making Work source system owners analysts understand source data e g data profiling definition mapping Design implement efficient data loads using traditional structured data ETL techniques Design implement real time near real time data load solutions using technologies like data streaming Design implement unstructured data loads e g text speech images video Design implement load monitoring tools procedures perform continuous monitoring optimising loads Work analysts architect design implement effective efficient data models using appropriate modelling techniques Design implement data warehouse data models Design implement data pipelines ad hoc unstructured data models Design implement appropriate aggregation data structures enhance usability data e g multi dimensional OLAP structures summary tables etc Design implement maintain appropriate indexing tables enhance speed access Design implement data models support automated decision making analytics Continuously search data elements sources enhance existing data objects supplement enhance context Design implement interfaces data access e g batch exports real time decision API etc Design implement interface monitoring management solutions ensure availability accuracy Monitor maintain integrity existing environment troubleshoot technical data issues make appropriate changes required Implement meta data solutions assist understanding managing data Work together business owners analysts IT maintain good data governance Provide technical data related support source system teams external parties exchange data Manage data growth usage designing implementing effective strategies e g archiving indexing Manage systems technology tools enable data management analytics Take ownership work delivering high quality work time Show initiative pre active finding opportunities improve data processes Take ownership career development continuously improving skills knowledge application thereof designing implementing solutions Positive engagement team activities actively contribute ideas improve team dynamics performance Stakeholder management internal external Assist development others e g mentoring knowledge share Quality control work Degree information technology mathematics engineering actuarial science related discipline At least years technical data role preferably formal data data warehouse business intelligence environment SQL Data analysis Data visualisation Data modelling Microsoft business intelligence data technologies SSIS SSAS SQL Server Data warehouse concepts best practices Financial services knowledge specifically personal unsecured loans Business process monitoring optimising Microsoft business intelligence visualisation technologies SSRS Power BI IT infrastructure e g storage networking servers security Unstructured data experience Information gathering problem analysis Applying professional specialist technical expertise Creating innovating Quality Detail orientation Analysing", "Possess bachelor degree Computer Science Applied Mathematics Engineering technology related field", "", "NoSQL databases like MongoDB Cassandra Neo4J", "", "You precise thought code You serious interest SQL Data Your T SQL Dev skills strong Stored Procs etc You knowledge SSIS standard ETL drives Some SSAS would useful", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "", "", "", "Expert designing implementing supporting highly scalable data systems services Java Scala Extensive experience Hadoop ecosystem technologies particular MapReduce Spark Spark SQL Spark Streaming Hive YARN MR2 Expertise building running large scale data pipelines including distributed messaging Kafka data ingest multiple sources feed batch near realtime streaming compute components Experience data modeling data architecture optimized big data patterns ie warehousing concepts efficient storage query HDFS data security privacy techniques Knowledgable distributed storage network resources level hosts clusters DCs troubleshoot prevent performance issues", "", "", "years software engineering experience A track record making difference past projects Naturally accountable responsible self motivated self sufficient Experience designing distributed systems services scale Experience working Cassandra SOLR Spark Hadoop Kafka similar technologies production contexts scale Preference experience Scala Python Apple important resource soul people Apple benefits help well employees families meaningful ways No matter work Apple take advantage health wellness resources time away programmes We proud provide stock grants employees levels company also give employees option buy Apple stock discount offer everyone Apple chance share company success You discover many benefits working Apple programmes match charitable contributions reimburse continuing education give special employee pricing Apple products Apple benefits programmes vary country subject eligibility requirements", "High level understanding well hands experience implementing data pipelines Proficient scripting functional programming languages Python Scala Bash Groovy Ruby Experience database message queueing data streaming solutions instance PostgreSQL AWS RDS Apache Kafka AWS Kinesis RabbitMQ Redis Apache Spark similar tools Experience regression testing data pipelines Experience DevOps application monitoring tools plus instance Docker Kubernetes Terraform CloudFormation Ansible Chef Puppet Salt Splunk Elastic ELK Stack Sentry Datadog similar tools Knowledge Machine Learning Computer Vision plus", "Bachelor degree higher quantitative technical field Computer Science Statistics Engineering Minimum two years work experience related field required Working knowledge data design architecture warehousing Understanding data management fundamentals data storage principles Knowledge distributed systems pertains data storage cloud computing Understanding administration AWS Docker Linux based systems Experience custom ETL design implementation maintenance Experience large scale data processing using traditional distributed systems like Hadoop Spark Dataflow Airflow Knowledge practical experience machine learning AI fundamentals Experience implementing machine learning solutions scale Experience working Batch Real Time data processing systems Ability work communicate effectively stakeholders Opportunity work one fastest growing financial startups country Competitive Salary Equity 401k Company Match Gym Public Transportation Subsidy Student Loan Assistance Relocation Assistance Unlimited PTO", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "Bachelor degree higher quantitative technical field Computer Science Statistics Engineering Working knowledge data design architecture warehousing Understanding data management fundamentals data storage principles Knowledge distributed systems pertains data storage cloud computing Understanding administration AWS Docker Linux based systems Experience custom ETL design implementation maintenance Experience large scale data processing using traditional distributed systems like Hadoop Spark Dataflow Airflow Knowledge practical experience machine learning AI fundamentals Experience implementing machine learning solutions scale Experience working Batch Real Time data processing systems Ability work communicate effectively stakeholders Opportunity work one fastest growing financial startups Competitive salary equity Health dental vision insurance 401K Gym public transportation subsidy Relocation assistance", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "", "Experience SQL databases Graph Databases largest growth No SQL Neo4J currently Data transformation experience scripting Python Java Perl PL SQL platforms Spark Knime Exposure AWS Data Services Experience Architect design implement updates enhancements data repositories indices support data ingest enrichment analysis visualization dissemination", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "Relevant degree equivalent Applied knowledge database architecture concepts within traditional RDBMS environments also memory noSQL virtualised federated approaches columnar streaming databases Strong knowledge concepts OLTP OLAP star snowflake schemas dimensional modelling normalisation Extensive track record performing data engineering domain including Extracting data enterprise systems SAP Security management Data modelling ETL development using tools Data Integrator Services Experience experience scrum agile project management Annual Bonus Plan Discretionary Cash Award Group Personal Pension Plan enhanced company contribution Medical Travel Health Life Insurances Holiday days annual leave option buy additional days per year Sabbatical paid days every four year service Volunteering One paid working day year TeamARM Varies location cycle work free car parking gym site team social events", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "", "Experience areas data driven statistical modeling discriminative methods feature extraction analysis supervised learning", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "career categories", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "Experience building data pipelines analytics systems distributed data systems AWS using spark Experience Scala Python Experience building batch pipelines data event data streams NoSQL APIs Competitive health insurance benefits Competitive salary Annual target bonus commission Paid vacation sick time Vacation rental yearly basis taxable benefit Employee Stock Purchase Program Free snacks beverages Frequent company update talks leadership team Free listing HomeAway com Electronic adjustable stand desk Discounted Metro Rail pass", "", "Identify data sources add value decision making Work source system owners analysts understand source data e g data profiling definition mapping Design implement efficient data loads using traditional structured data ETL techniques Design implement real time near real time data load solutions using technologies like data streaming Design implement unstructured data loads e g text speech images video Design implement load monitoring tools procedures perform continuous monitoring optimising loads Work analysts architect design implement effective efficient data models using appropriate modelling techniques Design implement data warehouse data models Design implement data pipelines ad hoc unstructured data models Design implement appropriate aggregation data structures enhance usability data e g multi dimensional OLAP structures summary tables etc Design implement maintain appropriate indexing tables enhance speed access Design implement data models support automated decision making analytics Continuously search data elements sources enhance existing data objects supplement enhance context Design implement interfaces data access e g batch exports real time decision API etc Design implement interface monitoring management solutions ensure availability accuracy Monitor maintain integrity existing environment troubleshoot technical data issues make appropriate changes required Implement meta data solutions assist understanding managing data Work together business owners analysts IT maintain good data governance Provide technical data related support source system teams external parties exchange data Manage data growth usage designing implementing effective strategies e g archiving indexing Manage systems technology tools enable data management analytics Take ownership work delivering high quality work time Show initiative pre active finding opportunities improve data processes Take ownership career development continuously improving skills knowledge application thereof designing implementing solutions Positive engagement team activities actively contribute ideas improve team dynamics performance Stakeholder management internal external Assist development others e g mentoring knowledge share Quality control work Degree information technology mathematics engineering actuarial science related discipline At least years technical data role preferably formal data data warehouse business intelligence environment SQL Data analysis Data visualisation Data modelling Microsoft business intelligence data technologies SSIS SSAS SQL Server Data warehouse concepts best practices Financial services knowledge specifically personal unsecured loans Business process monitoring optimising Microsoft business intelligence visualisation technologies SSRS Power BI IT infrastructure e g storage networking servers security Unstructured data experience Information gathering problem analysis Applying professional specialist technical expertise Creating innovating Quality Detail orientation Analysing", "BS MS equivalent Computer Science related technical field years software engineering OOP languages years architectural experience developing scalable data pipelines data processing frameworks cloud native distributed computing environment years serving lead data pipeline architect large scale cloud based high volume data processing organization business division Demonstrated experience writing architectural requirements systems design documents Experience designing governing scalable cloud native backend compute capabilities REST APIs microservices distributed computing frameworks geospatial processing indexing messaging frameworks paradigms data quality management Excellent written verbal communication including presentation complex engineering designs concepts solutions clear concise manner technical non technical audiences alike Expertise processing aggregating high volume geospatially oriented IoT data Expertise imagery processing feature extraction satellite aerial sources Depth knowledge Data Operations Data Quality management space Experience layered geospatial data structures data representations Expertise designing implementing highly scalable data intensive distributed computing solutions using modern cloud native processing frameworks Experience Amazon Web Services EC2 S3 RDS SQS etc strongly preferred Experience compiled JVM language including Scala plus Superb medical dental vision life disability benefits 401k matching program A stocked kitchen large assortment snacks drinks get day Encouragement get office field agents farmers see first hand products used Inspire one another Innovate Leave mark world Find possible impossible", "", "", "Extensive experience relational database development particularly Oracle MS SQL server Experience writing optimising stored procedures views transform deliver data Experience using performance monitoring alerting tools Experience scripting automation language Shell Python Familiar ETL processes Interest NoSQL database BigData concepts systems Knowledge SCRUM Agile methodologies Any experience Data Architecture Dimensional Modelling would plus Any experience Markit EDM would plus Knowledge investment management including investment risk would definite plus Good communicator collaborator keen work closely across teams business Take ownership show willingness tackle difficult issues Embrace effectively manage change Get hands providing technical direction problem solving support team Ensure third party development conforms organisation best practice quality standards Demonstrate exceptional problem solving skills intellectual curiosity Show passion innovation continuous improvement initiate efforts implement alternative solutions", "", "", "years data extraction front end report building PHP similar Proficient data access preparation methods using Teradata SQL relational databases Proficient scripting glue languages like PHP Python web technologies like HTML CSS Javascript Strong interpersonal skills verbal written Ability work multiple assignments excellent attention detail Flexibility handle directional changes ability support multiple deadline specific projects maintaining day day business support Driven Self motivated individual experienced working global matrixed fast paced environment Ability comprehensively understand data elements sources relationships Ability establish manage relationships cross functional team environment Apple Equal Opportunity Employer committed inclusion diversity We also take affirmative action offer employment advancement opportunities applicants including minorities women protected veterans individuals disabilities Apple discriminate retaliate applicants inquire disclose discuss compensation applicants", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "Minimum five years data analytics programming database administration data management experience", "", "Degree educated Data Science similar Strong experience data preparation techniques including exploration visualisation Experience statistical models times series analysis multiple machine learning techniques clustering regression classification Strong skills using Python SQL Elastic visualise data surfacing tool Experience developing machine learning systems Experience Amazon Quicksite advantage", "The stated experience level guide preclude applications candidates less experience provided requisite skills demonstrated", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "Bachelors degree Computer Science Computer Engineering Applied Math Statistics related field Certified Data Management Professional CDMP plus years experience designing building maintaining data management systems Broad experience planning architecting delivering mission critical enterprise grade systems solutions Experience cloud architecture data repositories Data design experience Experience data cleansing optimization data consumption Experience source control tools Git TFS plus Experience Net framework Web Services SOAP REST XML plus Experience Azure Service Fabric microservices plus Working familiarity front end web framework using C JavaScript Angular plus Experience using CSV JSON XML data formats Experience developing LOB Line Business Applications well Consumer Websites Experience consumer facing ecommerce mobile systems plus FREE day resort stays cruises anniversary Medical Health Insurance Onsite Wellness Clinic Long Term Disability Life Insurance Dental Vision Coverage 401K Plan Pet Care Insurance Legal Insurance Flexible Spending Accounts FSA Employee Assistance Program Discounted Employee Services dry cleaning nail services massage personal training etc Dedicated Employee Enrichment Recognition Programs", "career categories", "career categories", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "You excellent written verbal communication skills You tenacious relentless determined You curious always learning new technologies rapidly synthesizing new information understanding You self directed capable operating amid ambiguity You poised display excellent judgment prioritizing across difficult tradeoffs You pragmatic letting perfect enemy good", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "Work cool people impact millions daily players", "", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "Experience high level programming languages Java Scala Python Proficiency databases SQL required Proficiency data processing using technologies like Spark Streaming Spark SQL Map Reduce Expertise Hadoop related technologies HDFS Azkaban Oozie Impala Hive Pig Expertise developing big data pipelines using technologies like Kafka Flume Storm Experience large scale data warehousing mining analytic systems Ability work analysts gather requirements translate data engineering tasks", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "years experience data warehouse space years experience working either MapReduce MPP system years experience writing complex SQL ETL processes years experience object oriented programming languages BS BA Technical Field Computer Science Mathematics Knowledge Python Java Experience analyzing data identify deliverables gaps inconsistencies Actively mentored team members careers Experience effectively collaborating communicating complex technical concepts broad variety audiences", "", "Four years development experience working Python Data skills SQL document stores Large scale ETL Apache beam Apache spark High scale Restful Services Cloud experience Google Cloud Platform Azure AWS BSc B Tech Computer Science IT preferred", "Experience Azure Data Factory Data Bricks Data Lake", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "years experience data engineering Expertise various ETL technologies familiar ETL tools You engineered metrics statistical information massive complex datasets e g Hive Spark MLlib Druid Solr Kafka You proficient least one programming language e g Python Scala comfortable developing code within team environment e g git testing code reviews You built robust data analytic pipelines keen eye automate e g Oozie Airflow Have solid understanding relational NoSQL database technologies Experience visualization data mining statistical tools", "", "", "", "You years experience deep understanding data engineering concepts database designs Advanced SQL knowledge working relational data Postgres programming experience Java Python working unstructured data APIs Experience ETL integration tooling DMS Stitch Experience data analysis visualization tools Mode Working knowledge message queuing SNS SQS RabbitMQ stream processing Kinesis Strong communication skills positive attitude empathy Self awareness desire continually improve Desire write maintain clean well tested code base avoiding tech debt Experience business operations tools Salesforce Zuora Hubspot etc Experience Apache Spark General understanding data science machine learning technology landscape Experience AWS services including Lambda DynamoDB etc Competitive salary Employee Stock Option Plan Generous health commuter benefits Dog Friendly Office", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "Commercial client facing project experience including working close knit teams A proven ability clearly communicating complex solutions Data security governance expertise Strong experience traditional data warehousing ETL tools Informatica Talend Pentaho DataStage Experience interest Big Data technologies Hadoop Spark NoSQL DBs Cloud AWS Azure Strong SQL experience optional Python Scala Java R Exceptional attention detail", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "Assist gathering new data sources scale including API calls web scraping Process unstructured structured data use analysis Proficient one common scripting languages Python preferred Experience designing data architecture ground Experience processing large amounts structured unstructured data Extensive AWS Experience", "", "", "", "years experience working data systems years experience data warehousing processing pipelines infrastructure query patterns years experience Spark Hadoop years experience open source ETL frameworks Airflow Luigi similar years experience Python SQL Experience systems data processing Spark Flink Hadoop Airflow storage S3 Kafka ElasticSearch Dynamo MySQL Postgres Experience ELK Experience reading optimizing data schema queries content performance", "years engineering experience years focused architecting data platforms Working experience large scale data warehouse platform Hands experience working either MapReduce Spark Presto MPP system Skilled dimensional data modeling schema design data warehousing Bachelor Degree computer science engineering mathematics related fields equivalent experience Expert SQL knowledge experience optimizing large datasets Masters Degree computer science engineering mathematics related fields equivalent experience", "", "", "career categories", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "career categories", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "career categories", "A curious mind An obsession quality Background Data science Data mining Multivariate statistics Computer vision Machine learning Experience working large scale data sets Solid programming skills including Python C C Experience data visualization presentation familiar data analysis tools Tableau", "", "", "Identify data sources add value decision making Work source system owners analysts understand source data e g data profiling definition mapping Design implement efficient data loads using traditional structured data ETL techniques Design implement real time near real time data load solutions using technologies like data streaming Design implement unstructured data loads e g text speech images video Design implement load monitoring tools procedures perform continuous monitoring optimising loads Work analysts architect design implement effective efficient data models using appropriate modelling techniques Design implement data warehouse data models Design implement data pipelines ad hoc unstructured data models Design implement appropriate aggregation data structures enhance usability data e g multi dimensional OLAP structures summary tables etc Design implement maintain appropriate indexing tables enhance speed access Design implement data models support automated decision making analytics Continuously search data elements sources enhance existing data objects supplement enhance context Design implement interfaces data access e g batch exports real time decision API etc Design implement interface monitoring management solutions ensure availability accuracy Monitor maintain integrity existing environment troubleshoot technical data issues make appropriate changes required Implement meta data solutions assist understanding managing data Work together business owners analysts IT maintain good data governance Provide technical data related support source system teams external parties exchange data Manage data growth usage designing implementing effective strategies e g archiving indexing Manage systems technology tools enable data management analytics Take ownership work delivering high quality work time Show initiative pre active finding opportunities improve data processes Take ownership career development continuously improving skills knowledge application thereof designing implementing solutions Positive engagement team activities actively contribute ideas improve team dynamics performance Stakeholder management internal external Assist development others e g mentoring knowledge share Quality control work Degree information technology mathematics engineering actuarial science related discipline At least years technical data role preferably formal data data warehouse business intelligence environment SQL Data analysis Data visualisation Data modelling Microsoft business intelligence data technologies SSIS SSAS SQL Server Data warehouse concepts best practices Financial services knowledge specifically personal unsecured loans Business process monitoring optimising Microsoft business intelligence visualisation technologies SSRS Power BI IT infrastructure e g storage networking servers security Unstructured data experience Information gathering problem analysis Applying professional specialist technical expertise Creating innovating Quality Detail orientation Analysing", "", "Architect build data pipelines Architect implement data warehouse structure table schemas Develop data models enable end users effectively analyze data Optimize tune data warehouse query performance analytical workloads Identify troubleshoot resolve data quality issues Write complex SQL queries data analysis Design maintain robust data reporting visualization tools based requirements Develop integrations BI tools third party productivity applications years engineering experience Expert SQL preferably across number dialects commonly write Snowflake Redshift PostgreSQL MySQL SQL Server Experience developing software code one programming languages Python Java Scala Ruby Experience managing database data warehouse technologies bonus Redshift Snowflake Experience implementing ETL tools Bonus Stitch Fivetran Matillion Understanding data analytics ecosystem Experience one relevant tools Spark Kafka AWS Glue Amazon Kinesis Sqoop Flume Flink Experience implementing Business Intelligence tools Bonus Looker Experience developing data pipelines scratch", "career categories", "", "", "", "", "", "", "", "", "", "career categories", "Identify data sources add value decision making Work source system owners analysts understand source data e g data profiling definition mapping Design implement efficient data loads using traditional structured data ETL techniques Design implement real time near real time data load solutions using technologies like data streaming Design implement unstructured data loads e g text speech images video Design implement load monitoring tools procedures perform continuous monitoring optimising loads Work analysts architect design implement effective efficient data models using appropriate modelling techniques Design implement data warehouse data models Design implement data pipelines ad hoc unstructured data models Design implement appropriate aggregation data structures enhance usability data e g multi dimensional OLAP structures summary tables etc Design implement maintain appropriate indexing tables enhance speed access Design implement data models support automated decision making analytics Continuously search data elements sources enhance existing data objects supplement enhance context Design implement interfaces data access e g batch exports real time decision API etc Design implement interface monitoring management solutions ensure availability accuracy Monitor maintain integrity existing environment troubleshoot technical data issues make appropriate changes required Implement meta data solutions assist understanding managing data Work together business owners analysts IT maintain good data governance Provide technical data related support source system teams external parties exchange data Manage data growth usage designing implementing effective strategies e g archiving indexing Manage systems technology tools enable data management analytics Take ownership work delivering high quality work time Show initiative pre active finding opportunities improve data processes Take ownership career development continuously improving skills knowledge application thereof designing implementing solutions Positive engagement team activities actively contribute ideas improve team dynamics performance Stakeholder management internal external Assist development others e g mentoring knowledge share Quality control work Degree information technology mathematics engineering actuarial science related discipline At least years technical data role preferably formal data data warehouse business intelligence environment SQL Data analysis Data visualisation Data modelling Microsoft business intelligence data technologies SSIS SSAS SQL Server Data warehouse concepts best practices Financial services knowledge specifically personal unsecured loans Business process monitoring optimising Microsoft business intelligence visualisation technologies SSRS Power BI IT infrastructure e g storage networking servers security Unstructured data experience Information gathering problem analysis Applying professional specialist technical expertise Creating innovating Quality Detail orientation Analysing", "Architect build data pipelines Architect implement data warehouse structure table schemas Develop data models enable end users effectively analyze data Optimize tune data warehouse query performance analytical workloads Identify troubleshoot resolve data quality issues Write complex SQL queries data analysis Design maintain robust data reporting visualization tools based requirements Develop integrations BI tools third party productivity applications years engineering experience Expert SQL preferably across number dialects commonly write Snowflake Redshift PostgreSQL MySQL SQL Server Experience developing software code one programming languages Python Java Scala Ruby Experience managing database data warehouse technologies bonus Redshift Snowflake Experience implementing ETL tools Bonus Stitch Fivetran Matillion Understanding data analytics ecosystem Experience one relevant tools Spark Kafka AWS Glue Amazon Kinesis Sqoop Flume Flink Experience implementing Business Intelligence tools Bonus Looker Experience developing data pipelines scratch", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "", "You love hack things come creative ways approach problems Passionate social consumer applications travel Detail oriented communicates clearly writing conversation years experience integrating variety consumer APIs Comfortable working Packer Terraform update dependencies Experience NLP Named Entity Recognition Machine Learning PHP Rust React Swift Experience building browser plugins scratch Experience Mechanical Turk similar marketplaces Competitive Salary Equity Healthcare Flexible hours Unlimited Vacation Time", "", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark Flink Kafka etc building efficient extraction transformation pipelines scale Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth attitude Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "You excellent written verbal communication skills You curious excellent analytical problem solving skills You excited digging massive petabyte scale semi structured datasets years industry experience working distributed data technologies e g Hadoop MapReduce Spark etc Proficiency least one high level programming language Python Go Java Scala equivalent Experience large complex highly dimensional data sets hands experience SQL You pragmatic letting perfect enemy good You self directed capable operating amidst ambiguity You humble continually growing self awareness possessing growth mindset Extras excited Experience building stream processing applications using Apache Flink Spark Streaming Apache Storm Kafka Streams others", "", "career categories", "Agile Engineering Kanban Lean Hybrid agile experience big plus", "", "", "", "You highly expert battle tested lead core contributor data processing projects Consistent record designing implementing scalable performant data pipelines data services data products This hands position expect write code Programming experience building high quality software Skills Java Python Scala preferred Proficiency Hadoop Kafka Spark MPP No SQL databases like Vertica Redshift Snowflake large scale environment Strong aptitude learning new technologies related Data Management Data Science Demonstrated ability work well independently within fast paced team oriented environment Work noisy dirty unstructured data Data cleansing scraping unstructured data converting structured data Evaluate benchmark improve scalability robustness efficiency performance big data platform applications Experience building reports using Tableau Microstrategy Knowledge engineering machine learning feature engineering systems plus", "", "Design build launch extremely efficient reliable data pipelines move data across number platforms including Data Warehouse online caches real time systems BA BS Degree Computer Science Engineering discipline Statistics Information Systems another quantitative field Action Oriented", "", "", "Strong Java experience mainly Core Java Strong knowledge OOP SQL Hands Google Cloud Platform Dataflow BigQuery Pub Sub Hadoop echosystem experience Hbase Hive Spark Commercial experience Linux Messagedriven architecture experience using ActiveMQ Kafka similar Track record developing technology enable large scale data transformation ETL data load process development Experience dealing large complex data sets Development Testing best practices Maven Git Familiar NoSQL technologies Embrace agile software engineering practices tools TDD Continuous Integration etc Understanding software development lifecycle Agile software design principles build processes Excellent organisation communication interpersonal skills Ability work collaboratively limited supervision Can deliver results within set deadlines Bachelor Java years", "Travel", "", "", "", "Identify data sources add value decision making Work source system owners analysts understand source data e g data profiling definition mapping Design implement efficient data loads using traditional structured data ETL techniques Design implement real time near real time data load solutions using technologies like data streaming Design implement unstructured data loads e g text speech images video Design implement load monitoring tools procedures perform continuous monitoring optimising loads Work analysts architect design implement effective efficient data models using appropriate modelling techniques Design implement data warehouse data models Design implement data pipelines ad hoc unstructured data models Design implement appropriate aggregation data structures enhance usability data e g multi dimensional OLAP structures summary tables etc Design implement maintain appropriate indexing tables enhance speed access Design implement data models support automated decision making analytics Continuously search data elements sources enhance existing data objects supplement enhance context Design implement interfaces data access e g batch exports real time decision API etc Design implement interface monitoring management solutions ensure availability accuracy Design implement data monitoring solutions procedures continuously monitor maintain integrity existing environment troubleshoot technical data issues make appropriate changes required Design implement meta data solutions assist understanding managing data Work together business owners analysts IT maintain good data governance Work together business owners analysts IT manage changes data organisation Provide technical data related support source system teams external parties exchange data Manage data growth usage implementing effective strategies e g archiving indexing Manage systems technology tools enable data management analytics liaise IT infrastructure IT Operations regarding system infrastructure management Take ownership work delivering high quality work time Show initiative pre active finding opportunities improve data processes Take ownership career development continuously improving skills knowledge application thereof designing implementing solutions Positive engagement team activities actively contribute ideas improve team dynamics performance Complex solution service design implementation Cross functional data team knowledge gathering sharing Responsible team activities team dynamics performance Manage project task delivery team Multiple stakeholder management internal external Assist development others e g mentoring knowledge share Quality control work Degree information technology engineering mathematics statistics actuarial related discipline At least years experience working data business intelligence analytics environment SQL Data analysis Data visualisation Data modelling Microsoft business intelligence data technologies SSIS SSAS SQL Server Data warehouse concepts best practices Information gathering problem analysis Applying professional specialist technical expertise Creating innovating Quality Detail orientation Planning organizing Presenting Communicating information Analysing Leadership", "", "", "An open office environment ideas flow among marketers developers product managers support reps sit shoulder shoulder collaborating challenging encouraging", "", "", "Advanced working SQL knowledge experience working relational databases query authoring SQL well working familiarity variety databases Several years experience building optimizing data pipelines architectures data sets Experience performing root cause analysis internal external data processes answer specific business questions identify opportunities improvement Strong analytic skills related working unstructured datasets Build processes supporting data transformation data structures metadata dependency workload management Working knowledge message queuing stream processing highly scalable data stores Experience leading cross functional teams dynamic environment Experience using following software tools years Experience big data tools Hadoop Spark Kafka etc years Experience relational SQL NoSQL databases including Postgres Experience data pipeline workflow management tools years Experience AWS cloud services EC2 EMR RDS Redshift Experience stream processing systems A comprehensive medical dental vision package provided Empire Blue Cross Blue Shield Life disability insurance also included Enrollment 401K plans Once enrolled plan change contributions rate opt time Stock option program Eight company paid holidays calendar year Paid time PTO uncapped accordance Company policy outlined New Hire Orientation", "", "Robust Perks generous PTO 401k contributions tuition assistance entertainment discounts", "", "", "", "Vibrancy Wellness Program Yoga fitness classes onsite massage volunteer opportunities company happy hours product demos outings", "", "", "years experience Data Engineer role Preferred Bachelor Graduate degree Computer Science Statistics Informatics Information Systems another quantitative field commensurate experience Experience using following software tools Intermediate development experience one following Java Python Scala Experience relational SQL NoSQL databases strong knowledge database systems general Foreign keys indexes basic DBA tasks Experience big data tools Intermediate Advanced knowledge Python EMR Spark Lambda plus Working knowledge scripting language Bash Python PowerShell Familiarity Linux Unix environment Experience data pipeline workflow management tools plus Experience stream processing systems plus Willingness roll sleeves analyst work purposes data exploration assessment Demonstrated experience measuring handling large data sets relational databases Communication collaboration project management skills ability distill complex subjects wider audience Creativity flexibility entrepreneurial mindset solution business issues sound business judgment The ability meet exceed deadlines demonstrated sense urgency Clear concise ability communicate complex concepts English OwnershipPerformance Unit Grants Peer Recognition Awards Employee Referral Bonus Program 401k Company Match Free Access Office Health Club Oakbrook Chicago employees Discounted gym memberships BlueCross BlueShield Illinois Medical Prescription Drug Insurance monthly premiums paid employee coverage Dental Insurance monthly premiums paid employee coverage Vision Insurance monthly premiums paid employee coverage Provided No Cost Employees Group Term Life Insurance Long Term Disability Accidental Death Personal Loss Insurance Flexible Spending Accounts Health Care Dependent Care Commuter Benefits Identity Protection Insurance Voluntary Term Life Insurance Group Universal Life Insurance Accident Critical Illness Insurance Paid Time Off Vacation Illness Maternity Paternity Leave Corporate sponsored Activities Events Year Round", "", "", "", "", "Work phenomenal team individuals constantly pushing market boundaries offer healthy food utmost convenience", "Previously healthcare experience highly desirable", "", "", "", "", "Distributed computing principles Legacy modern database architectures Hadoop based technologies e g MapReduce Hive Pig SQL based technologies e g PostgreSQL MySQL NoSQL technologies e g Cassandra MongoDB Stream processing systems e g Storm Spark Streaming ETL tools APIs Optimizing data storage retrieval specific use cases Testing validating accuracy data transformations Cloud computing architectures preferably specific expertise Microsoft Azure AWS Programming multiple programming languages including Python Java Creative problem solving sensitive available time resource constraints Effective listening communication Project managing", "", "SQL Server T SQL SSIS stored procedures user defined functions table functions Managing design risk Software development lifecycles Unit test techniques debugging analytical techniques Help career growth joining industry leader continuing advance Echo web based technologies Working organization defined market goals products customers revenue development teams Experienced mentors learn adopt new practices Ability introduce views takes product offerings Work wide variety data management Ability constantly enhance improve applications Have clearly defined career growth track enough flexibility pave way", "The opportunity work smart people challenging problems", "", "Bachelor Degree Computer Science related field years experience Data Platform Administration Engineering", "Strong knowledge SQL Python Bash Expert database design Experience Git General knowledege Linux server administration BS MS Computer Science Engineering Experience Google Cloud Platform Experience Spark Hadoop stack Interest data science machine learning Career rapidly growing IT Official employment according Labor Code Russian Federation white salary Flexible working day start working days Mn Fr Comfortable cosy office Friendly employees Corporate education trainings seminars conferences Fitness compensation Medical insurance", "", "", "Extensive experience SQL Ruby web services Big Data skills appreciated Experience testing multi tier consumer facing web applications UI level Experience testing batch streaming ETL processes using Spark Beam etc Parsing analysis free form fixed form data sets Good problem solving debugging skills Comfortable working Agile development environment Experience executing API tests Broad experience designing maintaining automated tests whitebox blackbox testing Experience unit testing frameworks RSpec preferred Minitest Test Unit similar Experience libraries used implement browser automation Watir preferred Selenium Capybara etc Knowledge best practices Software Development Life Cycle SLDC Working knowledge JIRA issues project tracking software Experience Git distributed revision control source code management systems Background payments desirable required Experience platforms non functional requirements operating systems Experience performance testing security testing", "Excellent understanding manipulation analysis large complex data sets", "", "", "", "modern tech tools hi tech equipment", "", "Employee referral bonuses get opportunity work friends get extra cash pocket", "A commitment open inclusive diverse work culture", "Upper intermediate knowledge English Proficiency R Java Python numpy scipy matplotlib pandas sklearn Hands experience Kafka ActiveMQ RabbitMQ Kestrel message brokers Cassandra Understanding Hadoop MapReduce MPP systems Apache Storm Spark Amazon AWS Knowledge one several NewSQL solutions Drawntoscale VoltDB SpliceMachine SQLFire Impala Redshift Clustrix NuoDB Hadapt Skills analysis multi dimensional datasets production performance Experience predictive analytics statistical analysis solutions development data mining Knowledge machine learning k NN Naive Bayes SVM GBM etc artificial intelligence AI Experience common data science toolkits R Weka Scikit learn Pandas Proficiency NoSQL strongly desired Proficiency data lakes enterprise data models Hands experience digital twins production processes Proficient Linux relational database design methods efficiently retrieving data A degree applied mathematics computer science physics comparable fields Solid experience custom ETL design implementation maintenance Great business sense understanding business metrics communication skills Experience relevant positions strong plus Knowledge scrum agile waterfall methodologies Ability handle situations numerous unknowns set questions tasks little guidance Willingness dive deep unstructured material find answer yet unknown question Ability clearly communicate findings orally written visually come suggestions advices Be able work fast paced environment \u0413\u0440\u0430\u0444\u0438\u043a \u0440\u0430\u0431\u043e\u0442\u044b \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u043e\u0435 \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u043e C\u043e\u0446\u043f\u0430\u043a\u0435\u0442 \u0423\u0441\u043b\u043e\u0432\u0438\u044f \u043f\u043e \u0437\u0430\u0440\u0430\u0431\u043e\u0442\u043d\u043e\u0439 \u043f\u043b\u0430\u0442\u0435 \u0431\u0443\u0434\u0443\u0442 \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u044b \u043f\u043e \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430\u043c \u0441\u043e\u0431\u0435\u0441\u0435\u0434\u043e\u0432\u0430\u043d\u0438\u044f", "", "", "", "Bachelors degree Computer Engineering Computer Science related discipline Masters Degree preferred years ETL design development performance tuning Microsoft SSIS SQL Server preferable multi dimensional Data Warehousing environment years SSAS design development maintenance performance tuning Microsoft SQL Server preferable expert MDX DAX skills years advanced SQL Programming PL SQL T SQL U SQL years Enterprise Data Analytics solution architecture years Power BI experience including mobile solutions years strong extensive hands experience Azure preferably data heavy analytics applications leveraging relational NoSQL databases Data Warehouse Big Data Experience Azure Data Lake Azure SQL Data Warehouse Data Catalog Azure Analysis Services Data Bricks Storage Account Gen2 Azure SQL Database Azure DNS Virtual Network DocumentDB Azure App Service Data Factory Experience Big Data Technologies Hadoop Sqoop Hive Kafka Spark Pyspark Python Scala Pig Experience Big Data Management BDM relational non relational data formats like json xml avro parquet copybook etc Experience setting operating data pipelines using Python SQL Strong analytical abilities strong intellectual curiosity", "", "Ability work large amounts data Experience map reduce frameworks Hive Hadoop Spark Elastic Map Reduce would plus Strong grasp statistics data modelling designing algorithms Cloud service credits AWS Google Cloud Azure Digital Ocean Public Transit allowance Mobile data allowance Flex days Tea Coffee Bar In office Snacks", "Hackathons", "", "", "", "Analysing problem domains identify entities data flows Designing implementing efficient scalable data models Automating provisioning management data platforms Familiarity RDBMS NoSQL Distributed data technologies End end involvement software delivery Working production systems Ownership product set features within product A range software delivery tools source control agile tools CI etc Implementing following best practices Effective prioritisation tasks personal time management Producing estimates self others Demonstrating initiative Coaching mentoring junior team members Interacting clients product owners Degree computer science related discipline Delivering highly collaborative agile environment Understanding blockchain technologies", "", "", "", "Bachelor degree field Computer Science Mathematics Data Architecture equivalent experience skills Strong development knowledge experience key languages environments Python Scala SQL noSQL databases Advanced data sourcing content management skills Experience time task management Strong attention detail Good written verbal communication skills including ability collaborate across teams Experience mentoring junior team members Master degree Computer Science technical field Strong development knowledge experience Hadoop big data stack e g HDFS Hive Spark etc Demonstrated capability learn new technologies follow industry trends", "", "", "", "", "", "", "", "Work data science teams deliver metrics consumers", "", "", "PhD related discipline least years experience Master degree years experience Bachelor degree experience biomedical data management data engineering quality assurance assay development specimen data management related discipline Demonstrated proficiency molecular biology concepts ability support develop deploy laboratory research data management processes procedures apply complex high dimensional data sets Demonstrated ability understand translate high level scientific datasets results data curation management strategies underlying structures curation processes infrastructure required Strong understanding LIMS systems systematic relational approaches data integration data processing workflows Familiarity Amazon Web Services AWS Excellent skills R programming experience additional computer languages Perl Python PHP S PLUS Java C C Extensive practical experience working diverse highly connected scientific knowledge collections query interfaces enable research hypotheses around compound targets mechanisms action patient response Proven ability work team environment clinical personnel study monitors computational biologists biostatisticians programmers medical writers Knowledge FDA ICH guidelines industry standard practices regarding data management helpful required Detailed knowledge experience case report form design central laboratories programming databases query resolution data validation Computer skills detailed knowledge least one data management system Oracle Clinical Clintrial preferred experience SAS data sets conversion procedures required knowledge MS Office program suite required Knowledge distributed database design implementation LAMP MySQL etc capability perform direct assess implementation databases Working knowledge Windows Linux operating systems required Along programming proficiency must creativity show strong capacity independent thinking ability grasp underlying biological questions Must thrive complex dynamic environment adapting dynamically changing priorities Must excellent time management organizational skills", "years experience software engineering related field Extensive experience working stack Python PostgreSQL AWS something similar BA BS degree computer science engineering degree Ability quickly learn understand work new emerging technologies methodologies solutions Experience building managing production quality ML models plus Growth company DNA thrives fast paced environment shares excitement lead change", "PhD related discipline least years experience Master degree years experience Bachelor degree experience biomedical data management data engineering quality assurance assay development specimen data management related discipline Demonstrated proficiency molecular biology concepts ability support develop deploy laboratory research data management processes procedures apply complex high dimensional data sets Demonstrated ability understand translate high level scientific datasets results data curation management strategies underlying structures curation processes infrastructure required Strong understanding LIMS systems systematic relational approaches data integration data processing workflows Familiarity Amazon Web Services AWS Excellent skills R programming experience additional computer languages Perl Python PHP S PLUS Java C C Extensive practical experience working diverse highly connected scientific knowledge collections query interfaces enable research hypotheses around compound targets mechanisms action patient response Proven ability work team environment clinical personnel study monitors computational biologists biostatisticians programmers medical writers Knowledge FDA ICH guidelines industry standard practices regarding data management helpful required Detailed knowledge experience case report form design central laboratories programming databases query resolution data validation Computer skills detailed knowledge least one data management system Oracle Clinical Clintrial preferred experience SAS data sets conversion procedures required knowledge MS Office program suite required Knowledge distributed database design implementation LAMP MySQL etc capability perform direct assess implementation databases Working knowledge Windows Linux operating systems required Along programming proficiency must creativity show strong capacity independent thinking ability grasp underlying biological questions Must thrive complex dynamic environment adapting dynamically changing priorities Must excellent time management organizational skills", "Experience integration data multiple data sources", "Healthy Wellness programs competitive medical benefit offerings Happy Recognition programs confidential employee assistance program Perkspot employee discount program potentially flexible work arrangements staggered start times Enriched Tuition reimbursement training learning programs leadership development opportunities", "", "", "", "BS BA MS plus Computer Science Information Systems Engineering related field years experience equivalent training Experience working enterprise cloud database systems like MySQL MongoDB Oracle MSSQL Hadoop In depth knowledge Mac OS X system Strong proficiency PHP preferable years hands experience Fluency bash python scripting languages significant automation experience Proficient scripting languages PHP Python Ruby Rails NodeJS Java etc Experience designing developing programming API solutions integration various client end points including native applications Desire build lead rapid development team project definition scoping estimating planning development testing launch Strong preference someone done Up date current industry trends third party integration open source tools regard database design integration data storage analysis security implementation Strong analytical skills Excellent work ethic meticulous attention detail", "", "", "Bachelors degree Computer Engineering Computer Science related discipline Masters Degree preferred years ETL design development performance tuning Microsoft SSIS SQL Server preferable multi dimensional Data Warehousing environment years SSAS design development maintenance performance tuning Microsoft SQL Server preferable expert MDX DAX skills years advanced SQL Programming PL SQL T SQL U SQL years Enterprise Data Analytics solution architecture years Power BI experience including mobile solutions years strong extensive hands experience Azure preferably data heavy analytics applications leveraging relational NoSQL databases Data Warehouse Big Data Experience Azure Data Lake Azure SQL Data Warehouse Data Catalog Azure Analysis Services Data Bricks Storage Account Gen2 Azure SQL Database Azure DNS Virtual Network DocumentDB Azure App Service Data Factory Experience Big Data Technologies Hadoop Sqoop Hive Kafka Spark Pyspark Python Scala Pig Experience Big Data Management BDM relational non relational data formats like json xml avro parquet copybook etc Experience setting operating data pipelines using Python SQL Strong analytical abilities strong intellectual curiosity", "", "PhD related discipline least years experience Master degree years experience Bachelor degree experience biomedical data management data engineering quality assurance assay development specimen data management related discipline Demonstrated proficiency molecular biology concepts ability support develop deploy laboratory research data management processes procedures apply complex high dimensional data sets Demonstrated ability understand translate high level scientific datasets results data curation management strategies underlying structures curation processes infrastructure required Strong understanding LIMS systems systematic relational approaches data integration data processing workflows Familiarity Amazon Web Services AWS Excellent skills R programming experience additional computer languages Perl Python PHP S PLUS Java C C Extensive practical experience working diverse highly connected scientific knowledge collections query interfaces enable research hypotheses around compound targets mechanisms action patient response Proven ability work team environment clinical personnel study monitors computational biologists biostatisticians programmers medical writers Knowledge FDA ICH guidelines industry standard practices regarding data management helpful required Detailed knowledge experience case report form design central laboratories programming databases query resolution data validation Computer skills detailed knowledge least one data management system Oracle Clinical Clintrial preferred experience SAS data sets conversion procedures required knowledge MS Office program suite required Knowledge distributed database design implementation LAMP MySQL etc capability perform direct assess implementation databases Working knowledge Windows Linux operating systems required Along programming proficiency must creativity show strong capacity independent thinking ability grasp underlying biological questions Must thrive complex dynamic environment adapting dynamically changing priorities Must excellent time management organizational skills", "", "", "", "", "", "", "", "", "Live GoHealth Culture ensure represented within team Design develop deploy optimal extraction transformation loading data various GoHealth external data sources Monitor execute report data pipeline tasks working appropriate teams take corrective action quickly case issues Perform unit testing system integration testing assist user acceptance testing Adapt data components accommodate changes source data new business requirements Create maintain documentation technical detail design operational support maintenance procedures data pipeline tasks Ensure data quality compliance development architecture reporting regulatory standards throughout entire data pipeline Collaborate rest Data Engineering Team subject matter experts department leaders understand analyze build deliver new data related processes reports Ability work rest Data Engineering Team cross train provide support various data engineering tasks Bachelor Degree computer science equivalent experience required years experience design development data pipelines tasks Strong analytical problem solving ability strong attention detail accuracy Good understanding data warehousing concepts dimensional data modeling Hands experience troubleshooting performance issues fine tuning SQL queries Experience Python including modules libraries pandas numpy Flask scikit learn sci py Proven experience extracting data structured data sources SQL Excel CSV files Couchbase unstructured data sources Splunk log files premise cloud Experience consuming data web services REST SOAP HTML XML JSON Knowledge version control systems using Git Bitbucket SVN Team Foundation Ability handle multiple tasks adapt evolving business technical environments Self starter ability work independently take initiative learn new skills Excellent written oral communication skills ability articulate complex processes individuals varying technical abilities Experience software engineering practices required Experience Microsoft SQL Server SSIS SSRS Power BI Azure preferred required Familiar data warehouse platforms like AWS Redshift AWS Data Pipeline Join team daily meeting includes data engineers data scientists data analysts Review open git pull requests JIRA tickets Airflow DAG runs Work Data Engineering team various teams following Analyzing designing implementing Airflow DAGs Operators RESTful services integration external internal RESTful services e g Hubspot Five9 etc Troubleshooting issues resolving Airflow SSIS Tableau SQL Server SSRS AWS MySQL Couchbase etc Design implement evolve GoHealth data pipelines Tableau data sources data extracts build test automation Jenkins python bash gradle etc Participate lead Demo Wednesdays Release Thursdays Join weekly Data Engineering team meeting review roadmap progress projects Open vacation policy 401k match program Medical life dental vision benefits Flexible spending accounts Subsidized gym memberships Commuter transit benefits Professional growth opportunities Casual dress code Generous employee referral bonuses Happy hours ping pong tournaments company sponsored events GoHealth Equal Opportunity Employer", "Track record successfully executing projects multiple partners", "", "", "", "Knowledge sharing activities", "years data engineering backend development experience Python Experience technologies like Hadoop Spark Hive Presto NiFi Luigi AWS experience preferred Data modeling experience preferred Scala Java experience preferred You pragmatic engineer help execute also provide strong voice technological direction systems Avant You passion data empowering business You excited evaluating automating new technologies You entrepreneurial self driven take pride improving user experiences You strong knowledge Software Engineering Data fundamentals well DevOps best practices You thrive collaborative environment involving different stakeholders subject matter experts enjoys working diverse group people different expertise", "Bachelor degree relevant discipline least years experience Master degree least years experience PhD least years experience biomedical data management assay development specimen data management related discipline Demonstrated proficiency molecular biology assay concepts ability support develop deploy laboratory research data management processes procedures apply complex high dimensional data sets Extensive practical experience curating working diverse highly connected scientific knowledge collections query interfaces enable research hypotheses around compound targets mechanisms action patient response Demonstrated ability understand translate high level scientific datasets results data curation management strategies Proven ability work team environment clinical personnel operational personnel study monitors computational biologists biostatisticians programmers medical writers Demonstrated proficiency current software engineering methodologies Agile source control project management issue tracking Working knowledge cloud computing Preference given candidates AWS experience Working knowledge Rest APIs container strategies strongly preferred Knowledge distributed database design implementation LAMP MySQL etc capability perform direct assess implementation databases Strong understanding LIMS systems systematic relational approaches data integration data processing workflows Excellent skills R programming experience additional computer languages Perl Python PHP S PLUS Java C C Experience producing visualization data sets eg R shiny Spotfire etc Working knowledge Windows Linux operating systems required Along programming proficiency must creativity show strong capacity independent thinking ability grasp underlying biological questions Must thrive complex dynamic environment adapting dynamically changing priorities Must excellent written verbal communication presentation skills Must excellent time management organizational skills", "Ingestion pipelines ETL using technologies like Kafka Apache Spark Experience big data technologies Hadoop Kafka Akka Mesos similar highly desirable Microservices design implementation REST JSON must Experience ElasticSearch highly desirable Experience Semantic Web RDF OWL SPARQL Linked Data highly desirable Experience large scale production databases Experience graph database highly desirable Neo4J Neptune Any experience commercial search engines may advantageous Pair programming experience Scrum agile experience Kanban agile experience JIRA experience Release search applications cloud environment ideally blue green deployments Experience working across matrixed distributed international organization AWS system administration Release processes dev ops", "", "", "Proficient understanding distributed computing principles Management Hadoop cluster included services unless going specific Big Data DevOps roles Ability solve ongoing issues operating cluster unless going specific Big Data DevOps roles Proficiency Hadoop v2 MapReduce HDFS Experience building stream processing systems using solutions Storm Spark Streaming stream processing relevant role Good knowledge Big Data querying tools Pig Hive Impala Experience Spark including planning include Experience integration data multiple data sources Experience NoSQL databases HBase Cassandra MongoDB Knowledge various ETL techniques frameworks Flume Experience various messaging systems Kafka RabbitMQ Experience Big Data ML toolkits Mahout SparkML H2O going integrate Machine Learning Big Data infrastructure Good understanding Lambda Architecture along advantages drawbacks Experience Cloudera MapR Hortonworks specify distribution currently using planning use List technologies using planning use Most Big Data Engineers know ones listed The Hadoop Ecosystem Table List education level certification require", "Hadoop Spark Google Cloud Dataflow Kafka Kinesis AWS Google Pub Sub GCP Elasticsearch BigQuery Other distributed SQL NoSSQL databases Python Scala Golang R year experience provisioned demand cloud computing platforms GCP AWS Azure year experience standard development tooling e g Git Jira etc Knowledge distributed computing fundamentals ability design scalability Linux platforms Some experience machine learning algorithms libraries e g scikit learn A bachelor degree relevant technical field Computer Science Mathematics Statistics similarly relevant engineering computational discipline Data analytics modeling experience Strong mathematical statistical analysis skills", "", "", "years experience data engineering constructing maintaining databases data pipelines year experience creating supporting production databases year experience working data lake environment Experience collecting transforming storing large amounts data Bachelor degree experience working data engineering OR Bachelor degree Master degree computer science field Computer Science Information Sciences Informatics Experience creating data pipelines machine learning Data management certifications Strong knowledge SQL NoSQL database technologies Strong knowledge least one scripting language Java Python Knowledge Hadoop Spark big data processing frameworks Submit Staff Vacancy Application Submit Voluntary Self Identification Disability forms Upload cover letter resume months years employment must included academic credentials unofficial transcripts diploma may acceptable names contact information three references", "", "Relevant degree work experience", "", "", "", "This full time exempt position", "", "", "", "", "", "Bonus points bring real world experience AWS EMR E2 Kinesis S3", "Distributed computing principles Legacy modern database architectures Hadoop based technologies e g MapReduce Hive Pig SQL based technologies e g PostgreSQL MySQL NoSQL technologies e g Cassandra MongoDB Stream processing systems e g Storm Spark Streaming ETL tools APIs Optimizing data storage retrieval specific use cases Testing validating accuracy data transformations Cloud computing architectures preferably specific expertise Microsoft Azure AWS Creative problem solving sensitive available time resource constraints Effective listening communication", "Demonstrate strong understanding development processes agile methodologies", "", "You undergraduate graduate degree computer science similar technical field sound understanding statistics You years industry experience data engineer You hands experience ETL written data pipelines either Spark MapReduce You sound understanding SQL CQL You worked data lakes S3 HDFS You worked various databases Postgres Cassandra Redshift understand pros cons You working knowledge following technologies afraid picking fly Mesos Chronos cron Marathon Jenkins You fluent least one scripting language preferably NodeJS python one compiled language Scala Java C You great communication skills ability work others", "", "", "", "", "Data serialization JSON avro parquet", "Building Cube Cube like products", "", "", "", "", "Cluster managers eg Docker Apache Mesos Kubernetes", "401k retirement savings plan", "", "", "", "", "", "Daily catered lunches LA best restaurants fully stocked kitchen", "Indemnity according profile", "Ability work successfully 3rd party vendors support application enhancements troubleshoot problems required meet business processes priorities", "", "Excellent experience Amazon Web Services AWS Strong coding skills Python Java Demonstrable experience messaging queue technology Apache Kafka similar Hands experience real time systems production stage years post academic experience data engineering capacity Experience Docker Apache Spark ElasticSearch", "Google Analytics", "", "Agile Scrum working practices", "", "", "Bachelors years experience Masters degree years experience Experience proficiency Scala Experience proficiency Spark A deep understanding machine learning interest applying scale Experience data cleaning preparation feature building selection techniques Experience working large data sets solve problems Effective communication interpersonal teamwork skills Ability handle multiple concurrent projects working independently teams Ability work fast paced deadline driven environment Experience hierarchical models random effect models online learning", "", "", "", "Performs duties assigned", "", "", "", "", "", "Bachelor Degree years Information Technology experience OR Technical Certification College Courses years Information Technology experience OR years Information Technology experience Proficiency domain driven design domain modeling Experience NoSql solutions Gemfire Cassandra HBase Distributed Caching Experience relational database system limited MySQL SQL Server Oracle PostgreSQL Communicate written verbal form effectively CI CD tools Jenkins Concourse Ansible CA", "", "All persons employed Baltimore County Public Schools regular temporary required fingerprinted criminal background investigation State Maryland Senate Bill effective October completed The fee charged fingerprinting An identification card issued must shown prior employment Anyone offered employment required provide proper identification documentation eligibility employment US If military experience asked provide copy DD214 Official transcripts higher education must received prior contract signing Some positions require employees undergo physical examination drug testing All newly hired personnel must attend Badges Benefits session Additional job verification required salary credit", "", "Fluent English years experience working Java Scala Object Oriented language Strong Object Oriented experience true passion writing high quality code Experience quick prototyping ability work dynamic environment Experience NoSQL databases MongoDB etc Experience API based architecture Experience distributed framework parallel processing Hadoop Pig Spark Hive Strong experience Java Scala plus Experience large scale data distributed systems Ability work independently strong part team Experience real time applications plus Very attractive compensation package including equity Have real impact Awesome work environment company huge vision Be right start success story Relaxed fun work environment flexible working hours Extras like catered lunch gym membership private health insurance", "A good understanding adherence data security standards", "", "", "years experience least one following Google Cloud Dataflow Google PubSub Elasticsearch Spark Any following plus Hadoop Kafka Kinesis BigQuery Other distributed SQL NoSSQL databases years experience least one following Python Golang Clojure R year experience provisioned demand cloud computing platforms GCP AWS Azure year experience standard development tooling e g Git Jira etc Knowledge distributed computing fundamentals ability design scalability Linux platforms", "Google Analytics", "", "", "", "", "", "", "Their current tech stack includes Python Go AWS Spark GraphDB Docker Kubernetes Jenkins JSON Git Extensive experience developing data solutions AWS Experience building data vision strategy together upper management Previous experience within FinTech related area plus", "", "", "", "", "", "", "", "", "A workplace recognized Best Consumer Web Company Built Chicago Top Company Culture Entrepreneur Top Workplace Chicago Tribune one Chicago Best Places Work Women Under Crain Chicago Business", "Power BI skills", "Excellent experience Amazon Web Services AWS Strong coding skills Python Java Demonstrable experience messaging queue technology Apache Kafka similar Hands experience real time systems production stage years post academic experience data engineering capacity Experience Docker Apache Spark ElasticSearch", "Experience HTTP REST SSL identity authentication", "", "", "Comfortable building maintaining data infrastructure cloud", "", "years", "Spontaneous nerf gun wars wake Thursday happy hours wind", "", "Excellent verbal written communication skills", "Experience Big Data analytics systems Hadoop Storm Spark etc Years back end web services programming Java PHP Years database work mysql Postgres RedShift Experience using Amazon Web Services plus Experience scalable systems load balanced environment plus B S Computer Science Object Oriented Programming Python Java Database Technologies Redshift Postgres Spark Presto Amazon Web Services S3 SQS Kinesis ECS ECR EMR", "Bachelor degree MIS Computer Science related field accredited college university equivalent year developing ETL processes using enterprise tools SAP Data Services Talend Informatica year working relational databases developing complex SQL Experience cloud native databases development tools Familiarity memory databases SAP HANA Proven ability collaborate cross functional teams System availability Data Availability Data Quality", "", "Advanced degree computer science information systems closely related field years hands experience software engineering IT infrastructure role Advanced knowledge Hadoop stack prior experience Hive Pig HBase Impala Sqoop Advanced knowledge object oriented programming distributed systems software design principles Advanced knowledge database maintenance administration using MS SQL Server Strong programming experience Java Python R Hands experience Microsoft Azure Amazon EC2 cloud platform Demonstrated ability design implement ETL workflows across Windows Linux environments Should highly motivated individual ability work effectively people across levels organization Position requires ability travel Nice programming experience C SAS JavaScript Experienced RDBMS systems like Oracle Database IBM DB2 MySQL Experienced NoSQL systems like MongoDB Redis Cassandra Experienced Apache Spark", "", "", "", "Share success Given hard promote change industry celebrate success along way", "", "Google Analytics", "Experienced data modeling ETL development data warehousing Experience various AWS services including RDS redshift S3 Experience consuming cleaning data third party APIs sources Experience Big Data technologies Hive Hadoop Spark Strong organizational analytical skills ability extract meaning data Strong communication skills interact stakeholders customers Strong experience Python similar languages plus", "", "", "", "Inspire offers competitive compensation equity packages plus benefits health vision life dental insurance Not mention unlimited vacation k plan LOTS cupcakes", "", "A collaborative nature entrepreneurial spirit Prior startup experience huge plus", "", "", "", "", "", "Are excited hear", "MSSQL server SQL query Microsoft Excel Embrace VBA project Develop internal tools utilities Set unit test strategy develop Improve code performance Participate innovation process VBA language Microsoft Excel Unit test strategy Object oriented programming Software versioning revision control SVN Familiarity Windows Mac OS cross platform development Continuous integration environment Jenkins Embrace C project Visual Studio XCode Develop internal tools utilities Set unit test strategy develop Improve C architecture performance Lead statistical developers improving C code Participate innovation process OOP C C Visual studio XCode higher Software versioning revision control SVN C unit test strategy HPC multi threading COM object Familiarity design pattern Continuous integration environment Jenkins m2 office space doctors data scientists developers specializing mathematics statistics people total spread floors place XLSTAT www xlstat com About Addinsoft www addinsoft com", "", "", "", "Bachelor degree accredited college university Computer Science Computer Engineering Engineering related field seven years experience Master degree five years experience PhD two years experience Fluency several programming languages Python Scala Java ability pick new languages technologies quickly Understanding cloud distributed systems principles including load balancing networks scaling memory vs disk Experience Large Scale Big Data methods MapReduce Hadoop Spark Hive Impala Storm Strong written verbal communication skills ability work dynamic team environments multi task effectively", "Google Analytics", "", "", "", "", "Are excited hear", "", "At least three years working Data Engineer ideally involved setting data infrastructure storage cloud even better GCP Experience building production level Python applications data modelling using SQL Comfort delivering automated reports data visualisation solutions using tools like Tableau full stack ness comes play An autonomous mindset given mandate design implement modern data solutions choosing You challenge", "", "LI PA1", "", "Working truly global company offices countries", "Monthly team outings Ball games happy hours hikes etc", "", "", "At least years experience developing business intelligence solutions using Tableau Experience tools SSRS Cognos Microstrategy QlikView Spotfire etc plus Familiarity least two different database platforms Teradata Oracle MS SQL server platforms Teradata MS SQL strongly preferred Extremely strong SQL skills Dimensional data modeling skills Hands experience ETL development plus Excellent interpersonal team management facilitation communication skills must able communicate effectively levels client organization Competitive salary performance based bonus opportunities Single Family Health Insurance plans including Dental coverage Short Term Long Term disability Matching k Competitive Paid Time Off Training Certification opportunities eligible expense reimbursement Team building social activities Mentor program help develop career", ""], "extra": [{}, {"Healthcare": 0.17714833045962328}, {"data Ability": 0.12416962942767902, "Medical dental vision insurance Life disability coverage": 0.10845165484730476, "401K Flexible Spending Accounts Apple equipment Daily breakfast lunch dinner": 0.09222474599876147, "graduation date": 0.07829022071220104, "Competitive": 0.05632088217963122, "Tableau": 0.052011858121540175, "backgrounds": 0.03757879669362854}, {}, {"novel biomarkers dissect gene disease relationships": 0.10698435987976905, "Strong interested biology immunological diseases": 0.10455017953987247, "Excellent interpersonal team skills": 0.10418554407274896, "Experience Bayesian analysis causal inference": 0.10097727914992641, "PhD MS computational biology computer science statistics": 0.10005977968227556, "benchmark apply predictive algorithms": 0.0943022066955192, "AI machine learning methods": 0.09191081306286868, "non linear regression models": 0.08681521612443001, "dimensionality reduction clustering": 0.08423055574365479, "data R": 0.07701529632244157, "Immunology Inflammation": 0.07254650006554561, "Proficiency": 0.06689141383341198, "Bayesian": 0.0583871847470735, "Ability": 0.058173332388479854, "hypotheses": 0.05730555011327086, "AI": 0.056957448293938236, "Excellent": 0.05571825450847092}, {"relevant work experience": 0.10932643615057941, "depth knowledge": 0.14398003107916382, "neural networks": 0.06638864503340897, "Bachelor degree": 0.061204395307126416, "Minimum years": 0.11243411328760236, "Hadoop Spark": 0.05149081715526703, "Proficiency R": 0.05025174519454988, "data": 0.04910794568196587, "scikit": 0.0384191856805612, "Hadoop": 0.07299086676325034}, {"Experience": 0.11499064280711913, "Java Scala Python": 0.07718804695954314, "production environments": 0.07688911614495422, "analytical techniques": 0.07516915267683284, "Software": 0.06704924444131254, "Self": 0.049448559837396176, "algorithms": 0.048411702719644144}, {}, {}, {}, {"Bachelor degree": 0.06608106524044824, "Minimum years": 0.17592452599722347, "Experience": 0.10708496383824495, "algorithms": 0.05384192189160731, "Experiences": 0.10708496383824495, "computing frameworks": 0.0898405989260963, "actionable insights": 0.08510793731436689, "Python Java R": 0.15659649942054257, "Deep learning": 0.14664325366376615, "PhD": 0.05101596691088396, "Master": 0.023538470791261177}, {}, {}, {"Master Degree PhD Experience working AWS": 0.19843166060319534, "Master Degree PhD": 0.18029300714996951, "Degree PhD": 0.16197554092174848, "large scale data analysis": 0.15511201296367802, "At least year experience open source programming languages": 0.14571980964507927, "Python Scala R": 0.14459951299551801, "At least year experience machine": 0.13839454682407448, "At least years experience machine": 0.13839454682407448, "data analytics": 0.13093535624071054, "Bachelor Degree": 0.1250288744093708, "At least year": 0.10092133141642518, "At least years": 0.20184266283285035}, {}, {}, {}, {}, {"novel biomarkers dissect gene disease relationships": 0.1065103798625192, "Strong interested biology immunological diseases": 0.10564280693609536, "Excellent interpersonal team skills": 0.10364283708197375, "Experience Bayesian analysis causal inference": 0.10070529327716927, "PhD MS computational biology computer science statistics": 0.10031847795468746, "benchmark apply predictive algorithms": 0.09371343687011452, "AI machine learning methods": 0.09140096782922574, "non linear regression models": 0.08646858566202387, "dimensionality reduction clustering": 0.08381291316646461, "data R": 0.06689168350250484, "Immunology Inflammation": 0.07261293106990085, "Proficiency": 0.06692141554542581, "Bayesian": 0.05810611267643973, "Ability": 0.05783106178615456, "hypotheses": 0.05709353907915304, "AI": 0.056654075760545354, "Excellent": 0.05554344627461939}, {"Good English language skills": 0.23831630413576207, "Computer Science related degree years related work experience Experience working Open Source project": 0.2177852120492239, "English": 0.13250317337675863}, {"Spark": 0.07373431048907042, "ability": 0.0583089063539134, "Java Scala": 0.041624004984308106, "Python Java": 0.03565345172054076}, {}, {}, {}, {}, {"strong baselines ability": 0.12157930419585478, "experimental analytic plans data modeling processes": 0.12152421354707506, "Demonstrable track record": 0.10725866858554156, "results": 0.09803319929009362, "well ambiguity": 0.09603790016542696, "effect relations": 0.09455180724241954, "hands": 0.0641682363415909}, {}, {"Drilling Completion Production Operations": 0.6004398931859963, "Upstream oil gas industry experience": 0.18960624429787884}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {"PhD": 0.19131532291202843, "Master Degree PhD": 0.14695474689955715, "Degree PhD": 0.13201101232992216, "large scale data analysis": 0.1501302129082214, "At least year experience open source programming languages": 0.15344665313791592, "Python Scala R": 0.13752825145843411, "At least year experience machine": 0.1493030670392931, "data analytics": 0.13979316458105856, "Bachelor Degree": 0.10503710203514639, "At least year": 0.3499482879811745, "At least years": 0.4665977173082327, "year experience data analytics": 0.2188752727618717, "At least year experience": 0.14256230707935622, "Master Degree": 0.1321409191224797, "Degree": 0.10224912030518302, "machine": 0.08829576568085411, "SQL": 0.15154562288715193, "AWS": 0.072450216325384}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {"Tableau": 0.29499743629328806, "tools Tableau": 0.3498759579292246, "Experience Data Visualizaiton": 0.2340164370673894, "Experience Data": 0.19418352986099446, "Visualizaiton": 0.1749217208134885}, {"BA Computer Science Engineering relevant field graduate degree Data Science quantitative field": 0.19992961383919514, "Strong math skills": 0.14560880942882218, "Excellent communication presentation": 0.11192827048512666}, {}, {}, {"Excellent": 0.07532999633388258, "English": 0.08584777810152168, "Basic knowledge web development Experience data work\ufb02ow management tools advantage Experience big data cloud computing advantage": 0.16482328316843017, "R Python Linux Experience systems biology research data": 0.14233496780874647, "PhD bioinformatics computer science similar experience Experience relational database management systems": 0.1363824907210576, "Ability work team": 0.10786238297731261, "goals": 0.07386613899385822}, {"consistent research institutes": 0.3466800150008662, "Employment payment social benefits": 0.2396672665936658}, {}, {}, {}, {"scikit": 0.06446254281149151, "able work": 0.13435899580084953, "Excellent understanding machine": 0.11103912051737216, "techniques": 0.07783579925814488}, {}, {}, {}, {}, {}, {}, {"Tableau": 0.06282158639855802, "ability": 0.06223908004332709, "data mining machine": 0.1039822465552801, "SQL Oracle": 0.16238324044077962, "large amounts": 0.07837673055866912, "Possess": 0.05785761782596446}, {}, {}, {}, {"data": 0.16569875222855443, "media mix": 0.19879140223445313, "visualization": 0.1821150341259923, "multi touch attribution": 0.16997431481007577}, {}, {}, {"Ability": 0.05173314010426464, "PhD": 0.1081394259897659, "data science": 0.09476000972077436, "data scientists": 0.0833827647365057, "problems": 0.06773463158860583, "customers": 0.05343728225329194, "Masters": 0.052708442548986524}, {}, {}, {}, {"bars": 0.33592266913231045, "Social environment": 0.2601864215065202}, {}, {"Fluency English": 0.039891855586046784}, {"hard questions data": 0.11701614075486663, "complex ideas": 0.07856296627780977, "skills": 0.06740303131664434, "The ability": 0.035044059805881406}, {}, {}, {}, {}, {}, {"results": 0.04893267554450265, "industry experience": 0.11224465263828681, "AI ML": 0.35643300832394625, "NLP": 0.05356827176323383}, {}, {"Experience cleaning visualizing data": 0.22007530695967087, "Mathematics Statistics Physics Computer Science Engineering Background": 0.349053710359966, "algebra multivariable calculus": 0.1731698611979051, "Experience Python": 0.31889173546064686}, {"Proficiency": 0.12618799452212387, "Python R": 0.18294366299242354, "Oracle graph": 0.14236067889104292}, {}, {"Hadoop Spark": 0.08505921202710723, "machine": 0.06940964418806782, "SQL": 0.06722745808298143, "techniques ability": 0.10844251997838761, "Proven ability": 0.10506869869041388, "Math": 0.05209239907757467}, {"Knowledge immunology tumor immunology tumor biology genetics Proficiency Python R": 0.16167789142239433, "D degree Bioinformatics Computer Science Biostatistics Applied": 0.15923232223466136, "Ph D degree Bioinformatics Computer Science Biostatistics": 0.13824267337182264}, {}, {"data": 0.08197013670687313, "visualization": 0.041900625713690035, "Proven ability": 0.21454382120619808, "environment": 0.1262591266336017, "problem": 0.06281150190008453, "Agile": 0.04369039633482256, "Expertise": 0.04300093792295871, "Proven": 0.08116957138235463, "Python": 0.03753261675720237, "time": 0.0354460175338695}, {}, {"Minimum years": 0.09963021572526244, "PhD": 0.1583400406748614, "predictive analytics multivariate testing optimization algorithms": 0.15591583320027025, "Working knowledge upstream data Experience analytical simulation tools field": 0.15114778386321365}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"Restaurant Retail industry experience": 0.3117268033405843}, {"The Best Jobs Retail Time Holiday Shopping Jobs Rated Report": 0.2343905708617411, "The Jobs Rated Report The Best Jobs The Toughest Jobs Fill": 0.1769530140550504, "The Jobs Rated Report": 0.1683909264507124, "The Best Jobs Advertising": 0.16214011579751963, "The Toughest Jobs Fill": 0.16061517799306704, "The Best Jobs": 0.2935182493112787}, {}, {"Tableau": 0.05888377151940974, "analytic processes": 0.08397758235429138, "best practices": 0.07745970556311262, "BI": 0.06460227518255818, "industry": 0.058970832858079456, "Working": 0.05781362977440286, "recommendations": 0.05339807678077599, "Complex": 0.04518287947738715}, {"neural networks": 0.051525332033759835, "PhD": 0.040435254804637624, "techniques": 0.036342856457391944, "visualization": 0.03790281766883818, "Python": 0.10397537816264904, "AI Machine Learning": 0.2575289673915155, "Machine Learning": 0.11397853094899552, "Deep Learning": 0.10508111009833966, "Deep": 0.05215951323839246, "Git": 0.0808812942497943, "GPU": 0.07947838620781895}, {}, {}, {"Experience Looker Tableau data visualization software": 0.27853404319695196, "statistical analysis techniques": 0.2205415644182886, "experimental design data": 0.18865742492708354}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"Experience": 0.08664088672633324, "techniques": 0.07928340740765676, "complex analytical concepts": 0.10560553831154926, "business problems": 0.07548263825158424, "NoSQL": 0.06737444820736346, "Knowledge": 0.06568831140219202, "people": 0.0641866521840512, "year": 0.04468412485788866, "R Python": 0.04084516297734857, "ML": 0.0367935467276339}, {"Minimum years": 0.0888917382419235, "analytics development industrial applications commercial industrial setting": 0.20146086491950357, "college university Ph D STEM field Science Technology Engineering Math": 0.16276120963515064, "Demonstrated skill feature extraction realtime analytics development deployment": 0.16149134514669364, "Science Technology Engineering Math": 0.3024280574620259, "Bachelor Degree STEM field Science Technology Engineering Math": 0.15116784021612512, "Desired Characteristics Master Degree STEM field Science Technology Engineering Math": 0.14383318217334004, "Demonstrated skill data management methods": 0.13941544371985926, "college university Minimum years": 0.13334998736946443, "college university": 0.12959855494475503}, {}, {}, {"Ability": 0.20445871266611615, "move equipment pounds assistance Ability": 0.13737960905536156, "operations equipment": 0.12997752747448055, "hours": 0.04065356128746521}, {}, {}, {"Tableau": 0.044618747368805806, "PhD": 0.02034775223985317, "goals": 0.04421142448626217, "Expertise": 0.04231440718361365, "Proven": 0.04810326812635421, "Deep": 0.12398408358392254, "ML": 0.12214347454137842, "business questions": 0.14798826743260807, "deliverables Domain knowledge clinical data real world data life sciences related research data Expertise data science related tools": 0.1112868408599056, "meaningful solutions life sciences business Task oriented ability": 0.09272478224594995, "Deep understanding ML": 0.09225551598728196, "Deep understanding tools trade": 0.09071174994364162, "e g SQL Tableau D3": 0.08894896595196349, "variety modern programming languages": 0.08041302875273283, "PhD computational quantitative discipline e g statistics computer science": 0.0803047715866504, "keen eye detail visual communication findings": 0.0785180804974437, "g regression techniques": 0.07550922959283284, "strong knowledge mathematical underpinnings": 0.07507634455817937, "informatics genetics physics epidemiology health economics": 0.0748435858469764, "non technical teams": 0.07350652060620556, "neural networks decision trees": 0.07041106969585985, "Linux TensorFlow Hadoop Spark": 0.060543840034781284, "various methods": 0.057720359341988395, "D3": 0.05674874113970467, "Comfort": 0.047603525455780483, "source technologies": 0.04367427895922296, "R Python JavaScript": 0.034934886579238586}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"scikit": 0.06525817208321996, "Deep": 0.07835357693339529, "PhD Data Science Analytics Statistics Mathematics Physics Economics Computer Science": 0.1611087008261288, "Bachelor Data Science Analytics Statistics Mathematics Physics Economics Computer Science": 0.15990757719658702, "Master degree PhD Data Science Analytics Statistics Mathematics Physics Economics Computer Science": 0.15783163806216163, "data Experience deep learning frameworks": 0.1376035095340256, "Professional experience machine": 0.13596170330421933, "machine learning models": 0.12834489439021596, "Professional experience": 0.12149002563233081, "Data Scientist Machine Learning Engineer": 0.22116371808315693, "real world problems": 0.09757862572233603, "keras": 0.08023195870914607, "statistical concepts": 0.07948379159160544, "libraries": 0.061536400093739084}, {"Familiarity AWS ecosystem": 0.43301270189221913}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"Bachelor degree": 0.052259512838372435, "people": 0.03668235271975122, "technology customer operations analytics": 0.1441810033360367, "business performance Journey Analytics clients": 0.14366005698030285, "statistical advanced analytic methods": 0.14268019367183554, "senior clients colleagues": 0.1294130744811594, "Ability work": 0.12397446759924721, "collaboratively team environment": 0.06634939138468357}, {}, {"Masters PhD student statistics computer science economics physics quantitative field Internship work experience": 0.18286227653297005, "Bachelors degree statistics computer science economics physics quantitative field Experience": 0.17961254937081264, "applied statistics machine": 0.1757591532040676, "Proficiency Python R Experience working imperfect data Passion eagerness": 0.16776705917366294, "others": 0.0838261254913212}, {}, {}, {"Ability": 0.17109252827124755, "Experiences": 0.08555564122793344, "business problems": 0.07113323593135257, "statistical concepts": 0.10574417604636338, "statistical techniques": 0.0900607699510726, "Experience MS Office Word Access Excel PowerPoint Outlook": 0.17003967191319247, "non technical audiences": 0.0782947839808435}, {"algorithms": 0.06458086687557257, "Math": 0.05518037906571917, "Machine Learning": 0.09437336539284569, "Experienced building large scale data analysis system Extensive knowledge experience": 0.14311573605315706, "Strong project management leadership skills": 0.12896487673728788, "Extensive knowledge details": 0.1278740092363317, "Machine": 0.08832753447771811, "Apache Hadoop": 0.07761287226276761}, {"SQL": 0.058768307026100836, "similar Total Cost Ownership Net Present Value analysis Approaches systems biology proteomics analysis": 0.1354183394853346, "platforms": 0.060514805142897136, "Data": 0.05707024126556832, "MS years": 0.03643867419447329}, {"Experience": 0.1363024879554495, "research results commercialization": 0.30069402708873205}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"At least years": 0.01699144401545234, "ability": 0.05800052007813764, "Proven": 0.04923856239094166, "Strong knowledge": 0.0880864804100791, "complex analyses": 0.07554594308824736, "simple terms": 0.06286260643477158, "quantitative field": 0.06133143194974497, "equity": 0.057986279112909066, "Deep knowledge": 0.05145254250276202}, {"work level position": 0.805965666080819, "minimum acceptable considered position": 0.7203154444966106, "relevant position": 0.7124645301180246, "hiring manager organization": 0.5985724717434636, "account information": 0.5278423914732228, "based candidates": 0.5159346260215218, "Salary": 0.3792204123780951, "The qualifications": 0.16531562794918556}, {}, {"Degrees Physics Mathematics Computer Science Engineering": 0.6998542122237651}, {"Tableau": 0.04736217634323199, "data": 0.10551789396853675, "scikit": 0.04975772652506343, "Experience": 0.1161872793085426, "results": 0.05226662876752364, "data visualization tools years experience packages": 0.15521857197358127, "project management experience years": 0.14094467176588485, "multiple data sources Experience": 0.1369115095244175, "role data analysis metrics development years": 0.13580750983407938, "experience": 0.1161872793085426, "large datasets": 0.08761615380829463, "Hands": 0.05438422891458051}, {}, {}, {"ability": 0.19481519902330333, "Master Degree": 0.021850850901583334, "problems": 0.04457627356116374, "Proven": 0.07067918179371996, "others": 0.04696594018302026, "organization Ability": 0.10258469151684993, "SAS R Python": 0.0536476504775662, "Significant experience": 0.04959366798723373, "relational databases": 0.04382432092597222, "depth experience": 0.03844271217323536}, {"mathematics computer science physical sciences": 0.16820562105763823, "deep learning solutions": 0.15825973898162424, "similar technical field Experience": 0.15592772958694323, "TensorFlow": 0.23944463355595383, "xgboost": 0.09335099285927816}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"Tableau": 0.06737584287900637, "Java Scala": 0.030216315513075704, "Proven": 0.04809169164301532}, {"MongoDB Solr Indexes": 0.36432994274734615, "Solr Indexes": 0.3498759579292246, "Experience SQL": 0.19418352986099446}, {}, {}, {"algorithms": 0.08627833588742198, "Mechanical Engineering Materials Engineering Chemical Engineering Electrical Engineering Chemistry Physics Expertise": 0.17520136236111694, "Mechanical Engineering Materials Engineering Chemical Engineering Electrical Engineering Chemistry Physics Expertise engineering analysis tools data analysis scripting methods order automate train standard analytical tasks": 0.17145309418212604, "numerical computing": 0.14275336933092814}, {}, {}, {"related field Computational social science Computer science Data analytics": 0.12048273570748999, "Computer science Data analytics Economics Engineering Geospatial": 0.10466285371614022, "Quantitative finance": 0.08434433541161113, "Economics Engineering Geospatial analysis": 0.08582762216141174, "Mathematics Operations research": 0.09980310564566422, "Creativity Initiative Integrity Leadership": 0.08091045953048813, "Problem solving skills": 0.0888404983275615, "Mathematics Operations": 0.0745582203198448, "Computational": 0.052544924802327135, "scale": 0.0380954418841372, "A thorough medical psychological exam": 0.058786064823826874, "GPA": 0.027690621536651302, "A comprehensive background investigation": 0.060706402021510175, "A polygraph interview": 0.041607317561258565, "Ability work": 0.07262873957414878, "Advanced degree data science equivalent field sub field Experience working data rich problems": 0.13282744706444863, "research programs Experience computer programming user experience user interface Ability": 0.1290466075267808, "Experience real world data thesis research internships": 0.12040595805754659, "work experience Creativity Initiative Integrity Leadership": 0.11221234732672943, "large incomplete data": 0.09520107664442307, "verbal communication": 0.07380834459127009, "solutions": 0.053066513645152975, "Strong": 0.052893491815632784, "projects": 0.05186656934406856}, {"Tableau": 0.044618747368805806, "PhD": 0.02034775223985317, "goals": 0.04421142448626217, "Expertise": 0.04231440718361365, "Proven": 0.04810326812635421, "Deep": 0.12398408358392254, "ML": 0.12214347454137842, "business questions": 0.14798826743260807, "deliverables Domain knowledge clinical data real world data life sciences related research data Expertise data science related tools": 0.1112868408599056, "meaningful solutions life sciences business Task oriented ability": 0.09272478224594995, "Deep understanding ML": 0.09225551598728196, "Deep understanding tools trade": 0.09071174994364162, "e g SQL Tableau D3": 0.08894896595196349, "variety modern programming languages": 0.08041302875273283, "PhD computational quantitative discipline e g statistics computer science": 0.0803047715866504, "keen eye detail visual communication findings": 0.0785180804974437, "g regression techniques": 0.07550922959283284, "strong knowledge mathematical underpinnings": 0.07507634455817937, "informatics genetics physics epidemiology health economics": 0.0748435858469764, "non technical teams": 0.07350652060620556, "neural networks decision trees": 0.07041106969585985, "Linux TensorFlow Hadoop Spark": 0.060543840034781284, "various methods": 0.057720359341988395, "D3": 0.05674874113970467, "Comfort": 0.047603525455780483, "source technologies": 0.04367427895922296, "R Python JavaScript": 0.034934886579238586}, {"Masters": 0.06485613787466389, "proficiency SQL Excellent communication organization analytical skills experience": 0.13402004841142057, "Background": 0.06307655703953584}, {}, {}, {"Hadoop Spark": 0.10028242515444764, "PhD": 0.07854848857417175, "Master": 0.03466885383171598, "Java Scala": 0.09878183711281853, "Python": 0.08773719032976003, "SQL Python R SAS preferred Demonstrate familiarity work experience": 0.15317266319550196, "driving product impact": 0.14403200898011995, "SAS": 0.0823667470129212, "OOP": 0.06933770766343196}, {"Casual Work Environment": 0.1938846627079447, "US": 0.02695376017109293}, {"seriously huge datasets": 0.22394480434190045}, {}, {"Experience": 0.10888205191371587, "machine": 0.07198389628012994, "Expertise Python R Expertise": 0.25217822920492694, "Master degree": 0.050031627476136056}, {}, {}, {"placement different job level": 0.3644870160185702}, {"joy clients": 0.2353292397628332, "work Stitch Fix": 0.22620767443874928, "Stitch Fix": 0.1839144947304601, "work": 0.17370647730158886, "every day": 0.11134422906452164}, {"ability": 0.06987238462801143, "Knowledge": 0.043323360950632654, "tensorflow R caret Experience curating datasets": 0.10578386595873522, "Spark MLLib SQL OS Experience Windows Linux Windows Ability": 0.10567492930161282, "Spark MLLib SQL OS Experience Windows Linux Windows Ability compile results": 0.10286940357936036, "modeling Experience scikit": 0.09981853037813422, "Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical": 0.09972764628924106, "related Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical Modeling Geo spatial analytics Data Munging Cleaning Bachelor Degree Ability work datasets": 0.09852891658098631, "unsupervised machine learning methods Experience C": 0.09668982999617534, "spatial analysis Experience PCAP": 0.08608123700199659, "neural networks cluster analysis feature engineering extraction reduction web scraping decision trees": 0.08473325182528316, "working Intelligence Community teams": 0.07313805640235801, "Intelligence Community": 0.07089410760273644, "multi TB dataset manipulation cleaning": 0.06902849386525074, "Java R Javascript PhP MatLab Pig Hive Impala PySpark Scala Ruby Pytorch": 0.06715283906276817, "senior level leadership": 0.06543557295005008, "present material audiences": 0.06517797007371225, "Elastic Search Hadoop": 0.0635289306518915, "different sizes formats": 0.06299730280115924, "specific techniques": 0.058085805613774084, "multiple databases": 0.057197642535013866, "working fields": 0.049191474206016564, "Impala PySpark": 0.04837715570861541, "Java R Javascript": 0.048328684223073896, "CART": 0.04520606428022443, "presentations": 0.043185899714091563, "PhP MatLab": 0.04216774640090927, "TB": 0.040994860964704456}, {}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {}, {"advanced topics analytics artificial intelligence data engineering": 0.12619946362828915, "professional experience media company": 0.12166837235744554, "SQL Tableau Excel interest": 0.10528548595306969, "analytics tools": 0.10512190115422484, "work sweat details": 0.09664903807750103, "either R Python Experience building web applications agile development": 0.09498097708421006, "learning libraries": 0.08584650422273911, "visualization machine": 0.08476235737415024, "Excel": 0.06599852781738813, "statistics": 0.04824675124296681}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"date thread subject author": 0.3644870160185702, "Messages": 0.1363024879554495}, {"equal access benefits details training office": 0.11279208862132963, "accommodation": 0.18997652446893273, "Registered Selective Service": 0.1700512931780461, "job": 0.07653779613489343, "An employee disability": 0.12421246261839121, "one year": 0.028057961252967792}, {}, {"hours": 0.045620862682835925, "Salary": 0.05882156388040787, "equal access benefits details training office": 0.05032800614260733, "accommodation": 0.0874389081522791, "job": 0.05681650317587723, "An employee disability": 0.03770876878242987, "online application": 0.1710917854079438, "business requirements": 0.060332113991820424, "applicants": 0.1038020339393852, "requirements": 0.05162217491401544, "position": 0.07473780728005498, "Develop": 0.0320276060908767, "Provide": 0.03062509744116862}, {}, {"date thread subject author": 0.3644870160185702, "Messages": 0.1363024879554495}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"LA location": 0.3498759579292246, "Gated dog run": 0.2340164370673894, "LA": 0.22514738896862999}, {}, {"Ability": 0.04585082738034847, "Develop": 0.052440644310730096, "Provide": 0.04338792230678816, "large complex data sets": 0.06414524185341185, "Demonstrated ability": 0.05194728441729538, "tools": 0.05075708270769997, "self": 0.045726173584060406, "decisions": 0.04485737969300725, "Communicate": 0.04328725546958105}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"knowledge system identification statistical inference": 0.2572647482221939, "knowledge MATLAB": 0.22309882666731606}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {}, {"positive impact livelihood world": 0.17032584544291615, "401k": 0.08368868153730655}, {}, {"neural networks": 0.06241861383755796, "Experience": 0.23587825495990716, "At least years": 0.08833533827408564, "techniques": 0.051279453083833984, "GPU": 0.04290866819924826, "NoSQL": 0.04225618357462963, "people": 0.04308417756767289, "C C": 0.13336435961373955, "product": 0.05518830913819678}, {"Ability": 0.07630567330861139, "SQL": 0.08337286241541988, "statistics": 0.04997112962160454, "job": 0.07631474947119496, "information": 0.07613395358250201}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {"data": 0.11348228124317566, "English": 0.06104386334561915, "SQL": 0.05368353140438974, "data scientists": 0.11957945141384041, "customers": 0.0574929140845608, "Proven": 0.05824735365648322, "people": 0.05613665224399951, "SAS": 0.07131237535355654, "Excel": 0.05699975089627714, "requirements": 0.0555932695165281, "SQL data exploration tools SAS R Experience data analytics design Experience": 0.1561504914243364, "data analysis Experience": 0.1515741989377827, "Health care industry experience Demonstrated ability": 0.1375665844585941, "Formulas Bilingual Spanish English Master Degree Experience": 0.12706457321124703, "Proven organizational skills ability flexible work ambiguity": 0.11900475372401198, "deep technical concepts": 0.11453168723628562, "SAS R Python Proficient MS Office applications Excel proficiency Pivots V Lookups": 0.10930208768117076, "SAS R Python Proficient MS Office": 0.10363679108811297, "Bachelor degree Minimum year experience": 0.10155604775523161, "deeper understanding": 0.09035006587451908, "Pivots V Lookups": 0.08827834931139683, "technical well technical senior stakeholders": 0.07727475269760889, "large databases": 0.0728984855703774, "predictive statistical modeling": 0.07167244420536713, "Spanish": 0.060681071768047885, "Bilingual": 0.06028501286325526, "deliverables": 0.05781206593599976}, {"Tableau": 0.10142090343035008, "ability": 0.08440357187329922, "SQL": 0.05116396785707833, "work": 0.05216246940046129, "Excellent time management skills ability": 0.11125972234702075, "data elements sources relationships business technical terms": 0.10931721895393368, "big data technologies Hadoop Spark Familiarity Python R data visualization tools": 0.10854205064790827, "full stack data analysis insight synthesis presentation Ability": 0.10744979460044347, "complex analysis technical concepts": 0.0983083659173481, "years recent experience data science data analyst role": 0.094391071863998, "Hadoop Spark Familiarity Python": 0.09156255393086675, "Strong business mindset": 0.0886783349811985, "Excellent presentation": 0.08804156525579818, "AB experiments": 0.08244030508736502, "Familiarity": 0.0678369840692615, "Comfortable": 0.02399826108198082}, {"United States Preferred": 0.8660254037844383}, {"Ability": 0.04148511312919706, "relational databases": 0.08974042186605587, "SAS": 0.028702815817354677, "advanced optimization methodologies": 0.10134145699328057, "advanced quantitative analyses": 0.09829307187196293, "analysis Ability": 0.09704743970115745, "advanced statistical methodologies mixed model random fixed effects": 0.09475902762523405, "actual working experience": 0.0946598478721357, "mixed integer optimization Ability": 0.09266203182976625, "analysis variance correlation techniques": 0.09166243812366025, "ARIMA neural networks multinomial discrete choice Ability": 0.08985932097897303, "Demonstrated experience": 0.08776849678220341, "features software packages": 0.08369861437118076, "Utilize complex computer operations": 0.08338706295259586, "mathematical operations tasks cluster analytics": 0.08000167715868862, "theory design experiments": 0.0700407807342211, "methodologies": 0.06757454793797711, "Working knowledge": 0.05636839465000078, "A strong passion empirical research": 0.05029628457577041, "3rd": 0.04496185397037498}, {}, {"Tableau": 0.055075740971198786, "algorithms": 0.05586382011587492, "Proven": 0.04794588396617723, "Map Reduce": 0.05570364926756001}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"data": 0.17034426291295268, "SQL": 0.16438825931393847, "BI": 0.08615020315856237, "recommendations": 0.11877559248742184, "depth experience": 0.15373975749970398, "Advanced data modeling experience": 0.21330672221640948, "working data": 0.17990361275506978, "trends": 0.08628676414348442, "ETL": 0.08544813453611905}, {"techniques": 0.03014764090067338, "SAS R Python": 0.18888022670493462, "Artificial Neural Nets": 0.24809917059436207}, {"algorithms": 0.04267714016909563, "skills": 0.09356823819396033, "AI ML": 0.06618954351473044, "keras": 0.04728725997684822, "libraries": 0.04822590628998957, "production": 0.15328302703050883, "models": 0.0982655565708498, "code": 0.06902000117505856}, {}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"Ability work team": 0.2340164370673894}, {"PhD": 0.0194843644872548, "Deep Learning": 0.12132151460822119, "Deep": 0.041448759500956986, "MS years": 0.04111937461608863, "Deep knowledge": 0.062258895662656924, "solutions": 0.1581573782581352, "US": 0.04527650845130134, "requirements": 0.04354602327052094, "Demonstrated ability": 0.06606976017574621, "ETL": 0.043539452655746935, "models": 0.05574970605997304, "Breadth skills experience machine": 0.10651211819208238, "business process outsourcing systems transportation systems healthcare systems financial services": 0.0952706146109928, "novel solutions problems": 0.0924895675655186, "real world context Prior experience similar role": 0.09215572427105945, "practice Experience knowledge services": 0.08817637149068558, "feasibility solutions": 0.0853215832129521, "analytics models": 0.08394115138490749, "Desired interdisciplinary skills": 0.08207944801510013, "big data technologies ETL statistics causal inference": 0.08022836506624882, "analytics packages": 0.07624254746411682, "diverse learning settings": 0.0753326610597479, "multi disciplinary environments": 0.07402041996080519, "data mining statistical predictive": 0.07233224714414609, "work US employer": 0.06951113825551561, "Ability inclination": 0.06596067878002476, "different types": 0.06533239373341822, "sponsorship": 0.06198243713621002, "history driving": 0.052612076507412404, "related field": 0.04790755308721288, "Breadth": 0.04544048582764686, "simulation": 0.04539951113677476, "methods": 0.042795403204940144, "experiments": 0.04249035753967234, "ideas": 0.02500487360261578, "desire": 0.0194843644872548}, {}, {}, {"Proficiency": 0.05299491692857569, "Proven ability": 0.12596696456934545, "Proven": 0.05181776298255524, "programming languages": 0.0961673681492541, "multiple data sources": 0.0895539258228027, "metadata": 0.07058753524494195}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"explain point": 0.3711047733623777, "story": 0.19959129852727492, "Visualization": 0.15552550751170974}, {}, {}, {"Tableau": 0.15243518247936194, "requirements": 0.08502211912869125, "minimal guidance Ability work business system owners": 0.16101632029826296, "SQL experience": 0.12701160379119622, "Business Objects": 0.23876415377618487}, {}, {}, {}, {"PhD": 0.0194843644872548, "Deep Learning": 0.12132151460822119, "Deep": 0.041448759500956986, "MS years": 0.04111937461608863, "Deep knowledge": 0.062258895662656924, "solutions": 0.1581573782581352, "US": 0.04527650845130134, "requirements": 0.04354602327052094, "Demonstrated ability": 0.06606976017574621, "ETL": 0.043539452655746935, "models": 0.05574970605997304, "Breadth skills experience machine": 0.10651211819208238, "business process outsourcing systems transportation systems healthcare systems financial services": 0.0952706146109928, "novel solutions problems": 0.0924895675655186, "real world context Prior experience similar role": 0.09215572427105945, "practice Experience knowledge services": 0.08817637149068558, "feasibility solutions": 0.0853215832129521, "analytics models": 0.08394115138490749, "Desired interdisciplinary skills": 0.08207944801510013, "big data technologies ETL statistics causal inference": 0.08022836506624882, "analytics packages": 0.07624254746411682, "diverse learning settings": 0.0753326610597479, "multi disciplinary environments": 0.07402041996080519, "data mining statistical predictive": 0.07233224714414609, "work US employer": 0.06951113825551561, "Ability inclination": 0.06596067878002476, "different types": 0.06533239373341822, "sponsorship": 0.06198243713621002, "history driving": 0.052612076507412404, "related field": 0.04790755308721288, "Breadth": 0.04544048582764686, "simulation": 0.04539951113677476, "methods": 0.042795403204940144, "experiments": 0.04249035753967234, "ideas": 0.02500487360261578, "desire": 0.0194843644872548}, {}, {"Big Data": 0.0568563532357816, "United States": 0.11150249382328883, "Interested candidates": 0.05187607905280792}, {}, {"Experience": 0.15552550751170974, "small teams projects": 0.382201141444222}, {}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {}, {"Tableau": 0.044618747368805806, "PhD": 0.02034775223985317, "goals": 0.04421142448626217, "Expertise": 0.04231440718361365, "Proven": 0.04810326812635421, "Deep": 0.12398408358392254, "ML": 0.12214347454137842, "business questions": 0.14798826743260807, "deliverables Domain knowledge clinical data real world data life sciences related research data Expertise data science related tools": 0.1112868408599056, "meaningful solutions life sciences business Task oriented ability": 0.09272478224594995, "Deep understanding ML": 0.09225551598728196, "Deep understanding tools trade": 0.09071174994364162, "e g SQL Tableau D3": 0.08894896595196349, "variety modern programming languages": 0.08041302875273283, "PhD computational quantitative discipline e g statistics computer science": 0.0803047715866504, "keen eye detail visual communication findings": 0.0785180804974437, "g regression techniques": 0.07550922959283284, "strong knowledge mathematical underpinnings": 0.07507634455817937, "informatics genetics physics epidemiology health economics": 0.0748435858469764, "non technical teams": 0.07350652060620556, "neural networks decision trees": 0.07041106969585985, "Linux TensorFlow Hadoop Spark": 0.060543840034781284, "various methods": 0.057720359341988395, "D3": 0.05674874113970467, "Comfort": 0.047603525455780483, "source technologies": 0.04367427895922296, "R Python JavaScript": 0.034934886579238586}, {}, {"data": 0.03260516601884557, "results": 0.047887771618643604, "goals": 0.03401767123243638, "skills": 0.047628902690186714, "The ability": 0.0611464615385973, "Proven": 0.02627890496811178, "complex analytical concepts": 0.047222837316457725, "business problems": 0.0808052852784222, "people": 0.14311413324962227, "statistical techniques": 0.05258537187349913, "experience": 0.12647163897244415, "Strong": 0.025749973826901248, "Visualization": 0.024757552410581567, "complex business problems": 0.07977704160925515, "business results": 0.14524135582711045, "technology roadmaps realization": 0.06709353786120631, "existing problems": 0.06237585295233952, "new solution methods": 0.05844420833375736, "working knowledge": 0.05315097967887373, "External Technology Knowledge Keeps": 0.04567204077271489, "latest technological developments areas": 0.04438111412702908, "Analytics": 0.036597392417912315, "operations": 0.03627312063459991, "opportunities": 0.028420955248182087, "things": 0.02629710764806314}, {}, {"hours": 0.206337265298148, "sports games": 0.2801458834578816}, {"results": 0.07106640594404998, "The ability": 0.03212288493356315, "Python R": 0.09629605108097312, "complex analyses": 0.11904645695744556, "ETL": 0.06796154314541757, "analysis impact": 0.1158466344491504, "key business product decisions": 0.10773157142830043, "SQL Hive": 0.18059807069637115}, {"e g filtering morphology": 0.23799157941279617, "compression": 0.1821150341259923, "Background image processing concepts": 0.1718771991253443}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"ping pong tournaments": 0.4030933718572922}, {}, {"Hadoop": 0.054172781722306766, "data analytics": 0.05638591947180853, "Master Degree": 0.029345505692439947, "statistical predictive modeling concepts machine learning approaches": 0.09159287758178906, "classification techniques recommendation optimization algorithms": 0.08730425323235907}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {}, {"Experience": 0.07802180310364597, "Spark": 0.06183621558172766, "large datasets": 0.07049450734171384, "SAS": 0.05898774030636932, "Demonstrated ability": 0.10906080999682286, "complex business problems": 0.10538682857847938, "big data technologies": 0.11819275731049034, "machine learning": 0.07340878474168505}, {}, {"Experience": 0.11733464702960177, "Self": 0.03551724070627476, "environment": 0.07630679519918404, "Ability work": 0.057557867333520724, "ETL": 0.052741771461470806, "Continuous": 0.051723184535666114}, {}, {"Experience": 0.10206171508346584, "Master": 0.030440901046505903, "verbal communication": 0.08015755587901373, "Familiarity": 0.06358629272747436, "functional teams": 0.09852846880777612, "Java C": 0.08657448355113324, "statistical models": 0.08465218063998534, "analysis": 0.06745923619747914}, {}, {}, {"data": 0.09938431205580343, "trends": 0.08219105801591031, "opportunities": 0.08304007059280688, "new business development proof concepts": 0.15916193308254664}, {"Computer Science Computer Science Engineering Engineering Computer Science Math Computer Science Mathematical": 0.19371568470831754, "Computer Science Computer Science Engineering Engineering Computer Science Math Computer Science Mathematical Engineering Mathematical Science Mathematics Statistics Strong data wrangling skills": 0.18997352186447317, "Ability manipulate JSON XML data Experience Splunk Experience data manipulation platforms": 0.18224101440100224, "Experience Ansible Puppet Jenkins Chef": 0.16854997246525094}, {"hands": 0.10594235162311615, "opportunities": 0.0946569359271388}, {"PhD": 0.0194843644872548, "Deep Learning": 0.12132151460822119, "Deep": 0.041448759500956986, "MS years": 0.04111937461608863, "Deep knowledge": 0.062258895662656924, "solutions": 0.1581573782581352, "US": 0.04527650845130134, "requirements": 0.04354602327052094, "Demonstrated ability": 0.06606976017574621, "ETL": 0.043539452655746935, "models": 0.05574970605997304, "Breadth skills experience machine": 0.10651211819208238, "business process outsourcing systems transportation systems healthcare systems financial services": 0.0952706146109928, "novel solutions problems": 0.0924895675655186, "real world context Prior experience similar role": 0.09215572427105945, "practice Experience knowledge services": 0.08817637149068558, "feasibility solutions": 0.0853215832129521, "analytics models": 0.08394115138490749, "Desired interdisciplinary skills": 0.08207944801510013, "big data technologies ETL statistics causal inference": 0.08022836506624882, "analytics packages": 0.07624254746411682, "diverse learning settings": 0.0753326610597479, "multi disciplinary environments": 0.07402041996080519, "data mining statistical predictive": 0.07233224714414609, "work US employer": 0.06951113825551561, "Ability inclination": 0.06596067878002476, "different types": 0.06533239373341822, "sponsorship": 0.06198243713621002, "history driving": 0.052612076507412404, "related field": 0.04790755308721288, "Breadth": 0.04544048582764686, "simulation": 0.04539951113677476, "methods": 0.042795403204940144, "experiments": 0.04249035753967234, "ideas": 0.02500487360261578, "desire": 0.0194843644872548}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {}, {"experiments": 0.09388570936639071, "multiple projects": 0.0872992353558228, "Excellent problem": 0.08364720285146562, "Java": 0.06002418752303151}, {}, {"PhD": 0.060011654638820654, "Salary": 0.06310803121946774, "statistical models": 0.08515258270805937, "Cigna Healthcare MetLife Dental VSP Vision": 0.21759717001701961, "advanced data analysis": 0.10352172248938422}, {}, {}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"people": 0.11477160922369026, "world": 0.25409456980845746, "data things": 0.20358404371393707, "connections": 0.17743725822400744}, {}, {"Ability": 0.22622848297036718, "Hadoop": 0.08046493170120635, "problems": 0.06426215530980249, "skills": 0.07604929650899711, "Ability work": 0.1170440837438806, "statistical techniques": 0.0917678010816515, "Java": 0.027655671213463087}, {"Significant experience": 0.1327367500867685, "relational databases": 0.09852167065302059, "Map Reduce": 0.12066499933310021, "Reduce Experience working Hadoop Map": 0.17527611366746398, "Substantial data analysis experience": 0.1498168405434012, "complex problems": 0.09666334295651435, "new technologies": 0.09231790769569692}, {}, {"projects": 0.1401053244921844, "major impact business": 0.2573558505963801, "prowess data scientist right": 0.18958522098980135}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {}, {"At least years": 0.05625703010185719, "Degree": 0.05236182315663105, "techniques": 0.07854965564214672, "Proficiency scripting language Python R MATLAB Proficiency": 0.1811409788922317}, {}, {"Ability": 0.08197225781171034, "written oral diagram form": 0.29013041626376423, "carry instructions": 0.18646369080383335}, {}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {"Tableau": 0.1290731008297145, "Experience": 0.09702608363221081, "Self": 0.05496601722370256, "ETL": 0.05221789808294021, "Strong experience": 0.1150020905103011, "Computer Science": 0.0713083719379893}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {}, {}, {}, {}, {"Ability": 0.04363995746838563, "algorithms": 0.057891682242406886, "relational databases": 0.05587622792315143, "software C C": 0.17584251257919647, "large scale data management big data technologies Skilled aspects software project life cycle feasibility requirements": 0.09783109901765838, "important project success Sufficient interpersonal skills necessary interact levels personnel": 0.0966001900271099, "scientific data analysis statistical analysis knowledge discovery computer security systems": 0.09498619043436038, "Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules": 0.0919427259421957, "algorithms data management": 0.09068623156232872, "design implementation integration test deployment Fundamental experience": 0.08905027028348389, "necessary work": 0.08572541055326695, "data analysis": 0.08481768306966782, "Fundamental knowledge": 0.07691025227787122, "project": 0.07684090898077958, "Bachelor degree computer science computer engineering related field equivalent combination education related experience": 0.07624052360696243, "Linux UNIX Windows environments": 0.07082325222330953, "enthusiasm creativity change": 0.06820880954873267, "concurrent technical tasks": 0.06680190430024818, "research concepts": 0.061931138719078946, "conflicting priorities": 0.06070601071236942, "difficult problems": 0.06008197271029187, "Java Python R Matlab software applications": 0.059966863096430394, "Linux UNIX Windows": 0.057131374480868774, "high performance": 0.05695011771262829, "Skilled": 0.04207201359035096, "Java Python R Matlab": 0.03777478033080642}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"share knowledge others": 0.2717541906348583, "organization": 0.25409456980845746, "skill": 0.14729004418874336, "Access opportunities": 0.14433557441502345}, {"volunteer time fuel efficient vehicle purchase assistance transit fare contribution": 0.23126702768235938, "first": 0.135227973097095}, {"video call": 0.4067069769086525, "call": 0.348624126893826, "As always interviews": 0.029047375096555625}, {"Tableau": 0.4137874235739136, "Matplotlib": 0.5134080078003356, "Plotly ggplot": 0.1870828201468148, "An eye great data visualization": 0.16291858516929755}, {"Spark": 0.05390374267124934, "results": 0.05107069066964958, "hard questions data": 0.09045200751486916, "A strong passion empirical research": 0.049748798805669237, "complex data analysis": 0.11417956170076057, "qualitative quantitative clear compelling manner": 0.10858095091973476, "action Strong understanding statistical analysis": 0.10821895490066527, "Quick learner ability": 0.09638615949146248, "large data": 0.0940640806586284, "production level code Proficiency": 0.09405604515484024, "academic institution Expert Python SQL": 0.08808623603876249, "minimal guidance Ability": 0.08694653923001104, "varying levels": 0.08337547654909823, "quantitative discipline": 0.0805786306431583, "working Spark process": 0.08057572896529144, "Expert Python SQL": 0.07975001484214961, "Excellent communication skills": 0.07900465825798944, "dynamic fast paced environment Drive change": 0.06971425284738322, "initiate drive projects completion": 0.06763002451748311, "Drive": 0.06301647689363961, "comfort ambiguity": 0.06211195170772839, "A flexible analytic approach": 0.04372521215824216}, {}, {"Interest politics educational policy": 0.4}, {}, {"Medical dental vision insurance Life disability coverage": 0.0947069090378902, "401K Flexible Spending Accounts Apple equipment Daily breakfast lunch dinner": 0.08347207369770868, "Competitive": 0.05196714178801003, "Tableau": 0.04581968110432556, "tools": 0.049174392804525485, "experiments": 0.048652595932222195, "complex business problems": 0.0717995422470659, "industry experience Experience Python R Experience Tableau Ability model": 0.12935208325229341, "Ability ramp data science manager role": 0.117906948009437, "technical levels Ability": 0.11587052112751704, "Airflow Ability": 0.2317018705387099, "sound analytical modeling solutions Ability": 0.11260797873986642, "data pipelines": 0.07958954059062512, "functional partners": 0.06725751682631331, "Proficiency SQL": 0.061265433071426234}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {}, {"Tableau": 0.1564390132039097, "At least years": 0.020807640549739687, "machine learning models": 0.0935369957259479, "Big Data": 0.08051192636567137, "Java C C SQL relational database experience": 0.13776441915106521, "business plan Experience shelf": 0.1302514304325648, "algorithms Experience visualization tools": 0.12799598577500484, "relevant experience": 0.1209628160287713, "Java C C SQL": 0.11504881704544911, "complex concepts": 0.06435029211215977}, {}, {"At least year": 0.09206970100819285, "At least year experience": 0.12347540609268157, "Retail eCommerce company": 0.3466800150008662}, {}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {"Ability": 0.04363995746838563, "algorithms": 0.057891682242406886, "relational databases": 0.05587622792315143, "software C C": 0.17584251257919647, "large scale data management big data technologies Skilled aspects software project life cycle feasibility requirements": 0.09783109901765838, "important project success Sufficient interpersonal skills necessary interact levels personnel": 0.0966001900271099, "scientific data analysis statistical analysis knowledge discovery computer security systems": 0.09498619043436038, "Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules": 0.0919427259421957, "algorithms data management": 0.09068623156232872, "design implementation integration test deployment Fundamental experience": 0.08905027028348389, "necessary work": 0.08572541055326695, "data analysis": 0.08481768306966782, "Fundamental knowledge": 0.07691025227787122, "project": 0.07684090898077958, "Bachelor degree computer science computer engineering related field equivalent combination education related experience": 0.07624052360696243, "Linux UNIX Windows environments": 0.07082325222330953, "enthusiasm creativity change": 0.06820880954873267, "concurrent technical tasks": 0.06680190430024818, "research concepts": 0.061931138719078946, "conflicting priorities": 0.06070601071236942, "difficult problems": 0.06008197271029187, "Java Python R Matlab software applications": 0.059966863096430394, "Linux UNIX Windows": 0.057131374480868774, "high performance": 0.05695011771262829, "Skilled": 0.04207201359035096, "Java Python R Matlab": 0.03777478033080642}, {"Hadoop Spark": 0.11146225744173643, "Hadoop": 0.10386149236477668, "SQL": 0.07723548386804095, "Big Data": 0.10906094092354925, "NoSQL SQL database experience Experience Google products": 0.1307825858733537, "code populate HDFS Hadoop log Kafka data": 0.12140655465400152, "Java Scala Python Hadoop stack HIVE Pig Hadoop streaming MapReduce HBase": 0.11926508391791746, "Big Data Systems": 0.2217305520215076, "years experience": 0.0979847500170113, "Build": 0.05854274142360258, "Kafka": 0.05737373663326707}, {"LAN": 0.7217127527814065, "Parties": 0.2222496308952425}, {}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"graduation date": 0.06624090224422371, "ability": 0.18678386041579298, "analytic processes": 0.0744298110290886, "Deep": 0.04590688485541542, "statistical predictive modeling concepts machine learning approaches": 0.09601280644289965, "classification techniques recommendation optimization algorithms": 0.08218421408060261, "first year": 0.09183530974236723, "one programming languages": 0.040001686918747434}, {"Tableau": 0.10142090343035008, "ability": 0.08440357187329922, "SQL": 0.05116396785707833, "work": 0.05216246940046129, "Excellent time management skills ability": 0.11125972234702075, "data elements sources relationships business technical terms": 0.10931721895393368, "big data technologies Hadoop Spark Familiarity Python R data visualization tools": 0.10854205064790827, "full stack data analysis insight synthesis presentation Ability": 0.10744979460044347, "complex analysis technical concepts": 0.0983083659173481, "years recent experience data science data analyst role": 0.094391071863998, "Hadoop Spark Familiarity Python": 0.09156255393086675, "Strong business mindset": 0.0886783349811985, "Excellent presentation": 0.08804156525579818, "AB experiments": 0.08244030508736502, "Familiarity": 0.0678369840692615, "Comfortable": 0.02399826108198082}, {"Designing data architecture table dashboard": 0.37267799624996495}, {}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {}, {"Spark": 0.05390374267124934, "results": 0.05107069066964958, "hard questions data": 0.09045200751486916, "A strong passion empirical research": 0.049748798805669237, "complex data analysis": 0.11417956170076057, "qualitative quantitative clear compelling manner": 0.10858095091973476, "action Strong understanding statistical analysis": 0.10821895490066527, "Quick learner ability": 0.09638615949146248, "large data": 0.0940640806586284, "production level code Proficiency": 0.09405604515484024, "academic institution Expert Python SQL": 0.08808623603876249, "minimal guidance Ability": 0.08694653923001104, "varying levels": 0.08337547654909823, "quantitative discipline": 0.0805786306431583, "working Spark process": 0.08057572896529144, "Expert Python SQL": 0.07975001484214961, "Excellent communication skills": 0.07900465825798944, "dynamic fast paced environment Drive change": 0.06971425284738322, "initiate drive projects completion": 0.06763002451748311, "Drive": 0.06301647689363961, "comfort ambiguity": 0.06211195170772839, "A flexible analytic approach": 0.04372521215824216}, {}, {}, {"Minimum years": 0.09891895174082141, "skills": 0.11175436839906888, "statistical predictive modeling concepts machine learning approaches": 0.12461892660601635, "physics related quantitative discipline preferred Experience Hive SQL": 0.1501771589075385, "statistics data mining machine": 0.1351764255398765, "classification techniques recommendation optimization": 0.12320525604499144, "Ph D Master Degree operations research": 0.12281648835586104, "Strong analytical problem": 0.12160080910373339}, {"others": 0.29499743629328806, "Collaborative team player values": 0.2680718301601967}, {"passionate Data Science": 0.21488243997507409, "Data Science": 0.20199313028321797}, {}, {"Dog friendly office": 0.43301270189221913}, {"Bayesian": 0.05161859163670356, "AI": 0.05116147008964135, "Experience": 0.09650587926161594, "PhD": 0.04872878583608598, "C C": 0.09556236054630218, "Java C": 0.07097565457256078, "field Electrical Engineering Computer Science Data Science Statistics relevant fields": 0.11892777452139912, "Java C scripting language Experience database systems systems": 0.1175332534776074, "MS BS years": 0.23450341253166868, "aforementioned fields": 0.11710249959289268, "PhD aforementioned fields": 0.11554743962868291, "similar Experience project product program management customer design Excellent storytelling team work": 0.11518155727363691, "BS MS": 0.3341473265155325, "probabilistic graphical models": 0.0751597135213931, "degree": 0.04071272277895663}, {"Jobs Fwd inedinfo Fwd JOB Statistician fte": 0.2733175342336984, "Next message Jobs NPD Group": 0.27067808860805487, "Fwd JOB Statistician fte Next": 0.25515905454811094, "Jobs NPD Group": 0.24741357280085424, "Jobs Fwd": 0.2281192363392978, "Previous message": 0.1697888549455238}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"algorithms": 0.0750030476325901, "Expertise": 0.07560921218978699, "Experience working data analytics Experience": 0.14155876982262003, "e g": 0.12408233454614492, "moderate large scale data": 0.12253655036676595, "innovate state art machine": 0.11849646058039223, "predictive explanatory models experimentation processes": 0.11122560592355904}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {}, {"Minimum years": 0.08245627748497156, "skills": 0.07482877725920983, "related field": 0.0773250349690226, "Excellent problem": 0.09804602473146581, "R Python programming proficiency Proficiency data integration data quality development Programming experience": 0.1638509287784808, "non technical audience Interest educational applications": 0.14764143484421846, "track record Experience": 0.14125014185419774, "Experience technologies": 0.13311873160456028, "technical projects database components": 0.1319086071381395, "technical topics": 0.12808873174721513, "R Shiny Python": 0.12443649948193183, "Django": 0.11474559781680628}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {}, {}, {}, {"At least years": 0.04424142398797163, "SQL": 0.19490096344838082, "Excellent understanding machine": 0.10411418772654205, "techniques": 0.07191537161605531, "advanced quantitative analyses": 0.10282268704977013, "Experience data visualization tools": 0.15350584432131975, "Experience relational databases": 0.1491460979493673, "R Python Experience working AWS environments": 0.14188305625576, "common data science toolkits": 0.11240662614888929, "At least years experience": 0.08532990786823862, "Applied": 0.030959882064885407}, {"Nordstrom Stock Purchase Plan": 0.8}, {}, {"ability": 0.07808841380199534, "data science math physics computer science equivalent degree": 0.1555613730637134, "Exceptional understanding machine learning concepts data science programming": 0.14380924738397527, "mobile video games": 0.1413168569126142, "product managers": 0.12904277776088038}, {}, {}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {"United States": 0.21739245091817708, "Proficiency Python R SQL Authorization work United States": 0.2432146192129675, "Python R SQL Authorization": 0.20321170558259705, "Ph D M S quantitative discipline graduating Passion machine": 0.17272539880945004}, {"computing frameworks": 0.3711047733623777, "Experience Spark": 0.22156958603625435}, {}, {"even new folks": 0.14996520887367523, "An open work environment": 0.13810922110488308}, {"Java Scala": 0.02390225009523722, "SAS": 0.04382220104199382, "Comfortable": 0.03675724050270138, "Computer Science": 0.030674751852071684, "large knowledge stores Experience information extraction creation application layer Experience developing REST JSON applications": 0.13626287405577114, "recommendation engines Experience": 0.12677257636804476, "Python Ruby Strong experience": 0.12147847877561704, "Knowledge statistics experience": 0.12132417418259273, "Fluency": 0.038459099717392864, "Microsoft Azure": 0.034559854857454}, {}, {"able work": 0.23713474573709195, "Self starter results": 0.18968443873813}, {}, {}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"At least years": 0.02816148312018265, "skills": 0.04128603135616575, "SAS": 0.04346893050786188, "Data Science Analytics Engineering Mathematics Industrial Engineering Computer Science Information Technology Economics Finance": 0.11813518369761436, "Bachelor degree Data Science Analytics Engineering Mathematics Industrial Engineering Computer Science Information Technology Economics Finance": 0.11493570809876046}, {"At least year": 0.04468249128075182, "R Python": 0.08781333784009754, "big data technologies": 0.12733333627504884, "Big data experience": 0.1563593105047975, "US Citizenship Advanced degree computer science data science business analytics": 0.1434164504091514, "tools Experience": 0.13386048612369905, "Hive Spark Pig MapReduce Knowledge industry leading analytics": 0.1331509933276854, "oral presentation skills": 0.122492920661959, "Hive Spark": 0.08910793787217897}, {}, {"Proven ability": 0.07322144220389404, "SAS": 0.05636637771467125, "days": 0.050113749054838196}, {"skills": 0.044985756633930465, "Proven": 0.0671749901168194, "collaboratively team environment": 0.08810375155173159, "SAS": 0.06371985974250792, "experience familiarity multivariate predictive modeling analytics software": 0.1260967313969095, "Deep familiarity analytics actuarial market landscape corresponding information": 0.12450568414000734, "Bachelor degree Master degree years work experience completing undergraduate degree years advanced analytics": 0.11998600557683749, "knowledge insurance industry": 0.1192278865765991}, {"Ability": 0.08984743809199851, "functional partners": 0.08809372789516831, "Experience building deploying cloud based data pipelines": 0.12797694360486409, "Demonstrated programming experience": 0.1150184446275592, "team": 0.09024446023413406}, {"BI": 0.08920322029834618, "Strong experience": 0.10375734241290419, "relevant experience": 0.11916752086589907, "business processes related client business questions years": 0.13724319705183172, "BI Tool e OBIEE Cognos Business Objects": 0.24872767275714097, "role Experience": 0.11788132959829851, "g Excel Word PowerPoint Experience": 0.1156125055032833, "Microsoft": 0.043239696794906135}, {}, {"Ability": 0.03969560916849632, "algorithms": 0.05162269528771919, "relational databases": 0.048737920423638934, "large scale data management big data technologies Skilled aspects software project life cycle feasibility requirements": 0.0947206237453477, "scientific data analysis statistical analysis knowledge discovery computer security systems": 0.2082120457225532, "Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules": 0.07771408803337211, "algorithms data management": 0.08868608303980578, "necessary work": 0.0711511968163108, "data analysis": 0.09092050227399612, "project": 0.06898264139774235, "Bachelor degree computer science computer engineering related field equivalent combination education related experience": 0.07772748193805325, "Linux UNIX Windows environments": 0.06579936006235057, "enthusiasm creativity change": 0.06034631684856126, "concurrent technical tasks": 0.06895413379736977, "research concepts": 0.06373020913594289, "conflicting priorities": 0.055363579875351704, "difficult problems": 0.07055348597709955, "Java Python R Matlab software applications": 0.055861554287231246, "Linux UNIX Windows": 0.05391482022788545, "high performance": 0.06707388657488517, "Skilled": 0.03456073721277682, "Java Python R Matlab": 0.03650451783922231, "implementation integration test deployment Experience developing software C C": 0.13318618256546264, "large scale data management big data technologies": 0.09543085202352027, "important project success Effective interpersonal skills necessary interact levels personnel": 0.08966036744582029, "Significant experience demonstrated expertise": 0.07736595655475448, "technical languages concepts": 0.07565785648581894, "creative solutions complex problems": 0.07493141606290966, "Effective advanced analytical problem": 0.07437038086426064, "advanced areas high performance": 0.07354338370220871, "Comprehensive knowledge": 0.06616186577598786, "decision making skills": 0.06440402084228106, "Effective": 0.04418694380070367}, {}, {"hours": 0.06685362093930335, "real world problems": 0.08796295531230966, "401k": 0.06794226451979736, "program entrepreneurial environment Top notch health dental vision insurance Stock options fast growing tech company 401k plan matching contribution": 0.11576044083437186, "Frequent company": 0.10591466245567661}, {"Preferred Master Required United States": 0.32712714606416576, "Data Science years": 0.18521643372082883}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {}, {}, {}, {"requirements": 0.06624698394660714, "Strong data mining data visualization Ability": 0.14776716739293516, "Strong least code bases": 0.14363919514943918, "machine learning models production environment": 0.137968505451815, "Python Healthcare Population Health knowledge preferred Experience": 0.13729294264270395, "Strong working stakeholders": 0.1278145608536644, "Python Healthcare Population Health": 0.12352911888749565, "fast paced environment Experience various math statistics methodologies": 0.11761785772784615, "multiple competing priorities": 0.10409747314311144}, {}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {}, {"Bayesian": 0.13005408544131633, "insights": 0.19733550774960887, "basic knowledge statistical concepts regression time series mixed model": 0.18362555913642048, "Bayesian methods": 0.17584251355560876}, {}, {"Experience": 0.24777310535488486, "algorithms": 0.06463883353306629, "SQL": 0.02941021440424337, "NLP": 0.06627043880425763, "Microsoft Azure": 0.08203967080764993, "BA Computer Science Engineering relevant field graduate degree Data Science quantitative field preferred Experience": 0.13871707922508514, "anomaly detection Experience bioinformatics NLP": 0.13730116627117445, "Experience building": 0.13183304361907033, "Proficient Jupyter Python Spark": 0.11741497678573179, "cases": 0.0664526189211853}, {"AI": 0.3103916281470674, "ideas": 0.06663841083673103, "internal non AI expert business partners": 0.1324689106958545, "asset drive diffusion AI": 0.12430573276273234, "execute coordinate innovative data analytics initiatives": 0.11611823255295908, "BASF": 0.128305615047387}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"Machine": 0.050900496617966674, "Microsoft": 0.069526045616303, "HDFS Hadoop Hive HBase Spark Modern versioning systems git subversion": 0.13600141158860796, "Windows OS Linux OS command line tools": 0.12382583515367843, "neural networks recommendation systems": 0.11937712513791426, "addition time series analysis Modern ML techniques": 0.11625022995742881, "SQL SQL": 0.17516859355455539}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"ability": 0.06987238462801143, "Knowledge": 0.043323360950632654, "tensorflow R caret Experience curating datasets": 0.10578386595873522, "Spark MLLib SQL OS Experience Windows Linux Windows Ability": 0.10567492930161282, "Spark MLLib SQL OS Experience Windows Linux Windows Ability compile results": 0.10286940357936036, "modeling Experience scikit": 0.09981853037813422, "Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical": 0.09972764628924106, "related Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical Modeling Geo spatial analytics Data Munging Cleaning Bachelor Degree Ability work datasets": 0.09852891658098631, "unsupervised machine learning methods Experience C": 0.09668982999617534, "spatial analysis Experience PCAP": 0.08608123700199659, "neural networks cluster analysis feature engineering extraction reduction web scraping decision trees": 0.08473325182528316, "working Intelligence Community teams": 0.07313805640235801, "Intelligence Community": 0.07089410760273644, "multi TB dataset manipulation cleaning": 0.06902849386525074, "Java R Javascript PhP MatLab Pig Hive Impala PySpark Scala Ruby Pytorch": 0.06715283906276817, "senior level leadership": 0.06543557295005008, "present material audiences": 0.06517797007371225, "Elastic Search Hadoop": 0.0635289306518915, "different sizes formats": 0.06299730280115924, "specific techniques": 0.058085805613774084, "multiple databases": 0.057197642535013866, "working fields": 0.049191474206016564, "Impala PySpark": 0.04837715570861541, "Java R Javascript": 0.048328684223073896, "CART": 0.04520606428022443, "presentations": 0.043185899714091563, "PhP MatLab": 0.04216774640090927, "TB": 0.040994860964704456}, {"Comfort": 0.068158475144475, "large datasets": 0.11320548469896705, "time series regression cluster analysis decision trees": 0.12330521816301772, "advanced analytic techniques": 0.12027895072353914, "oral Hands experience manipulating deriving": 0.11915865987800467, "unstructured datasets": 0.11871192832625344, "practical casework agency corporate side Strong knowledge experience wide variety tools": 0.11391674375230662, "SQL SAS R Alteryx Tableau Proficient Excel PowerPoint presentation communication skills": 0.113841832829939, "Degree Statistics Information Systems Mathematics Finance": 0.1144217233191134}, {}, {"Data Visualization skills": 0.43301270189221913, "Data Visualization": 0.3263027573257299}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {}, {"SF Financial District": 0.6933600300017324, "Fun puzzle loving office": 0.2396672665936658}, {"machine": 0.07579126756842287, "SQL": 0.024611648110241132, "US": 0.09373965655626673, "Required Statistical Algorithms years Required expert usage R Python years": 0.12988528117803322, "analytic requirement Modern machine learning models expert level years": 0.12244892062427326, "Strong coding skills": 0.09380905042401659}, {"Excellent": 0.04825012114398577, "SQL": 0.03674457176028379, "Python R": 0.05453022708191249, "experience": 0.04811253843480367, "solutions": 0.04712309181743703, "Drive": 0.044150685795942154, "technical non technical stakeholders": 0.11086937184573918, "verbal communication skills ability": 0.08695700878562118, "large data sets": 0.07307453126904531, "clustering decision trees neural networks": 0.07030633810639601, "databases": 0.03504700031161522}, {}, {}, {}, {}, {}, {"Experience": 0.09374977920472881, "large data sets": 0.20199139108599962, "computing tools Hive Redshift": 0.31120756477299005}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"SQL": 0.2961745101860818, "SQL experience": 0.4714045207910316}, {}, {"Tableau": 0.09623212504793642, "Experience": 0.10636611823292734, "ETL": 0.08591850654245448, "SQL Hive": 0.09909954664062177, "ETL validations Experience Druid columnar data stores Experience BI tools": 0.17942897202938926, "PREFERRED QUALIFICATIONS Experience designing data quality metrics": 0.1608867779057185, "quantitative data analysis years": 0.14299031455375175, "SQL Hive experience years": 0.1428307401112809, "Python R scripting languages": 0.13832075777851455, "Experience BI": 0.13764522525935874}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {"organization Ability": 0.10206703495854182, "methods": 0.06796134753392691, "statistical data analysis linear models": 0.13272093948677877, "Machine Learning PhD Data Science Statistics similar technical quantitative field Ability initiate": 0.13176654737199822, "Research Economics Computer Science Mathematics Physics Electrical Engineering Industrial Engineering": 0.1296952430628345, "g Statistics Operations Research Economics Computer Science Mathematics Physics Electrical Engineering Industrial Engineering": 0.1296574952603314, "analysis stochastic models": 0.12823573807891464, "commitment drive success teams peers": 0.12136557564896198}, {}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"Ability": 0.0893325822671326, "Previous work experience": 0.14376569007795975, "Experience large scale data analysis": 0.14090043874067756, "data mining statistical analysis": 0.11785308897487479, "aggressive deadlines": 0.11591969234359778, "key Strong communication data presentation": 0.11361835630111644, "new technologies tools techniques": 0.11337764828742586}, {"algorithms": 0.041288808750130496, "results": 0.04565547769715315, "large datasets": 0.05043945688928204, "tools": 0.06327487709313016, "things": 0.061470146673193816, "classification techniques recommendation optimization": 0.07959496360524332, "structured unstructured data Strong communication interpersonal skills ability work team environment": 0.10904218142763066}, {"algorithms": 0.06185886988258506, "Agile": 0.055673045544975076, "Java": 0.049268308406802366, "statistical analysis software development Solid background machine": 0.1318066090170279, "Multivariate Regression Logistic Regression Combinatorial Optimization Stochastic Processes Complex Analysis Principal Component Analysis Time Series Analysis Experience Matlab R Weka Experience": 0.1226128792271726, "Multivariate Regression Logistic Regression Combinatorial Optimization Stochastic Processes Complex Analysis Principal Component Analysis Time Series Analysis": 0.12123635458644146, "Strong software development": 0.11976057335785531, "Agile software development methodology": 0.11395392757274113, "software support continuous integration continuous deployment process": 0.11076595795963642, "statistical analysis": 0.10407117788226812}, {"people": 0.0537101359282971, "experience": 0.0772219911495834, "high throughput data ingestion analysis": 0.14233555655375207, "new things test solutions technologies": 0.12255938286774527, "enterprise products": 0.10375410815205229, "deep learning": 0.10325804412004808, "TensorFlow PyTorch": 0.2047504728047294, "unique solutions": 0.1010300470731045, "micro managed freedom": 0.0974204190565185, "cloud console": 0.09702949367124886, "better path": 0.09331532047876613, "frameworks": 0.0764731478932353, "Data science dynamic evolving profession": 0.0665345576462926}, {"PhD": 0.0194843644872548, "Deep Learning": 0.12132151460822119, "Deep": 0.041448759500956986, "MS years": 0.04111937461608863, "Deep knowledge": 0.062258895662656924, "solutions": 0.1581573782581352, "US": 0.04527650845130134, "requirements": 0.04354602327052094, "Demonstrated ability": 0.06606976017574621, "ETL": 0.043539452655746935, "models": 0.05574970605997304, "Breadth skills experience machine": 0.10651211819208238, "business process outsourcing systems transportation systems healthcare systems financial services": 0.0952706146109928, "novel solutions problems": 0.0924895675655186, "real world context Prior experience similar role": 0.09215572427105945, "practice Experience knowledge services": 0.08817637149068558, "feasibility solutions": 0.0853215832129521, "analytics models": 0.08394115138490749, "Desired interdisciplinary skills": 0.08207944801510013, "big data technologies ETL statistics causal inference": 0.08022836506624882, "analytics packages": 0.07624254746411682, "diverse learning settings": 0.0753326610597479, "multi disciplinary environments": 0.07402041996080519, "data mining statistical predictive": 0.07233224714414609, "work US employer": 0.06951113825551561, "Ability inclination": 0.06596067878002476, "different types": 0.06533239373341822, "sponsorship": 0.06198243713621002, "history driving": 0.052612076507412404, "related field": 0.04790755308721288, "Breadth": 0.04544048582764686, "simulation": 0.04539951113677476, "methods": 0.042795403204940144, "experiments": 0.04249035753967234, "ideas": 0.02500487360261578, "desire": 0.0194843644872548}, {}, {}, {}, {"Computer science Data analytics Economics Engineering Geospatial": 0.2066545393647228, "Economics Engineering Geospatial analysis": 0.08655614600535444, "Mathematics Operations research": 0.19128763256688797, "Creativity Initiative Integrity Leadership": 0.07279234445801354, "Mathematics Operations": 0.14533726423478918, "Computational": 0.10470552480156531, "Bachelor": 0.04766753825018256, "Advanced degree data science equivalent field sub field Experience working data rich problems": 0.11534619223739115, "research programs Experience computer programming user experience user interface Ability": 0.11465152313376208, "Experience real world data thesis research internships": 0.11015226347796168, "work experience Creativity Initiative Integrity Leadership": 0.09902163303262418, "large incomplete data": 0.08654944725911146, "solutions": 0.047780633682502564, "projects": 0.046743575320753315, "current area expertise interest related interest positions": 0.128070894576311, "Bachelor degree Computational social science Computer science Data analytics Economics Engineering Geospatial analysis": 0.11137925312730639, "Bachelor degree Computational social science Computer science Data analytics": 0.10940611826543917, "Quantitative finance Statistics GPA": 0.17708373343747816, "CIA": 0.11755371327120726}, {"SQL": 0.06588040530214372, "SAS": 0.028605717185972313, "continuous improvement data science analytics Presents data insights": 0.14619721679578077, "analytics related field Certificate business analytics data mining statistical analysis": 0.1373848231096337, "Doctoral degree Statistics Economics Analytics Mathematics year experience analytics related field": 0.13157382999555792, "large data analytics project teams Models compliance company": 0.12940483425972377, "analytics insights": 0.12614136022063963, "data science experience years": 0.12098718382843293, "DB2 Oracle SQL Server years": 0.11063716833550258}, {"Commuter Benefits Flexible Spendi": 0.4}, {}, {"Tableau": 0.04911605457905818, "Bayesian": 0.048758583887770865, "data": 0.0904307719754521, "ability": 0.09900756535300498, "Knowledge": 0.15611657072863055, "Microsoft": 0.048958118957755946, "Bayesian methods": 0.06531371669729215, "Demonstrable knowledge healthcare data": 0.12048487229199854, "little supervision Strong oral written presentation skills levels organization Ability": 0.11039692384327648, "working data science team": 0.11036534603357413, "R Python preferred ability interest": 0.10747116311678481, "g": 0.06511282809678427, "least one scripting language": 0.02465253729440563}, {}, {}, {"Expertise": 0.28448553895959316, "ML": 0.0694800238982679, "neural networks decision trees": 0.11282805882808505, "data mining Strong knowledge experiences machine": 0.1294406612905801, "Expertise data warehouse SQL programming": 0.12572756915865457, "Math quantitative field strong background machine": 0.11795571890586588, "Python based ML libraries": 0.11766549013242977, "Experience payment fraud detection prevention": 0.11534082795441172, "Python R SAS Base SAS Stats SAS Enterprise": 0.11386916352402167, "Python R SAS Base SAS Stats SAS Enterprise Miner": 0.11372185722163108}, {"TensorFlow": 0.2646126144072281, "xgboost": 0.12285361368018546, "Java": 0.33634821724284325, "mathematics statistics physics": 0.15956383639901173, "computer science artificial intelligence": 0.14402945444990406}, {"Java Scala": 0.08140428870161, "NLP": 0.05474184213411689, "relevant work experience Experience building": 0.12471996307819778, "MS Computer Science emphasis Data Science Analytics Machine Learning PhD": 0.11854839458578811, "ideas efficient elegant code Development experience": 0.1152667508673706, "RDF S OWL SPARQL Strong command linear algebra statistics ability": 0.1108023187734821, "Python Java Scala good command respective data pipelining matrix algebra statistics": 0.10884829634791231, "Java Python": 0.08385505496546813}, {}, {}, {}, {"SAS": 0.07615423718253587, "tools": 0.06660588946157295, "Java Python": 0.14284646847104246, "common methods data transformation": 0.1593119795498423, "various data structures": 0.15927487011182334, "years practical experience SAS ETL data processing database programming data analytics Experience predictive": 0.15773482073750061, "Qlik SAP BO Experience mining Claims EMR data preferably Oncology related data": 0.13917984155682261, "statistical analysis Experience analytics": 0.13885824766117846, "Python SAS Alteryx Angos R Experience programming languages": 0.13560666076285766, "Tableau MS Power BI Tibco": 0.11715710661413538, "Extensive": 0.049600871732928944}, {"data analytics": 0.156569108959593, "English": 0.06221547167095306, "data warehouse data cubes": 0.19399184409138878, "Pentaho data integration experience": 0.17850053853700223, "ETL ELT processes": 0.14622448708060906, "ETL ELT": 0.13235553529617888, "operational data PLAN TRACK VIEW": 0.12303485802177781, "applying structure schema": 0.10910988690426339, "Create": 0.18919929871544167}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"Computer Science": 0.20122315003292307, "Mathematics related field": 0.3054129409993863, "Ph D MS degree": 0.18438141779870657, "D MS degree": 0.1823400424586527}, {"Competitive": 0.1307952640160164, "business problems": 0.08458821461357892, "ML": 0.04895442551491851, "Frequent company": 0.07144751228238055, "HomeAway com Electronic adjustable stand desk": 0.09102317759994927, "talks leadership team": 0.08864731152452338, "Discounted Metro Rail": 0.16611341666544338, "unstructured data": 0.07960335754373472, "real time": 0.07695089295253979, "weeks": 0.10408114299802201, "Annual": 0.04942313211454808, "e": 0.0361468398217773}, {"Ability": 0.12186027597311673, "complex analytical concepts": 0.26255703162980437, "people": 0.21448185310445242}, {"Deep": 0.06330296423748374, "Ability work": 0.0948870723488869, "projects": 0.05894486907649776, "relevant experience": 0.0797348512936727, "Strong statistical knowledge intuition ability": 0.12555966593515014, "Hive Pig Presto Spark Data visualization skills": 0.11817946211347764, "Strong skills": 0.11783094737739581, "massive amounts data drive product innovation": 0.1163040662730726, "Deep product sense": 0.11278403252659644, "predictive modeling time series probabilistic graphical models": 0.11096294537844048, "track record": 0.08110982349999098}, {"PhD": 0.0194843644872548, "Deep Learning": 0.12132151460822119, "Deep": 0.041448759500956986, "MS years": 0.04111937461608863, "Deep knowledge": 0.062258895662656924, "solutions": 0.1581573782581352, "US": 0.04527650845130134, "requirements": 0.04354602327052094, "Demonstrated ability": 0.06606976017574621, "ETL": 0.043539452655746935, "models": 0.05574970605997304, "Breadth skills experience machine": 0.10651211819208238, "business process outsourcing systems transportation systems healthcare systems financial services": 0.0952706146109928, "novel solutions problems": 0.0924895675655186, "real world context Prior experience similar role": 0.09215572427105945, "practice Experience knowledge services": 0.08817637149068558, "feasibility solutions": 0.0853215832129521, "analytics models": 0.08394115138490749, "Desired interdisciplinary skills": 0.08207944801510013, "big data technologies ETL statistics causal inference": 0.08022836506624882, "analytics packages": 0.07624254746411682, "diverse learning settings": 0.0753326610597479, "multi disciplinary environments": 0.07402041996080519, "data mining statistical predictive": 0.07233224714414609, "work US employer": 0.06951113825551561, "Ability inclination": 0.06596067878002476, "different types": 0.06533239373341822, "sponsorship": 0.06198243713621002, "history driving": 0.052612076507412404, "related field": 0.04790755308721288, "Breadth": 0.04544048582764686, "simulation": 0.04539951113677476, "methods": 0.042795403204940144, "experiments": 0.04249035753967234, "ideas": 0.02500487360261578, "desire": 0.0194843644872548}, {"advanced topics analytics artificial intelligence data engineering": 0.12619946362828915, "professional experience media company": 0.12166837235744554, "SQL Tableau Excel interest": 0.10528548595306969, "analytics tools": 0.10512190115422484, "work sweat details": 0.09664903807750103, "either R Python Experience building web applications agile development": 0.09498097708421006, "learning libraries": 0.08584650422273911, "visualization machine": 0.08476235737415024, "Excel": 0.06599852781738813, "statistics": 0.04824675124296681}, {"PhD": 0.0194843644872548, "Deep Learning": 0.12132151460822119, "Deep": 0.041448759500956986, "MS years": 0.04111937461608863, "Deep knowledge": 0.062258895662656924, "solutions": 0.1581573782581352, "US": 0.04527650845130134, "requirements": 0.04354602327052094, "Demonstrated ability": 0.06606976017574621, "ETL": 0.043539452655746935, "models": 0.05574970605997304, "Breadth skills experience machine": 0.10651211819208238, "business process outsourcing systems transportation systems healthcare systems financial services": 0.0952706146109928, "novel solutions problems": 0.0924895675655186, "real world context Prior experience similar role": 0.09215572427105945, "practice Experience knowledge services": 0.08817637149068558, "feasibility solutions": 0.0853215832129521, "analytics models": 0.08394115138490749, "Desired interdisciplinary skills": 0.08207944801510013, "big data technologies ETL statistics causal inference": 0.08022836506624882, "analytics packages": 0.07624254746411682, "diverse learning settings": 0.0753326610597479, "multi disciplinary environments": 0.07402041996080519, "data mining statistical predictive": 0.07233224714414609, "work US employer": 0.06951113825551561, "Ability inclination": 0.06596067878002476, "different types": 0.06533239373341822, "sponsorship": 0.06198243713621002, "history driving": 0.052612076507412404, "related field": 0.04790755308721288, "Breadth": 0.04544048582764686, "simulation": 0.04539951113677476, "methods": 0.042795403204940144, "experiments": 0.04249035753967234, "ideas": 0.02500487360261578, "desire": 0.0194843644872548}, {}, {"PhD": 0.0194843644872548, "Deep Learning": 0.12132151460822119, "Deep": 0.041448759500956986, "MS years": 0.04111937461608863, "Deep knowledge": 0.062258895662656924, "solutions": 0.1581573782581352, "US": 0.04527650845130134, "requirements": 0.04354602327052094, "Demonstrated ability": 0.06606976017574621, "ETL": 0.043539452655746935, "models": 0.05574970605997304, "Breadth skills experience machine": 0.10651211819208238, "business process outsourcing systems transportation systems healthcare systems financial services": 0.0952706146109928, "novel solutions problems": 0.0924895675655186, "real world context Prior experience similar role": 0.09215572427105945, "practice Experience knowledge services": 0.08817637149068558, "feasibility solutions": 0.0853215832129521, "analytics models": 0.08394115138490749, "Desired interdisciplinary skills": 0.08207944801510013, "big data technologies ETL statistics causal inference": 0.08022836506624882, "analytics packages": 0.07624254746411682, "diverse learning settings": 0.0753326610597479, "multi disciplinary environments": 0.07402041996080519, "data mining statistical predictive": 0.07233224714414609, "work US employer": 0.06951113825551561, "Ability inclination": 0.06596067878002476, "different types": 0.06533239373341822, "sponsorship": 0.06198243713621002, "history driving": 0.052612076507412404, "related field": 0.04790755308721288, "Breadth": 0.04544048582764686, "simulation": 0.04539951113677476, "methods": 0.042795403204940144, "experiments": 0.04249035753967234, "ideas": 0.02500487360261578, "desire": 0.0194843644872548}, {}, {"algorithms": 0.038386369006501886, "Spark": 0.02165991995468779, "problems": 0.08480371546395653, "skills": 0.07284805183659741, "industry experience": 0.07575954224930545, "NLP": 0.04717991359581088, "structured semi structured unstructured data": 0.09853935656815116, "millions": 0.05165140552517689, "Years": 0.0245373028873681, "daily": 0.0}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {}, {}, {"Masters": 0.39918259705454984}, {"Education Computer science Statistics Physics Mathematics Economics Specialization Certification": 0.6}, {}, {"Excellent": 0.05821725911452372, "Computer Science": 0.18608323367744775, "quantitative trading research role Experience top tier quantitative investment firms": 0.15617872845682806, "working experience": 0.13951617405663153, "AQR Capital QMS Capital": 0.12790357364587326, "Publications top tier journals": 0.12299871535671775}, {}, {"Bayesian": 0.04833855749361184, "Masters": 0.05285251133562155, "hard questions data": 0.07502466521486231, "Proven": 0.04485827571471869, "Professional experience": 0.2497801688792307, "advanced optimization methodologies": 0.12045956656250778, "advanced quantitative analyses": 0.10978345143296236, "mixed integer optimization Ability": 0.10882025947607402, "A strong passion empirical research": 0.05432549989619069, "Professional experience software development practices": 0.11943885910358529, "advanced statistical methodologies multiple regression model mixed models time series models": 0.11905231054784486, "prior experience optimization simulation marketing mix multivariate testing ensemble modeling graph": 0.11423218440048041, "Python R SQL": 0.15996755722860168}, {"Ability": 0.03969560916849632, "algorithms": 0.05162269528771919, "relational databases": 0.048737920423638934, "large scale data management big data technologies Skilled aspects software project life cycle feasibility requirements": 0.0947206237453477, "scientific data analysis statistical analysis knowledge discovery computer security systems": 0.2082120457225532, "Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules": 0.07771408803337211, "algorithms data management": 0.08868608303980578, "necessary work": 0.0711511968163108, "data analysis": 0.09092050227399612, "project": 0.06898264139774235, "Bachelor degree computer science computer engineering related field equivalent combination education related experience": 0.07772748193805325, "Linux UNIX Windows environments": 0.06579936006235057, "enthusiasm creativity change": 0.06034631684856126, "concurrent technical tasks": 0.06895413379736977, "research concepts": 0.06373020913594289, "conflicting priorities": 0.055363579875351704, "difficult problems": 0.07055348597709955, "Java Python R Matlab software applications": 0.055861554287231246, "Linux UNIX Windows": 0.05391482022788545, "high performance": 0.06707388657488517, "Skilled": 0.03456073721277682, "Java Python R Matlab": 0.03650451783922231, "implementation integration test deployment Experience developing software C C": 0.13318618256546264, "large scale data management big data technologies": 0.09543085202352027, "important project success Effective interpersonal skills necessary interact levels personnel": 0.08966036744582029, "Significant experience demonstrated expertise": 0.07736595655475448, "technical languages concepts": 0.07565785648581894, "creative solutions complex problems": 0.07493141606290966, "Effective advanced analytical problem": 0.07437038086426064, "advanced areas high performance": 0.07354338370220871, "Comprehensive knowledge": 0.06616186577598786, "decision making skills": 0.06440402084228106, "Effective": 0.04418694380070367}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"Postgres Druid Aerospike Elasticsearch": 0.31120756477299005, "Nice Experience working Database storage systems": 0.21983850454982395}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"techniques": 0.05883505161508465, "complex ideas": 0.07814121469672944, "problem": 0.10733604761263751, "real world problems": 0.11562372569523144, "g artificial intelligence operations research": 0.1316524005187437, "Familiarity operations research CPLEX": 0.12280458934079744, "complicated problems": 0.11581226724917949, "integer problems": 0.11443465535040033, "actionable manner Ability": 0.11273035311190911, "quantitative research e": 0.11168328262300231, "languages": 0.08390524155010144, "key decisions": 0.0780570714737914, "colleagues": 0.063056702278848}, {}, {"experience": 0.1359943915578266, "IT systems": 0.18243217794431832, "preferably Big similar firm Demonstrated expertise business analysis data analysis Experience writing requirements": 0.1803174068458849, "accessing data years": 0.1671335572223526, "working SQL": 0.10357308949613159}, {"Ability": 0.04055029109031064, "algorithms": 0.050092959770347396, "machine": 0.04288205287663034, "Machine Learning": 0.050157558549782, "Best Places Work Glassdoor Work premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules": 0.07687926694261168, "project": 0.046215580247616246, "concurrent technical tasks": 0.062361458332695685, "difficult problems": 0.05717480395276384, "probabilistic graphical models": 0.060095012781292256, "deep learning": 0.07275792979985703, "Master degree computer science computer engineering related field equivalent combination education related experience Experience developing software": 0.11066628331421603, "Broad": 0.040462226469543706}, {}, {}, {"relevant experience": 0.22642420225309795, "years experience": 0.24837749738674433, "PhD Masters approved field minimum years": 0.22774698911916366, "minimum years": 0.19281187842373576, "PhD Masters": 0.16866051710250332, "Preferred Bachelors Science Computer Science Math Scientific Computing Data Analytics Machine Learning Business Analyst nanodegree equivalent experience": 0.16022626756200278}, {}, {"At least years": 0.04206776572351816, "SQL": 0.06293442060256807, "Excel": 0.06281095203626212, "data data sources": 0.16661286337863845, "Advanced knowledge R Experience SAS SPSS Experience": 0.15277652597936886, "Exposure Big Data technologies Hadoop Hive Advanced knowledge Excel Experience handling": 0.1374710961051051, "solid experience marketing analytics": 0.13595143120438533, "digital behavioural data": 0.13529435537730194, "segmentation predictive analytics": 0.11530749641365354, "information webpages product characteristics reviews": 0.11372684058242695}, {}, {"goals": 0.18810125548596754, "ML": 0.14526202384379108, "track record application ML NLP": 0.23689363126861704, "global business rely diversity culture": 0.16949374856596988, "Multiple years": 0.22259255080863039}, {}, {"techniques": 0.0766793606548531, "SAS": 0.07806296573957174, "Comfortable": 0.07243908520727463, "statistical analysis Experience Python development": 0.1688034387566401, "Python SAS R statistical packages": 0.15856295529220857, "Master Degree Economics Math Statistics Finance Engineering similar discipline year experience business application machine": 0.14874505680252395, "Comfortable developing statistical models": 0.1428199327248952, "Bachelor Degree Economics Math Science Finance": 0.25698001003330734, "similar discipline": 0.12147494813024291}, {}, {}, {}, {}, {}, {"Excellent communication presentation": 0.11322812237012522, "Possess": 0.07204237180033911, "Background": 0.07025983005757269, "data pipelines": 0.0943729061918972, "Experience working scientists R D systems": 0.13971748068380155, "good organizational communication analytical technical writing skills": 0.13388539596793603, "data science statistics": 0.12622399023503914, "Experience scripting languages": 0.12340376022907072}, {}, {"Minimum years": 0.13251040900529212, "healthcare domain Masters PhD Application data science solutions industrial projects": 0.225125426420805, "data science problems": 0.1862561567924216, "Masters PhD Application": 0.1770309037832678, "BS MS PhD healthcare related field Minimum years": 0.16086609672934665, "BS MS PhD": 0.12837741145967574}, {}, {"A love games": 0.24999999999999997}, {"Tableau": 0.04976441810679003, "Proven": 0.050595687032169184, "large datasets": 0.06716262567636808, "Strong": 0.11573060236129787, "Excel": 0.05695667015284167, "multiple projects": 0.08371553019383572, "related field minimum years general management experience business marketing analytics field equivalent combination experience training": 0.11580046286893748, "Alteryx": 0.05028077728147317, "CRM": 0.04649282552822586}, {}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {}, {}, {}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {}, {"Java Scala": 0.2559096402889515, "internship school project": 0.1755784839564672, "Machine Learning Algorithms Statistics": 0.14765009840771978, "Python R Programming": 0.13810740073899636, "engine implementation": 0.13401324156539504, "Theoretical knowledge Machine Learning Algorithms Statistics etc Basic coding ability": 0.12340523058138786}, {"data": 0.11348228124317566, "English": 0.06104386334561915, "SQL": 0.05368353140438974, "data scientists": 0.11957945141384041, "customers": 0.0574929140845608, "Proven": 0.05824735365648322, "people": 0.05613665224399951, "SAS": 0.07131237535355654, "Excel": 0.05699975089627714, "requirements": 0.0555932695165281, "SQL data exploration tools SAS R Experience data analytics design Experience": 0.1561504914243364, "data analysis Experience": 0.1515741989377827, "Health care industry experience Demonstrated ability": 0.1375665844585941, "Formulas Bilingual Spanish English Master Degree Experience": 0.12706457321124703, "Proven organizational skills ability flexible work ambiguity": 0.11900475372401198, "deep technical concepts": 0.11453168723628562, "SAS R Python Proficient MS Office applications Excel proficiency Pivots V Lookups": 0.10930208768117076, "SAS R Python Proficient MS Office": 0.10363679108811297, "Bachelor degree Minimum year experience": 0.10155604775523161, "deeper understanding": 0.09035006587451908, "Pivots V Lookups": 0.08827834931139683, "technical well technical senior stakeholders": 0.07727475269760889, "large databases": 0.0728984855703774, "predictive statistical modeling": 0.07167244420536713, "Spanish": 0.060681071768047885, "Bilingual": 0.06028501286325526, "deliverables": 0.05781206593599976}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"people": 0.11525876102834683, "young growing company": 0.2608068623959588, "today": 0.1389732147177363, "Fetch": 0.1294096178853818}, {}, {}, {"technology roadmaps realization": 0.16349481697991047, "existing problems": 0.20174238740745434, "new solution methods": 0.180410241034476, "External Technology Knowledge Keeps": 0.20803683332230963, "latest technological developments areas": 0.15110156652548595, "opportunities": 0.11549623764742417}, {"web mobile applications business intelligence tools": 0.31053380567540323, "Building": 0.24062426851434826}, {}, {"Bachelor degree": 0.029329789371349196, "ETL": 0.047877227053157466, "large data": 0.10310501303215314, "insights": 0.04808203463301625, "data systems": 0.08347333478777039}, {"Crown Center": 0.22369220085444674, "site cafeteria": 0.15130319566206213}, {"English": 0.1314284336687967, "strong baselines ability": 0.08116588114827482, "experimental analytic plans data modeling processes": 0.10399783643556462, "machine": 0.08482483489686432, "techniques": 0.07964520837800988, "ML": 0.056912396690115025, "MS years": 0.07880079681733679, "Fluency": 0.057954168842638994}, {"Java Scala": 0.057326205115803205, "problems": 0.047615278099329916, "NLP": 0.033016441655972735, "Expertise": 0.03359185359895023, "Proven": 0.03414769576937941, "Machine Learning": 0.13165454958622666, "Communicate": 0.03495903968568136, "ideas": 0.033274204639916996, "Machine Learning algorithms models": 0.143743815355129, "Background Machine Learning Statistics Information Retrieval Design": 0.12993325491554136, "Scala Golang Haskell Clojure": 0.12659847390188672, "collaborative environment": 0.04497793926213313, "Write": 0.03465232710779792, "company": 0.03251909272919973, "features": 0.032104139799020444, "Superb": 0.03172833690877689}, {"Bayesian": 0.056137645820502034, "data": 0.1180790470221248, "algorithms": 0.054202500838421284, "The ability": 0.025801617362211916, "new trends data science": 0.1407478680229112, "implementation data science project": 0.12809931275693612, "digital marketing data": 0.1235232213260736, "connecting data": 0.12288472793440103, "new challenges": 0.10027568337713019, "business": 0.07323583064222323, "Education": 0.05642003810567418}, {"New York NY": 0.43301270189221913, "New York": 0.3263027573257299}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {}, {}, {"SQL": 0.10990845834633606, "problems": 0.05485009844110767, "clients": 0.054914467761325546}, {"machine": 0.06569979813326511, "Write": 0.07564173417219397, "real world Experience Python": 0.1431535853180977, "natural language processing Development deployment software": 0.1283760839909503, "related degree equivalent experience years": 0.12444779534987158, "work ethic passion problem": 0.12385091188419345}, {"Ability": 0.05646685104843648, "Degree": 0.05900936983576015, "real world problems": 0.08341102359496755, "analysis impact": 0.09304427301659332, "key business product decisions": 0.11363321284298807, "Familiar data pipelines": 0.13169648910183587, "knowledge": 0.07040383211336797}, {"smartest people": 0.29064737094615933, "boundaries": 0.164191770372194, "Huge technical problems": 0.16095789879425387}, {}, {"Background": 0.06221395179626451, "e g": 0.0996188511054264, "extensive operational data analysis experience data analysis regression analysis": 0.17550883717574783, "industry experience predictive modeling data science analysis Programming experience": 0.16278948872828128, "Python R equivalent Demonstrated experience data science data analysis Desire": 0.14552444295668482, "Comfortable Linux environment Experience Amazon Web Services AWS": 0.12629889294625252, "e g Computer Science Operations Research Systems Engineering Physics equivalent experience years": 0.12581539125539362, "Desire": 0.054529364734777104}, {}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"PhD": 0.0194843644872548, "Deep Learning": 0.12132151460822119, "Deep": 0.041448759500956986, "MS years": 0.04111937461608863, "Deep knowledge": 0.062258895662656924, "solutions": 0.1581573782581352, "US": 0.04527650845130134, "requirements": 0.04354602327052094, "Demonstrated ability": 0.06606976017574621, "ETL": 0.043539452655746935, "models": 0.05574970605997304, "Breadth skills experience machine": 0.10651211819208238, "business process outsourcing systems transportation systems healthcare systems financial services": 0.0952706146109928, "novel solutions problems": 0.0924895675655186, "real world context Prior experience similar role": 0.09215572427105945, "practice Experience knowledge services": 0.08817637149068558, "feasibility solutions": 0.0853215832129521, "analytics models": 0.08394115138490749, "Desired interdisciplinary skills": 0.08207944801510013, "big data technologies ETL statistics causal inference": 0.08022836506624882, "analytics packages": 0.07624254746411682, "diverse learning settings": 0.0753326610597479, "multi disciplinary environments": 0.07402041996080519, "data mining statistical predictive": 0.07233224714414609, "work US employer": 0.06951113825551561, "Ability inclination": 0.06596067878002476, "different types": 0.06533239373341822, "sponsorship": 0.06198243713621002, "history driving": 0.052612076507412404, "related field": 0.04790755308721288, "Breadth": 0.04544048582764686, "simulation": 0.04539951113677476, "methods": 0.042795403204940144, "experiments": 0.04249035753967234, "ideas": 0.02500487360261578, "desire": 0.0194843644872548}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {}, {"depth knowledge": 0.05018400425368634, "problems": 0.029450414224380765, "Bachelor": 0.022642899580559834, "large datasets": 0.035302660374762096, "projects": 0.03156283356050533, "methodologies": 0.023880268501067798, "things": 0.025278355710994998, "healthcare data": 0.06065055025761246, "Advanced": 0.04816847475878319, "areas": 0.04202588112469803, "five years": 0.013796992366283376}, {"date thread subject author": 0.211135472072854, "Chief Statistician Next message Jobs Tenure track position University Hawaii Messages": 0.19800344324350086, "University Hawaii Messages": 0.1635256074853059, "Jobs Fwd OMB": 0.3033344712384062, "Jobs Tenure": 0.14722945253665914, "Statistician": 0.10748708497253395}, {"AI": 0.058707729407044495, "machine": 0.07351016475353951, "United States": 0.09728480158558783, "Extensive": 0.06343678122112067, "key decisions": 0.08233779440139935, "CRM": 0.06899633726374259, "Python R similar data science language Advanced proficiency data visualization Prefer financial services industry experience Prefer experience CRM financial analysis financial advisory Bachelors Master degree Computer Science Math Data Science Statistics": 0.15113754228419643}, {"Best Corporate Citizens InformationWeek": 0.19669410693284783, "FORTUNE World Most Admired Companies Corporate Responsibility Magazine Best Corporate Citizens": 0.19147452894563152, "Elite Women Business Enterprise National Council America Top Corporations Women Business Enterprises Reputation Institute World Most Reputable Companies": 0.1870974639108549, "Corporate Responsibility Magazine": 0.17002558665561687, "FORTUNE World Most Admired Companies": 0.14920133671800753}, {}, {}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"PhD": 0.054770339164348654, "Machine Learning": 0.19015366088616995, "simple terms": 0.0903731479871624, "diverse technical non technical audiences": 0.14947894491386318, "technical concepts": 0.12219682167521126}, {}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {}, {}, {"Doctorate Preferred": 0.4714045207910316}, {"Experience": 0.11358025337582056, "Proven ability": 0.06812740905915352, "Python development language emphasis data science Experience Python data analysis packages": 0.13795590141171823, "Postgres Knowledge Bayesian data analysis methods model comparison": 0.1297947805979622}, {"Technologies Linux Python": 0.4485244621691702, "Numerical topic": 0.16600229555606477, "MS PhD degree Computer Science Artificial Intelligence Machine Learning": 0.1564076256059939, "technical field": 0.15370915147213973}, {"ability": 0.06987238462801143, "Knowledge": 0.043323360950632654, "tensorflow R caret Experience curating datasets": 0.10578386595873522, "Spark MLLib SQL OS Experience Windows Linux Windows Ability": 0.10567492930161282, "Spark MLLib SQL OS Experience Windows Linux Windows Ability compile results": 0.10286940357936036, "modeling Experience scikit": 0.09981853037813422, "Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical": 0.09972764628924106, "related Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical Modeling Geo spatial analytics Data Munging Cleaning Bachelor Degree Ability work datasets": 0.09852891658098631, "unsupervised machine learning methods Experience C": 0.09668982999617534, "spatial analysis Experience PCAP": 0.08608123700199659, "neural networks cluster analysis feature engineering extraction reduction web scraping decision trees": 0.08473325182528316, "working Intelligence Community teams": 0.07313805640235801, "Intelligence Community": 0.07089410760273644, "multi TB dataset manipulation cleaning": 0.06902849386525074, "Java R Javascript PhP MatLab Pig Hive Impala PySpark Scala Ruby Pytorch": 0.06715283906276817, "senior level leadership": 0.06543557295005008, "present material audiences": 0.06517797007371225, "Elastic Search Hadoop": 0.0635289306518915, "different sizes formats": 0.06299730280115924, "specific techniques": 0.058085805613774084, "multiple databases": 0.057197642535013866, "working fields": 0.049191474206016564, "Impala PySpark": 0.04837715570861541, "Java R Javascript": 0.048328684223073896, "CART": 0.04520606428022443, "presentations": 0.043185899714091563, "PhP MatLab": 0.04216774640090927, "TB": 0.040994860964704456}, {"Master": 0.025392751393769692, "quantitative field": 0.08551561050030565, "complex problems": 0.08288526616059683, "Statistician": 0.059622218514518155, "Spark Hadoop": 0.1622301375677709}, {"data": 0.07796889516495273, "SQL": 0.04890235739113012, "data mining machine": 0.03858252542695961, "complex concepts": 0.0787652200853765, "large data sets": 0.08706416398888263, "track record": 0.06689546943855529, "working SQL": 0.06507841674076452}, {"date thread subject author": 0.3644870160185702, "Messages": 0.1363024879554495}, {}, {"Tableau": 0.0745785201599565, "At least years": 0.03725393027723467, "techniques": 0.0702635719747134, "Professional experience": 0.14210309071651167, "SAS": 0.06061706531939157, "analysis Experience machine": 0.1529892394663261, "Python scikit computer language experience": 0.14691725027816638, "statistical software Insurance industry experience": 0.1456610811160259, "progressive experience data science statistical analysis data modeling years": 0.1415058021561058, "regression segmentation decision tree time series design experiments": 0.12474392451579702}, {"Advanced Degree": 0.26099183937612236, "MBA": 0.17776537474909693}, {"data science": 0.1113087227851925, "Deep": 0.028527458067248025, "large datasets": 0.09360621307148817, "ETL": 0.05081110880499199, "Build": 0.1253388465827312, "internal data processing visualization tools years": 0.12562782038546624, "data sources": 0.06110788192023853, "data warehouses": 0.05628855561745655}, {}, {"Hadoop": 0.06362529200862335, "Bachelor": 0.06164373162236906, "quantitative discipline": 0.08346927887334356}, {"hypotheses": 0.0378472750107983, "At least years": 0.05128973629477643, "problems": 0.04388291957074681, "libraries": 0.036761666719364976, "Machine": 0.05018909640126455, "US": 0.11217753106526804, "work": 0.01853452092279411, "information": 0.035259256802345, "ETL": 0.03782393778710561, "opportunities": 0.0450803720947766, "advanced data analysis": 0.06890635586929712, "first year": 0.052033747303223056, "At least years experience": 0.0388128869795116, "insights": 0.03404153103149105, "frameworks": 0.035830872266287755, "Regularization Boosting Random Forests Decision Trees Bayesian": 0.14092235736341635, "Washington DC": 0.12659489774166538, "hour": 0.055281562868462523, "U S": 0.10562027764575473, "Willingness": 0.04123332412515369, "Designing": 0.03655597134130605, "Health": 0.03536469493612245}, {}, {"data": 0.11062248047365958, "Experience": 0.22825169224697883, "3rd": 0.08042035276300949, "clustering decision trees neural networks": 0.11441651036059898, "databases": 0.0472241361456283, "Google Analytics Adobe Analytics Experience": 0.3220676082083148, "analyzing data 3rd party providers": 0.14671083832954734, "Hadoop Hive Spark Experience visualizing": 0.14179970256456093, "Map Reduce Hadoop Hive": 0.12482261050455051, "data computing tools": 0.11897425461615699, "etc Experience": 0.05271247038471234}, {}, {"ML": 0.06109585943450685, "Java": 0.03992479290208136, "data science analysis": 0.16386713727077862, "preferred Excellent communication collaborative skills years": 0.14527721857605022, "Python R C": 0.1417035182742587, "Mathematics Physics Engineering MS PhD": 0.12119601446419997, "Scikit Learn Keras TensorFlow": 0.23813626211909344}, {}, {"United States Preferred": 0.8660254037844383}, {}, {"ability": 0.06987238462801143, "Knowledge": 0.043323360950632654, "tensorflow R caret Experience curating datasets": 0.10578386595873522, "Spark MLLib SQL OS Experience Windows Linux Windows Ability": 0.10567492930161282, "Spark MLLib SQL OS Experience Windows Linux Windows Ability compile results": 0.10286940357936036, "modeling Experience scikit": 0.09981853037813422, "Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical": 0.09972764628924106, "related Data Science Statistical Modeling Information Retrieval Text Analysis Data Mining Machine Learning Intelligence Analysis Cyber Threat Analysis Image Analysis Network Security Statistical Modeling Geo spatial analytics Data Munging Cleaning Bachelor Degree Ability work datasets": 0.09852891658098631, "unsupervised machine learning methods Experience C": 0.09668982999617534, "spatial analysis Experience PCAP": 0.08608123700199659, "neural networks cluster analysis feature engineering extraction reduction web scraping decision trees": 0.08473325182528316, "working Intelligence Community teams": 0.07313805640235801, "Intelligence Community": 0.07089410760273644, "multi TB dataset manipulation cleaning": 0.06902849386525074, "Java R Javascript PhP MatLab Pig Hive Impala PySpark Scala Ruby Pytorch": 0.06715283906276817, "senior level leadership": 0.06543557295005008, "present material audiences": 0.06517797007371225, "Elastic Search Hadoop": 0.0635289306518915, "different sizes formats": 0.06299730280115924, "specific techniques": 0.058085805613774084, "multiple databases": 0.057197642535013866, "working fields": 0.049191474206016564, "Impala PySpark": 0.04837715570861541, "Java R Javascript": 0.048328684223073896, "CART": 0.04520606428022443, "presentations": 0.043185899714091563, "PhP MatLab": 0.04216774640090927, "TB": 0.040994860964704456}, {"Experience": 0.050852985702668066, "ongoing operational needs": 0.2042350531286779, "satisfactory job performance continuing availability funds": 0.1924985903997622, "This full time year term appointment possibility extension conversion Career appointment": 0.15054795238716925, "Career": 0.10716821200147675}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {}, {"SAS": 0.1252990491127433, "quantitative methods principles statistics": 0.22032765453150516, "masters level degree statistics biostatistics related fields": 0.19159423942944268, "research setting": 0.16281976182205798}, {"Experience": 0.09703924061160855, "machine": 0.04724087625032758, "SQL": 0.04806333556537523, "Math": 0.039700083114558825, "Python": 0.04228761506596738, "decisions": 0.04682593841484125, "team": 0.0643216147227221}, {"PhD": 0.0194843644872548, "Deep Learning": 0.12132151460822119, "Deep": 0.041448759500956986, "MS years": 0.04111937461608863, "Deep knowledge": 0.062258895662656924, "solutions": 0.1581573782581352, "US": 0.04527650845130134, "requirements": 0.04354602327052094, "Demonstrated ability": 0.06606976017574621, "ETL": 0.043539452655746935, "models": 0.05574970605997304, "Breadth skills experience machine": 0.10651211819208238, "business process outsourcing systems transportation systems healthcare systems financial services": 0.0952706146109928, "novel solutions problems": 0.0924895675655186, "real world context Prior experience similar role": 0.09215572427105945, "practice Experience knowledge services": 0.08817637149068558, "feasibility solutions": 0.0853215832129521, "analytics models": 0.08394115138490749, "Desired interdisciplinary skills": 0.08207944801510013, "big data technologies ETL statistics causal inference": 0.08022836506624882, "analytics packages": 0.07624254746411682, "diverse learning settings": 0.0753326610597479, "multi disciplinary environments": 0.07402041996080519, "data mining statistical predictive": 0.07233224714414609, "work US employer": 0.06951113825551561, "Ability inclination": 0.06596067878002476, "different types": 0.06533239373341822, "sponsorship": 0.06198243713621002, "history driving": 0.052612076507412404, "related field": 0.04790755308721288, "Breadth": 0.04544048582764686, "simulation": 0.04539951113677476, "methods": 0.042795403204940144, "experiments": 0.04249035753967234, "ideas": 0.02500487360261578, "desire": 0.0194843644872548}, {"Ability": 0.02732039087982368, "presentations": 0.030872042040526033, "Provide": 0.03896493629105418, "areas": 0.030642711142581096, "data sets": 0.07910254933525727, "USAID": 0.16388557698607464, "Design": 0.04227829723915609}, {"data": 0.2096698116493077, "strong baselines ability": 0.08697392386462299, "experimental analytic plans data modeling processes": 0.10718558017339902, "Demonstrable track record": 0.0708634109673397, "results": 0.048804499148281284, "well ambiguity": 0.06405340121813465, "effect relations": 0.06186530704586467, "techniques": 0.06228572117587532, "business questions": 0.07308384811379329, "Master degree": 0.0631427537951328, "statistical analysis": 0.0698094772413326, "e": 0.04357233088067286, "languages": 0.08206085401081152, "modeling data mining years": 0.11666731093620618, "Millions Billions": 0.12481023870999737}, {}, {}, {}, {"Interest causal inference": 0.43301270189221913}, {"PhD": 0.0194843644872548, "Deep Learning": 0.12132151460822119, "Deep": 0.041448759500956986, "MS years": 0.04111937461608863, "Deep knowledge": 0.062258895662656924, "solutions": 0.1581573782581352, "US": 0.04527650845130134, "requirements": 0.04354602327052094, "Demonstrated ability": 0.06606976017574621, "ETL": 0.043539452655746935, "models": 0.05574970605997304, "Breadth skills experience machine": 0.10651211819208238, "business process outsourcing systems transportation systems healthcare systems financial services": 0.0952706146109928, "novel solutions problems": 0.0924895675655186, "real world context Prior experience similar role": 0.09215572427105945, "practice Experience knowledge services": 0.08817637149068558, "feasibility solutions": 0.0853215832129521, "analytics models": 0.08394115138490749, "Desired interdisciplinary skills": 0.08207944801510013, "big data technologies ETL statistics causal inference": 0.08022836506624882, "analytics packages": 0.07624254746411682, "diverse learning settings": 0.0753326610597479, "multi disciplinary environments": 0.07402041996080519, "data mining statistical predictive": 0.07233224714414609, "work US employer": 0.06951113825551561, "Ability inclination": 0.06596067878002476, "different types": 0.06533239373341822, "sponsorship": 0.06198243713621002, "history driving": 0.052612076507412404, "related field": 0.04790755308721288, "Breadth": 0.04544048582764686, "simulation": 0.04539951113677476, "methods": 0.042795403204940144, "experiments": 0.04249035753967234, "ideas": 0.02500487360261578, "desire": 0.0194843644872548}, {"Statistics": 0.05249246972508509, "others": 0.07227560278731736, "SAS": 0.19361875512792331, "SAS Enterprise Guide manipulate data": 0.13876970017551532, "SAS Enterprise Guide": 0.12078561687984325, "broader goal": 0.12034252362359937}, {"people": 0.06412389956276505, "high throughput data ingestion analysis": 0.14704120528441064, "new things test solutions technologies": 0.1368019375278374, "enterprise products": 0.10518003541727519, "TensorFlow PyTorch": 0.10231644866077536, "unique solutions": 0.1147403813597996, "micro managed freedom": 0.10974301325258524, "cloud console": 0.10678772700400452, "better path": 0.10334385694746409, "frameworks": 0.07644761455628815, "Data science dynamic evolving profession": 0.10062124352617785}, {"Proficiency R": 0.1445513660754129, "Strong interest gaming industry": 0.2044696962685844, "HiveQL Knowledge data visualization Experience advanced analytics": 0.17127274365941952, "software engineer data engineer data scientist Proficiency R": 0.15134139170327898}, {}, {}, {}, {}, {}, {"work level position": 0.805965666080819, "minimum acceptable considered position": 0.7203154444966106, "relevant position": 0.7124645301180246, "hiring manager organization": 0.5985724717434636, "account information": 0.5278423914732228, "based candidates": 0.5159346260215218, "Salary": 0.3792204123780951, "The qualifications": 0.16531562794918556}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {}, {"data": 0.11348228124317566, "English": 0.06104386334561915, "SQL": 0.05368353140438974, "data scientists": 0.11957945141384041, "customers": 0.0574929140845608, "Proven": 0.05824735365648322, "people": 0.05613665224399951, "SAS": 0.07131237535355654, "Excel": 0.05699975089627714, "requirements": 0.0555932695165281, "SQL data exploration tools SAS R Experience data analytics design Experience": 0.1561504914243364, "data analysis Experience": 0.1515741989377827, "Health care industry experience Demonstrated ability": 0.1375665844585941, "Formulas Bilingual Spanish English Master Degree Experience": 0.12706457321124703, "Proven organizational skills ability flexible work ambiguity": 0.11900475372401198, "deep technical concepts": 0.11453168723628562, "SAS R Python Proficient MS Office applications Excel proficiency Pivots V Lookups": 0.10930208768117076, "SAS R Python Proficient MS Office": 0.10363679108811297, "Bachelor degree Minimum year experience": 0.10155604775523161, "deeper understanding": 0.09035006587451908, "Pivots V Lookups": 0.08827834931139683, "technical well technical senior stakeholders": 0.07727475269760889, "large databases": 0.0728984855703774, "predictive statistical modeling": 0.07167244420536713, "Spanish": 0.060681071768047885, "Bilingual": 0.06028501286325526, "deliverables": 0.05781206593599976}, {"Advanced Degree Mathematics Statistics Economics Computer Science related fields": 0.3, "Degree Mathematics Statistics Economics Computer Science": 0.2585235193068112}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {}, {"PhD": 0.0194843644872548, "Deep Learning": 0.12132151460822119, "Deep": 0.041448759500956986, "MS years": 0.04111937461608863, "Deep knowledge": 0.062258895662656924, "solutions": 0.1581573782581352, "US": 0.04527650845130134, "requirements": 0.04354602327052094, "Demonstrated ability": 0.06606976017574621, "ETL": 0.043539452655746935, "models": 0.05574970605997304, "Breadth skills experience machine": 0.10651211819208238, "business process outsourcing systems transportation systems healthcare systems financial services": 0.0952706146109928, "novel solutions problems": 0.0924895675655186, "real world context Prior experience similar role": 0.09215572427105945, "practice Experience knowledge services": 0.08817637149068558, "feasibility solutions": 0.0853215832129521, "analytics models": 0.08394115138490749, "Desired interdisciplinary skills": 0.08207944801510013, "big data technologies ETL statistics causal inference": 0.08022836506624882, "analytics packages": 0.07624254746411682, "diverse learning settings": 0.0753326610597479, "multi disciplinary environments": 0.07402041996080519, "data mining statistical predictive": 0.07233224714414609, "work US employer": 0.06951113825551561, "Ability inclination": 0.06596067878002476, "different types": 0.06533239373341822, "sponsorship": 0.06198243713621002, "history driving": 0.052612076507412404, "related field": 0.04790755308721288, "Breadth": 0.04544048582764686, "simulation": 0.04539951113677476, "methods": 0.042795403204940144, "experiments": 0.04249035753967234, "ideas": 0.02500487360261578, "desire": 0.0194843644872548}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {"Experience": 0.1363024879554495, "Amazon Web Services AWS": 0.7289740320371404}, {"Proficient R Python": 0.1833830302925752, "tasks text mining sentiment analysis language": 0.17609372451296748, "professional experience Data Scientist NLP experience": 0.15759302844026382, "unstructured text data": 0.1561116848314744, "classification information retrieval": 0.15452394316768556}, {"Experience": 0.09005806975903068, "PhD": 0.04028353917644506, "machine": 0.04296878247159149, "SAS": 0.04394773676258015, "Demonstrated ability": 0.06091898621280498, "self": 0.046191118257795066, "multiple competing priorities": 0.06985140108050021, "technical concepts": 0.059299284168963975, "process": 0.0944071854730715, "initiative": 0.045180188091450975}, {"Minimum years": 0.034557440033454775, "ability": 0.07092225517454452, "Machine Learning": 0.0680611038088289, "Familiarity": 0.08050230607175203, "programming languages": 0.07986795602220685, "U S": 0.2067299111023237, "U S government U S citizenship": 0.12181177096067126, "Minimum years experience": 0.09504935032941261, "Familiarity Agile": 0.08922792216190559}, {"Proficiency": 0.04074180452870151, "computing frameworks": 0.05332669438242552, "machine": 0.07372671074501344, "SQL": 0.08210333403048477, "techniques": 0.07276985354133311, "ML": 0.0436358341962481, "Data": 0.05734139194069279, "Big Data": 0.06663369100168248, "k NN Naive Bayes SVM Decision Forests": 0.14306118820534536}, {"data Ability": 0.1135256587927493, "actionable insights": 0.08422272395558161, "Working": 0.02593075657214903, "SAS": 0.13999366805069988, "advanced quantitative analyses": 0.13829170950093345, "analysis variance correlation techniques": 0.1295347470439472, "mathematical operations tasks cluster analytics": 0.1045294611155382, "theory design experiments": 0.09627948360244466, "Working knowledge": 0.036942288803716916, "analysis": 0.10370839538210226, "Intermediate advanced experience": 0.1362194924341469, "original innovative techniques style Ability": 0.12952921205131943}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {"Excellent understanding machine": 0.05366165113280199, "techniques": 0.04871274165397345, "NoSQL": 0.04419785271489298, "k NN Naive Bayes SVM Decision Forests": 0.2131428910865694, "Python Java B S Computer Science Software Engineering Information Science Mathematics Statistics Electrical Engineering Physics related fields": 0.15241212238059992}, {"Proficiency": 0.035505787256983536, "Hadoop Spark": 0.043145916081307065, "data": 0.05046485213135665, "ability": 0.044452006787085344, "Excellent understanding machine": 0.048810971206809016, "techniques": 0.0310429499720183, "problems": 0.032989496892470146, "opportunities": 0.05875642767745565, "technical concepts": 0.06874721111678089, "Communication": 0.07577801950796463, "seven years": 0.020968650392711355}, {"hands": 0.05795989144891371, "machine": 0.08024890166362725, "Proven": 0.06251142011417149, "R Python": 0.042706038284615694, "Demonstrated ability": 0.10159914299431738, "Data Visualization": 0.08088073411731604, "knowledge": 0.08490824842708555, "data Experience": 0.15372640738736548, "large volume data Experience": 0.14835719283212673, "healthcare industry Proven ability experience design development solutions increasing yield Proven analytical skills experience": 0.1470478174805039, "statistical analysis data mining algorithms mathematical segmentation": 0.1253066451698202, "Working knowledge statistical programming languages": 0.12421685889155652}, {}, {"joy clients": 0.2353292397628332, "work Stitch Fix": 0.22620767443874928, "Stitch Fix": 0.1839144947304601, "work": 0.17370647730158886, "every day": 0.11134422906452164}, {"Ability": 0.05752488692971041, "Experience": 0.09962936996922582, "hands": 0.05320798485340841, "Expertise": 0.060544234925724985, "Bachelor": 0.05019816090678387, "Strong SQL experience ability": 0.12143263600904404, "clear precise actionable manner": 0.08031671585865574}, {"Tableau": 0.0510312876024953, "Ability": 0.05657068601637132, "Degree": 0.030664673831145708, "SAS": 0.04909233982930762, "large data sets": 0.10569656711503947, "clients": 0.05678172191684937, "Experience data": 0.1382253008490077, "Travel Master Degree statistics actuarial science related field study Experience data mining predictive modeling experience": 0.12581984697353124, "Extensive knowledge tools data mining statistics Experience HR Analytics Strong knowledge MS Office products": 0.12385140974017848, "statistical modeling programming Experience Tableau": 0.12321378185697697, "team environment": 0.0742118264006639, "MS Office": 0.06912118826786036}, {"Ability work": 0.09196080754026027, "measurement teams product teams members": 0.37273708420148155, "wider analytical teams": 0.3538548689805455}, {}, {"Ability": 0.14823356684925312, "skills": 0.0737954695745091, "solutions": 0.08945677139588926, "Extensive": 0.058464896416408105, "challenges years work experience technology industry": 0.11926686703315065, "public speaking engagements Extensive software development experience": 0.11777152952829353, "Extensive experience software development expertise": 0.11545614258434352, "Strong customer facing relationship building skills": 0.10615870108739908, "present big picture offer solutions": 0.10397276175796123, "custom solutions": 0.09919457243572793, "Python Experience": 0.09754513321960719, "Prior technical paper publications": 0.08969024681712404, "business challenges": 0.0882328992805693, "bright charismatic people": 0.08699486682740706, "highly reliable cloud services Experience": 0.08051086510822592, "Strong algorithmic problem": 0.06769566163132952, "highly reliable service offerings": 0.061462002814272054, "C": 0.06047969383540252, "uncover": 0.05705541095391192, "Windows Linux": 0.051190857875329246, "JAVA C": 0.03857102890653427, "An extraordinarily intelligent rigorous thinker": 0.036737793791199014}, {}, {"Experience Data": 0.07322737077704364, "Proven": 0.056338335548295225, "Deep": 0.05400102999426447, "SAS": 0.05546600226768804, "applicants": 0.13027664466454938, "working knowledge": 0.2025615687569272, "Apple discriminate retaliate applicants inquire": 0.14718434842374045, "compensation applicants": 0.14406856747898136, "Apple": 0.08723440781299903, "SQL Proven": 0.1482902757948052}, {"Prior experience finance": 0.43301270189221913}, {}, {"A solid understanding ad networks media campaigns": 0.20517566677147003}, {}, {"joy clients": 0.2353292397628332, "work Stitch Fix": 0.22620767443874928, "Stitch Fix": 0.1839144947304601, "work": 0.17370647730158886, "every day": 0.11134422906452164}, {"Hadoop Spark": 0.09664295904031257, "Hive Spark": 0.09689769941951198, "Spark Streaming Experience Data": 0.13463486355952828, "e g Hive Spark Experience": 0.12960715147753027, "RNN LSTM GANs Streaming Analytics e": 0.1233535156487411}, {}, {}, {}, {}, {"Ability": 0.05399486567074931, "data": 0.09549455772425951, "BI": 0.05078730409513725, "dynamic innovative years applicable experience Experience Digital Media Experience": 0.15204539517525723, "user event data analysis Experience": 0.1343297768303895, "SQL Excel": 0.13073854479677427}, {"Ability": 0.08323021644475133, "hard questions data": 0.078480239961669, "quantitative field": 0.0679477544656609, "relational databases": 0.08550433782919378, "SAS": 0.04546363275689353, "advanced optimization methodologies": 0.10858679890313876, "advanced quantitative analyses": 0.11089368432296717, "analysis Ability": 0.10416724287865442, "advanced statistical methodologies mixed model random fixed effects": 0.10220179352802262, "actual working experience": 0.08978935863117615, "mixed integer optimization Ability": 0.09846250627094232, "analysis variance correlation techniques": 0.09109193377670431, "ARIMA neural networks multinomial discrete choice Ability": 0.09327297751395566, "features software packages": 0.08202908210733223, "Utilize complex computer operations": 0.08428719646360804, "mathematical operations tasks cluster analytics": 0.0810636023639773, "theory design experiments": 0.06800828238193679, "methodologies": 0.06841780602332725, "Working knowledge": 0.16329722222804052, "A strong passion empirical research": 0.051963453873045504, "3rd": 0.04230176757112324, "knowledge": 0.07302865341688108}, {"SQL": 0.050487718400468895, "data patterns": 0.08809360591817877, "Excellent communication skills": 0.07649422594674102}, {"Ability": 0.07482568774603746, "techniques": 0.05143319221798413, "skills": 0.07305536112933049, "Deep": 0.04931988938509984, "complex business problems": 0.09020834471107059, "machine learning": 0.08343420281666808, "healthcare data": 0.11271976161003572}, {}, {}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {}, {}, {}, {}, {"English": 0.40284073716052415}, {}, {"Experience": 0.14654355285288728, "Google Cloud Platform NET Experience": 0.185141110752002, "OCR Experience": 0.16249193526148237, "successful machine learning systems": 0.159792871278586, "Cloud ML resources": 0.15418846800557193, "Cloud ML": 0.14435616426506864, "regression clustering word embeddings": 0.14202355707816494, "Tensorflow Keras Data Science algorithms decision trees": 0.14118538962865823, "Tensorflow Keras Data Science": 0.12512950368769885, "Python R Javascript Machine": 0.1978973969307851, "Development languages": 0.05473628660097535}, {"machine learning models": 0.11546768996536953, "Kafka": 0.055249322402461123}, {"data": 0.04498265240469511, "Experience": 0.08940345807420615, "Master": 0.0442953341835667, "problem": 0.05148871125505322, "position": 0.056155463395643965, "statistical modeling techniques": 0.09899831989099979, "Detail Oriented Process": 0.09175504557266712, "Knowledge variety machine": 0.09166748121899662, "new process efficiencies": 0.09142977866982731, "Data Scientist A Data Geek": 0.09070812295658004, "best technique": 0.09069116511410472, "Mathematics Statistics Computer Science equivalent work experience": 0.08832543192870189, "ML Proficiency Python R scripting languages": 0.08732370526724854, "business setting Ability": 0.08501958888618272, "comfortable working numbers patterns": 0.08018192270098812, "looking people": 0.07548082641265572, "work kinds": 0.0748553965301181, "GCP cloud platforms": 0.07347187687233969, "actionable results": 0.06766668349796451, "ready code": 0.0664760585006428, "data patterns": 0.06570390772902043, "Driven looking folks": 0.0656994675408903, "Mathematics Statistics Computer Science": 0.05397288649595849, "Mass relocation": 0.0524452952762489, "toolkits": 0.051725169718201354, "production": 0.04984281932487463, "A sense humor perspective": 0.04972226819761852, "puzzles": 0.04666794646038496, "local candidates": 0.04549080482092384, "Mass": 0.03943145816719681, "pandas NumPy etc Experience": 0.037512175094559515, "Bachelor Degree concentration": 0.03598113362005921, "A mindset research": 0.035268814203569365, "intelligently passionately interesting challenges projects": 0.03062106459515456, "even solution": 0.023151498997144398, "Preference": 0.04191448329775483}, {"Minimum years": 0.06118604831917039, "Hadoop Spark": 0.054113011620199276, "Experience": 0.11820879913906862, "techniques ability": 0.08764637900796264, "GPU": 0.03153045380156194, "large datasets": 0.08154409668272317, "Strong": 0.04419208293720165}, {}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {}, {"AI": 0.07227148811089734, "data": 0.12106049808211773, "Software": 0.03809850009292536, "data analytics": 0.07055312348627353, "Possess": 0.035011495788039186, "Bachelor": 0.03500209671452012, "ML": 0.08247667668756745, "large data": 0.12241229967161485, "insights": 0.05366292732805793, "statistical analysis": 0.0659829983876469, "track record": 0.0535508868707175}, {}, {}, {"Tableau": 0.026015729728128763, "Ability": 0.04994305819170103, "Experience": 0.09967004892902427, "business problems": 0.10142043655713862, "solutions": 0.08215408512873752, "SAS": 0.02296507174644381, "large databases": 0.11053240043191871, "Communication": 0.051906022232159184}, {"Minimum years": 0.15938958792948701, "data science problems": 0.16555788495035823, "Masters PhD Application": 0.161434660757617}, {"Bayesian": 0.057951367431479266, "Machine Learning": 0.08106408459857678, "complex analyses": 0.12477792311110517, "Deep knowledge": 0.06018300856452896, "statistics": 0.07309722899319535, "complex business problems": 0.11011566339245732, "Proficiency SQL": 0.11114617413488109}, {}, {"data": 0.08624346972835344, "actionable insights": 0.0781799681478226, "ability": 0.09345223329438503, "able work": 0.0777479219310504, "Python R": 0.05467969341035984, "Proven ability": 0.19490152675686473, "Proven": 0.04416347796212331, "business problems": 0.045346378034658, "NoSQL": 0.04117944000854862, "Demonstrated ability": 0.10373831374675668, "first": 0.04315498259535218, "team": 0.04299928927987497, "data sets": 0.09000292323286664}, {"Tableau": 0.044618747368805806, "PhD": 0.02034775223985317, "goals": 0.04421142448626217, "Expertise": 0.04231440718361365, "Proven": 0.04810326812635421, "Deep": 0.12398408358392254, "ML": 0.12214347454137842, "business questions": 0.14798826743260807, "deliverables Domain knowledge clinical data real world data life sciences related research data Expertise data science related tools": 0.1112868408599056, "meaningful solutions life sciences business Task oriented ability": 0.09272478224594995, "Deep understanding ML": 0.09225551598728196, "Deep understanding tools trade": 0.09071174994364162, "e g SQL Tableau D3": 0.08894896595196349, "variety modern programming languages": 0.08041302875273283, "PhD computational quantitative discipline e g statistics computer science": 0.0803047715866504, "keen eye detail visual communication findings": 0.0785180804974437, "g regression techniques": 0.07550922959283284, "strong knowledge mathematical underpinnings": 0.07507634455817937, "informatics genetics physics epidemiology health economics": 0.0748435858469764, "non technical teams": 0.07350652060620556, "neural networks decision trees": 0.07041106969585985, "Linux TensorFlow Hadoop Spark": 0.060543840034781284, "various methods": 0.057720359341988395, "D3": 0.05674874113970467, "Comfort": 0.047603525455780483, "source technologies": 0.04367427895922296, "R Python JavaScript": 0.034934886579238586}, {"Self": 0.04560053259488904, "problems": 0.08555366630959514, "Demonstrated experience": 0.15347557118065827, "technologies": 0.07853209097077134}, {"Experience": 0.10769153779908949, "experience": 0.10769153779908949}, {"PhD": 0.0194843644872548, "Deep Learning": 0.12132151460822119, "Deep": 0.041448759500956986, "MS years": 0.04111937461608863, "Deep knowledge": 0.062258895662656924, "solutions": 0.1581573782581352, "US": 0.04527650845130134, "requirements": 0.04354602327052094, "Demonstrated ability": 0.06606976017574621, "ETL": 0.043539452655746935, "models": 0.05574970605997304, "Breadth skills experience machine": 0.10651211819208238, "business process outsourcing systems transportation systems healthcare systems financial services": 0.0952706146109928, "novel solutions problems": 0.0924895675655186, "real world context Prior experience similar role": 0.09215572427105945, "practice Experience knowledge services": 0.08817637149068558, "feasibility solutions": 0.0853215832129521, "analytics models": 0.08394115138490749, "Desired interdisciplinary skills": 0.08207944801510013, "big data technologies ETL statistics causal inference": 0.08022836506624882, "analytics packages": 0.07624254746411682, "diverse learning settings": 0.0753326610597479, "multi disciplinary environments": 0.07402041996080519, "data mining statistical predictive": 0.07233224714414609, "work US employer": 0.06951113825551561, "Ability inclination": 0.06596067878002476, "different types": 0.06533239373341822, "sponsorship": 0.06198243713621002, "history driving": 0.052612076507412404, "related field": 0.04790755308721288, "Breadth": 0.04544048582764686, "simulation": 0.04539951113677476, "methods": 0.042795403204940144, "experiments": 0.04249035753967234, "ideas": 0.02500487360261578, "desire": 0.0194843644872548}, {"related field Computational social science Computer science Data analytics": 0.11517428785742728, "Computer science Data analytics Economics Engineering Geospatial": 0.10647300723251168, "Economics Engineering Geospatial analysis": 0.08833007090382292, "Mathematics Operations research": 0.09505483390451566, "internship Creativity Initiative Integrity Leadership": 0.0954988596543562, "Creativity Initiative Integrity Leadership": 0.08506853183772511, "Problem solving skills": 0.08292978135268139, "Mathematics Operations": 0.07513680032402585, "Attending": 0.05722557614782065, "Computational": 0.05528471227044376, "A thorough medical psychological exam": 0.05825640984118815, "GPA": 0.09865278127936619, "A comprehensive background investigation": 0.05921189887100761, "A polygraph interview": 0.04081656562004366}, {}, {"work level position": 0.805965666080819, "minimum acceptable considered position": 0.7203154444966106, "relevant position": 0.7124645301180246, "hiring manager organization": 0.5985724717434636, "account information": 0.5278423914732228, "based candidates": 0.5159346260215218, "Salary": 0.3792204123780951, "The qualifications": 0.16531562794918556}, {"related field Computational social science Computer science Data analytics": 0.13620954136630883, "Ability work diverse team environment Interest experience science technology engineering mathematics": 0.12803560232234204, "Computer science Data analytics Economics Engineering Geospatial": 0.12264335037121388, "Quantitative finance": 0.10691603377561229, "Economics Engineering Geospatial analysis": 0.10177489146106818, "prior graduation Attending school": 0.1011070782795761, "Availability work": 0.0977144866586612, "Mathematics Operations research": 0.0976518933849233, "Bachelor degree technical field": 0.09670756647526808, "internship Creativity Initiative Integrity Leadership": 0.09528031397917733, "Creativity Initiative Integrity Leadership": 0.09252033676487442, "full time basis": 0.09247487187363317, "Problem solving skills": 0.09223535232040388, "Full time student": 0.08765356321368122, "Mathematics Operations": 0.08658118082177525, "Attending": 0.0634967532669913, "Computational": 0.063216296047433, "scale": 0.05985478177399255, "A thorough medical psychological exam": 0.058230439652381005, "GPA": 0.11345607414842356, "A comprehensive background investigation": 0.051601358212610936, "Bachelor": 0.05044819392411268, "two day tours": 0.04363122821306619, "A polygraph interview": 0.03237719945627855, "two day": 0.028395434247085394, "Statistics": 0.026839185118670967}, {}, {"data": 0.08131884308189037, "SQL": 0.07187714060293378, "non technical audiences": 0.12309944372383966, "ETL": 0.08191011931344512, "g": 0.07858913237183791}, {"Experience": 0.10430549020743467, "results": 0.05873336859017888, "libraries": 0.054291656329408, "US": 0.02607690193871082, "Familiarity": 0.07966884059309892, "Java": 0.02607690193871082, "Spark Hadoop": 0.079172855121078, "Familiarity Agile": 0.0954332397740554}, {}, {"Ability": 0.060903755236748194, "results": 0.05978677369396501, "hard questions data": 0.10030933163878641, "work": 0.06088763889171279, "A strong passion empirical research": 0.05777010103004582, "varying levels": 0.09421744852331365, "A flexible analytic approach": 0.057898209649411975, "clear precise actionable manner": 0.05157163193973786}, {"PhD": 0.0194843644872548, "Deep Learning": 0.12132151460822119, "Deep": 0.041448759500956986, "MS years": 0.04111937461608863, "Deep knowledge": 0.062258895662656924, "solutions": 0.1581573782581352, "US": 0.04527650845130134, "requirements": 0.04354602327052094, "Demonstrated ability": 0.06606976017574621, "ETL": 0.043539452655746935, "models": 0.05574970605997304, "Breadth skills experience machine": 0.10651211819208238, "business process outsourcing systems transportation systems healthcare systems financial services": 0.0952706146109928, "novel solutions problems": 0.0924895675655186, "real world context Prior experience similar role": 0.09215572427105945, "practice Experience knowledge services": 0.08817637149068558, "feasibility solutions": 0.0853215832129521, "analytics models": 0.08394115138490749, "Desired interdisciplinary skills": 0.08207944801510013, "big data technologies ETL statistics causal inference": 0.08022836506624882, "analytics packages": 0.07624254746411682, "diverse learning settings": 0.0753326610597479, "multi disciplinary environments": 0.07402041996080519, "data mining statistical predictive": 0.07233224714414609, "work US employer": 0.06951113825551561, "Ability inclination": 0.06596067878002476, "different types": 0.06533239373341822, "sponsorship": 0.06198243713621002, "history driving": 0.052612076507412404, "related field": 0.04790755308721288, "Breadth": 0.04544048582764686, "simulation": 0.04539951113677476, "methods": 0.042795403204940144, "experiments": 0.04249035753967234, "ideas": 0.02500487360261578, "desire": 0.0194843644872548}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {"Java Python": 0.07493138994701604}, {}, {}, {}, {}, {"time": 0.056472224503270725, "large datasets": 0.07288254962407775, "US": 0.08213482902141138, "ETL": 0.0418038612572105, "weeks": 0.11358166510865216, "Education": 0.06068734361882514, "New York": 0.08197088285927691, "Health": 0.05050923395349243}, {}, {}, {"Hadoop": 0.06482114096204271, "hands": 0.06205805346833006, "SQL": 0.04624445891296419, "Kafka": 0.11810941849154626}, {}, {"Proven": 0.03442707305394533, "Master degree": 0.045302073140859, "minimum years": 0.036130794634489136, "technologies": 0.03649803849824999}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {"experience": 0.09673907550637899, "ETL": 0.05163337723041343, "Java": 0.053378000125185246, "degree": 0.05029601773071508, "colleagues": 0.05239072689591445, "knowledge": 0.022177595112711425}, {"Hadoop Spark": 0.09824781962999908, "SQL": 0.2209700454358049, "Kafka": 0.06120333599273102}, {"Hadoop Spark": 0.11185650135284594, "Hadoop": 0.0969506451406489, "At least years": 0.043916811530715395, "SQL": 0.02922608364442522, "problems": 0.030611149903804105, "best practices": 0.036721716656321984, "NoSQL": 0.0, "TB": 0.029707204966079644, "Map Reduce": 0.036847478180134466, "metadata": 0.028942512234664576, "Big Data": 0.39881538852595244, "Java": 0.0, "team": 0.05843047224783043}, {}, {"Fluency English": 0.5203728430130404}, {"Java Scala": 0.07251149467995507, "Python": 0.051194261271534355, "401k": 0.06010203730333915, "ETL": 0.05125874123392879, "Health": 0.058868201803681734}, {}, {"ML": 0.15228632689673627}, {}, {}, {"relevant work experience": 0.11857736602170926, "multiple databases": 0.10474678342071116, "schemas": 0.09819419043253512}, {}, {}, {"Gym membership compensation": 0.43301270189221913}, {"Ability": 0.03984872334809008, "techniques": 0.039687181692857454, "data scientists": 0.09445748977430664, "Knowledge": 0.03992579383939482, "Background": 0.03928197100494243, "ETL": 0.03964114851501563}, {"Git SDLC": 0.30370960170729866}, {"Experience": 0.12186027597311673, "advanced courses data science machine": 0.29531036809083494}, {"ability": 0.14611435298174952, "communicate data driven insight": 0.31120756477299005}, {"Ability": 0.08267374413205254, "multiple projects": 0.08007571413104711, "Java": 0.06193403640657585, "Effective": 0.08370542063575485, "e": 0.055703703178598026}, {"Gym membership compensation": 0.43301270189221913}, {}, {"Knowledge digital AdTech landscape": 0.4, "AdTech": 0.24697543336253017}, {"Creative analytic problem solver diligent attention detail": 0.24748737341529156}, {"libraries": 0.1899799209503104}, {"Experience Cloudera": 0.4714045207910316}, {}, {"Experience": 0.05930422556506244, "world": 0.03685279807297181, "languages": 0.02759877547216782, "Spark Hadoop": 0.13195875879234104, "technologies": 0.05964743119727975, "MPP": 0.08283742162121877}, {"Ability": 0.05156011570104529, "metadata": 0.0498050811630019, "Spark Hadoop": 0.07028202742380643, "various data sources": 0.08801859891671487}, {}, {"data": 0.1457510983887629, "Proven": 0.06807150304942586, "ML": 0.06857275634980088}, {}, {"video call": 0.4067069769086525, "call": 0.348624126893826, "As always interviews": 0.029047375096555625}, {}, {}, {"Ability": 0.07401934229264333, "SQL": 0.054528421726880355, "techniques": 0.05683420123517024, "best practices": 0.07219186349519936, "BI": 0.07447975254503787, "others": 0.07131007493228449, "large datasets": 0.07543146636496763, "etc Experience": 0.056508681192195646}, {}, {"Willingness travel": 0.4714045207910316}, {"Python Django Flask": 0.43301270189221913}, {"Gym membership compensation": 0.43301270189221913}, {}, {"Gym membership compensation": 0.43301270189221913}, {"best practices": 0.2781718993756284, "methodologies": 0.1649876786131199, "Responsible staying current enterprise standards industry standards technologies": 0.2612836697927243}, {}, {}, {}, {"data": 0.015797708638942864, "results": 0.03197294442626285, "industry": 0.03724936363895485, "Java": 0.015797708638942864, "world": 0.036006033266523234, "knowledge": 0.0317369449948157, "MPP": 0.034566539955532855, "data access data storage techniques": 0.11227258005591527}, {}, {"hour": 0.2795984421205809, "video person hour": 0.3466800150008662}, {}, {}, {}, {"Gym membership compensation": 0.43301270189221913}, {}, {}, {}, {}, {}, {}, {"Willingness travel": 0.4714045207910316}, {"large datasets": 0.08396005625900999, "business requirements": 0.03729687164508272}, {"employee benefits": 0.39309699602751175}, {}, {}, {"kitchen": 0.11410443634960715}, {"Gym membership compensation": 0.43301270189221913}, {"SQL": 0.7217127527814065}, {"data visualization tools": 0.4030933718572922}, {"Minimum years": 0.07353761441950948, "Hadoop Spark": 0.08199642651021187, "data": 0.07113293715986944, "NoSQL": 0.05322071249620811, "tools": 0.06086787626030751, "ETL": 0.05984657583331188, "Java C": 0.01192066470144193}, {}, {}, {"Hadoop Spark": 0.07240994052146914, "Experience": 0.21692868006245908, "SQL": 0.12807794563060884, "relational databases": 0.07865738711457149, "Strong": 0.062302108817529525, "metadata": 0.044659795865648326, "opportunities": 0.0484904522462748, "Kafka": 0.048061723473288166, "Experience building": 0.11016301384289379, "big data data pipelines": 0.15695023887119353, "data transformation data structures metadata dependency workload management": 0.13344934949850035, "working familiarity variety": 0.08721791483185806, "NoSQL databases": 0.06707087320716724}, {}, {"Knowledge": 0.09374977920472881, "third": 0.12031213425717413}, {"data": 0.14501159776996178, "Develop": 0.10303212729412907}, {"Minimum years": 0.11252739674052542, "Java Scala Python": 0.06581935309832812, "Spark": 0.05667767540927016, "Big Data": 0.08489806124580326}, {"Mustache Get Mustache": 0.5236717735104779}, {}, {"data flows": 0.3498759579292246}, {"Git": 0.13637496796053136}, {}, {}, {}, {"Pet friendly office environment": 0.4}, {}, {"Fixed term contract option perm": 0.37267799624996495}, {}, {}, {"Experience Agile Methodologies Scrum Kanban": 0.37267799624996495}, {}, {"Python": 0.33592266913231045, "Java": 0.0}, {}, {}, {"Gym membership compensation": 0.43301270189221913}, {"environment": 0.07381586879054358, "Proven": 0.05509322777505838, "relevant experience": 0.0923204352818143, "knowledge": 0.0678729918318812, "least one high level programming language": 0.069384191282866}, {}, {}, {"English": 0.05858144587622777, "Spark": 0.05517716595152764, "SQL": 0.023093626785170736, "NoSQL": 0.0, "Big Data": 0.07042621082697234, "cases": 0.06321028533092839}, {}, {}, {"Tableau": 0.040329555560457496, "Minimum years": 0.1469294143924564, "data": 0.08310436610576631, "Experience": 0.1072134566594603, "Spark": 0.03983696923542278, "Python Java": 0.025325844777956866, "Interested candidates": 0.05314737498477737, "big data technologies": 0.09293964128368934, "Java": 0.020138418299794517, "New York NY": 0.06546120997882406, "Minimum years experience": 0.10317433143925775, "data visualization tools": 0.09971126753211002}, {"Ability": 0.14823356684925312, "skills": 0.0737954695745091, "solutions": 0.08945677139588926, "Extensive": 0.058464896416408105, "challenges years work experience technology industry": 0.11926686703315065, "public speaking engagements Extensive software development experience": 0.11777152952829353, "Extensive experience software development expertise": 0.11545614258434352, "Strong customer facing relationship building skills": 0.10615870108739908, "present big picture offer solutions": 0.10397276175796123, "custom solutions": 0.09919457243572793, "Python Experience": 0.09754513321960719, "Prior technical paper publications": 0.08969024681712404, "business challenges": 0.0882328992805693, "bright charismatic people": 0.08699486682740706, "highly reliable cloud services Experience": 0.08051086510822592, "Strong algorithmic problem": 0.06769566163132952, "highly reliable service offerings": 0.061462002814272054, "C": 0.06047969383540252, "uncover": 0.05705541095391192, "Windows Linux": 0.051190857875329246, "JAVA C": 0.03857102890653427, "An extraordinarily intelligent rigorous thinker": 0.036737793791199014}, {"others": 0.048081774384387266, "ETL": 0.05265954621589242, "new technologies": 0.10606085872973348, "new challenges": 0.11118441318450857}, {}, {}, {}, {}, {}, {"Tableau": 0.17618607536220587}, {}, {}, {"Java Scala": 0.07251149467995507, "Python": 0.051194261271534355, "401k": 0.06010203730333915, "ETL": 0.05125874123392879, "Health": 0.058868201803681734}, {}, {}, {}, {}, {"English": 0.5320302570578413}, {}, {}, {"Gym membership compensation": 0.43301270189221913}, {}, {}, {"areas": 0.1813970902228858}, {"Deep knowledge": 0.07386245559694732, "ETL": 0.0561393756069162, "Kafka": 0.05885041379242372, "languages": 0.08713663870239687}, {}, {"data": 0.08321784331868287, "SQL": 0.039128414712364064, "Career": 0.03575460632715913}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {"computing frameworks": 0.04450898946324566, "English": 0.055884215700549085, "Spark": 0.09135489836056637, "SQL": 0.036756246511234575, "goals": 0.051651351931525306, "Python": 0.022149617071385894, "opportunities": 0.04853005601293603}, {}, {}, {}, {}, {"data": 0.10300537617207152, "Deep": 0.04700777647390219, "platforms": 0.0886743676700163, "Java": 0.04700777647390219, "C": 0.08646263517880089}, {}, {}, {}, {}, {"data": 0.10692238772718439, "Bachelor": 0.05694758668364584, "Big Data": 0.08339208159057705, "various data sources": 0.11268408445027149}, {}, {}, {"Java Scala": 0.07251149467995507, "Python": 0.051194261271534355, "401k": 0.06010203730333915, "ETL": 0.05125874123392879, "Health": 0.058868201803681734}, {}, {}, {}, {}, {"data": 0.17546770521893076, "problems": 0.03229121061667588, "big data data pipelines": 0.2048545767999444}, {"Gym membership compensation": 0.43301270189221913}, {}, {"hours": 0.17716194788237424}, {}, {"Java Scala": 0.07571279161999644, "NoSQL": 0.11295383396836245, "process": 0.0672135232800958}, {}, {"Minimum years": 0.05706990565382176, "Python Java": 0.06989358684292013, "SQL": 0.031199393328787253, "techniques": 0.06574976519211527, "Java": 0.05263194980682855}, {"AWS": 0.31331493760038376}, {"world": 0.38383772205248956}, {}, {}, {"Tableau": 0.034487457235235934, "data": 0.11801230247765775, "relational databases": 0.10658234154348267, "Big Data": 0.06963381397369445}, {}, {"Bachelor Degree": 0.082653662953277, "ETL": 0.051910451625613356}, {"English": 0.0826769825909926, "skills": 0.11880679914594935}, {"Competitive": 0.053718412958299946, "Minimum years": 0.07067552560634438, "Experience": 0.10670955911963712, "SQL": 0.08717916445673955, "ETL": 0.04810933115859821}, {}, {}, {"Spark": 0.06780400870561662, "Java Python": 0.10853160626778383, "technologies": 0.0473572190927325}, {}, {}, {"Demonstrated ability": 0.07620746444427177, "Comfortable": 0.058460693109620536, "BS MS": 0.026870792221539368, "third": 0.04217105381563701}, {}, {}, {}, {}, {"Experience": 0.10660333673960487, "Expertise": 0.044120821596687544, "Working": 0.07977007223923363, "platforms": 0.04484793204441217, "experience": 0.10660333673960487, "solutions": 0.044843156752839855, "business requirements": 0.07083853072916604, "Java C": 0.059392695692058045, "new technologies": 0.08563894538427061}, {"Bachelor Degree": 0.03017415490516397, "At least years": 0.02257053493667042, "multiple competing priorities": 0.0687994172569206}, {}, {"Java Scala": 0.05441579069024394, "NoSQL": 0.08220418013168944, "Machine": 0.04095562492628326, "experience": 0.07873849888441878, "cases": 0.04239286479447462, "process": 0.054595788652952545}, {}, {"SQL": 0.2928199615991006, "relational databases": 0.07087231811727002, "metadata": 0.05059851383756694, "Kafka": 0.09754233536066119, "Experience building": 0.1036479588221147, "big data data pipelines": 0.14575509569327877, "data transformation data structures metadata dependency workload management": 0.1231196111892294, "working familiarity variety": 0.08763103344078685, "NoSQL databases": 0.14329580981219453}, {}, {}, {}, {}, {"ability": 0.1398085968158274, "one year": 0.07152996680549055}, {}, {}, {}, {}, {}, {"Ability": 0.06777544730722068, "data": 0.06475180178661612, "Hadoop": 0.03753498640434436, "ability": 0.13555089461444136, "results": 0.11577735412702442, "skills": 0.06065283607909886, "Proven": 0.031929761564770065, "BI": 0.02997124046670111, "Deep": 0.02412412511153214, "business problems": 0.1690010988073827, "Deep knowledge": 0.04037182650209441, "Demonstrated ability": 0.07762133637659502, "ideas": 0.031035533239150297, "Analytics": 0.031447898315433855, "data analysis": 0.07361598920983131, "technologies": 0.03076138452558423}, {}, {}, {}, {}, {}, {}, {}, {"Java Scala": 0.05894861323533511, "NoSQL": 0.09092139157956956}, {}, {}, {"Python Java": 0.05761939423259869, "401k": 0.05024578943162026, "Comfortable": 0.042190113846589467, "Java": 0.04340226152124825, "databases": 0.05410135328757311, "weeks": 0.07099927658616557}, {}, {}, {}, {}, {}, {}, {}, {"Ability": 0.06164050777806816, "data": 0.09458648214558539, "problems": 0.04760995100754993, "NoSQL": 0.03495480559514543, "Familiarity": 0.04485846077737862, "Effective": 0.04929755973451587}, {"data": 0.09489919776452513, "Hadoop": 0.11329732219307091, "solutions": 0.09128235859758434, "opportunities": 0.0820976929805981}, {"Hadoop": 0.08208762993677422, "Java Scala Python": 0.048940909491806114, "algorithms": 0.09299622594277544, "SQL": 0.028505573384448257, "Strong knowledge": 0.1364562196445072, "ETL": 0.0827127538577916, "Java": 0.028505573384448257}, {}, {"Tableau": 0.1981126712031637, "At least year": 0.18641956118237765, "At least years": 0.09320978059118883, "At least year experience": 0.11608899022851786, "SQL": 0.08984063656990407, "ETL": 0.07962755287192291, "At least years experience": 0.11608899022851786}, {}, {}, {}, {"Experience": 0.3346092796456446, "SQL": 0.14428134635700748, "Bachelor": 0.05118492263423172, "projects": 0.0685328770111724, "data analysis": 0.11550097713753057, "Alteryx": 0.045526609390343455}, {}, {}, {}, {}, {"skills": 0.09868519453514898, "Excellent problem": 0.07435516312190268, "BS MS": 0.03622513680303316}, {"Master Degree": 0.22851282415784008, "Degree": 0.19158512362400001}, {"Ability": 0.11064890287161872, "data": 0.09143029609084563, "ability": 0.11064890287161872, "new technologies": 0.08900662277178545, "e": 0.0832140126040466, "various data sources": 0.11420758631870956}, {}, {}, {"Hadoop": 0.05069646556173889, "Agile": 0.021558144110035107, "Proven": 0.043140564380311636, "BI": 0.07567192677104598, "C C": 0.31836113582639325, "Big Data": 0.07508340533890775}, {"Ability": 0.19571534127709087, "SQL": 0.04111385406657796, "technical concepts": 0.1053670934118451}, {}, {"Ability": 0.15708160707514668, "results": 0.03618384675749586, "Proven": 0.038046253795593364, "information": 0.04282076858804251, "ETL": 0.08797255688867282, "things": 0.030667571374544463, "structured semi structured unstructured data": 0.10321778890303888}, {}, {}, {"desire": 0.13804851507607008}, {}, {"SQL": 0.059028250310071785, "people": 0.03724446641667176, "ETL": 0.03494787156994643, "Kafka": 0.0645946666133538, "millions": 0.0754076077704973}, {}, {}, {}, {}, {}, {}, {"Java Scala": 0.05697042677186816, "NoSQL": 0.0860362815259274}, {}, {"skills": 0.07424522533564942, "product": 0.06410901616164151, "ETL": 0.05384157006082976, "Strong analytical problem": 0.07487827698019807}, {"production environments": 0.07069520829691783, "SQL": 0.04531622019069652, "projects": 0.05934104622307089, "Background": 0.042798018536152393, "Big Data": 0.09461596855478178, "operations": 0.06039266750453707, "data warehouses": 0.11762956727545718}, {}, {"Experience": 0.11932044711536877, "SQL": 0.15512832023049175, "relational databases": 0.07417457248347309, "metadata": 0.05733751490463701, "Experience building": 0.12449431418304399, "Advanced": 0.05867363384092288, "big data data pipelines": 0.16179387282714464, "working familiarity variety": 0.11437255741574173}, {}, {}, {}, {"Hadoop": 0.08208762993677422, "Java Scala Python": 0.048940909491806114, "algorithms": 0.09299622594277544, "SQL": 0.028505573384448257, "Strong knowledge": 0.1364562196445072, "ETL": 0.0827127538577916, "Java": 0.028505573384448257}, {}, {}, {}, {}, {}, {}, {"time": 0.025828655939157744, "others": 0.03602275076687384, "SAS": 0.016705788051776357, "ideas": 0.038788160203083635, "organization": 0.027224623530124854, "business": 0.057384962882896504}, {}, {}, {}, {"data engineering": 0.12143962186963597}, {"data engineering": 0.12143962186963597}, {}, {}, {}, {}, {}, {}, {"millions daily players": 0.3466800150008662, "millions daily": 0.27010136077940194, "cool people": 0.19667082547981898}, {}, {}, {}, {"Microsoft": 0.042804834004070896, "unstructured data acquisition Realtime Data Integration Patterns Engagement": 0.14471950751889004, "data services": 0.14214618787976052, "Operational analytical data provisioning insights data landscape": 0.13811263343861713, "Group Data": 0.13623724355609376, "Assist driving data services strategy": 0.1347756733279453, "Realtime Data Integration Patterns": 0.13023504743159375, "Building Big Data Platform": 0.12781673177759406, "next level excellence Building Big Data Platform": 0.12726482928804, "Data Flow Patterns": 0.12543103147268347, "Data Initiatives": 0.12372526166378472, "Strategic Alignment Group Architecture": 0.10924612254630749, "Visualisation Storyboarding experience Stats": 0.10038274348361853, "Building operation frameworks processes": 0.10034448896777955, "Net Language experience": 0.09613915214306182, "Banking financial sector experience": 0.09473676409284926, "Assist": 0.055320073041904914}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"career categories": 0.4714045207910316}, {}, {"Java Scala": 0.07424944856211585, "techniques": 0.05924137632609059, "Kafka": 0.05975160170697423, "realtime streaming compute components Experience data modeling data architecture": 0.133982568587124, "big data patterns": 0.11813190404754229, "Knowledgable distributed storage network resources level hosts": 0.11764009912293394, "DCs troubleshoot prevent performance issues": 0.11602516638043624, "particular MapReduce Spark Spark SQL": 0.11506109923670571, "large scale data pipelines": 0.10715827086874104, "Spark Streaming Hive YARN MR2 Experience building": 0.10229843783147842, "MapReduce Spark": 0.09502237676303896, "ie warehousing concepts efficient storage query HDFS data security privacy": 0.09297166834005562, "highly scalable data systems services": 0.06424726655773984, "batch": 0.06150857039671778}, {"Tableau": 0.04742124301189587, "Minimum years": 0.11444198911303927, "BS MS": 0.0687699134648054, "technical non technical stakeholders": 0.10564586122709325, "commitment data governance Demonstrated ability": 0.10937657988592787, "analytics data engineering role": 0.10583916973536252, "verbal visual communication capabilities Ability": 0.10527495942669714, "relevant business people analytics": 0.10339186186101441, "BS MS degree quantitative field equivalent practical experience": 0.09740601669738559, "data analytics solutions": 0.09615600587797413, "continuous refinement improvement": 0.09425680083244098, "least years": 0.14511910981566864}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {"Software": 0.030039915704753367, "Spark": 0.05374717498766281, "Machine": 0.05531892849479911, "Data": 0.054037692507906944, "g": 0.07324412394619557, "e g Linux Mac OS Experience": 0.13073645703760842, "nice required Data modeling Experience working search engines": 0.11038708931409055, "analytic skills Solid computer science systems foundations ability": 0.106597249403011, "new domains Proven system development": 0.10410856242501619, "Machine learning Natural": 0.1027793578882717, "Good communication skills teamwork Passion": 0.09916579747088573, "Natural language processing": 0.09476603288699911, "Apache": 0.055689751503037704}, {}, {"backgrounds": 0.047459079300263406, "data": 0.09293768920242426, "Java Scala": 0.022342324195809747, "The ability": 0.019142766521525034, "NoSQL": 0.019829481765430368, "others": 0.03128030488247721, "Excel": 0.027509183347496424, "tools": 0.04428040287604865, "information": 0.03249938197387201, "ETL": 0.10196583442693592, "Big Data": 0.06793492647937263, "structured semi structured unstructured data": 0.08792220926592331, "colleagues": 0.026862249246426315, "clients": 0.06674433326075009, "Designing": 0.03464716092563359, "MPP": 0.03305212048508692, "Work clients model data landscape": 0.09760694675905611, "data extracts": 0.09271979088012472, "operational ETL data pipelines": 0.09207460654705199, "data fields hypotheses": 0.08990924488286221, "Collaborate data scientists": 0.08895362797915148, "Strong development background experience": 0.0782016742383545, "Processing Spark Hadoop EMR": 0.06326383665449463, "MPP AWS Redshift Oracle Exadata Teradata IBM Netezza": 0.06307106425200625, "Traditional RDBMS MS SQL Server Oracle": 0.0611171103977755, "Redshift Oracle": 0.052523986869852574, "Distributed Systems": 0.0870664747739859, "clear timely professional manner": 0.03513772618122774}, {"data": 0.10654656010328646, "decisions": 0.0552981017191605, "Data Science": 0.09847225832898145, "third": 0.04678213954946153, "context data processing Experience proficiency Python Experience design implementation data": 0.1249600916721233, "Google Cloud Platform DevOps Stack development experience Apache Airflow data pipeline tools": 0.1129360032035352, "various sources data Manage": 0.11202256629912846, "Data Engineering Hadoop Spark Data Processing products": 0.10978113268494535, "data science production environments": 0.10964280570686127, "working engineering team best track record data": 0.10962519563774462, "third party elements data pipeline": 0.1087197831715627, "key data functions": 0.10869944140508675, "Support sophisticated predictive data products": 0.1084982660622458, "Data Engineering Hadoop Spark Data": 0.10820798643252474, "data inconsistencies": 0.10711667280164555, "Cloud experience": 0.10056320508045886, "outputs Data Science models": 0.09987600517289466, "open source tools": 0.09141621092322441, "similar Software Engineering Data Science etc experience software": 0.0784381500403463, "infrastructure layout": 0.07524089511690035, "cloud service integrations": 0.06931731126928627, "Big Query Redshift Spectrum S3 Athena Kafka Spark Storm Flink Beam Presto Hive ETL": 0.06778885658080011, "Apache Airflow": 0.05951580737908358, "python": 0.05123798445415902, "transformations": 0.045584308699836, "Manage": 0.045180892480622833, "Scala Java": 0.03215837771093971}, {}, {"401K": 0.2309401076758503}, {}, {}, {}, {"Tableau": 0.04325664485871448, "Java Scala": 0.035399200058243124, "Agile": 0.04644033948465185, "NoSQL": 0.019241579888648615, "information": 0.04029853614272132, "ETL": 0.05558564685286257, "Analytics": 0.04942882951608526, "structured semi structured unstructured data": 0.08344649498265308, "clients": 0.044973948678245876, "knowledge": 0.03857760782629905, "MPP": 0.033823838597025827, "Strong development background experience": 0.0924748787711508, "Processing Spark Hadoop EMR": 0.07503130207276042, "MPP AWS Redshift Oracle Exadata Teradata IBM Netezza": 0.06715502059126857, "Traditional RDBMS MS SQL Server Oracle": 0.0492663419046741, "Redshift Oracle": 0.053777661954734865, "clear timely professional manner": 0.08349631217609303, "Agile projects Data Warehousing experience": 0.10444909582676278, "Experience multiple Database technologies": 0.09314968282846212, "technical aspects Data Technology industry personal professional development work life": 0.09236679662887709, "different multiple projects": 0.0852148279161972, "Titan Experience developing solutions": 0.08406091483673189, "Cloud": 0.05224992736731576}, {}, {"career categories": 0.4714045207910316}, {}, {"career categories": 0.4714045207910316}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {}, {}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {"career categories": 0.4714045207910316}, {"At least years": 0.042660140881312154, "Complex": 0.027687093954137564, "Data": 0.20859395057172617, "Provide": 0.026935725402768715, "ETL": 0.02723716105228059, "ideas": 0.02832301698082865, "data pipelines": 0.10136993226230945, "Microsoft": 0.02788640394746022, "g": 0.03496997849555885, "real time": 0.059166709200366326, "e": 0.03459736580357689, "data sources": 0.10919033453061855, "Design": 0.3484350681629307, "technologies": 0.046018896166138155, "Assist": 0.028032358232169804, "Manage": 0.10968807353134477, "data streaming Design": 0.11977400036371816, "data warehouse data models": 0.10785041660207487, "source data e g data profiling definition mapping Design": 0.10762239812090121, "data Manage data growth usage": 0.10735334688621762, "data monitoring solutions procedures": 0.10667696671102622, "efficient data loads": 0.10616599878978636, "good data governance Work": 0.10404935934661055, "unstructured data loads": 0.10394990216074276, "functional data team knowledge gathering": 0.103794835432205, "managing data": 0.10373091496672956, "traditional structured data ETL techniques Design": 0.10349245473221372, "technical data related support source system teams": 0.10291117294615235, "usability data": 0.10151106479628316, "real time data load solutions": 0.09851208883259796, "appropriate aggregation data structures": 0.09845998434762333, "changes data organisation": 0.0980513399810516, "troubleshoot technical data issues": 0.09630132893207254, "working data business intelligence analytics environment": 0.0961598170636963, "SQL Data analysis Data visualisation Data": 0.09434390101081226, "data management analytics": 0.09267718715400096, "meta data solutions": 0.09265251495619113, "team dynamics performance Complex solution service design implementation": 0.09006551402872655, "effective efficient data models": 0.08857633555927515, "Microsoft business intelligence data technologies": 0.08833896751259532, "speed access Design": 0.08591180763769243, "data processes": 0.08466318797040909, "data elements": 0.08410624974886913, "Work source system owners analysts": 0.08354788427726087, "availability accuracy Design": 0.08253762158438192, "Responsible team activities team dynamics performance Manage project task delivery team": 0.08148632703391528, "supplement enhance context Design": 0.07966016182077537, "interface monitoring management solutions": 0.07791172324426537, "solutions Positive engagement team activities": 0.07768930602185288, "data access e g batch exports": 0.07746351791635504, "Work analysts": 0.07461102723390724, "e g text speech images video Design": 0.07429922829406735, "knowledge share Quality control work Degree information technology engineering mathematics statistics actuarial related discipline": 0.06996202632489378, "ownership work": 0.06935195328441357, "business owners analysts": 0.13833003502811306, "load monitoring tools procedures": 0.06854156954219583, "high quality work time Show initiative": 0.06777706592837883, "system infrastructure management": 0.06652516243043535, "real time decision": 0.06538084348165632, "Manage systems technology tools": 0.06517978097414644, "Information gathering problem analysis": 0.06137782200834538, "appropriate indexing tables": 0.06046208404613174, "SSAS SQL Server Data warehouse": 0.05757885972719333, "Presenting Communicating information": 0.05660196137859942, "appropriate modelling techniques": 0.056588219820686424, "appropriate changes": 0.05605997116169901, "internal external Assist development others": 0.055312379432028984, "professional specialist technical expertise": 0.05497870843644437, "Multiple stakeholder management": 0.05490536598317708, "SQL Data": 0.05340953852252053, "skills knowledge application": 0.053361408949206345, "loads": 0.05304390246469944, "ownership career development": 0.052686417337748155, "Quality Detail orientation Planning": 0.05172816973146134, "continuous monitoring": 0.05143841047515044, "sources": 0.050348646908253664, "integrity existing environment": 0.049950826370128903, "IT infrastructure IT Operations": 0.049082846992024275, "Analysing Leadership": 0.04797071706239034, "automated decision": 0.04709156740992211, "value decision": 0.046306019851437535, "active finding opportunities": 0.044154371019275926, "effective strategies": 0.04289335623470404, "Presenting Communicating": 0.042246687368454994, "external parties": 0.04224181518884275, "Quality": 0.03793417854974236, "g multi dimensional OLAP structures summary tables": 0.03675811259096596, "Take": 0.03643944234183073, "interfaces": 0.036168632677745845, "Cross": 0.056320866078397196, "Positive": 0.028006600616488183, "SSIS": 0.02656662322977185, "OLAP": 0.026319599748848507, "etc Design implement": 0.026160022990063658, "ad hoc unstructured data models": 0.023579620407417536, "API etc Design": 0.022370286165731158}, {}, {"ETL": 0.08710691037490867, "days": 0.08596944989191106, "Java Python": 0.05485840229626899, "Spark Hadoop": 0.03633769210757913, "code Scala Experience working Agile environment Experience building data processing pipelines": 0.13919164546736776, "Amazing working environment Employee referral scheme ETL Scala": 0.13450016373701065, "Competitive Salary Company Bonus Private Healthcare Life Insurance Income protection Pension Scheme company contribution": 0.11831317822841526, "analytics pipelines": 0.11792573028898956, "Competitive Salary Company Bonus Private Healthcare Life Insurance Income": 0.11392916453156157, "big data experience": 0.10531641169146472, "Scala Experience": 0.10174295853609412, "sell days": 0.1003899600434777, "production handsoff batch systems": 0.09755881448962467, "Scala": 0.09055846488959786}, {"career categories": 0.4714045207910316}, {}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {"social events": 0.3711047733623777, "Virtual company": 0.22156958603625435, "Virtual": 0.15552550751170974}, {"Team player excellent communication skills": 0.37267799624996495}, {}, {"Competitive": 0.057998061903160716, "Tableau": 0.0634444549035479, "Minimum years": 0.07507018939640697, "ETL": 0.16175536012856823, "Exposure Business Intelligence tools Business Objects": 0.12005856278752125, "Business Objects Informatica": 0.10518067259805636, "developing testing ETL interfaces": 0.10505154189115862, "Exposure Business Intelligence": 0.1049685497636986, "Teradata Oracle MS SQL": 0.08460816231558413, "MDM": 0.11936157956356498}, {"Kinesis Riak": 0.269337257568918, "Aurora Dynamo": 0.4069752754210053}, {"data": 0.10654656010328646, "decisions": 0.0552981017191605, "Data Science": 0.09847225832898145, "third": 0.04678213954946153, "context data processing Experience proficiency Python Experience design implementation data": 0.1249600916721233, "Google Cloud Platform DevOps Stack development experience Apache Airflow data pipeline tools": 0.1129360032035352, "various sources data Manage": 0.11202256629912846, "Data Engineering Hadoop Spark Data Processing products": 0.10978113268494535, "data science production environments": 0.10964280570686127, "working engineering team best track record data": 0.10962519563774462, "third party elements data pipeline": 0.1087197831715627, "key data functions": 0.10869944140508675, "Support sophisticated predictive data products": 0.1084982660622458, "Data Engineering Hadoop Spark Data": 0.10820798643252474, "data inconsistencies": 0.10711667280164555, "Cloud experience": 0.10056320508045886, "outputs Data Science models": 0.09987600517289466, "open source tools": 0.09141621092322441, "similar Software Engineering Data Science etc experience software": 0.0784381500403463, "infrastructure layout": 0.07524089511690035, "cloud service integrations": 0.06931731126928627, "Big Query Redshift Spectrum S3 Athena Kafka Spark Storm Flink Beam Presto Hive ETL": 0.06778885658080011, "Apache Airflow": 0.05951580737908358, "python": 0.05123798445415902, "transformations": 0.045584308699836, "Manage": 0.045180892480622833, "Scala Java": 0.03215837771093971}, {"Machine": 0.18263162765420737, "statistical analysis": 0.39309699602751175}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {}, {"career categories": 0.4714045207910316}, {}, {"Spark": 0.06900596115992853, "skills": 0.050983775899865205, "others": 0.044461169848392525, "requirements": 0.046293608358591136, "ETL": 0.06871825284511895, "Java Python": 0.16189046010355448, "data systems": 0.09499981803763514, "MPP": 0.10920620583200706, "data access data storage techniques": 0.11937556898828551, "Python SQL Spark Scala Extensive Experience SQL": 0.11602232423400105, "big data years": 0.10372812145642032, "NoSQL solutions": 0.17824562795687804}, {"self": 0.08827521336499865, "new technologies": 0.1310658267708788, "perfect enemy": 0.14088837738788587, "display excellent judgment": 0.1460334946068168, "difficult tradeoffs": 0.1332988224175615, "new information": 0.1330580410187721}, {"BA BS Degree Computer Science Engineering discipline Statistics Information Systems": 0.23593641242799313, "Statistics Information Systems": 0.23292845799299977, "BA BS Degree Computer Science Engineering": 0.19222146567896448, "another quantitative field": 0.14283765093987727}, {}, {}, {}, {}, {}, {}, {}, {"career categories": 0.4714045207910316}, {}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"career categories": 0.4714045207910316}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {"statistical modeling discriminative methods": 0.21049165789381155, "extraction analysis": 0.20461147087363563, "Experience areas data": 0.13270482343132717}, {}, {}, {"related field": 0.2794994225688866, "Computer Science": 0.1756109317940242, "Mathematics Engineering technology": 0.23933153782684763, "Possess bachelor degree": 0.1500421213156909}, {}, {"millions daily players": 0.3466800150008662, "millions daily": 0.27010136077940194, "cool people": 0.19667082547981898}, {}, {}, {}, {}, {}, {}, {"Experience": 0.08745015641875505, "actionable insights": 0.05479942844949495, "Agile": 0.04293266279179999, "Proven": 0.042872251497491326, "BI": 0.05616529286419835, "Master degree": 0.06365220628732077, "big data technologies": 0.0825041056063883, "Java": 0.03953906113349366, "data stores data": 0.1373295768551446, "model evaluation validation Enthusiasm big data translating data": 0.12206507739731101, "unstructured data Proficient building robust data pipelines": 0.11867580983446299, "data processing tools": 0.11090778461818321, "leading successful data engineering projects": 0.10877653505957513, "reliable data services stakeholders": 0.10615786617720031, "Agile project development experience": 0.09638698232107122, "Data Engineer Machine Learning Engineer": 0.16132838497858767, "Kafka Apache Spark": 0.07362342585515755}, {}, {}, {"Tableau": 0.0504141335953309, "Desire": 0.050606396022965655, "analyze present data answer business questions Experience data visualization tools": 0.13024052882216658, "Experience data induction validation source systems Experience working Capital Projects": 0.11895907318738357, "Advanced SQL knowledge years data extraction experience": 0.11407915018193526, "UAT Expert normalizing data": 0.10996487779063929, "Familiarity Finance Operations Retail Contact Center data": 0.10829634861822347, "Desire end end ownership work Flexibility balance directional changes ability": 0.10647287412837618, "Strong analytical skills ability": 0.09838132360719304, "day day": 0.09602483799699868, "business support Ability deal ambiguity Proactive driven individual comfortable working global matrixed fast paced environment": 0.09262913794101406, "multiple deadline specific projects": 0.08363665611946813, "Oracle Teradata Vertica Hadoop": 0.15945197399708616}, {"self": 0.08827521336499865, "new technologies": 0.1310658267708788, "perfect enemy": 0.14088837738788587, "display excellent judgment": 0.1460334946068168, "difficult tradeoffs": 0.1332988224175615, "new information": 0.1330580410187721}, {}, {}, {"technical field": 0.06405996490113101, "k Savings Plan Company Match Paid Vacations": 0.11172685906927798, "Safety Quality First Valuing Ethics Integrity Diversity Passion": 0.10893364316856397, "Competitive Salary Comprehensive Health Wellness Income Protection Benefits": 0.10470431585315694, "Safety Quality First Valuing Ethics Integrity Diversity Passion Serving Our Customers Globally Dedication": 0.08038148863790867, "Bachelor Master degree Computer Science": 0.05824886545137991, "Servant Leadership": 0.049085625952781826}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {"Python": 0.5}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"self": 0.08827521336499865, "new technologies": 0.1310658267708788, "perfect enemy": 0.14088837738788587, "display excellent judgment": 0.1460334946068168, "difficult tradeoffs": 0.1332988224175615, "new information": 0.1330580410187721}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"AI": 0.05184328688133426, "Spark": 0.05802692697554538, "skills": 0.04467767182177629, "NoSQL": 0.0929439790849809, "ETL": 0.04825091004645268, "Big Data": 0.07583686218583252, "Computer Science": 0.041594203885234715, "Kafka": 0.044173656676296545, "Pig Hive Impala Experience integration data multiple data sources": 0.10796286620225859, "TDD Continuous Integration Experience refactoring code scale production mind": 0.09736988811170011, "Solid knowledge data structures": 0.09698355156850443, "Experience Big Data ML": 0.09521475541783438, "services Experience building stream processing systems": 0.09241711435125108, "Good knowledge Big Data querying tools": 0.08853101692289089, "Big Data ML": 0.07998955247917519, "Lambda Architecture": 0.11999626766939656, "advantages": 0.05988760785309302}, {"career categories": 0.4714045207910316}, {}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {"At least years": 0.010738143368982706, "best practices": 0.043188478836426764, "Data": 0.20422774519201015, "Provide": 0.027471897962396852, "ETL": 0.02766795077765829, "ideas": 0.02983077240041819, "data pipelines": 0.09951412077786717, "Microsoft": 0.0739579137012215, "g": 0.037709161376624806, "real time": 0.061226537974961, "e": 0.04434373047854841, "data sources": 0.10833103324082717, "Design": 0.2381880611819147, "technologies": 0.051589874682063365, "Assist": 0.029112577828350066, "Manage": 0.05655225062071425, "data streaming Design": 0.11426671031143512, "data warehouse data models": 0.11532756122759574, "source data e g data profiling definition mapping Design": 0.10932946664291852, "efficient data loads": 0.1056208370808152, "unstructured data loads": 0.10322018203280173, "managing data": 0.09985557388912371, "traditional structured data ETL techniques Design": 0.09964272161053585, "technical data related support source system teams": 0.0972154153482658, "usability data": 0.09982859850715414, "real time data load solutions": 0.10010127204674811, "appropriate aggregation data structures": 0.0986889775814539, "troubleshoot technical data issues": 0.09594806343682549, "SQL Data analysis Data visualisation Data": 0.0949851035737128, "data management analytics": 0.09306414349161134, "effective efficient data models": 0.0929755134003854, "Microsoft business intelligence data technologies": 0.09806554101092776, "speed access Design": 0.0812062409051634, "data processes": 0.09326812278856712, "data elements": 0.08923726364080767, "Work source system owners analysts": 0.07797953136123277, "supplement enhance context Design": 0.07483621606954394, "interface monitoring management solutions": 0.07455651642271897, "solutions Positive engagement team activities": 0.06309559349198342, "data access e g batch exports": 0.0841139369988743, "Work analysts": 0.06944827440502596, "e g text speech images video Design": 0.07809801402626126, "ownership work": 0.06692821196105123, "business owners analysts": 0.06787659215473385, "load monitoring tools procedures": 0.0695358549968918, "high quality work time Show initiative": 0.06730654230933943, "real time decision": 0.0675632150658713, "Manage systems technology tools": 0.06281085576683419, "Information gathering problem analysis": 0.054265143218216794, "appropriate indexing tables": 0.0641290675146661, "SSAS SQL Server Data warehouse": 0.06053974574399368, "appropriate modelling techniques": 0.058199527772794066, "appropriate changes": 0.05354983683102944, "professional specialist technical expertise": 0.05679257592058184, "SQL Data": 0.05382831745333183, "skills knowledge application": 0.04696468137144062, "loads": 0.05502988446731909, "ownership career development": 0.05256383921013647, "continuous monitoring": 0.05527506391266071, "sources": 0.05268131909747703, "integrity existing environment": 0.053088590673675176, "automated decision": 0.04843690767783768, "value decision": 0.04757173527652384, "active finding opportunities": 0.04499027554962136, "effective strategies": 0.04427024575559782, "external parties": 0.04375310306537262, "Quality": 0.03712199965891115, "g multi dimensional OLAP structures summary tables": 0.04272349664258385, "Take": 0.03693110154227723, "interfaces": 0.03742843157223792, "Positive": 0.028459010751305934, "SSIS": 0.026386680168071795, "OLAP": 0.03341003575143006, "etc Design implement": 0.028086446193715472, "ad hoc unstructured data models": 0.024104921462218928, "API etc Design": 0.023674364715064705, "technical data role": 0.10007888998985862, "good data governance": 0.09677327801692917, "Unstructured data experience": 0.09559788465449992, "Implement meta data solutions": 0.08934870953645419, "Microsoft business intelligence visualisation technologies": 0.07618073472156765, "knowledge share Quality control work Degree information technology": 0.07016335790047894, "Stakeholder management internal external Assist development others": 0.060959311398218224, "SSRS Power BI IT infrastructure e g storage networking servers": 0.056238394357191454, "team dynamics performance": 0.053837553960832826, "mathematics engineering actuarial science related discipline": 0.05377992673132049, "specifically personal unsecured loans Business process monitoring": 0.050328968801213445, "Quality Detail orientation": 0.04969722171793543, "availability accuracy Monitor": 0.0433181959339979, "SSRS Power BI": 0.04090385824105545, "Stakeholder": 0.029977429463297154, "Unstructured": 0.029974422990354674}, {}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {"Ability": 0.06068019228920722, "SQL": 0.08328603665373344, "Excellent problem": 0.08768085454665439, "Java": 0.028995477192749666, "Computer Science": 0.07959326806268666, "data processing systems Experience": 0.1516777669832962, "years experience schema": 0.1514932832759122, "internal clients Experience designing building": 0.13000512543694193, "communicating data warehouse": 0.11467879431909697, "troubleshooting skills Process oriented great documentation skills": 0.11293294996645513, "dimensional data": 0.1099017050163106, "keen sense customer service BS MS degree": 0.10714540299962905}, {}, {"technical field": 0.06405996490113101, "k Savings Plan Company Match Paid Vacations": 0.11172685906927798, "Safety Quality First Valuing Ethics Integrity Diversity Passion": 0.10893364316856397, "Competitive Salary Comprehensive Health Wellness Income Protection Benefits": 0.10470431585315694, "Safety Quality First Valuing Ethics Integrity Diversity Passion Serving Our Customers Globally Dedication": 0.08038148863790867, "Bachelor Master degree Computer Science": 0.05824886545137991, "Servant Leadership": 0.049085625952781826}, {"SQL": 0.1544164974611002, "BI": 0.047754489141275905, "Develop": 0.17240627031500227, "ETL": 0.04569919754775136, "data pipelines": 0.21062261009157013, "one programming languages": 0.040625641727760016, "Write": 0.06403287521541275, "schemas": 0.04602510079811948, "third": 0.04774583490561785, "data Optimize tune data warehouse query performance analytical workloads": 0.11612990831515296, "SQL Server Experience developing software code": 0.11165702141446558, "integrations BI tools third party productivity applications years engineering experience Expert SQL": 0.11100244401166783, "data warehouse structure table": 0.10960740060476303, "Python Java Scala Ruby Experience managing database data warehouse technologies bonus Redshift Snowflake Experience": 0.10618945432279257, "robust data": 0.10354845506364396, "resolve data quality issues": 0.10352315093738043, "Bonus Stitch Fivetran Matillion Understanding data analytics ecosystem": 0.10291489898440892, "data analysis Design": 0.10218959751772395, "visualization tools based requirements": 0.10133037296082091, "Business Intelligence tools": 0.10097082450040376, "ETL tools": 0.10033006010565265, "Spark Kafka AWS Glue Amazon Kinesis Sqoop Flume Flink Experience": 0.09688307673002862, "Bonus Looker Experience": 0.09334193908372415, "Snowflake Redshift PostgreSQL": 0.08660390587299582, "Bonus Stitch Fivetran Matillion Understanding": 0.08386143155739119, "Redshift Snowflake": 0.08349987740753534, "Snowflake Redshift": 0.08349987740753534, "Bonus Looker": 0.07307790417438763, "Kinesis Sqoop": 0.06608153091469407, "Business Intelligence": 0.06223616033090468, "Spark Kafka": 0.06215690553516344, "one relevant tools": 0.05354573836762207, "troubleshoot": 0.04880862160792828, "users": 0.04790624636457893, "Architect": 0.08272146771469116}, {}, {}, {}, {}, {"data analytics": 0.12217952365124554, "ML": 0.09412417919077616, "JSON ProtocolBuffers XML": 0.1689485925449067, "Numpy Scipy Experience query APIs": 0.16024031848873493, "JSON ProtocolBuffers": 0.1349159272141298, "Numpy Scipy": 0.127311806643223, "algebra ML": 0.1250773868012535, "RDB MPP DB": 0.11159771340175242, "Oozie Big data warehousing RDB": 0.10835509556596774}, {"Apple": 1.1856464794670734, "Apple benefits programmes": 0.1257792946375731, "Apple benefits": 0.12312008705413605, "Apple programmes": 0.11797688595699932, "Apple important resource soul people": 0.10280906435128735, "Apple chance share company success": 0.10269182227580867, "Supporting data collection curation data provenance": 0.09127487512769487, "stock grants employees levels company": 0.09119074618105487, "special employee pricing": 0.07923923286154434, "benefits privileges": 0.0790749916346076, "many benefits": 0.0790668221668578, "distributed systems blob storage elastic compute virtual instances Familiarity Software Development Life Cycles tools methodologies": 0.0779782840503056, "reasonable accommodation applicants": 0.07291834912815039, "Familiarity Software Development Life Cycles": 0.07242771859425544, "reasonable accommodation": 0.07187575670860522, "employees": 0.14355248218370834, "charitable contributions reimburse continuing education": 0.06638919148669689, "programmes": 0.06356518410489033, "country subject eligibility requirements": 0.06315418503191926, "Apple products": 0.053072208286055425, "meaningful ways": 0.0522610793643936, "Experience Scala": 0.1009397914821711, "option": 0.03843447039642778}, {}, {"Competitive": 0.03795693031096253, "Ability": 0.06403933869286546, "data": 0.08486038461894185, "Experience": 0.13751107477735747, "SQL": 0.035513105805420185, "skills": 0.05360885879349119, "NoSQL": 0.03834890128795595, "requirements": 0.03816730895566733, "Develop": 0.11792734313261212, "Communicate": 0.07374142192586465, "401k": 0.0, "ETL": 0.09760609030181415, "Excellent problem": 0.05383792520407213, "Build": 0.03571601539885791, "Create": 0.037892648441507235, "ETL tools": 0.05690809732460734, "source systems data": 0.10717385177869436, "published data sources": 0.1014157335502289, "Create manage data sources": 0.08970449733942487, "ETL programs data pipelines": 0.08892446367563044, "AWS Redshift Python R Hadoop Spark technologies Work": 0.08660622192240722, "unstructured data Competitive wages": 0.08581785239687616, "practical demonstrable hands work experience SQL": 0.08566355131490817, "relational NoSQL columnar data stores": 0.08563284278577898, "open source cloud based environment": 0.08329604284991994, "Python Java Scala R Sharp attention detail ability": 0.08140729130707522, "Health Savings Account Medical Dependent Care Flexible Spending Accounts Wellness Program Membership TPC": 0.07981171632429489, "database design execution Work": 0.0779520770637937, "Health Savings Account Medical Dependent Care Flexible Spending Accounts": 0.07754323918394523, "Redshift Python R Hadoop": 0.07738714621649502, "data release testing processes": 0.07414544786981007, "multiple tasks": 0.052914547283715835, "Data Engineering": 0.04568515170252883}, {"Spark": 0.1347053217716663, "Python": 0.05870308538994792, "ETL": 0.10116781892603316, "MPP": 0.19175245994421572, "Spark development years": 0.21817021791054858, "data engineering ETL pipeline development years": 0.20488974374424923, "preferred years": 0.1815798941706476, "Python preferred Experience": 0.17440876605261948, "Big Data Technologies Hadoop MapReduce Hive": 0.17006869284912773, "Big Data Technologies Hadoop MapReduce Hive etc Spark experience": 0.1510966969558833}, {}, {"Hadoop Spark": 0.08890667225853793, "SQL": 0.23728896636580682, "relational databases": 0.09399895889329563, "working familiarity variety": 0.1341965143179741, "SSAS SSRS Degree Information Technology": 0.14278098774602535, "Full SQL Stack": 0.14082120066458048, "SQL knowledge experience": 0.13109623145028262, "Five seven years": 0.13516439156845453}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {"things": 0.09657268594382133, "SQL NoSQL database experience": 0.25648655007826393, "challenge": 0.07525145166809963}, {}, {"Hadoop": 0.04423418805812291, "Experience": 0.09165225299679731, "skills": 0.0409312664695826, "Proven ability": 0.061252467487949075, "Proven": 0.04587114406578773, "Background": 0.04288371693679773, "Microsoft Azure": 0.04947682765020582, "Cloud": 0.03911042929524927, "data analytic pipelines": 0.12677103232751036, "Experience data movement management Pharmaceutical industry": 0.12150871131016996, "Computer Science Bioinformatics related degree years experience data movement data wrangling delivery data analytics pipelines": 0.11641254938683596, "diverse omic data types": 0.11385380528660682, "RNA Seq DNA Seq Chip Seq WES WGS ATAC seq microbiome proteomic metabolomic data": 0.11190527103572032, "Familiarity data mining machine": 0.11073129986286477, "RNA Seq DNA Seq Chip Seq WES WGS ATAC": 0.10221884382688619, "scientific fields Experience core components Hadoop stack": 0.09658761896365323, "judgement balance pace": 0.0825262388343462, "honest open conversations": 0.07680181100445424, "Operating pace": 0.0758520477242576, "rigour risk": 0.07491640658456278, "agile decision making": 0.07315770796381384, "Cloud computing HPC systems": 0.06957150950793554, "artificial intelligence techniques": 0.06782687574643652, "HDFS Apache Spark": 0.13441605835478762}, {}, {"At least years": 0.042660140881312154, "Complex": 0.027687093954137564, "Data": 0.20859395057172617, "Provide": 0.026935725402768715, "ETL": 0.02723716105228059, "ideas": 0.02832301698082865, "data pipelines": 0.10136993226230945, "Microsoft": 0.02788640394746022, "g": 0.03496997849555885, "real time": 0.059166709200366326, "e": 0.03459736580357689, "data sources": 0.10919033453061855, "Design": 0.3484350681629307, "technologies": 0.046018896166138155, "Assist": 0.028032358232169804, "Manage": 0.10968807353134477, "data streaming Design": 0.11977400036371816, "data warehouse data models": 0.10785041660207487, "source data e g data profiling definition mapping Design": 0.10762239812090121, "data Manage data growth usage": 0.10735334688621762, "data monitoring solutions procedures": 0.10667696671102622, "efficient data loads": 0.10616599878978636, "good data governance Work": 0.10404935934661055, "unstructured data loads": 0.10394990216074276, "functional data team knowledge gathering": 0.103794835432205, "managing data": 0.10373091496672956, "traditional structured data ETL techniques Design": 0.10349245473221372, "technical data related support source system teams": 0.10291117294615235, "usability data": 0.10151106479628316, "real time data load solutions": 0.09851208883259796, "appropriate aggregation data structures": 0.09845998434762333, "changes data organisation": 0.0980513399810516, "troubleshoot technical data issues": 0.09630132893207254, "working data business intelligence analytics environment": 0.0961598170636963, "SQL Data analysis Data visualisation Data": 0.09434390101081226, "data management analytics": 0.09267718715400096, "meta data solutions": 0.09265251495619113, "team dynamics performance Complex solution service design implementation": 0.09006551402872655, "effective efficient data models": 0.08857633555927515, "Microsoft business intelligence data technologies": 0.08833896751259532, "speed access Design": 0.08591180763769243, "data processes": 0.08466318797040909, "data elements": 0.08410624974886913, "Work source system owners analysts": 0.08354788427726087, "availability accuracy Design": 0.08253762158438192, "Responsible team activities team dynamics performance Manage project task delivery team": 0.08148632703391528, "supplement enhance context Design": 0.07966016182077537, "interface monitoring management solutions": 0.07791172324426537, "solutions Positive engagement team activities": 0.07768930602185288, "data access e g batch exports": 0.07746351791635504, "Work analysts": 0.07461102723390724, "e g text speech images video Design": 0.07429922829406735, "knowledge share Quality control work Degree information technology engineering mathematics statistics actuarial related discipline": 0.06996202632489378, "ownership work": 0.06935195328441357, "business owners analysts": 0.13833003502811306, "load monitoring tools procedures": 0.06854156954219583, "high quality work time Show initiative": 0.06777706592837883, "system infrastructure management": 0.06652516243043535, "real time decision": 0.06538084348165632, "Manage systems technology tools": 0.06517978097414644, "Information gathering problem analysis": 0.06137782200834538, "appropriate indexing tables": 0.06046208404613174, "SSAS SQL Server Data warehouse": 0.05757885972719333, "Presenting Communicating information": 0.05660196137859942, "appropriate modelling techniques": 0.056588219820686424, "appropriate changes": 0.05605997116169901, "internal external Assist development others": 0.055312379432028984, "professional specialist technical expertise": 0.05497870843644437, "Multiple stakeholder management": 0.05490536598317708, "SQL Data": 0.05340953852252053, "skills knowledge application": 0.053361408949206345, "loads": 0.05304390246469944, "ownership career development": 0.052686417337748155, "Quality Detail orientation Planning": 0.05172816973146134, "continuous monitoring": 0.05143841047515044, "sources": 0.050348646908253664, "integrity existing environment": 0.049950826370128903, "IT infrastructure IT Operations": 0.049082846992024275, "Analysing Leadership": 0.04797071706239034, "automated decision": 0.04709156740992211, "value decision": 0.046306019851437535, "active finding opportunities": 0.044154371019275926, "effective strategies": 0.04289335623470404, "Presenting Communicating": 0.042246687368454994, "external parties": 0.04224181518884275, "Quality": 0.03793417854974236, "g multi dimensional OLAP structures summary tables": 0.03675811259096596, "Take": 0.03643944234183073, "interfaces": 0.036168632677745845, "Cross": 0.056320866078397196, "Positive": 0.028006600616488183, "SSIS": 0.02656662322977185, "OLAP": 0.026319599748848507, "etc Design implement": 0.026160022990063658, "ad hoc unstructured data models": 0.023579620407417536, "API etc Design": 0.022370286165731158}, {"Agile Engineering Kanban Lean Hybrid agile experience": 0.2800280856177859}, {}, {"techniques": 0.1026632959065837, "Python SQL Elastic visualise data surfacing tool Experience developing machine learning systems Experience Amazon Quicksite advantage": 0.16381858214055792, "exploration visualisation Experience statistical models times": 0.14567631518082422, "Degree educated Data Science similar Strong experience data preparation techniques": 0.1326274753856413, "regression classification Strong skills": 0.13128364580746574, "Python SQL Elastic": 0.1165953955790625, "series analysis": 0.10501264228684692}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"Splunk Hadoop": 0.3263027573257299}, {}, {}, {"insightful data performance visualizations": 0.19565044697536516, "optimized pipelines data acquisition": 0.1885559299049776, "algorithm variants": 0.1863277909505755, "Expertise Python programming functional object": 0.10664755076072875}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"limited personnel policies policies": 0.23989703090071807, "University Administrative Guide http": 0.19290563969950608, "comply applicable University policies procedures": 0.18944006631356136, "University Administrative Guide": 0.17861246646481085}, {}, {}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"unsolicited services": 0.30375669934033167}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"career categories": 0.4714045207910316}, {}, {}, {}, {"Self": 0.11293187208502543, "able work": 0.18868254428671566, "Linux system administration command line tools": 0.16841188259451137, "Strong analytical thinking": 0.16394498252980755, "Excellent programming skills C C Python Java": 0.13836614278517984, "minimum experience": 0.12796620928200514, "production software": 0.1081450702626184}, {"Experience": 0.1138678587888797, "Spark": 0.0649412800584299, "Apache Hadoop": 0.08375024472563937, "ETL": 0.041180364522869176, "new technologies": 0.10175423933100682, "Scala": 0.06577535091226472, "Experience data tools": 0.16729347147892848, "streaming data processing Ability": 0.14906946035930752, "Scala preferred Proficient schema design data": 0.13524852045916655, "analytic skills Ability program several scripting languages Python Perl Bash Experience workflow management tools": 0.13244284190974367, "high volume data Apache Hadoop ecosystem": 0.12912208000707284, "Oozie Airflow Azkaban": 0.11695752566213621, "Python Perl Bash": 0.09145669103817104, "Oozie Airflow Azkaban etc Experience": 0.09014548379849507, "working cross functional projects": 0.08669534775390914, "one object oriented programming languages": 0.07327529057284067, "Passion customer privacy Strong interpersonal skills": 0.0708353801579834}, {"At least years": 0.010738143368982706, "best practices": 0.043188478836426764, "Data": 0.20422774519201015, "Provide": 0.027471897962396852, "ETL": 0.02766795077765829, "ideas": 0.02983077240041819, "data pipelines": 0.09951412077786717, "Microsoft": 0.0739579137012215, "g": 0.037709161376624806, "real time": 0.061226537974961, "e": 0.04434373047854841, "data sources": 0.10833103324082717, "Design": 0.2381880611819147, "technologies": 0.051589874682063365, "Assist": 0.029112577828350066, "Manage": 0.05655225062071425, "data streaming Design": 0.11426671031143512, "data warehouse data models": 0.11532756122759574, "source data e g data profiling definition mapping Design": 0.10932946664291852, "efficient data loads": 0.1056208370808152, "unstructured data loads": 0.10322018203280173, "managing data": 0.09985557388912371, "traditional structured data ETL techniques Design": 0.09964272161053585, "technical data related support source system teams": 0.0972154153482658, "usability data": 0.09982859850715414, "real time data load solutions": 0.10010127204674811, "appropriate aggregation data structures": 0.0986889775814539, "troubleshoot technical data issues": 0.09594806343682549, "SQL Data analysis Data visualisation Data": 0.0949851035737128, "data management analytics": 0.09306414349161134, "effective efficient data models": 0.0929755134003854, "Microsoft business intelligence data technologies": 0.09806554101092776, "speed access Design": 0.0812062409051634, "data processes": 0.09326812278856712, "data elements": 0.08923726364080767, "Work source system owners analysts": 0.07797953136123277, "supplement enhance context Design": 0.07483621606954394, "interface monitoring management solutions": 0.07455651642271897, "solutions Positive engagement team activities": 0.06309559349198342, "data access e g batch exports": 0.0841139369988743, "Work analysts": 0.06944827440502596, "e g text speech images video Design": 0.07809801402626126, "ownership work": 0.06692821196105123, "business owners analysts": 0.06787659215473385, "load monitoring tools procedures": 0.0695358549968918, "high quality work time Show initiative": 0.06730654230933943, "real time decision": 0.0675632150658713, "Manage systems technology tools": 0.06281085576683419, "Information gathering problem analysis": 0.054265143218216794, "appropriate indexing tables": 0.0641290675146661, "SSAS SQL Server Data warehouse": 0.06053974574399368, "appropriate modelling techniques": 0.058199527772794066, "appropriate changes": 0.05354983683102944, "professional specialist technical expertise": 0.05679257592058184, "SQL Data": 0.05382831745333183, "skills knowledge application": 0.04696468137144062, "loads": 0.05502988446731909, "ownership career development": 0.05256383921013647, "continuous monitoring": 0.05527506391266071, "sources": 0.05268131909747703, "integrity existing environment": 0.053088590673675176, "automated decision": 0.04843690767783768, "value decision": 0.04757173527652384, "active finding opportunities": 0.04499027554962136, "effective strategies": 0.04427024575559782, "external parties": 0.04375310306537262, "Quality": 0.03712199965891115, "g multi dimensional OLAP structures summary tables": 0.04272349664258385, "Take": 0.03693110154227723, "interfaces": 0.03742843157223792, "Positive": 0.028459010751305934, "SSIS": 0.026386680168071795, "OLAP": 0.03341003575143006, "etc Design implement": 0.028086446193715472, "ad hoc unstructured data models": 0.024104921462218928, "API etc Design": 0.023674364715064705, "technical data role": 0.10007888998985862, "good data governance": 0.09677327801692917, "Unstructured data experience": 0.09559788465449992, "Implement meta data solutions": 0.08934870953645419, "Microsoft business intelligence visualisation technologies": 0.07618073472156765, "knowledge share Quality control work Degree information technology": 0.07016335790047894, "Stakeholder management internal external Assist development others": 0.060959311398218224, "SSRS Power BI IT infrastructure e g storage networking servers": 0.056238394357191454, "team dynamics performance": 0.053837553960832826, "mathematics engineering actuarial science related discipline": 0.05377992673132049, "specifically personal unsecured loans Business process monitoring": 0.050328968801213445, "Quality Detail orientation": 0.04969722171793543, "availability accuracy Monitor": 0.0433181959339979, "SSRS Power BI": 0.04090385824105545, "Stakeholder": 0.029977429463297154, "Unstructured": 0.029974422990354674}, {"related field": 0.2794994225688866, "Computer Science": 0.1756109317940242, "Mathematics Engineering technology": 0.23933153782684763, "Possess bachelor degree": 0.1500421213156909}, {}, {"NoSQL": 0.18263162765420737, "NoSQL databases": 0.2601864215065202, "Cassandra Neo4J": 0.39309699602751175, "MongoDB Cassandra": 0.11407306634806502}, {}, {"ETL": 0.12712843225896345, "code": 0.08168975460823717, "SQL Data": 0.281718029952146, "SSIS": 0.1193199665423707, "SSIS standard ETL": 0.18502395712681174, "strong Stored Procs": 0.1560976090024442, "Stored Procs": 0.14202215680089195, "serious interest": 0.12791085065371352, "SQL Dev": 0.1233111149795148}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {}, {}, {}, {"Hadoop": 0.05712062551560103, "techniques": 0.05827027531759137, "Kafka": 0.058805986746289556, "realtime streaming compute components Experience data modeling data architecture": 0.13982953161713543, "big data patterns": 0.1216506110667037, "Knowledgable distributed storage network resources level hosts": 0.1163988987490943, "DCs troubleshoot prevent performance issues": 0.11452367940502389, "large scale data pipelines": 0.10525906794863833, "MapReduce Spark": 0.0959315120408609, "ie warehousing concepts efficient storage query HDFS data security privacy": 0.09255519090171949, "highly scalable data systems services": 0.060694265014917204, "batch": 0.06133173213038811, "MapReduce Spark Spark SQL": 0.11505728455454008, "Java Scala Extensive experience Hadoop ecosystem technologies": 0.105079815781696, "Spark Streaming Hive YARN MR2 Expertise building": 0.09670324961310343, "Java Scala Extensive": 0.08042415813793687}, {}, {}, {"Preference": 0.053828180407764596, "Apple": 0.9878604290724337, "Apple benefits programmes": 0.14692189159788321, "Apple benefits": 0.14026956149470332, "Apple programmes": 0.1395049567443225, "Apple chance share company success": 0.12355272678238163, "stock grants employees levels company": 0.11310678546543533, "special employee pricing": 0.10250048129315276, "many benefits": 0.09192566547853905, "employees": 0.18751529699332858, "charitable contributions reimburse continuing education": 0.08432034670230634, "programmes": 0.08152543176075566, "country subject eligibility requirements": 0.09000904081498928, "Apple products": 0.06787780130989408, "meaningful ways": 0.06726214375367175, "option": 0.04940695501114863, "Scala Python Apple": 0.12410767425440432, "Scala Python Apple important resource soul people": 0.12053475686551895, "self sufficient Experience": 0.10408294411834655, "distributed systems services scale Experience": 0.09855707143302415, "Preference experience": 0.09664197337274795, "health wellness resources time": 0.09083275000383159, "similar technologies production contexts": 0.0839534419726521, "SOLR Spark Hadoop Kafka": 0.08033060573141021, "years software engineering experience": 0.078289345813229, "responsible self": 0.07743480578534312}, {"data": 0.09100193421536235, "hands": 0.04216462204347505, "data pipelines": 0.11250352761128365, "Redis Apache Spark similar tools Experience regression testing data pipelines": 0.14626102605016955, "instance Docker Kubernetes Terraform CloudFormation Ansible Chef Puppet Salt Splunk Elastic ELK Stack Sentry Datadog similar tools Knowledge Machine Learning Computer Vision": 0.13924465340851092, "Experience DevOps application monitoring tools": 0.12783323870378516, "AWS RDS Apache Kafka AWS Kinesis": 0.12631053200292025, "Knowledge Machine Learning Computer Vision": 0.12246244475598195, "Proficient scripting functional programming languages": 0.10801734109366186, "Docker Kubernetes Terraform CloudFormation Ansible": 0.1068524204997524, "RDS Apache Kafka": 0.10562460944433988, "Redis Apache": 0.1003121022813186, "streaming solutions instance": 0.1002757993994672, "Kinesis RabbitMQ": 0.08424366220201969, "Python Scala Bash Groovy Ruby Experience database message": 0.07654553160802807}, {"AI": 0.046997650779287026, "Hadoop Spark": 0.06389413008499578, "Experience": 0.099394022139714, "Working": 0.0463383792950513, "ETL": 0.04976702728271518, "working Batch Real Time data processing systems Ability work": 0.12237688808098521, "large scale data processing": 0.1203258021689488, "machine learning solutions scale Experience": 0.11702038802936195, "based systems Experience custom ETL design implementation maintenance Experience": 0.1160946765135852, "data storage principles": 0.11565881739231465, "Knowledge distributed systems": 0.11132631053874963, "data management": 0.11122515532269613, "data storage cloud computing Understanding administration AWS Docker Linux": 0.11071963958255325, "Hadoop Spark Dataflow Airflow Knowledge practical experience machine": 0.10903497959668679, "traditional distributed systems": 0.10449016185364611, "Competitive Salary Equity 401k Company Match Gym Public Transportation Subsidy Student Loan Assistance Relocation Assistance Unlimited PTO": 0.10379979563939636, "Competitive Salary Equity 401k Company Match Gym Public Transportation Subsidy Student Loan Assistance Relocation Assistance": 0.09959556104802586, "Unlimited PTO": 0.0895151988254552, "Opportunity work": 0.08597712559993312, "AI fundamentals": 0.07470986377817153, "Batch Real Time": 0.07298403655147895, "Computer Science Statistics Engineering": 0.06698284149937095, "higher quantitative technical field": 0.06243973002253567}, {}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {"AI": 0.05083932523737018, "Bachelor degree": 0.03460393293858804, "Hadoop Spark": 0.06745039756744, "Experience": 0.0969493799807425, "ETL": 0.052058754705179545, "working Batch Real Time data processing systems Ability work": 0.1242735192838651, "large scale data processing": 0.12334719873727272, "machine learning solutions scale Experience": 0.12118169265843692, "based systems Experience custom ETL design implementation maintenance Experience": 0.11902485480494637, "data storage principles": 0.11349328962017007, "Knowledge distributed systems": 0.1153660263918138, "data management": 0.10536454061710383, "data storage cloud computing Understanding administration AWS Docker Linux": 0.10630613239579029, "Hadoop Spark Dataflow Airflow Knowledge practical experience machine": 0.11234019567647058, "traditional distributed systems": 0.10843570794516089, "Opportunity work": 0.08218755537761914, "AI fundamentals": 0.07614163195512977, "Batch Real Time": 0.07966813436948612, "Computer Science Statistics Engineering": 0.14453281640767351, "higher quantitative technical field": 0.058109299937610576, "Working knowledge data design architecture": 0.11384647308359314, "401K Gym public transportation subsidy Relocation assistance": 0.08115576084075647, "fastest growing financial startups Competitive salary equity Health dental vision insurance": 0.0797318723057307, "K Gym": 0.07798021174513123}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {}, {"Experience SQL": 0.12322532423896487, "data ingest enrichment analysis visualization dissemination": 0.16605242908954335, "Spark Knime Exposure AWS Data Services Experience Architect design implement": 0.1465992718429829, "Spark Knime Exposure AWS Data Services": 0.13429186103594265, "Data transformation experience": 0.13261189066500795, "data repositories": 0.11664916516292281, "largest growth": 0.09323036846455562, "indices": 0.08827530475425763, "Graph Databases": 0.08746012240642784, "enhancements": 0.08660608483586547}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"year": 0.07830575136899164, "Data": 0.06767068447613168, "ETL": 0.048665103802980045, "Applied": 0.030198703921781894, "days": 0.09234512494814562, "working day year": 0.11896389798067955, "data enterprise systems SAP Security management Data modelling ETL development": 0.1045314606249528, "Annual Bonus Plan Discretionary Cash Award Group Personal Pension Plan": 0.20023660897900963, "additional days": 0.09937253034251799, "tools Data Integrator Services Experience experience": 0.09110822710993935, "agile project management": 0.08629701348561582, "Medical Travel Health Life Insurances": 0.08605144251234166, "data engineering domain": 0.08445030954258961, "Data Integrator Services": 0.08440117670359212, "free car parking gym site team": 0.0839680190034545, "schemas dimensional modelling normalisation": 0.08394993083799997, "Strong knowledge concepts": 0.08182324964040064}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {}, {"statistical modeling discriminative methods": 0.21049165789381155, "extraction analysis": 0.20461147087363563, "Experience areas data": 0.13270482343132717}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {"career categories": 0.4714045207910316}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {"Competitive": 0.1479388110964305, "Frequent company": 0.08969569698312065, "HomeAway com Electronic adjustable stand desk": 0.11802647659641453, "talks leadership team": 0.10196362391992062, "Discounted Metro Rail": 0.21258376697820808, "Annual": 0.05815452243924841, "yearly basis taxable benefit Employee Stock Purchase Program Free snacks": 0.11803364780367072, "spark Experience Scala Python Experience building batch pipelines data event data": 0.11136068732267497, "Employee Stock Purchase Program Free": 0.109362176945107, "Experience building data pipelines": 0.10500572967046706, "data systems AWS": 0.09005158094229739, "NoSQL APIs Competitive health insurance benefits Competitive salary Annual target bonus commission": 0.08941527404150612, "Vacation": 0.08407208146693344}, {}, {"At least years": 0.010738143368982706, "best practices": 0.043188478836426764, "Data": 0.20422774519201015, "Provide": 0.027471897962396852, "ETL": 0.02766795077765829, "ideas": 0.02983077240041819, "data pipelines": 0.09951412077786717, "Microsoft": 0.0739579137012215, "g": 0.037709161376624806, "real time": 0.061226537974961, "e": 0.04434373047854841, "data sources": 0.10833103324082717, "Design": 0.2381880611819147, "technologies": 0.051589874682063365, "Assist": 0.029112577828350066, "Manage": 0.05655225062071425, "data streaming Design": 0.11426671031143512, "data warehouse data models": 0.11532756122759574, "source data e g data profiling definition mapping Design": 0.10932946664291852, "efficient data loads": 0.1056208370808152, "unstructured data loads": 0.10322018203280173, "managing data": 0.09985557388912371, "traditional structured data ETL techniques Design": 0.09964272161053585, "technical data related support source system teams": 0.0972154153482658, "usability data": 0.09982859850715414, "real time data load solutions": 0.10010127204674811, "appropriate aggregation data structures": 0.0986889775814539, "troubleshoot technical data issues": 0.09594806343682549, "SQL Data analysis Data visualisation Data": 0.0949851035737128, "data management analytics": 0.09306414349161134, "effective efficient data models": 0.0929755134003854, "Microsoft business intelligence data technologies": 0.09806554101092776, "speed access Design": 0.0812062409051634, "data processes": 0.09326812278856712, "data elements": 0.08923726364080767, "Work source system owners analysts": 0.07797953136123277, "supplement enhance context Design": 0.07483621606954394, "interface monitoring management solutions": 0.07455651642271897, "solutions Positive engagement team activities": 0.06309559349198342, "data access e g batch exports": 0.0841139369988743, "Work analysts": 0.06944827440502596, "e g text speech images video Design": 0.07809801402626126, "ownership work": 0.06692821196105123, "business owners analysts": 0.06787659215473385, "load monitoring tools procedures": 0.0695358549968918, "high quality work time Show initiative": 0.06730654230933943, "real time decision": 0.0675632150658713, "Manage systems technology tools": 0.06281085576683419, "Information gathering problem analysis": 0.054265143218216794, "appropriate indexing tables": 0.0641290675146661, "SSAS SQL Server Data warehouse": 0.06053974574399368, "appropriate modelling techniques": 0.058199527772794066, "appropriate changes": 0.05354983683102944, "professional specialist technical expertise": 0.05679257592058184, "SQL Data": 0.05382831745333183, "skills knowledge application": 0.04696468137144062, "loads": 0.05502988446731909, "ownership career development": 0.05256383921013647, "continuous monitoring": 0.05527506391266071, "sources": 0.05268131909747703, "integrity existing environment": 0.053088590673675176, "automated decision": 0.04843690767783768, "value decision": 0.04757173527652384, "active finding opportunities": 0.04499027554962136, "effective strategies": 0.04427024575559782, "external parties": 0.04375310306537262, "Quality": 0.03712199965891115, "g multi dimensional OLAP structures summary tables": 0.04272349664258385, "Take": 0.03693110154227723, "interfaces": 0.03742843157223792, "Positive": 0.028459010751305934, "SSIS": 0.026386680168071795, "OLAP": 0.03341003575143006, "etc Design implement": 0.028086446193715472, "ad hoc unstructured data models": 0.024104921462218928, "API etc Design": 0.023674364715064705, "technical data role": 0.10007888998985862, "good data governance": 0.09677327801692917, "Unstructured data experience": 0.09559788465449992, "Implement meta data solutions": 0.08934870953645419, "Microsoft business intelligence visualisation technologies": 0.07618073472156765, "knowledge share Quality control work Degree information technology": 0.07016335790047894, "Stakeholder management internal external Assist development others": 0.060959311398218224, "SSRS Power BI IT infrastructure e g storage networking servers": 0.056238394357191454, "team dynamics performance": 0.053837553960832826, "mathematics engineering actuarial science related discipline": 0.05377992673132049, "specifically personal unsecured loans Business process monitoring": 0.050328968801213445, "Quality Detail orientation": 0.04969722171793543, "availability accuracy Monitor": 0.0433181959339979, "SSRS Power BI": 0.04090385824105545, "Stakeholder": 0.029977429463297154, "Unstructured": 0.029974422990354674}, {"Excellent": 0.03697444860537496, "Expertise": 0.11955311289708823, "OOP": 0.036121531899433734, "401k": 0.04142113278476147, "Computer Science": 0.034889622497703804, "first": 0.037008835568776696, "BS MS": 0.02473509732105856, "frameworks": 0.06619817181334671, "Superb": 0.03847941195247442, "kitchen": 0.01966871067589916, "scalable data pipelines data processing frameworks": 0.13068187388296815, "Depth knowledge Data Operations Data Quality management space Experience layered geospatial data structures data representations": 0.10506497746361186, "modern cloud native processing frameworks": 0.10318082253979695, "high volume data processing organization business division": 0.10219207544685374, "computing frameworks geospatial processing indexing": 0.10023212669199427, "data quality management": 0.09840706398374821, "Expertise processing": 0.09408682729470308, "scalable cloud native backend compute capabilities REST APIs microservices": 0.08326533237996392, "distributed computing environment years": 0.08250189114014567, "Inspire": 0.07679679940567971}, {}, {}, {"hands": 0.05340362192227296, "skills": 0.05137380464184728, "Knowledge": 0.060423006384078284, "business": 0.049830863169296885, "data Experience": 0.09281031643333888, "third": 0.051514323538411504, "intellectual curiosity Show passion innovation continuous improvement initiate efforts": 0.09784392945256624, "Extensive experience relational database development": 0.09387955246708084, "Experience scripting automation language": 0.09280579589577627, "technical direction problem": 0.09043450972696875, "organisation best practice quality standards": 0.08793017508876348, "Ensure third party development": 0.08656987239370366, "exceptional problem": 0.08259616105282391, "Knowledge investment management": 0.08194957921732175, "support team": 0.08114841262999756, "Interest NoSQL database": 0.07940552468669598, "Embrace": 0.10460221107493325}, {}, {}, {"applicants": 0.10627528358029092, "Apple discriminate retaliate applicants inquire": 0.12009528598097688, "compensation applicants": 0.11753188448843288, "Apple": 0.07121267743018223, "multiple deadline specific projects": 0.08162747095808931, "functional team environment Apple Equal Opportunity Employer": 0.09423285587057326, "relationships Ability": 0.09275985588537539, "HTML CSS Javascript Strong interpersonal skills verbal written Ability": 0.09049752938567537, "day day business support": 0.08891525292557619, "directional changes ability": 0.08825784118123912, "Apple Equal Opportunity Employer": 0.08781034620277667, "similar Proficient data access preparation methods": 0.08181442033929165, "Proficient scripting glue languages": 0.07713597863064903, "data elements sources": 0.07615121489233179, "PHP Python web technologies": 0.074605705643951, "PHP": 0.10897176820239156}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"five years": 0.04983556081017372, "Minimum five years data analytics programming database administration data management experience": 0.2438102125077615}, {}, {"techniques": 0.1026632959065837, "Python SQL Elastic visualise data surfacing tool Experience developing machine learning systems Experience Amazon Quicksite advantage": 0.16381858214055792, "exploration visualisation Experience statistical models times": 0.14567631518082422, "Degree educated Data Science similar Strong experience data preparation techniques": 0.1326274753856413, "regression classification Strong skills": 0.13128364580746574, "Python SQL Elastic": 0.1165953955790625, "series analysis": 0.10501264228684692}, {"requisite skills": 0.20616239854731622, "less experience": 0.20564896932640234, "applications candidates": 0.1866146151190337, "The stated experience level guide": 0.12288654090869425}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {"Experience": 0.19725797261993172, "experience": 0.09862898630996586, "Broad": 0.04117478760904082, "Medical Health Insurance Onsite Wellness Clinic Long Term Disability Life Insurance Dental Vision Coverage": 0.11876575785054228, "cruises anniversary Medical Health Insurance Onsite Wellness Clinic Long Term Disability Life Insurance Dental Vision Coverage": 0.11561866185305845, "Legal Insurance": 0.11530223028072924, "K Plan Pet Care Insurance": 0.11503487834157274, "Data design experience Experience data cleansing optimization data consumption Experience source control tools Git TFS": 0.11356860203955775, "Consumer Websites Experience consumer facing": 0.10388458987438359, "data management systems": 0.08438112006662318, "Experience Azure Service Fabric": 0.08427996334437433, "Working familiarity front end web framework": 0.08236406530354042, "CSV JSON XML data formats": 0.07917391897925374, "Dedicated Employee Enrichment Recognition Programs": 0.07846703372727493, "mobile systems": 0.07531814145465768}, {"career categories": 0.4714045207910316}, {"career categories": 0.4714045207910316}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {"self": 0.08827521336499865, "new technologies": 0.1310658267708788, "perfect enemy": 0.14088837738788587, "display excellent judgment": 0.1460334946068168, "difficult tradeoffs": 0.1332988224175615, "new information": 0.1330580410187721}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"millions daily players": 0.3466800150008662, "millions daily": 0.27010136077940194, "cool people": 0.19667082547981898}, {}, {}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"Java Scala Python": 0.052085659802924726, "SQL": 0.07752168162629779, "requirements": 0.07510418158502098, "technologies": 0.22050685346219534, "data engineering tasks": 0.1400845271989995, "Expertise Hadoop related technologies": 0.13708406841235385, "large scale data warehousing mining analytic systems Ability work analysts": 0.13209322724280284, "Spark Streaming Spark SQL Map": 0.1297324401815479, "big data pipelines": 0.12905603876549493, "Azkaban Oozie Impala Hive Pig Expertise": 0.1260895166119866, "Proficiency data processing": 0.12095450545023395, "Map Reduce Expertise Hadoop": 0.11565073785622584, "Kafka Flume Storm Experience": 0.10976119585652011, "Spark Streaming": 0.10441602783796856, "Kafka Flume Storm": 0.10229045409018014, "HDFS Azkaban Oozie": 0.10219007970467098}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"data": 0.07087775606955203, "Experience": 0.08035810952465423, "deliverables": 0.07373981406795388, "broad variety audiences": 0.136966241524824, "complex technical concepts": 0.12834261956171472, "object oriented programming languages": 0.12397745123276696, "BS BA Technical Field Computer Science Mathematics Knowledge Python Java Experience": 0.10763178720300788, "BA Technical Field Computer Science Mathematics Knowledge Python": 0.09691763714744647, "SQL ETL": 0.09130859346643895, "MapReduce MPP": 0.08431994370536677}, {}, {"SQL": 0.0787220443487601, "Apache": 0.1198186856151709, "Large scale ETL Apache beam Apache spark High scale Restful Services Cloud experience": 0.18977044060485465, "B Tech Computer Science IT": 0.15764682239246702, "Google Cloud Platform Azure AWS": 0.15538998014619315, "ETL Apache": 0.13998913277292258, "SQL document stores": 0.12161325249200518, "BSc B": 0.12051812850237843, "Python Data": 0.09549394525315116}, {"Experience Azure Data Factory Data Bricks Data Lake": 0.40902533962167537, "Bricks Data Lake": 0.37243542102984023}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"Expertise": 0.05799671891915877, "NoSQL": 0.064422616308321, "ETL": 0.08653794105262937, "Hive Spark": 0.06150849672882408, "team environment": 0.08292055338522997, "solid understanding relational NoSQL database technologies Experience visualization data mining statistical tools": 0.14066382322141793, "massive complex datasets": 0.14041220866304713, "metrics statistical information": 0.12925107826495985, "familiar ETL tools": 0.12607359624827358, "robust data analytic pipelines": 0.12446032602150546, "Expertise various ETL technologies": 0.11989789672334838, "e g Python Scala comfortable developing code": 0.1112324154236448, "Solr Kafka": 0.09413845583201864, "e g Oozie Airflow": 0.08531458400313623, "Oozie Airflow Have": 0.08094722882502266}, {}, {}, {}, {"Java Python": 0.1290320136229521, "Desire": 0.1443775138903167, "relational data Postgres programming experience": 0.12136334235050526, "unstructured data APIs Experience ETL integration": 0.11923097987664825, "DMS Stitch Experience data analysis visualization tools Mode Working knowledge message": 0.11716846321342424, "tech debt Experience business operations tools": 0.11330050026738155, "technology landscape Experience AWS services": 0.107663816210816, "data science machine": 0.1030918509653616, "positive attitude empathy Self awareness desire": 0.09713632680965924, "Dog Friendly Office": 0.0928955052023868, "deep understanding data engineering concepts database": 0.08828668416926307, "Lambda DynamoDB etc Competitive salary Employee Stock Option Plan Generous health commuter benefits": 0.0787906137150222, "Advanced SQL knowledge": 0.07849836121334558}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"Hadoop Spark": 0.20868250707872482, "NoSQL": 0.07996032142202736, "Data": 0.10402556085411907, "ETL": 0.06554846453342558, "Big Data": 0.12118579291673472, "Java": 0.03506360677301925, "Informatica Talend Pentaho DataStage Experience interest Big Data technologies": 0.1522210157422785, "Azure Strong SQL experience": 0.15137278176524632, "Data security governance expertise": 0.15113759605568922}, {}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"large amounts": 0.1294251298029777, "Python": 0.03865641319910382, "analysis": 0.08359914759831753, "structured unstructured data Extensive AWS Experience": 0.19139645380973164, "Python preferred Experience designing data architecture ground Experience": 0.18157096827241986}, {}, {}, {}, {"Spark Hadoop": 0.12150866967339166, "working data systems years": 0.15567686152655805, "Spark Hadoop years": 0.15282459867884607}, {"Bachelor Degree": 0.11142023057975806, "Working": 0.06596853707382071, "MapReduce Spark": 0.09411322104692202, "Bachelor Degree computer science engineering mathematics related fields equivalent experience Expert SQL knowledge experience": 0.17497171454108826, "large datasets Masters Degree computer science engineering mathematics related fields equivalent experience": 0.17116601584592436, "large scale data warehouse platform Hands experience": 0.1547022116262329, "engineering experience years": 0.15260717055522227}, {}, {}, {"career categories": 0.4714045207910316}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {"career categories": 0.4714045207910316}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {"career categories": 0.4714045207910316}, {"Tableau": 0.2447441640848511, "Python C C Experience data visualization presentation": 0.201037192570378, "familiar data analysis tools": 0.17339202623504754, "large scale data": 0.16687902033312804}, {}, {}, {"At least years": 0.010738143368982706, "best practices": 0.043188478836426764, "Data": 0.20422774519201015, "Provide": 0.027471897962396852, "ETL": 0.02766795077765829, "ideas": 0.02983077240041819, "data pipelines": 0.09951412077786717, "Microsoft": 0.0739579137012215, "g": 0.037709161376624806, "real time": 0.061226537974961, "e": 0.04434373047854841, "data sources": 0.10833103324082717, "Design": 0.2381880611819147, "technologies": 0.051589874682063365, "Assist": 0.029112577828350066, "Manage": 0.05655225062071425, "data streaming Design": 0.11426671031143512, "data warehouse data models": 0.11532756122759574, "source data e g data profiling definition mapping Design": 0.10932946664291852, "efficient data loads": 0.1056208370808152, "unstructured data loads": 0.10322018203280173, "managing data": 0.09985557388912371, "traditional structured data ETL techniques Design": 0.09964272161053585, "technical data related support source system teams": 0.0972154153482658, "usability data": 0.09982859850715414, "real time data load solutions": 0.10010127204674811, "appropriate aggregation data structures": 0.0986889775814539, "troubleshoot technical data issues": 0.09594806343682549, "SQL Data analysis Data visualisation Data": 0.0949851035737128, "data management analytics": 0.09306414349161134, "effective efficient data models": 0.0929755134003854, "Microsoft business intelligence data technologies": 0.09806554101092776, "speed access Design": 0.0812062409051634, "data processes": 0.09326812278856712, "data elements": 0.08923726364080767, "Work source system owners analysts": 0.07797953136123277, "supplement enhance context Design": 0.07483621606954394, "interface monitoring management solutions": 0.07455651642271897, "solutions Positive engagement team activities": 0.06309559349198342, "data access e g batch exports": 0.0841139369988743, "Work analysts": 0.06944827440502596, "e g text speech images video Design": 0.07809801402626126, "ownership work": 0.06692821196105123, "business owners analysts": 0.06787659215473385, "load monitoring tools procedures": 0.0695358549968918, "high quality work time Show initiative": 0.06730654230933943, "real time decision": 0.0675632150658713, "Manage systems technology tools": 0.06281085576683419, "Information gathering problem analysis": 0.054265143218216794, "appropriate indexing tables": 0.0641290675146661, "SSAS SQL Server Data warehouse": 0.06053974574399368, "appropriate modelling techniques": 0.058199527772794066, "appropriate changes": 0.05354983683102944, "professional specialist technical expertise": 0.05679257592058184, "SQL Data": 0.05382831745333183, "skills knowledge application": 0.04696468137144062, "loads": 0.05502988446731909, "ownership career development": 0.05256383921013647, "continuous monitoring": 0.05527506391266071, "sources": 0.05268131909747703, "integrity existing environment": 0.053088590673675176, "automated decision": 0.04843690767783768, "value decision": 0.04757173527652384, "active finding opportunities": 0.04499027554962136, "effective strategies": 0.04427024575559782, "external parties": 0.04375310306537262, "Quality": 0.03712199965891115, "g multi dimensional OLAP structures summary tables": 0.04272349664258385, "Take": 0.03693110154227723, "interfaces": 0.03742843157223792, "Positive": 0.028459010751305934, "SSIS": 0.026386680168071795, "OLAP": 0.03341003575143006, "etc Design implement": 0.028086446193715472, "ad hoc unstructured data models": 0.024104921462218928, "API etc Design": 0.023674364715064705, "technical data role": 0.10007888998985862, "good data governance": 0.09677327801692917, "Unstructured data experience": 0.09559788465449992, "Implement meta data solutions": 0.08934870953645419, "Microsoft business intelligence visualisation technologies": 0.07618073472156765, "knowledge share Quality control work Degree information technology": 0.07016335790047894, "Stakeholder management internal external Assist development others": 0.060959311398218224, "SSRS Power BI IT infrastructure e g storage networking servers": 0.056238394357191454, "team dynamics performance": 0.053837553960832826, "mathematics engineering actuarial science related discipline": 0.05377992673132049, "specifically personal unsecured loans Business process monitoring": 0.050328968801213445, "Quality Detail orientation": 0.04969722171793543, "availability accuracy Monitor": 0.0433181959339979, "SSRS Power BI": 0.04090385824105545, "Stakeholder": 0.029977429463297154, "Unstructured": 0.029974422990354674}, {}, {"SQL": 0.1544164974611002, "BI": 0.047754489141275905, "Develop": 0.17240627031500227, "ETL": 0.04569919754775136, "data pipelines": 0.21062261009157013, "one programming languages": 0.040625641727760016, "Write": 0.06403287521541275, "schemas": 0.04602510079811948, "third": 0.04774583490561785, "data Optimize tune data warehouse query performance analytical workloads": 0.11612990831515296, "SQL Server Experience developing software code": 0.11165702141446558, "integrations BI tools third party productivity applications years engineering experience Expert SQL": 0.11100244401166783, "data warehouse structure table": 0.10960740060476303, "Python Java Scala Ruby Experience managing database data warehouse technologies bonus Redshift Snowflake Experience": 0.10618945432279257, "robust data": 0.10354845506364396, "resolve data quality issues": 0.10352315093738043, "Bonus Stitch Fivetran Matillion Understanding data analytics ecosystem": 0.10291489898440892, "data analysis Design": 0.10218959751772395, "visualization tools based requirements": 0.10133037296082091, "Business Intelligence tools": 0.10097082450040376, "ETL tools": 0.10033006010565265, "Spark Kafka AWS Glue Amazon Kinesis Sqoop Flume Flink Experience": 0.09688307673002862, "Bonus Looker Experience": 0.09334193908372415, "Snowflake Redshift PostgreSQL": 0.08660390587299582, "Bonus Stitch Fivetran Matillion Understanding": 0.08386143155739119, "Redshift Snowflake": 0.08349987740753534, "Snowflake Redshift": 0.08349987740753534, "Bonus Looker": 0.07307790417438763, "Kinesis Sqoop": 0.06608153091469407, "Business Intelligence": 0.06223616033090468, "Spark Kafka": 0.06215690553516344, "one relevant tools": 0.05354573836762207, "troubleshoot": 0.04880862160792828, "users": 0.04790624636457893, "Architect": 0.08272146771469116}, {"career categories": 0.4714045207910316}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {"career categories": 0.4714045207910316}, {"At least years": 0.010738143368982706, "best practices": 0.043188478836426764, "Data": 0.20422774519201015, "Provide": 0.027471897962396852, "ETL": 0.02766795077765829, "ideas": 0.02983077240041819, "data pipelines": 0.09951412077786717, "Microsoft": 0.0739579137012215, "g": 0.037709161376624806, "real time": 0.061226537974961, "e": 0.04434373047854841, "data sources": 0.10833103324082717, "Design": 0.2381880611819147, "technologies": 0.051589874682063365, "Assist": 0.029112577828350066, "Manage": 0.05655225062071425, "data streaming Design": 0.11426671031143512, "data warehouse data models": 0.11532756122759574, "source data e g data profiling definition mapping Design": 0.10932946664291852, "efficient data loads": 0.1056208370808152, "unstructured data loads": 0.10322018203280173, "managing data": 0.09985557388912371, "traditional structured data ETL techniques Design": 0.09964272161053585, "technical data related support source system teams": 0.0972154153482658, "usability data": 0.09982859850715414, "real time data load solutions": 0.10010127204674811, "appropriate aggregation data structures": 0.0986889775814539, "troubleshoot technical data issues": 0.09594806343682549, "SQL Data analysis Data visualisation Data": 0.0949851035737128, "data management analytics": 0.09306414349161134, "effective efficient data models": 0.0929755134003854, "Microsoft business intelligence data technologies": 0.09806554101092776, "speed access Design": 0.0812062409051634, "data processes": 0.09326812278856712, "data elements": 0.08923726364080767, "Work source system owners analysts": 0.07797953136123277, "supplement enhance context Design": 0.07483621606954394, "interface monitoring management solutions": 0.07455651642271897, "solutions Positive engagement team activities": 0.06309559349198342, "data access e g batch exports": 0.0841139369988743, "Work analysts": 0.06944827440502596, "e g text speech images video Design": 0.07809801402626126, "ownership work": 0.06692821196105123, "business owners analysts": 0.06787659215473385, "load monitoring tools procedures": 0.0695358549968918, "high quality work time Show initiative": 0.06730654230933943, "real time decision": 0.0675632150658713, "Manage systems technology tools": 0.06281085576683419, "Information gathering problem analysis": 0.054265143218216794, "appropriate indexing tables": 0.0641290675146661, "SSAS SQL Server Data warehouse": 0.06053974574399368, "appropriate modelling techniques": 0.058199527772794066, "appropriate changes": 0.05354983683102944, "professional specialist technical expertise": 0.05679257592058184, "SQL Data": 0.05382831745333183, "skills knowledge application": 0.04696468137144062, "loads": 0.05502988446731909, "ownership career development": 0.05256383921013647, "continuous monitoring": 0.05527506391266071, "sources": 0.05268131909747703, "integrity existing environment": 0.053088590673675176, "automated decision": 0.04843690767783768, "value decision": 0.04757173527652384, "active finding opportunities": 0.04499027554962136, "effective strategies": 0.04427024575559782, "external parties": 0.04375310306537262, "Quality": 0.03712199965891115, "g multi dimensional OLAP structures summary tables": 0.04272349664258385, "Take": 0.03693110154227723, "interfaces": 0.03742843157223792, "Positive": 0.028459010751305934, "SSIS": 0.026386680168071795, "OLAP": 0.03341003575143006, "etc Design implement": 0.028086446193715472, "ad hoc unstructured data models": 0.024104921462218928, "API etc Design": 0.023674364715064705, "technical data role": 0.10007888998985862, "good data governance": 0.09677327801692917, "Unstructured data experience": 0.09559788465449992, "Implement meta data solutions": 0.08934870953645419, "Microsoft business intelligence visualisation technologies": 0.07618073472156765, "knowledge share Quality control work Degree information technology": 0.07016335790047894, "Stakeholder management internal external Assist development others": 0.060959311398218224, "SSRS Power BI IT infrastructure e g storage networking servers": 0.056238394357191454, "team dynamics performance": 0.053837553960832826, "mathematics engineering actuarial science related discipline": 0.05377992673132049, "specifically personal unsecured loans Business process monitoring": 0.050328968801213445, "Quality Detail orientation": 0.04969722171793543, "availability accuracy Monitor": 0.0433181959339979, "SSRS Power BI": 0.04090385824105545, "Stakeholder": 0.029977429463297154, "Unstructured": 0.029974422990354674}, {"SQL": 0.1544164974611002, "BI": 0.047754489141275905, "Develop": 0.17240627031500227, "ETL": 0.04569919754775136, "data pipelines": 0.21062261009157013, "one programming languages": 0.040625641727760016, "Write": 0.06403287521541275, "schemas": 0.04602510079811948, "third": 0.04774583490561785, "data Optimize tune data warehouse query performance analytical workloads": 0.11612990831515296, "SQL Server Experience developing software code": 0.11165702141446558, "integrations BI tools third party productivity applications years engineering experience Expert SQL": 0.11100244401166783, "data warehouse structure table": 0.10960740060476303, "Python Java Scala Ruby Experience managing database data warehouse technologies bonus Redshift Snowflake Experience": 0.10618945432279257, "robust data": 0.10354845506364396, "resolve data quality issues": 0.10352315093738043, "Bonus Stitch Fivetran Matillion Understanding data analytics ecosystem": 0.10291489898440892, "data analysis Design": 0.10218959751772395, "visualization tools based requirements": 0.10133037296082091, "Business Intelligence tools": 0.10097082450040376, "ETL tools": 0.10033006010565265, "Spark Kafka AWS Glue Amazon Kinesis Sqoop Flume Flink Experience": 0.09688307673002862, "Bonus Looker Experience": 0.09334193908372415, "Snowflake Redshift PostgreSQL": 0.08660390587299582, "Bonus Stitch Fivetran Matillion Understanding": 0.08386143155739119, "Redshift Snowflake": 0.08349987740753534, "Snowflake Redshift": 0.08349987740753534, "Bonus Looker": 0.07307790417438763, "Kinesis Sqoop": 0.06608153091469407, "Business Intelligence": 0.06223616033090468, "Spark Kafka": 0.06215690553516344, "one relevant tools": 0.05354573836762207, "troubleshoot": 0.04880862160792828, "users": 0.04790624636457893, "Architect": 0.08272146771469116}, {}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {}, {"Comfortable": 0.07243614432955463}, {}, {}, {"Proficiency": 0.05991459738095805, "hands": 0.05969406811836595, "skills": 0.04790191286586954, "industry experience": 0.10136193629811344, "least one high level programming language": 0.04668952447956812, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12596619567385442, "Experience building stream processing applications": 0.1047481121348821, "Python Go Java Scala": 0.09801295791039491, "massive petabyte scale semi structured datasets": 0.09071330029105461, "Apache Flink": 0.10174413157435054, "data technologies": 0.0759746492440442, "self awareness": 0.06031902465364336, "large complex highly dimensional data": 0.060221221178349764, "Extras": 0.09794674474372529, "perfect enemy": 0.04609939617505576, "You curious excellent analytical problem": 0.04250166224103968}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {"hands": 0.06237573252711118, "skills": 0.050335795126990025, "industry experience": 0.1060824139606841, "least one high level programming language": 0.06977125418721569, "Apache Flink Spark Streaming Apache Storm Kafka Streams others": 0.12600235689663492, "Experience building stream processing applications": 0.10968396974963136, "Python Go Java Scala": 0.10130415761122713, "massive petabyte scale semi structured datasets": 0.0953233099374448, "Apache Flink": 0.09339785463947714, "data technologies": 0.07968178908266287, "growth mindset": 0.06521775939973133, "self awareness": 0.06338372410400049, "large complex highly dimensional data": 0.06277799377364766, "Extras": 0.1029236643975937, "perfect enemy": 0.04844081964461941, "You curious excellent analytical problem": 0.04466080089380166}, {}, {"career categories": 0.4714045207910316}, {"Agile Engineering Kanban Lean Hybrid agile experience": 0.2800280856177859}, {}, {}, {}, {"position": 0.050648711774636215, "new technologies": 0.07047375804849113, "unstructured data": 0.12116925340191248, "MPP": 0.0480055596343536}, {}, {"data": 0.09402395012693654, "Design": 0.04084105634566445, "Statistics Information Systems": 0.1487044366120407, "BA BS Degree Computer Science Engineering": 0.16349847185908162, "another quantitative field": 0.07093824156409728, "online caches real time systems BA BS Degree Computer Science Engineering discipline Statistics Information Systems": 0.17693863646805866, "Data Warehouse": 0.22345396364886344}, {}, {}, {"results": 0.056235635050732855, "Agile": 0.07244839814652522, "Ability work": 0.07345894863224772, "ETL": 0.053577810749142175, "Kafka": 0.05246238388917232, "Embrace": 0.054529540385528354}, {"Travel": 0.5}, {}, {}, {}, {"At least years": 0.042660140881312154, "Complex": 0.027687093954137564, "Data": 0.20859395057172617, "Provide": 0.026935725402768715, "ETL": 0.02723716105228059, "ideas": 0.02832301698082865, "data pipelines": 0.10136993226230945, "Microsoft": 0.02788640394746022, "g": 0.03496997849555885, "real time": 0.059166709200366326, "e": 0.03459736580357689, "data sources": 0.10919033453061855, "Design": 0.3484350681629307, "technologies": 0.046018896166138155, "Assist": 0.028032358232169804, "Manage": 0.10968807353134477, "data streaming Design": 0.11977400036371816, "data warehouse data models": 0.10785041660207487, "source data e g data profiling definition mapping Design": 0.10762239812090121, "data Manage data growth usage": 0.10735334688621762, "data monitoring solutions procedures": 0.10667696671102622, "efficient data loads": 0.10616599878978636, "good data governance Work": 0.10404935934661055, "unstructured data loads": 0.10394990216074276, "functional data team knowledge gathering": 0.103794835432205, "managing data": 0.10373091496672956, "traditional structured data ETL techniques Design": 0.10349245473221372, "technical data related support source system teams": 0.10291117294615235, "usability data": 0.10151106479628316, "real time data load solutions": 0.09851208883259796, "appropriate aggregation data structures": 0.09845998434762333, "changes data organisation": 0.0980513399810516, "troubleshoot technical data issues": 0.09630132893207254, "working data business intelligence analytics environment": 0.0961598170636963, "SQL Data analysis Data visualisation Data": 0.09434390101081226, "data management analytics": 0.09267718715400096, "meta data solutions": 0.09265251495619113, "team dynamics performance Complex solution service design implementation": 0.09006551402872655, "effective efficient data models": 0.08857633555927515, "Microsoft business intelligence data technologies": 0.08833896751259532, "speed access Design": 0.08591180763769243, "data processes": 0.08466318797040909, "data elements": 0.08410624974886913, "Work source system owners analysts": 0.08354788427726087, "availability accuracy Design": 0.08253762158438192, "Responsible team activities team dynamics performance Manage project task delivery team": 0.08148632703391528, "supplement enhance context Design": 0.07966016182077537, "interface monitoring management solutions": 0.07791172324426537, "solutions Positive engagement team activities": 0.07768930602185288, "data access e g batch exports": 0.07746351791635504, "Work analysts": 0.07461102723390724, "e g text speech images video Design": 0.07429922829406735, "knowledge share Quality control work Degree information technology engineering mathematics statistics actuarial related discipline": 0.06996202632489378, "ownership work": 0.06935195328441357, "business owners analysts": 0.13833003502811306, "load monitoring tools procedures": 0.06854156954219583, "high quality work time Show initiative": 0.06777706592837883, "system infrastructure management": 0.06652516243043535, "real time decision": 0.06538084348165632, "Manage systems technology tools": 0.06517978097414644, "Information gathering problem analysis": 0.06137782200834538, "appropriate indexing tables": 0.06046208404613174, "SSAS SQL Server Data warehouse": 0.05757885972719333, "Presenting Communicating information": 0.05660196137859942, "appropriate modelling techniques": 0.056588219820686424, "appropriate changes": 0.05605997116169901, "internal external Assist development others": 0.055312379432028984, "professional specialist technical expertise": 0.05497870843644437, "Multiple stakeholder management": 0.05490536598317708, "SQL Data": 0.05340953852252053, "skills knowledge application": 0.053361408949206345, "loads": 0.05304390246469944, "ownership career development": 0.052686417337748155, "Quality Detail orientation Planning": 0.05172816973146134, "continuous monitoring": 0.05143841047515044, "sources": 0.050348646908253664, "integrity existing environment": 0.049950826370128903, "IT infrastructure IT Operations": 0.049082846992024275, "Analysing Leadership": 0.04797071706239034, "automated decision": 0.04709156740992211, "value decision": 0.046306019851437535, "active finding opportunities": 0.044154371019275926, "effective strategies": 0.04289335623470404, "Presenting Communicating": 0.042246687368454994, "external parties": 0.04224181518884275, "Quality": 0.03793417854974236, "g multi dimensional OLAP structures summary tables": 0.03675811259096596, "Take": 0.03643944234183073, "interfaces": 0.036168632677745845, "Cross": 0.056320866078397196, "Positive": 0.028006600616488183, "SSIS": 0.02656662322977185, "OLAP": 0.026319599748848507, "etc Design implement": 0.026160022990063658, "ad hoc unstructured data models": 0.023579620407417536, "API etc Design": 0.022370286165731158}, {}, {}, {"product managers": 0.16128379896487982, "sit shoulder shoulder": 0.2521062200211917, "challenging encouraging": 0.22509652287488446}, {}, {}, {"Hadoop Spark": 0.054629355319978215, "Experience": 0.1704276765401511, "SQL": 0.11939258299263185, "relational databases": 0.06525550238775799, "metadata": 0.041684780772508735, "opportunities": 0.044161384420775766, "data pipelines": 0.10164345625708644, "Kafka": 0.041552228004790644, "data transformation data structures metadata dependency workload management": 0.1079508905580439, "working familiarity variety": 0.07871957895613933, "NoSQL databases": 0.04398961144110323, "New Hire Orientation": 0.15092983266980362}, {}, {"401k": 0.14611435298174952, "Robust Perks generous PTO 401k contributions tuition assistance entertainment discounts": 0.28747978728803447}, {}, {}, {}, {"hours": 0.139944443674921, "company": 0.1336846966943919, "massage volunteer opportunities": 0.18875255544797798, "Vibrancy Wellness Program Yoga fitness classes": 0.15576784338299685}, {}, {}, {"English": 0.028052097530367238, "NoSQL": 0.035383593663943315, "experience": 0.0787882758016377, "relational databases": 0.06266027119794312, "complex concepts": 0.04333169349671849, "Java Python": 0.0585850926056999, "Communication": 0.0346965688614931, "employee coverage": 0.14940716080804645, "monthly": 0.16025646241133118}, {}, {}, {}, {}, {"healthy food utmost convenience": 0.29013041626376423, "market boundaries": 0.18646369080383335, "phenomenal team individuals": 0.1594336685563522}, {"Previously healthcare experience": 0.17304816931866904}, {}, {}, {}, {}, {"Hadoop": 0.05444852427499116, "NoSQL": 0.028763332994063234, "technologies": 0.08256371433786493, "g Storm Spark Streaming ETL tools": 0.12883243709591094, "sensitive available time resource constraints": 0.12600825429054144, "g Cassandra MongoDB Stream processing systems": 0.12552281916608218, "g MapReduce Hive Pig SQL": 0.12469361415616351, "Hadoop based technologies": 0.1105150061121642, "data storage retrieval specific use cases": 0.09230063221826684, "Cloud computing architectures": 0.08565347392632462, "NoSQL technologies": 0.08243028704543509, "Legacy modern database": 0.07130598857445816}, {}, {"Ability": 0.08635611193508383, "analytical techniques": 0.07700748396895254, "Working": 0.06195041527564543, "user defined functions table functions": 0.20330731714504, "career growth": 0.20829848016563715}, {"problems": 0.29499743629328806, "smart people": 0.24920231342436183}, {}, {"Data Platform Administration Engineering": 0.5802608325275285, "Bachelor Degree Computer Science related field years": 0.2049910260541008, "Bachelor Degree Computer Science": 0.16121851462217482}, {"Strong knowledge": 0.04031313251834863, "Career": 0.13581596199111273}, {}, {}, {"Git": 0.048983071868060384, "Background": 0.04857120072870351, "ETL": 0.04973382297351446, "Big Data": 0.05362293017243862}, {"large complex data sets": 0.33583601410541436, "Excellent understanding manipulation analysis": 0.21728822248292234}, {}, {}, {}, {"modern tech tools hi tech equipment": 0.39760980352123837}, {}, {"extra cash pocket": 0.28975208664196556, "opportunity work friends": 0.22736418796824281}, {"A commitment open inclusive diverse work culture": 0.24748737341529156}, {"Ability": 0.05456696166088762, "data": 0.07816464228548284, "English": 0.02711909675111341, "NoSQL": 0.03959709026692548, "Knowledge": 0.05139307795126172, "Hands": 0.1039316260134437, "ETL": 0.0403188807483822, "Kafka": 0.03918776903935639, "Java Python": 0.043188647707625955, "Willingness": 0.040547020050187156, "MPP": 0.02991055055938255}, {}, {}, {}, {"NoSQL": 0.0908776425236755, "ETL": 0.04227944646300601, "Kafka": 0.05929796462780854, "Microsoft": 0.11739437426699534, "Data Warehouse": 0.12613584591107996, "Data Warehouse Big Data": 0.15382634110912774, "SQL Data Warehouse Data Catalog Azure Analysis Services Data Bricks Storage Account": 0.14874651903173372, "SQL Server preferable multi dimensional Data Warehousing environment": 0.12190169433504865, "Data Warehousing": 0.12136071505925694, "Enterprise Data Analytics solution architecture years": 0.12019996088039404, "SQL Programming PL SQL": 0.11643973161431112, "Python SQL Strong": 0.1123447423122215, "SQL Programming PL SQL T": 0.11167564450294314, "Spark Pyspark Python Scala Pig Experience Big Data Management BDM relational non relational data formats": 0.10601221067591049, "Python SQL Strong analytical abilities": 0.10582074926077453, "Microsoft SQL Server preferable expert MDX DAX": 0.10351734751425114, "Azure": 0.10049244589293702, "SQL U": 0.10044871431001563, "mobile solutions years": 0.09550432117633947, "Power BI": 0.057652092825513895}, {}, {"Ability": 0.0348994061728761, "Map Reduce": 0.11346760656465628, "frameworks": 0.06931470047075208, "Hive Hadoop": 0.09650842973532756}, {"Hackathons": 0.5}, {}, {}, {}, {"Degree": 0.05318590403800622, "best practices": 0.058072331885699505, "product": 0.09709932429259219, "Familiarity": 0.06027369111285709, "features": 0.06316594665977965, "clients": 0.04604892831700494, "Designing": 0.09402039056903509, "initiative": 0.02751325758483261}, {}, {}, {}, {"Hadoop": 0.054168790950334035, "ability": 0.05645706649246594, "new technologies": 0.09324709321267485}, {}, {}, {}, {}, {}, {}, {}, {"metrics consumers": 0.33223519667364926, "Work data science teams": 0.2396672665936658}, {}, {}, {"PhD": 0.015657485489300026, "Proven": 0.037168047566813266, "industry": 0.026556812841401933, "Bachelor": 0.02981833495646361, "Knowledge": 0.06887861948570503, "SAS": 0.03490518779561408, "Demonstrated ability": 0.07204416074916611, "databases": 0.04434001392424178, "MS Office": 0.04415975830330694, "data management": 0.10386037828445906, "data curation management strategies": 0.09916762279950783, "laboratory research data management processes procedures": 0.0979248110624153, "biomedical data management data engineering quality assurance": 0.09653037243945774, "Excellent skills R programming experience": 0.08995165241711026, "development specimen data management related discipline Demonstrated proficiency molecular biology concepts ability support": 0.0866231320711355, "systematic relational approaches data integration data processing": 0.08657321485817025, "Detailed knowledge experience case report form design central laboratories": 0.08555525129069763, "Working knowledge Windows Linux operating systems": 0.07930739512509673, "query resolution data validation Computer": 0.07930613199932413, "SAS data": 0.0789791872186566, "detailed knowledge": 0.07877595987630434, "action patient response Proven ability work team environment clinical personnel study monitors": 0.07497766915302098, "strong capacity independent thinking ability": 0.07479769972118791, "Oracle Clinical Clintrial preferred experience": 0.07049808541846941, "Strong understanding LIMS systems": 0.06933150530768822, "Java C C Extensive practical experience": 0.0678126979098773, "database design implementation": 0.06749013287400088, "complex dynamic environment": 0.0665387284738052, "Along programming proficiency": 0.06611941054863452, "least one data management system": 0.06518638553150892, "additional computer languages": 0.06488396065980373, "high level scientific datasets": 0.06436522695691639, "medical writers": 0.06194339016527439, "organizational skills": 0.061419443520661074, "direct assess implementation": 0.058702628719473855, "computational biologists biostatisticians": 0.05616093005712433, "Familiarity Amazon Web Services": 0.055798781228787266, "research hypotheses": 0.054822371566036435, "underlying biological questions": 0.05342019501736756, "query interfaces": 0.05341570247007896, "diverse highly connected scientific knowledge collections": 0.051421808052233425, "Perl Python PHP S": 0.06158759542410408}, {"AWS": 0.07237364760153303, "Python": 0.07145856092535248, "ML": 0.07840851755317864, "work": 0.07466300525589842}, {"PhD": 0.015657485489300026, "Proven": 0.037168047566813266, "industry": 0.026556812841401933, "Bachelor": 0.02981833495646361, "Knowledge": 0.06887861948570503, "SAS": 0.03490518779561408, "Demonstrated ability": 0.07204416074916611, "databases": 0.04434001392424178, "MS Office": 0.04415975830330694, "data management": 0.10386037828445906, "data curation management strategies": 0.09916762279950783, "laboratory research data management processes procedures": 0.0979248110624153, "biomedical data management data engineering quality assurance": 0.09653037243945774, "Excellent skills R programming experience": 0.08995165241711026, "development specimen data management related discipline Demonstrated proficiency molecular biology concepts ability support": 0.0866231320711355, "systematic relational approaches data integration data processing": 0.08657321485817025, "Detailed knowledge experience case report form design central laboratories": 0.08555525129069763, "Working knowledge Windows Linux operating systems": 0.07930739512509673, "query resolution data validation Computer": 0.07930613199932413, "SAS data": 0.0789791872186566, "detailed knowledge": 0.07877595987630434, "action patient response Proven ability work team environment clinical personnel study monitors": 0.07497766915302098, "strong capacity independent thinking ability": 0.07479769972118791, "Oracle Clinical Clintrial preferred experience": 0.07049808541846941, "Strong understanding LIMS systems": 0.06933150530768822, "Java C C Extensive practical experience": 0.0678126979098773, "database design implementation": 0.06749013287400088, "complex dynamic environment": 0.0665387284738052, "Along programming proficiency": 0.06611941054863452, "least one data management system": 0.06518638553150892, "additional computer languages": 0.06488396065980373, "high level scientific datasets": 0.06436522695691639, "medical writers": 0.06194339016527439, "organizational skills": 0.061419443520661074, "direct assess implementation": 0.058702628719473855, "computational biologists biostatisticians": 0.05616093005712433, "Familiarity Amazon Web Services": 0.055798781228787266, "research hypotheses": 0.054822371566036435, "underlying biological questions": 0.05342019501736756, "query interfaces": 0.05341570247007896, "diverse highly connected scientific knowledge collections": 0.051421808052233425, "Perl Python PHP S": 0.06158759542410408}, {"multiple data sources": 0.39093127217386187, "Experience integration data": 0.3061197055953717}, {"Enriched Tuition reimbursement training learning programs": 0.18687053861954167}, {}, {}, {}, {"Hadoop": 0.023594100680872275, "hands": 0.043325438873257814, "Java": 0.023594100680872275, "Fluency": 0.04558567923415252, "Desire": 0.10778437225100476, "third": 0.0536154445521949, "open source tools": 0.07986194387447319, "PHP": 0.054143611446720245}, {}, {}, {"NoSQL": 0.0908776425236755, "ETL": 0.04227944646300601, "Kafka": 0.05929796462780854, "Microsoft": 0.11739437426699534, "Data Warehouse": 0.12613584591107996, "Data Warehouse Big Data": 0.15382634110912774, "SQL Data Warehouse Data Catalog Azure Analysis Services Data Bricks Storage Account": 0.14874651903173372, "SQL Server preferable multi dimensional Data Warehousing environment": 0.12190169433504865, "Data Warehousing": 0.12136071505925694, "Enterprise Data Analytics solution architecture years": 0.12019996088039404, "SQL Programming PL SQL": 0.11643973161431112, "Python SQL Strong": 0.1123447423122215, "SQL Programming PL SQL T": 0.11167564450294314, "Spark Pyspark Python Scala Pig Experience Big Data Management BDM relational non relational data formats": 0.10601221067591049, "Python SQL Strong analytical abilities": 0.10582074926077453, "Microsoft SQL Server preferable expert MDX DAX": 0.10351734751425114, "Azure": 0.10049244589293702, "SQL U": 0.10044871431001563, "mobile solutions years": 0.09550432117633947, "Power BI": 0.057652092825513895}, {}, {"PhD": 0.015657485489300026, "Proven": 0.037168047566813266, "industry": 0.026556812841401933, "Bachelor": 0.02981833495646361, "Knowledge": 0.06887861948570503, "SAS": 0.03490518779561408, "Demonstrated ability": 0.07204416074916611, "databases": 0.04434001392424178, "MS Office": 0.04415975830330694, "data management": 0.10386037828445906, "data curation management strategies": 0.09916762279950783, "laboratory research data management processes procedures": 0.0979248110624153, "biomedical data management data engineering quality assurance": 0.09653037243945774, "Excellent skills R programming experience": 0.08995165241711026, "development specimen data management related discipline Demonstrated proficiency molecular biology concepts ability support": 0.0866231320711355, "systematic relational approaches data integration data processing": 0.08657321485817025, "Detailed knowledge experience case report form design central laboratories": 0.08555525129069763, "Working knowledge Windows Linux operating systems": 0.07930739512509673, "query resolution data validation Computer": 0.07930613199932413, "SAS data": 0.0789791872186566, "detailed knowledge": 0.07877595987630434, "action patient response Proven ability work team environment clinical personnel study monitors": 0.07497766915302098, "strong capacity independent thinking ability": 0.07479769972118791, "Oracle Clinical Clintrial preferred experience": 0.07049808541846941, "Strong understanding LIMS systems": 0.06933150530768822, "Java C C Extensive practical experience": 0.0678126979098773, "database design implementation": 0.06749013287400088, "complex dynamic environment": 0.0665387284738052, "Along programming proficiency": 0.06611941054863452, "least one data management system": 0.06518638553150892, "additional computer languages": 0.06488396065980373, "high level scientific datasets": 0.06436522695691639, "medical writers": 0.06194339016527439, "organizational skills": 0.061419443520661074, "direct assess implementation": 0.058702628719473855, "computational biologists biostatisticians": 0.05616093005712433, "Familiarity Amazon Web Services": 0.055798781228787266, "research hypotheses": 0.054822371566036435, "underlying biological questions": 0.05342019501736756, "query interfaces": 0.05341570247007896, "diverse highly connected scientific knowledge collections": 0.051421808052233425, "Perl Python PHP S": 0.06158759542410408}, {}, {}, {}, {}, {}, {}, {}, {}, {"Tableau": 0.06999962213857526, "data": 0.09309979546227812, "Experience": 0.05315368285303229, "Bachelor Degree": 0.03227478876742519, "ability": 0.05849596880572209, "SQL": 0.027524125726890447, "Experience Python": 0.03775433277524427, "Proven": 0.02845671830289314, "hours": 0.027976768814738852, "Hands": 0.0530572938343258, "401k": 0.026618517468404358, "Strong analytical problem": 0.04416525821538819, "Microsoft": 0.023383069335111657, "Create": 0.0, "daily": 0.025821139531563196, "initiative": 0.027985939961385084, "multiple tasks": 0.052055697184874, "Data Engineering": 0.06451892208772514}, {"projects": 0.19815879675328218, "multiple partners": 0.3498759579292246, "Track record": 0.19418352986099446}, {}, {}, {}, {"Knowledge sharing activities": 0.43301270189221913}, {"Hadoop Spark": 0.07517314076998224, "data": 0.06880392750423811, "new technologies": 0.08474765074738755, "collaborative environment": 0.08485406950575508, "business": 0.042734503861994, "Scala Java": 0.07453710967576939, "preferred Data modeling experience": 0.12216490597570924}, {"Bachelor degree": 0.03294966328625932, "PhD": 0.05803275654773849, "AWS": 0.035890151877801875, "Agile": 0.015950238449129194, "Proven": 0.0353827899079486, "Knowledge": 0.07084620646811912, "Demonstrated ability": 0.0847445949900736, "Preference": 0.06848376256182162, "least years": 0.059245551739054575, "data curation management strategies": 0.0916853898225628, "laboratory research data management processes procedures": 0.08782824948127979, "Excellent skills R programming experience": 0.09157888554988676, "strong capacity independent thinking ability": 0.07871734109562929, "database design implementation": 0.06083030755119376, "complex dynamic environment": 0.06897281250990418, "Along programming proficiency": 0.07513700457906419, "additional computer languages": 0.06438012412205066, "high level scientific datasets": 0.06896094895584205, "medical writers": 0.0510132100796725, "direct assess implementation": 0.06275233207639427, "research hypotheses": 0.05768341231946573, "underlying biological questions": 0.05546477928024653, "query interfaces": 0.04696174395935266, "diverse highly connected scientific knowledge collections": 0.05351574911563475, "Perl Python PHP S": 0.0627396526668413}, {"Data": 0.06174220233909018, "ETL": 0.03457580209430124, "technologies": 0.06362114712956901, "Kafka Apache Spark": 0.08311937785982566, "advantageous Pair programming experience Scrum agile experience Kanban agile experience JIRA experience Release search applications cloud environment": 0.169916620633979, "Experience graph database": 0.15076914791486395, "Kafka Apache Spark Experience big data technologies Hadoop Kafka Akka Mesos": 0.13017654140787527, "highly desirable Experience Semantic Web RDF OWL SPARQL": 0.11163470685335324, "dev ops": 0.10363085896182385}, {}, {}, {"Ability": 0.0431071087689056, "Spark": 0.06183685341197904, "NoSQL": 0.09596939907595832, "ETL": 0.05184825122296049, "Big Data": 0.3597053188412481, "Kafka": 0.10274857525723534, "Experience Big Data ML": 0.11348201601141827, "Good knowledge Big Data querying tools": 0.11246135918885748, "Big Data ML": 0.11519664260077098, "Lambda Architecture": 0.1179362904747836, "advantages": 0.05787399426251423, "specific Big Data DevOps roles": 0.12108364118391396, "Most Big Data Engineers": 0.11329143908025392, "Machine Learning Big Data": 0.11152667202799516, "Machine Learning Big Data infrastructure": 0.10856545141988287, "Flume Experience various messaging systems": 0.10617142750165334}, {"algorithms": 0.05837597110404274, "SQL": 0.04775717231559948, "year": 0.08339782505959353, "Data": 0.06020079256501579, "GCP AWS Azure year experience": 0.13699243532987082, "Python Scala Golang R year experience provisioned demand cloud computing platforms": 0.1254420525051685, "computing fundamentals ability design scalability": 0.10338511316948835, "g Git Jira": 0.08931494176087737, "etc Knowledge": 0.08024103240665191, "Git Jira": 0.07935226538046274}, {}, {}, {"Data": 0.05115815691493654, "Strong knowledge": 0.12459417589367267, "information": 0.06287042871309624, "data pipelines": 0.12501865223931524, "databases": 0.07383914570775779, "least one scripting language": 0.021437244687663032, "data engineering": 0.12205035455175114, "year experience working data lake environment Experience collecting transforming": 0.1322153505950354, "working data engineering": 0.12434614423480325, "data pipelines machine": 0.12257758626678851, "large amounts data": 0.11840454760605743, "Bachelor degree experience": 0.11551900945507304, "year experience": 0.11380125699350808, "Java Python Knowledge Hadoop Spark big data processing frameworks": 0.10774802099970915, "Bachelor degree Master degree computer science field Computer Science Information Sciences Informatics Experience": 0.10757175308528029}, {}, {"Relevant degree work experience": 0.4}, {}, {}, {}, {"This full time exempt position": 0.2551551815399144}, {}, {}, {}, {}, {}, {"real world experience AWS EMR E2 Kinesis S3": 0.29479980173745224, "Bonus points": 0.12450281619874627}, {"Hadoop": 0.05910859223334058, "NoSQL": 0.03122516683251849, "Microsoft": 0.06131880634578647, "technologies": 0.08963192146233245, "g Storm Spark Streaming ETL tools": 0.13986353391734271, "sensitive available time resource constraints": 0.12870456207678407, "g Cassandra MongoDB Stream processing systems": 0.1362701580662209, "g MapReduce Hive Pig SQL": 0.13536988895161267, "Hadoop based technologies": 0.11997565582407727, "data storage retrieval specific use cases": 0.10020051891074737, "Cloud computing architectures": 0.09298438027041464, "NoSQL technologies": 0.08948689482574576, "Legacy modern database": 0.07740906017283969}, {"agile methodologies": 0.33223519667364926}, {}, {"ability": 0.0490585264699008, "others": 0.05993724561446161, "experience": 0.07464281899690703, "ETL": 0.09815139379979705, "data pipelines": 0.0809569527742073, "least one scripting language": 0.027590023871348086, "knowledge": 0.06738546176630583, "technologies": 0.06805426328136281, "Scala Java C": 0.20797941691547805}, {}, {}, {}, {}, {"Data serialization JSON avro parquet": 0.37267799624996495}, {"Building Cube Cube": 0.42007327207320844, "products": 0.33235585784531946}, {}, {}, {}, {}, {"Docker Apache Mesos Kubernetes": 0.35020975003718274, "Cluster managers eg Docker Apache Mesos Kubernetes": 0.3307189138830738}, {"401k": 0.18263162765420737, "401k retirement savings plan": 0.4}, {}, {}, {}, {}, {}, {"LA": 0.16061930593490664, "kitchen": 0.2660151285289207, "LA best restaurants": 0.258448099280998, "Daily catered lunches": 0.18968443873813}, {"profile": 0.3608563763907032, "Indemnity": 0.2222496308952425}, {"meet business processes priorities": 0.26402130893931103, "application enhancements": 0.16610922813886098, "3rd party vendors": 0.1499963630597183, "3rd party": 0.12728178540132457}, {}, {"Python": 0.07932156943844756, "Strong coding skills": 0.11358301833066464, "academic experience data engineering capacity Experience Docker Apache Spark ElasticSearch": 0.18105226622744613, "similar Hands experience": 0.16485386870388896, "queue technology Apache Kafka": 0.1477672566703813, "real time systems production stage years": 0.14724414596005891, "Excellent experience": 0.139825027346604, "Apache Kafka": 0.13597359756440502}, {"Google Analytics": 0.9428090415820632}, {}, {"Agile Scrum working practices": 0.4}, {}, {}, {"Spark": 0.13705169974643883, "problems": 0.06864129218169394, "Masters": 0.043758067084349025, "large data sets": 0.11530997322884548, "Masters degree years experience Experience proficiency Scala Experience proficiency": 0.17816088344728648, "interest applying scale Experience data cleaning preparation feature building selection techniques": 0.14871048382753108, "random effect models": 0.1323894597368409, "Effective communication interpersonal teamwork skills Ability": 0.12922528656774165}, {}, {}, {}, {"duties": 0.2653069489951205}, {}, {}, {}, {}, {}, {"Communicate": 0.082491384721719, "Information Technology experience": 0.1522572743825056, "years Information Technology experience Proficiency domain driven design domain modeling Experience NoSql solutions Gemfire Cassandra HBase": 0.15198243745717668, "CI CD tools": 0.14530301036766655, "Bachelor Degree years Information Technology experience": 0.1369179017013489, "MySQL SQL Server Oracle": 0.12913955168649477}, {}, {"US": 0.05973774913452062, "employees": 0.06152173537884112}, {}, {"English": 0.026558254931357776, "Java Scala": 0.08115315915890622, "NoSQL": 0.02729430849471219, "equity": 0.054205037325101894, "Extras": 0.06216559695024959}, {"A good understanding adherence data security standards": 0.24748737341529156}, {}, {}, {"SQL": 0.04657546964420337, "year": 0.12136705065855025, "years experience": 0.32450968447507667, "g Git Jira": 0.0683217307127203, "etc Knowledge": 0.07539616315559453, "Git Jira": 0.06422351371717651, "Python Golang Clojure R year experience provisioned demand cloud computing platforms GCP AWS Azure year experience": 0.1750624026113325}, {"Google Analytics": 0.9428090415820632}, {}, {}, {}, {}, {}, {}, {"data solutions AWS Experience building data vision strategy": 0.19013537452588347, "FinTech related area": 0.16897485425119663}, {}, {}, {}, {}, {}, {}, {}, {}, {"Chicago Top Company Culture Entrepreneur Top Workplace Chicago Tribune": 0.266809985091919, "Crain Chicago Business": 0.23295725700107855, "Best Consumer Web Company": 0.15773919093580982, "one Chicago Best Places Work Women": 0.15626353070323856, "Best Consumer": 0.14061437639929256}, {"Power BI": 0.3263027573257299}, {"Python": 0.07932156943844756, "Strong coding skills": 0.11358301833066464, "academic experience data engineering capacity Experience Docker Apache Spark ElasticSearch": 0.18105226622744613, "similar Hands experience": 0.16485386870388896, "queue technology Apache Kafka": 0.1477672566703813, "real time systems production stage years": 0.14724414596005891, "Excellent experience": 0.139825027346604, "Apache Kafka": 0.13597359756440502}, {"Experience HTTP REST SSL identity authentication": 0.34992710611188255}, {}, {}, {"data infrastructure cloud": 0.36432994274734615, "Comfortable building": 0.19418352986099446}, {}, {}, {"hours": 0.19676898110825397, "happy hours wind": 0.3179222345227429, "Spontaneous nerf gun wars": 0.19925608179072685, "Thursday": 0.33624459928872646}, {}, {"Excellent verbal written communication skills": 0.37267799624996495}, {"Years": 0.1796487613949784, "Java PHP Years database work mysql Postgres RedShift Experience": 0.14332420635301724, "Oriented Programming Python Java Database Technologies Redshift Postgres Spark Presto Amazon Web Services S3 SQS Kinesis ECS ECR EMR": 0.14161612397159756, "B S Computer Science Object": 0.2715207773002158}, {"Bachelor degree": 0.043995528396546135, "year": 0.09520327262650062, "relational databases": 0.11737904159475089, "ETL": 0.06783288534580414, "functional teams": 0.09994589589507448, "System availability Data Availability Data Quality": 0.16767511730825083, "SAP Data Services Talend": 0.15441623526012638, "SAP Data Services": 0.1534258056780586}, {}, {"Hadoop": 0.05368353985725349, "people": 0.054783451269846295, "ETL": 0.04913663225448611, "Microsoft Azure": 0.08431079516942044, "Microsoft": 0.05571715929686016, "Windows Linux": 0.07160713144031963, "MS SQL Server Strong programming experience": 0.12280292292682438}, {}, {}, {}, {"hard promote change industry": 0.2668791876143248, "Share success": 0.20745177879623483, "success": 0.201405874836723, "way": 0.19752221759144914}, {}, {"Google Analytics": 0.9428090415820632}, {"Experience": 0.10630632896790504, "ETL": 0.060544291138629094, "third": 0.08037787809572769, "Hive Hadoop": 0.12073966154098437, "RDS redshift S3 Experience consuming cleaning data third party APIs sources": 0.15912486899648629, "Hive Hadoop Spark": 0.151628352099855, "data Strong communication skills": 0.12759013214934853, "various AWS services": 0.1166561697933288}, {}, {}, {}, {"Inspire": 0.05869010457571941, "unlimited vacation k plan": 0.206501589067071, "benefits health vision life dental insurance": 0.19324732974665484, "cupcakes": 0.18132504449774048, "competitive compensation equity packages": 0.14041064090401453}, {}, {"A collaborative nature entrepreneurial spirit": 0.15288086229220466}, {}, {}, {}, {}, {}, {}, {"Software": 0.1232515731691127, "people": 0.05103718730029233, "OOP": 0.04548610967453731, "Develop": 0.07298220279724778, "Continuous": 0.12496734253931306, "Microsoft": 0.052336111528329565, "SVN C unit test strategy": 0.1267332446868575, "internal tools utilities Set unit test strategy": 0.23903939105397062, "revision control": 0.1647858453898881}, {}, {}, {}, {"Bachelor degree": 0.0606984884855417, "PhD": 0.10600094044895249, "Master degree": 0.07611059865228109, "Fluency": 0.055882346008177736, "verbal communication skills ability": 0.11155402506430179, "five years": 0.04005941170948063, "seven years": 0.04005941170948063, "Scala Java": 0.04367240614696084, "disk Experience Large Scale Big Data methods MapReduce Hadoop Spark Hive Impala Storm Strong": 0.12969484287639418}, {"Google Analytics": 0.9428090415820632}, {}, {}, {}, {}, {}, {}, {"Tableau": 0.08032175236865056, "tools": 0.08003624649534605, "automated reports data visualisation solutions": 0.15183137909670907, "modern data solutions": 0.14335444337582653, "Python applications data": 0.131109809335983, "SQL Comfort": 0.20724073749274}, {}, {"LI PA1": 0.9428090415820632}, {}, {"truly global company offices countries": 0.24249775370159418}, {"hours": 0.20543079036972156, "Ball games": 0.4440152067627612, "Monthly team": 0.15739762924864026}, {}, {}, {"Competitive": 0.05806246385252404, "Tableau": 0.05008459165016195, "At least years": 0.03508512740556967, "SQL": 0.08562997388973503, "Familiarity": 0.054981473785353396, "ETL": 0.05366146599896667, "Teradata Oracle MS SQL": 0.11519484798532283, "Teradata MS SQL": 0.2311173227856114, "SSRS": 0.05238701675479337}, {}], "meta": ["www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.nature.com", "www.nature.com", "www.linkedin.com", "www.linkedin.com", "www.google.com", "www.nature.com", "www.nature.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.nature.com", "www.linkedin.com", "www.google.com", "www.nature.com", "www.nature.com", "www.linkedin.com", "www.linkedin.com", "www.nature.com", "www.nature.com", "www.linkedin.com", "www.nature.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.nature.com", "www.nature.com", "bit.ly", "www.nature.com", "www.nature.com", "www.nature.com", "www.facebook.com", "www.linkedin.com", "www.google.com", "www.nature.com", "www.linkedin.com", "www.nature.com", "www.nature.com", "www.nature.com", "www.linkedin.com", "www.nature.com", "www.linkedin.com", "www.linkedin.com", "www.nature.com", "www.nature.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.nature.com", "www.linkedin.com", "www.nature.com", "www.nature.com", "www.linkedin.com", "www.nature.com", "www.google.com", "www.nature.com", "www.nature.com", "www.linkedin.com", "www.nature.com", "www.nature.com", "www.nature.com", "www.nature.com", "www.linkedin.com", "www.linkedin.com", "www.nature.com", "www.linkedin.com", "www.linkedin.com", "www.nature.com", "www.linkedin.com", "www.linkedin.com", "www.nature.com", "www.nature.com", "bit.ly", "www.linkedin.com", "www.nature.com", "www.nature.com", "www.nature.com", "www.nature.com", "www.linkedin.com", "www.nature.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.nature.com", "www.linkedin.com", "www.linkedin.com", "www.nature.com", "www.google.com", "www.mediabistro.com", "www.mediabistro.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.dlr.de", "www.glassdoor.com", "indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.accenture.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.verizon.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.glassdoor.com", "www.indeed.com", "www.dlr.de", "www.indeed.com", "www.indeed.com", "www.indeed.com", "stackoverflow.com", "www.indeed.com", "www.cc.gatech.edu", "www.quora.com", "www.indeed.com", "www.verizon.com", "www.quora.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.glassdoor.com", "www.indeed.com", "www.accenture.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.accenture.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.mediabistro.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "lists.demog.berkeley.edu", "www.usajobs.gov", "www.indeed.com", "www.usajobs.gov", "www.quora.com", "lists.demog.berkeley.edu", "www.indeed.com", "www.indeed.com", "www.ssrn.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.glassdoor.com", "www.indeed.com", "www.verizon.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.mediabistro.com", "www.quora.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.verizon.com", "cldb.ling.washington.edu", "www.indeed.com", "cldb.ling.washington.edu", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "stackoverflow.com", "www.usajobs.gov", "www.verizon.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "stackoverflow.com", "www.indeed.com", "www.quora.com", "www.mediabistro.com", "www.indeed.com", "www.indeed.com", "www.quora.com", "www.indeed.com", "www.glassdoor.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.glassdoor.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "cldb.ling.washington.edu", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "cldb.ling.washington.edu", "www.indeed.com", "www.accenture.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.glassdoor.com", "cldb.ling.washington.edu", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.glassdoor.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.quora.com", "stackoverflow.com", "www.accenture.com", "www.indeed.com", "www.llnl.gov", "www.indeed.com", "www.indeed.com", "www.indeed.com", "stackoverflow.com", "www.yelp.com", "www.indeed.com", "www.mediabistro.com", "www.indeed.com", "www.glassdoor.com", "www.airbnb.com", "www.indeed.com", "www.indeed.com", "www.mediabistro.com", "www.indeed.com", "www.indeed.com", "www.verizon.com", "www.indeed.com", "www.llnl.gov", "www.indeed.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.mckinsey.com", "www.indeed.com", "www.indeed.com", "www.quora.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.mediabistro.com", "www.indeed.com", "www.indeed.com", "lists.demog.berkeley.edu", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.verizon.com", "www.indeed.com", "www.indeed.com", "www.mediabistro.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.quora.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.quora.com", "www.llnl.gov", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.cc.gatech.edu", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.quora.com", "www.indeed.com", "www.quora.com", "www.indeed.com", "www.glassdoor.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "cldb.ling.washington.edu", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.verizon.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.cc.gatech.edu", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.quora.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.verizon.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.usajobs.gov", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.sitepoint.com", "www.verizon.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "stackoverflow.com", "www.indeed.com", "www.cc.gatech.edu", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.excite.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.mediabistro.com", "www.llnl.gov", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.llnl.gov", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.verizon.com", "indeed.com", "www.indeed.com", "www.indeed.com", "www.glassdoor.com", "www.indeed.com", "www.mediabistro.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.quora.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.meetup.com", "www.ucl.ac.uk", "www.indeed.com", "www.indeed.com", "www.indeed.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.verizon.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "lists.demog.berkeley.edu", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.glassdoor.com", "www.indeed.com", "www.indeed.com", "www.verizon.com", "www.indeed.com", "www.ucl.ac.uk", "www.indeed.com", "www.indeed.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "lists.demog.berkeley.edu", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.accenture.com", "www.indeed.com", "stackoverflow.com", "www.verizon.com", "www.indeed.com", "www.quora.com", "www.indeed.com", "www.quora.com", "www.indeed.com", "www.bath.ac.uk", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.sitepoint.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.quora.com", "www.monster.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.dlr.de", "www.indeed.com", "www.indeed.com", "www.indeed.com", "cldb.ling.washington.edu", "www.indeed.com", "www.indeed.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.mediabistro.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "japan.careers.vmware.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "indeed.com", "cldb.ling.washington.edu", "www.indeed.com", "www.indeed.com", "fr-jobs.about.ikea.com", "www.indeed.com", "www.indeed.com", "www.verizon.com", "www.mediabistro.com", "www.mediabistro.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "karriere.nzz.ch", "www.quora.com", "www.verizon.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.glassdoor.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.verizon.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.verizon.com", "www.indeed.com", "www.indeed.com", "cldb.ling.washington.edu", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.mediabistro.com", "www.indeed.com", "www.indeed.com", "www.indeed.com", "www.cc.gatech.edu", "www.indeed.com", "www.indeed.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "www.linkedin.com", "stackoverflow.com", "www.sitepoint.com", "www.verizon.com", "www.indeed.com", "stackoverflow.com", "stackoverflow.com", "www.indeed.com", "stackoverflow.com", "stackoverflow.com", "www.indeed.com", "japan.careers.vmware.com", "www.indeed.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "www.monster.com", "www.mediabistro.com", "www.sophos.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "www.sophos.com", "www.indeed.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "www.wix.com", "stackoverflow.com", "stackoverflow.com", "www.quora.com", "www.accenture.com", "www.cc.gatech.edu", "stackoverflow.com", "www.wix.com", "www.indeed.com", "www.indeed.com", "www.quora.com", "stackoverflow.com", "stackoverflow.com", "www.sophos.com", "stackoverflow.com", "www.sophos.com", "stackoverflow.com", "derstandard.at", "www.indeed.com", "stackoverflow.com", "www.sitepoint.com", "stackoverflow.com", "stackoverflow.com", "www.verizon.com", "www.indeed.com", "stackoverflow.com", "www.sophos.com", "www.glassdoor.com", "www.glassdoor.com", "nbacareers.nba.com", "stackoverflow.com", "stackoverflow.com", "www.indeed.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "www.indeed.com", "th-jobs.about.ikea.com", "stackoverflow.com", "www.sophos.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "www.indeed.com", "stackoverflow.com", "www.glassdoor.com", "stackoverflow.com", "stackoverflow.com", "www.accenture.com", "www.accenture.com", "stackoverflow.com", "www.quora.com", "stackoverflow.com", "stackoverflow.com", "www.indeed.com", "www.accenture.com", "stackoverflow.com", "stackoverflow.com", "www.indeed.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "japan.careers.vmware.com", "www.sophos.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.accenture.com", "www.wix.com", "www.glassdoor.com", "www.mediabistro.com", "japan.careers.vmware.com", "stackoverflow.com", "stackoverflow.com", "www.quora.com", "www.sitepoint.com", "www.sitepoint.com", "stackoverflow.com", "www.mediabistro.com", "www.indeed.com", "stackoverflow.com", "www.indeed.com", "stackoverflow.com", "stackoverflow.com", "remoteok.io", "stackoverflow.com", "stackoverflow.com", "www.indeed.com", "www.mediabistro.com", "www.sophos.com", "stackoverflow.com", "stackoverflow.com", "stackoverflow.com", "www.indeed.com", "www.sitepoint.com", "www.accenture.com", "www.verizon.com", "www.mediabistro.com", "stackoverflow.com", "www.indeed.com", "www.indeed.com", "www.wix.com", "www.indeed.com", "cldb.ling.washington.edu", "stackoverflow.com", "www.idealist.org", "stackoverflow.com", "stackoverflow.com", "www.indeed.com", "stackoverflow.com", "stackoverflow.com", "www.glassdoor.com", "stackoverflow.com", "www.cia.gov", "stackoverflow.com", "www.verizon.com", "dfwishiring.dallasnews.com", "stackoverflow.com", "stackoverflow.com", "www.indeed.com", "stackoverflow.com", "stackoverflow.com", "www.accenture.com", "stackoverflow.com", "www.indeed.com", "www.sophos.com", "www.indeed.com", "stackoverflow.com", "www.careercast.com", "www.biospace.com", "www.gfk.com", "www.geekwire.com", "www.snagajob.com", "zapier.com", "www.themuse.com", "www.gene.com", "www.governmentjobs.com", "www.internships.com", "www.kdnuggets.com", "www.standardmedia.co.ke", "www.themuse.com", "www.finn.no", "tweakers.net", "www.insurancejournal.com", "www.google.com", "www.timesofmalta.com", "www.snagajob.com", "www.cdp.net", "careers.allstate.com", "angel.co", "www.devex.com", "www.biospace.com", "www.insurancejournal.com", "www.biospace.com", "www.biospace.com", "www.f6s.com", "www.careercast.com", "www.careercast.com", "www.rigzone.com", "www.careerjet.com", "www.themuse.com", "www.careercast.com", "www.careercast.com", "www.snagajob.com", "www.devex.com", "www.careercast.com", "www.careercast.com", "usa.visa.com", "www.careercast.com", "www.internships.com", "www.f6s.com", "www.devex.com", "www.themuse.com", "www.devex.com", "in.linkedin.com", "www.biospace.com", "www.cio.com.au", "www.careercast.com", "www.geekwire.com", "www.biospace.com", "www.themuse.com", "www.insurancejournal.com", "feedproxy.google.com", "www.cdp.net", "www.careercast.com", "www.devex.com", "www.kdnuggets.com", "www.rigzone.com", "www.careercast.com", "hh.ru", "www.careercast.com", "www.careercast.com", "www.themuse.com", "www.careerjet.com", "www.airweb.org", "www.devex.com", "www.gene.com", "www.ziprecruiter.com", "slack.com", "www.biospace.com", "www.gene.com", "www.insurancejournal.com", "www.careercast.com", "www.careercast.com", "www.biospace.com", "feedproxy.google.com", "www.internships.com", "www.gene.com", "www.internships.com", "www.careercast.com", "www.geekwire.com", "www.biospace.com", "www.biospace.com", "www.cdp.net", "www.f6s.com", "www.careercast.com", "stripe.com", "www.insurancejournal.com", "www.devex.com", "www.biospace.com", "tweakers.net", "hh.ru", "www.insurancejournal.com", "elifesciences.org", "www.devex.com", "www.careercast.com", "www.devex.com", "angel.co", "www.careercast.com", "www.cdp.net", "www.rigzone.com", "angel.co", "www.careercast.com", "www.telekom.com", "angel.co", "www.insurancejournal.com", "www.themuse.com", "www.biospace.com", "www.themuse.com", "www.gene.com", "www.gene.com", "careers.trimble.com", "vtk.ugent.be", "www.f6s.com", "www.dice.com", "feedproxy.google.com", "www.cdp.net", "www.zynga.com", "www.avjobs.com", "newyork.craigslist.org", "www.reed.co.uk", "www.bizcommunity.com", "jobs.apple.com", "www.flexjobs.com", "www.reed.co.uk", "jobs.apple.com", "jobs.apple.com", "jobs.apple.com", "www.flexjobs.com", "www.latpro.com", "www.avjobs.com", "www.indeed.co.uk", "www.bizcommunity.com", "www.reed.co.uk", "www.shakeshack.com", "www.computerworld.dk", "www.reed.co.uk", "technical.ly", "www.indeed.co.uk", "www.reed.co.uk", "www.flexjobs.com", "www.reed.co.uk", "www.flexjobs.com", "jobs.apple.com", "www.careerjet.co.uk", "www.reed.co.uk", "www.reed.co.uk", "www.reed.co.uk", "www.ziprecruiter.com", "jobs.apple.com", "technical.ly", "www.reed.co.uk", "www.flexjobs.com", "www.bizcommunity.com", "www.reed.co.uk", "www.reed.co.uk", "www.flexjobs.com", "www.ziprecruiter.com", "www.careerjet.co.uk", "jobs.apple.com", "www.reed.co.uk", "jobs.apple.com", "jobs.apple.com", "www.avjobs.com", "technical.ly", "www.indeed.co.uk", "www.reed.co.uk", "www.smartrecruiters.com", "www.indeed.co.uk", "www.bizcommunity.com", "www.computerworld.co.nz", "www.reed.co.uk", "jobs.apple.com", "www.reed.co.uk", "www.avjobs.com", "jobs.apple.com", "jobs.apple.com", "www.ziprecruiter.com", "www.avjobs.com", "www.reed.co.uk", "www.flexjobs.com", "www.reed.co.uk", "www.nytco.com", "jobs.apple.com", "www.careerbliss.com", "www.reed.co.uk", "www.indeed.co.uk", "www.totaljobs.com", "www.reed.co.uk", "www.careerjet.co.uk", "www.indeed.co.uk", "www.reed.co.uk", "www.flexjobs.com", "www.reed.co.uk", "www.splunk.com", "jobs.apple.com", "www.flexjobs.com", "www.ziprecruiter.com", "jobs.apple.com", "www.reed.co.uk", "www.indeed.co.uk", "www.cs.mcgill.ca", "www.infomine.com", "www.ziprecruiter.com", "www.computerworld.co.nz", "www.reed.co.uk", "www.zynga.com", "www.reed.co.uk", "www.reed.co.uk", "www.gettinghired.com", "www.gettinghired.com", "www.avjobs.com", "www.gettinghired.com", "www.ziprecruiter.com", "www.indeed.co.uk", "optics.org", "jobs.apple.com", "jobs.apple.com", "www.ziprecruiter.com", "www.upwork.com", "www.gettinghired.com", "jobs.apple.com", "jobs.apple.com", "jobs.apple.com", "www.reed.co.uk", "www.cgi.com", "www.internweb.com", "jobs.apple.com", "www.ziprecruiter.com", "www.reed.co.uk", "jobs.apple.com", "jobs.apple.com", "jobs.apple.com", "jobs.apple.com", "jobs.apple.com", "www.indeed.co.uk", "www.flexjobs.com", "www.reed.co.uk", "www.ziprecruiter.com", "jobs.apple.com", "www.flexjobs.com", "www.ziprecruiter.com", "www.bizcommunity.com", "www.reed.co.uk", "www.reed.co.uk", "jobs.apple.com", "www.careerjet.co.uk", "hiring.monster.com", "www.reed.co.uk", "www.gettinghired.com", "www.ziprecruiter.com", "www.flexjobs.com", "www.indeed.co.uk", "www.avjobs.com", "seattle.craigslist.org", "jobs.apple.com", "jobs.apple.com", "www.flexjobs.com", "www.sportsbusinessdaily.com", "jobs.apple.com", "www.reed.co.uk", "www.bizcommunity.com", "jobs.apple.com", "jobs.apple.com", "www.reed.co.uk", "www.ziprecruiter.com", "theoceancleanup.com", "www.gettinghired.com", "www.reed.co.uk", "www.bizcommunity.com", "www.techworld.com.au", "www.avjobs.com", "www.techworld.com.au", "www.reed.co.uk", "jobs.apple.com", "www.computerworld.co.nz", "www.ziprecruiter.com", "www.infomine.com", "jobs.apple.com", "jobs.apple.com", "jobs.apple.com", "www.diglib.org", "www.ziprecruiter.com", "www.ziprecruiter.com", "www.careerjet.co.uk", "jobs.apple.com", "newyork.craigslist.org", "jobs.apple.com", "www.flexjobs.com", "www.careerjet.co.uk", "www.reed.co.uk", "www.reed.co.uk", "jobs.apple.com", "jobs.apple.com", "www.bizcommunity.com", "www.techworld.com.au", "www.avjobs.com", "www.indeed.co.uk", "www.reed.co.uk", "www.bizcommunity.com", "jobs.apple.com", "jobs.apple.com", "www.reed.co.uk", "www.reed.co.uk", "www.reed.co.uk", "www.ziprecruiter.com", "www.reed.co.uk", "jobs.apple.com", "www.flexjobs.com", "www.ziprecruiter.com", "jobs.apple.com", "jobs.apple.com", "technical.ly", "www.reed.co.uk", "www.gettinghired.com", "jobs.apple.com", "www.reed.co.uk", "www.careerjet.co.uk", "technical.ly", "jobs.apple.com", "www.reed.co.uk", "www.reed.co.uk", "www.reed.co.uk", "www.gettinghired.com", "jobs.apple.com", "careers.peopleclick.com", "jobs.apple.com", "www.reed.co.uk", "www.careerjet.co.uk", "www.reed.co.uk", "www.cs.mcgill.ca", "www.reed.co.uk", "jobs.apple.com", "www.ziprecruiter.com", "www.flexjobs.com", "www.reed.co.uk", "jobs.apple.com", "www.reed.co.uk", "www.reed.co.uk", "www.ziprecruiter.com", "www.flexjobs.com", "www.bizcommunity.com", "www.ziprecruiter.com", "www.flexjobs.com", "www.computerworld.dk", "www.efinancialcareers.com", "www.arkansasbusiness.com", "www.computerworld.dk", "jobs.apple.com", "jobs.apple.com", "www.reed.co.uk", "jobs.apple.com", "technical.ly", "www.reed.co.uk", "www.computerworld.co.nz", "www.indeed.co.uk", "jobs.apple.com", "jobs.apple.com", "www.reed.co.uk", "www.flexjobs.com", "www.ziprecruiter.com", "jobs.apple.com", "www.reed.co.uk", "jobs.apple.com", "technical.ly", "jobs.apple.com", "www.reed.co.uk", "www.reed.co.uk", "www.ziprecruiter.com", "www.flexjobs.com", "www.flexjobs.com", "jobs.apple.com", "www.reed.co.uk", "www.smartrecruiters.com", "jobs.apple.com", "jobs.apple.com", "www.zynga.com", "www.infomine.com", "www.jobbnorge.no", "www.reed.co.uk", "jobs.apple.com", "jobs.apple.com", "jobs.apple.com", "jobs.apple.com", "www.gettinghired.com", "www.reed.co.uk", "www.bizcommunity.com", "www.henkel.com", "jobs.apple.com", "jobs.apple.com", "www.reed.co.uk", "www.reed.co.uk", "www.careerjet.co.uk", "technical.ly", "www.reed.co.uk", "jobs.apple.com", "www.indeed.co.uk", "technical.ly", "www.avjobs.com", "jobs.apple.com", "www.ziprecruiter.com", "www.totaljobs.com", "www.careerjet.co.uk", "www.reed.co.uk", "www.ziprecruiter.com", "www.gettinghired.com", "www.reed.co.uk", "www.entertainmentcareers.net", "www.flexjobs.com", "www.ziprecruiter.com", "jobs.apple.com", "jobs.apple.com", "jobs.apple.com", "jobs.apple.com", "www.gettinghired.com", "www.reed.co.uk", "www.flexjobs.com", "jobs.apple.com", "www.flexjobs.com", "www.flexjobs.com", "jobs.apple.com", "www.indeed.co.uk", "www.axa.com", "www.bizcommunity.com", "www.reed.co.uk", "www.ziprecruiter.com", "www.flexjobs.com", "www.reed.co.uk", "www.reed.co.uk", "www.reed.co.uk", "www.reed.co.uk", "www.totaljobs.com", "www.ziprecruiter.com", "www.guru.com", "www.reed.co.uk", "www.cgi.com", "www.flexjobs.com", "www.bizcommunity.com", "www.ziprecruiter.com", "www.reed.co.uk", "www.reed.co.uk", "jobs.apple.com", "www.computerworld.dk", "www.reed.co.uk", "www.ziprecruiter.com", "www.ziprecruiter.com", "www.jobbnorge.no", "jobs.apple.com", "jobs.apple.com", "jobs.apple.com", "jobs.apple.com", "www.reed.co.uk", "www.flexjobs.com", "www.computerworld.co.nz", "www.reed.co.uk", "www.reed.co.uk", "www.ziprecruiter.com", "jobs.apple.com", "www.ziprecruiter.com", "www.careerbliss.com", "ipa.co.uk", "www.reed.co.uk", "www.indeed.co.uk", "www.net-temps.com", "www.ziprecruiter.com", "www.reed.co.uk", "www.computerworld.dk", "www.bizcommunity.com", "www.flexjobs.com", "www.flexjobs.com", "www.builtincolorado.com", "jobs.newscientist.com", "jobs.theguardian.com", "jobs.lever.co", "www.clearancejobs.com", "www.builtincolorado.com", "www.clearancejobs.com", "www.clearancejobs.com", "jobs.lever.co", "www.builtinchicago.org", "www.clearancejobs.com", "jobs.theguardian.com", "www.builtinchicago.org", "jobs.theguardian.com", "jobs.lever.co", "www.builtinchicago.org", "jobs.lever.co", "www.builtinchicago.org", "www.builtinchicago.org", "www.clearancejobs.com", "www.cv-library.co.uk", "www.cambridgenetwork.co.uk", "moikrug.ru", "careers.insidehighered.com", "www.builtinchicago.org", "www.builtinchicago.org", "www.builtinchicago.org", "jobs.newscientist.com", "www.builtinchicago.org", "spb.hh.ru", "jobs.theguardian.com", "oilvoice.com", "www.builtincolorado.com", "jobs.theguardian.com", "www.cambridgenetwork.co.uk", "www.clearancejobs.com", "www.cv-library.co.uk", "www.pracuj.pl", "www.epmag.com", "boards.greenhouse.io", "boards.greenhouse.io", "spb.hh.ru", "jobs.theguardian.com", "jobs.theguardian.com", "www.clearancejobs.com", "jobs.newscientist.com", "krb-sjobs.brassring.com", "ca.indeed.com", "www.builtincolorado.com", "jobs.theguardian.com", "jobs.theguardian.com", "jobs.theguardian.com", "jobs.theguardian.com", "www.clearancejobs.com", "jobs.theguardian.com", "www.oilvoice.com", "www.builtinchicago.org", "jobs.theguardian.com", "www.thinkspain.com", "jobs.theguardian.com", "jobs.theguardian.com", "jobs.lever.co", "jobs.theguardian.com", "jobs.newscientist.com", "www.builtinchicago.org", "www.oilvoice.com", "www.myvisajobs.com", "jobs.newscientist.com", "www.builtinchicago.org", "jobs.newscientist.com", "www.builtinchicago.org", "www.builtinchicago.org", "www.clearancejobs.com", "www.careerjet.co.uk", "jobs.theguardian.com", "careers.insidehighered.com", "jobs.theguardian.com", "careers.homedepot.com", "jobs.newscientist.com", "www.clearancejobs.com", "jobs.newscientist.com", "jobs.theguardian.com", "www.oilvoice.com", "www.profesia.sk", "jobs.lever.co", "jobs.theguardian.com", "jobs.theguardian.com", "jobs.theguardian.com", "www.builtinchicago.org", "www.builtinchicago.org", "www.builtinchicago.org", "jobs.theguardian.com", "www.clearancejobs.com", "krb-sjobs.brassring.com", "www.level39.co", "www.builtinchicago.org", "jobs.newscientist.com", "jobs.theguardian.com", "jobs.theguardian.com", "www.cambridgenetwork.co.uk", "www.toptal.com", "www.builtincolorado.com", "www.analytictalent.datasciencecentral.com", "www.clearancejobs.com", "careers.insidehighered.com", "jobs.theguardian.com", "jobs.theguardian.com", "www.clearancejobs.com", "jobs.lever.co", "jobs.theguardian.com", "www.builtinchicago.org", "jobs.newscientist.com", "www.clearancejobs.com", "www.oilvoice.com", "jobs.lever.co", "jobs.newscientist.com", "www.builtinchicago.org", "careers.insidehighered.com", "www.builtinchicago.org", "www.clearancejobs.com", "jobs.lever.co", "www.oilvoice.com", "www.clearancejobs.com", "jobs.theguardian.com", "ca.indeed.com", "www.builtinchicago.org", "www.builtinchicago.org", "www.irishjobs.ie", "krb-sjobs.brassring.com", "jobs.theguardian.com", "careers.insidehighered.com", "www.jobserve.com", "boards.greenhouse.io", "www.clearancejobs.com", "www.clearancejobs.com", "www.cv-library.co.uk", "www.classifiedads.com", "diversityjobs.com", "www.builtinla.com", "www.parking-net.com", "jobs.seattletimes.com", "www.nuon.com", "jobs.telegraph.co.uk", "www.careerjet.co.uk", "www.aplitrak.com", "www.careerjet.co.uk", "www.cybercoders.com", "www.godubai.com", "careers.walmart.com", "www.careerjet.co.uk", "www.godubai.com", "www.builtinla.com", "electricenergyonline.com", "careers.neoris.com", "secure2.sophos.com", "www.builtincolorado.com", "jobs.telegraph.co.uk", "www.godubai.com", "illinoisjoblink.illinois.gov", "www.godubai.com", "www.topschooljobs.org", "illinoisjoblink.illinois.gov", "www.indeed.es", "illinoisjoblink.illinois.gov", "www.indeed.es", "www.godubai.com", "www.builtincolorado.com", "www.careerjet.co.uk", "www.builtinla.com", "www.classifiedads.com", "www.godubai.com", "secure2.sophos.com", "secure2.sophos.com", "www.classifiedads.com", "www.iamexpat.nl", "www.hipo.ro", "careers.walmart.com", "www.godubai.com", "www.godubai.com", "www.indeed.es", "www.classifiedads.com", "www.godubai.com", "www.aplitrak.com", "www.parking-net.com", "www.randstad.co.uk", "jobs.telegraph.co.uk", "www.connecticum.de", "www.startupjobs.cz", "www.godubai.com", "www.builtinla.com", "illinoisjoblink.illinois.gov", "ejob.bz", "www.parking-net.com", "www.godubai.com", "www.builtinla.com", "jobs.gamasutra.com", "electricenergyonline.com", "www.indeed.es", "www.indeed.es", "www.godubai.com", "www.randstad.co.uk", "illinoisjoblink.illinois.gov", "marketingevolution.theresumator.com", "www.builtincolorado.com", "www.careerjet.co.uk", "www.builtinla.com", "www.godubai.com", "illinoisjoblink.illinois.gov", "jobs.telegraph.co.uk", "www.builtinla.com", "www.godubai.com", "www.parking-net.com", "www.classifiedads.com", "www.iamexpat.nl", "www.godubai.com", "dasauge.de", "www.classifiedads.com", "careers.walmart.com", "www.xlstat.com", "www.godubai.com", "jobs.telegraph.co.uk", "www.iamexpat.nl", "www.classifiedads.com", "www.careerjet.co.uk", "www.careerjet.co.uk", "www.godubai.com", "jobs.telegraph.co.uk", "www.godubai.com", "careers.walmart.com", "www.godubai.com", "www.iamexpat.nl", "illinoisjoblink.illinois.gov", "www.indeed.es", "diversityjobs.com", "join.irdeto.com", "www.builtinla.com", "illinoisjoblink.illinois.gov", "www.godubai.com", "justjobs.com", "www.builtincolorado.com"]}}; }
plotInterface = buildViz(1000,
600,
null,
null,
false,
true,
false,
false,
true,
true,
false,
false,
true,
0.1,
false,
undefined,
undefined,
getDataAndInfo(),
true,
false,
null,
null,
null,
null,
true,
false,
true,
false,
null,
null,
0,
null,
null,
null,
false,
true,
true,
undefined,
null,
false,
false,
".3f",
".3f",
false,
-1,
true,
false,
true,
false,
false,
false,
true,
null,
null,
null,
false,
null,
undefined,
undefined,
undefined,
undefined,
undefined,
undefined,
undefined,
14,
0);


autocomplete(
    document.getElementById('searchInput'),
    plotInterface.data.map(x => x.term).sort(),
    plotInterface
);

</script>
